{"text":"Chapter 1: Speaking in Tongues\nLearning Objectives\n\u2022 Understand the defining characteristics of human language\n\u2022 Explore the concept of language families and their typology\n\u2022 Describe the research techniques employed by psycholinguists\nLanguage is the most human of all qualities. No human population has been found that doesn\u2019t have\nlanguage and uses it not just for communication but as an instrument of cultural identity and\ntransmission. Psycholinguistics is a discipline with roots in psychology and linguistics. It combines the\ntheories from both to develop a scientific understanding of language.\nGiven the centrality of language to human culture, its analysis and investigation goes back thousands of\nyears. The earliest formalization of a language was conducted almost 4000 years ago in Babylonia. As\nSumerian was considered a language of prestige, word lists of the language were created to help people\nlearn it as a foreign language. A similar position was help by Sanskrit in India. Around 1200 BCE, the\noral transmission of the Vedas became standardized in as people started to notice that the language was\nchanging over time (Staal, 1986). Strict rules were developed to preserve the oral scriptures which have\nsurvived to this day. Of the six canonical areas of knowledge considered necessary for the proper study\nof the Vedas, four dealt with language: \u015bik\u1e63\u0101 (phonetics and phonology), chandas (prosody), vy\u0101kara\u1e47a\n(grammar), and nirukta (etymology). This impetus towards standardization led to Ancient Indians\nanalyzing the language for its properties and linguistics as a science was born. The 6th century BCE\ngrammarian P\u0101\u1e47ini wrote the A\u1e63\u1e6d\u0101dhy\u0101y\u012b, a grammatical treatise on Sanskrit. The sounds of Sanskrit\nwere organized into units based on place and manner of articulation (which we will discuss further in\nChapter 2). These ideas influenced an interest in what appears to be early psycholinguistics in the form\nof the Spho\u1e6da school of linguistics. This school dealt with investigating how linguistic units are\norganized in the mind and produced as speech (we will visit this issue later in Chapter 9). At the same\ntime, another school of linguistics was emerging in South India on India\u2019s other classical language:\nTamil. The Tolk\u0101ppiyam was written in the turn of the first millennium by an author known only as\nTolk\u0101ppiyar (he who wrote the Tolk\u0101ppiyam). This adapted the ideas from Sanskrit grammarians to an\nunrelated language.\nAt the same time, the Ancient Greeks were engaged in discussion about the origins of language. In\nCratylus, Plato presents the idea that the meaning of words emerges from a natural process. His student\nAristotle delved further into rhetoric and poetry as well as looking at language in terms of its\npossibilities for defining logic. The 4th century Roman grammarian Aelius Donatus compiled the Latin\n3 4 Chapter 1: Speaking in Tongues\ngrammar Ars Grammatica which dominated linguistic thought in the Middle Ages. Indeed we still use\nhis ideas for studying most European languages.\nThe Chinese were no less interested in linguistics or Xiaoxue (\u5c0f\u5b78). They divided their attention\nbetween three branches of knowledge: exegesis (Xungu, \u8a13\u8a41), analysis of writing (Wenzi, \u6587\u5b57), and\nphonology (Yinyun, \u97f3\u97fb). The first glossary of word from the 3rd century BCE was Erya. Confucius\nwas particularly concerned with the relationship between names and reality. In the Analects\n(12.11,13.3) he considers moral and social collapse as a result of people not acting according their\nnamed roles. Similar efforts can be seen in the Middle East with scholars attempting to standardize the\ndescription of Classical Arabic in the 8th century. Perhaps the most important injection of life to the\nfield of linguistics was Sir William Jones\u2019 1786 book The Sanscrit Language [sic]. Jones proposed that\nSanskrit and Persian resembled Classcial Greek and Latin starting off the field of comparative\nlinguistics. Analyzing the sound rules that led to the divergence of these languages from a common\nancestor has been a vibrant field within linguistics ever since.\nAlthough linguistics has a venerable history across the world, psycholinguistics itself has a relatively\nrecent history. Francis Galton studied word association as early as 1879 and Meringer and Mayer\n(1895) studied slips of the tongue which Freud (1901\/1975) tried to analyse with his theory of\npsychodynamics.\nThe modern field of linguistics can be traced to a 1951 conference held at Cornell University, USA. In\ndescribing the conference, Osgood and Sebeok\u2019s (1954) were the first to use the word\n\u201cpsycholinguistics.\u201d During this time, the dominant paradigm in psychology was behaviourism.\nPsychologists following the behaviourist tradition considered observable phenomena such as input\n(stimuli) and output (response) to be the only things that need be investigated within psychology as a\nscience. How the input was cogitated in the mind was considered too esoteric for scientific analysis\nbecause these processes were not measurable. As language was a type of behaviour, its acquisition and\nuse were explained in behaviourist terms such as reinforcement and conditioning as explained in\nSkinner\u2019s famous book Verbal Behaviour. Chomsky\u2019s (1959) scathing review of Skinner\u2019s book led to\na revolution (of the cognitive variety) by discussing how Skinner\u2019s explanations for language\nacquisition and use fell short of empirical evidence and couldn\u2019t explain natural language. He argued\nfor a new theory call transformation grammar to account for how underlying cognitive structure can\naccount for people\u2019s intuitive grasp of language production and comprehension. The field of\npsycholinguistics was abloom with the rarified perfume of new ideas attempting to find empirical\nevidence for this new theory. This exploration continues to this day as we also delve into this field to\nexplore language. 1.1 Language Change\nConsider the following poems:\nPoem A\nHw\u00e6t. We Gardena in geardagum,\n\u00feeodcyninga, \u00ferym gefrunon,\nhu \u00f0a \u00e6\u00feelingas ellen fremedon.\nPoem B\nWhan that Aprille with his shoures soote,\nThe droghte of March hath perced to the roote,\nAnd bathed every veyne in swich lic\u00f3ur\nOf which vert\u00fa engendred is the flour.\nPoem C\nShall I compare thee to a summer\u2019s day?\nThou art more lovely and more temperate:\nRough winds do shake the darling buds of May,\nAnd summer\u2019s lease hath all too short a date;\nYou may be familiar with poem c as a famous sonnet by Shakespeare. Some of the words, such as thee,\nmay be a little odd, but you can understand it. Poem b may be a little more difficult to understand; but\nyou may see some familiar words there. Try saying it out loud and you will hear even more familiar\nwords from this beginning of Chaucer\u2019s Canterbury Tales. Poem a (the beginning of Beowulf) would\nbe unintelligible to a modern English speaker and sounds more like German. However, this is also\nEnglish (of Old English) connected to us through a long line of speakers going back to the 7th century.\nThis shows us that languages change over time and may even change so much as to become different\nlanguages. Depending on how we count them, there are about 5000-6000 languages in the world. As\nlanguages change, is it possible that there were once fewer languages that then diverged into many over\ntime? We do notice the apparent similarities between languages when we hear familiar words. As you\ncan see in Figure 1.1, the word mother is quite similar in many European languages such as English\n5 6 Chapter 1: Speaking in Tongues\n(mother), Dutch (moeder) and Spanish (madre) but different from Turkish, Finnish and Hungarian. We\ncan also see similarities with far flung languages such as Sanskrit (Mata) and Persian (m\u00e2dar).\nFigure 1.1 The word \u2018Mother\u2019 in European Languages\nDetailed analysis of words and other linguistic elements across different languages has shown that most\nlanguages in Europe, West and South Asia derive from a common ancestor called proto-Indo-\nEuropean (or PIE). Analyzing the common words found in theses languages, scholars have tried to\ndetermine the common elements of this ancient culture. For examples, proto-Indo-Europeans must have\nhad horses, sheep and chariots as they share these words while they do not have common words for\npalm trees and vine. There are some languages in Europe which are not descended from PIE including\nBasque (a language isolate not related to any other language), Finnish, Hungarian and Estonian.\nMedia Attributions\n\u2022 Figure 1.1 The word \u2018Mother\u2019 in European Languages is an edited version of the European\nMap by TouN, is licensed under a CC BY-SA 4.0 licence. 1.2 Language Families\nIndo-European consists of a large number of languages spread across the world. As seen in Figure 1.2,\nthese can be broadly grouped into smaller families within the larger language family of PIE. We have\nEnglish and its closest cousins German, Dutch, Swedish, Norwegian, and Frisian grouped into the\nGermanic language family. Languages that descend from Latin such as Italian, Spanish, French and\nRomanian get classified as Romance languages. Russian, Polish, Czech, Slovak and Macedonian get\nclassified as Slavic languages. A broad ribbon of related languages spread from Eastern Turkey to India\nand Sri Lanka known as Indo-Iranian languages. These consist of languages descended from Ancient\nPersian including Modern Persian, Pashto and Kurdish and those descended from Vedic Sanskrit\nincluding Hindi, Urdu, Marathi, Bengali, Punjabi (in India), Sinhalese (in Sri Lanka) and Dhivehi (in\nMaldives). Some languages such as Greek, Albanian and Arminian remain isolated on their own within\nthe larger Indo-European language family.\nFigure 1.2 Proto-Indo-European Language Groups\nAs we have already seen, Indo-European is not the only language family found in Europe. Finnish,\n7 8 Chapter 1: Speaking in Tongues\nHungarian and Estonian fall within the Finno-Ugric language family. Some other language families\ninclude Afro-Asiatic (including languages spoken in North Africa and the Arabian Peninsula),\nDravidian (spoken in Southern India as well as parts of Sri Lanka and Pakistan), Sino-Tibetan, as well\nas the plethora of language families in North America.\nWhen talking about the Indigenous languages of North America, it is often the case that we confuse\nculture, tribe and language. As seen in Figure 1.3, Canada consists of six Indigenous cultural regions\nwhich codify the climate, outlook, and way of life of the people in them. If you compare Figure 1.3\nwith Figure 1.4, you will see that cultural regions do not necessarily overlap with language families. It\nis possible for Indigenous peoples of the same cultural region to speak very different languages.\nFigure 1.3 Cultural Regions of North America 1.2 Language Families 9\nFigure 1.4 Language Families of North America\nAs seen in Figure 1.4, there are 11 North American language families with 53 separate languages in\nCanada. This is a fraction of the over 296 languages belonging to 29 language families spoken north of\nMexico. These languages and language families are as distinct from each other as the languages of\nEurope and Asia. This means we need to understand these languages with the same lens of diversity\ninstead of grouping them under the category of Indigenous languages. The main legal categorization of\nthese communities is under First Nation, Inuit and M\u00e9tis consisting of 634 communities. These terms\nare continuously evolving and the term \u2018First Nation\u2019 itself consists of five sub-categories: Non-status,\nstatus treaty, status non-treaty, status Bill C-3 and status Bill C-31. These legal distinctions can overlap\nwith cultural and linguistic boundaries.\nIndigenous Languages of Canada\nAn interactive H5P element has been excluded from this version of the text. You can view it online here:\nhttps:\/\/opentextbc.ca\/psyclanguage\/?p=1181#h5p-14 10 Chapter 1: Speaking in Tongues\n\u2022 Colour pink \u2013 Haida \u2022 Colour gray: Salishan Languages\n\u25e6 Haida (a language isolate) \u25e6 Secwepemc\n\u2022 Colour purple: Wakashan Languages \u25e6 Bella Coola\n\u25e6 Haisla \u25e6 Coast Salish\n\u25e6 Kwak\u2019wala \u2022 Colour light orange: Kutenai\n\u25e6 Heiltsuk-Oowekyala \u25e6 Kutenai (a language isolate)\n\u25e6 Nuu-chah-nulth \u2022 Colour green: Siouan-Catawban Languages\n\u25e6 Nitinaht \u25e6 Stoney\n\u2022 Colour light blue: Na-Dene Languages \u25e6 Assinicoine\n\u25e6 Athabaskan languages \u2022 Colour yellow: Eskaleut Languages\n\u25e6 Eyak \u25e6 Aleut\n\u25e6 Tlingit languages \u25e6 Yupik\n\u25e6 Inuit 1.2 Language Families 11\n\u2022 Colour dark orange: \u2022 Colour dark blue: Iroquoian Languages\n\u25e6 Algic Languages \u25e6 Huron\n\u25e6 Algonquian languages \u25e6 Laurentian\n\u25e6 Cree \u25e6 Neutral Huron\n\u2022 Colour red: Iroquoian Languages\n\u25e6 Huron\n\u25e6 Laurentian\n\u25e6 Neutral Huron\nNavigate to the above link to view the interactive version of this map.\nMedia Attributions\n\u2022 Figure 1.2 Proto-Indo-European Language Groups by Hayden120 is licensed under a CC BY-\nSA 3.0 licence.\n\u2022 Figure 1.3 Cultural Regions of North America by Nikater is in the Public Domain.\n\u2022 Figure 1.4 Language Families of North America by Nicolas Eynaud is licensed under a CC\nBY-SA 4.0 licence.  1.3 Research Methods in Psycholinguistics\nPsycholinguistics employs a number of ways understand language. These range from observational\nstudies, speech error analysis to experiments and neuroimaging techniques. We also use computational\nmodels to simulate our theories about the language system. This section will explore some of the\ntechniques employed by researchers. However, keep in mind that we are always developing new\ntechniques to understand how language works.\nMental Chronometry\nThe study of reaction time on cognitive tasks is a common psychological paradigm in trying to infer the\nduration, sequence and content of cognition. As seen in Figure 1.5, reaction time (or RT) is measured\nas the time between the onset of a stimuli and the response by the participant. The mean and the\nvariance of reaction times are considered useful indices on processing speed. The most common form\nof reaction time experiments are button presses. However, eye movements and voice onset (in\nrepetition and reading tasks) can also be employed.\nFigure 1.5 Reaction Time Experiment [Image description]\n13 14 Chapter 1: Speaking in Tongues\nOne of the most popular reaction time paradigms is called priming. Priming is used in almost all areas\nof psychology. The basic idea is that if two things share some cognitive or psychological attribute, they\nwill either facilitate or interfere with each other. However, it they do not share such similarities, there\nwill be no such effect. For example, it is easier to recognize the word DOG if you have already seen the\nword CAT. This can be a kind of sematic priming in that both words belong to the same semantic\ncategory (ANIMAL). Such an effect is known as facilitation while the interference of slowing down of\nsuch an effect if known as interference.\nFigure 1.6 A Model Priming Web\nAs seen in Figure 1.6, the reasoning behind priming effects can be modelled as a web of interconnected\nideas or concepts in the mind. Concepts that are connected semantically (dogs and frogs are both\nanimals) or phonologically (dog and bog end with similar sounds) are more likely to facilitate priming.\nIn Figure 1.6, sematic connections are indicated with straight lines while phonological connects are\nindicated with dotted lines. The idea is that encountering a stimulus (by seeing or hearing it) will not\nonly activate that concept in the mind but also partially activate connected concepts to some degree. As\nsuch, when any one of those connected concepts is presented next, they will be retrieved quicker\nbecause they have already been partially activated (or primed) by the previous activation.\nLesion Studies\nAs the brain is a vulnerable organ, it can be damaged by external or internal trauma. If blood flow and\noxygen supply is constricted even for a few minutes to neurons they begin to die. These sites of\ndamage are called lesions. Such trauma can be from accidents, strokes, brain surgery, or the ingestion\nof certain toxins. Examining these lesions and associating them with the behavioural limitations of such\npatients can provide valuable information about which regions are responsible for which behaviour.\nCognitive Neuropsychology has contributed to psycholinguistics from the earliest times. Perhaps the\nearliest record of this is from case 20 in the Edwin Smith Papyrus. It is the report of a patient with a 1.3 Research Methods in Psycholinguistics 15\nhead injury which led to the following observation: \u201c\u2026He is speechless. An ailment not to be cured.\u201d\nA clear case of speech loss due to brain injury. Centuries later, Broca and Wernicke continue with such\nobservation and we will discuss them in Chapter 4. Cognitive neuropsychology attempts to relate brain-\ndamaged behavioural deficits to models of normal processing. Shallice (1988) overserved that\ncognitive neuropsychology has made significant advances in associating neurological disorders to\ncognitive model, emphasized the importance of single case studies over group studies, and contributed\nto the exploration of impaired brain behaviour as a way towards understanding unimpaired behaviour.\nWhile traditional lesion studies were conducted by post-mortem examination and backtracking to\nanalyse the behaviour of the patient while alive, modern neuroimaging techniques allow us to examine\nlesions in patients while they are alive and conduct behavioural analysis in real time.\nElectroencephalography (EEG)\nThe advent of neuroimaging techniques has led to a flowering of new research in psycholinguistics.\nWhile traditional X-rays are not able to provide much detail on the brain, other technology such as the\nmeasurement of electrical activity in the brain have provided valuable data. Such techniques include\nelectroencephalography or EEG which measures the brain\u2019s electrical activity by detecting them from\nelectrodes placed on the scalp. An amplifier can then amplify the millivoltage differences across the\nscalp and provide a continuous reading of brain activity.\nPsychologists go even further and measure such electrical activity by tying them to specific events\n(such as the presentation of a stimulus). Such event-related potential or ERPs can have positive or\nnegative polarities. These peaks in ERP readings are labelled according to their polarity (positive or\nnegative) and the time difference from the stimuli onset (in milliseconds). Some common ERPs include\nN400 (detected 400ms after stimulus onset as a negative voltage) and P300 (detected 600ms after\nstimulus onset as a positive voltage). As EEG and ERP are measuring electrical activity, they detect\nchanges in the brain almost instantly. We can say they have very good temporal resolution. However, as\nthey are detecting this electrical potential from the scalp, the signals that are detected tend to be an\naveraged out one from multiple brain regions and neurons. Therefore, it is not always possible to\npinpoint which brain region was actually involved in a particular EEG or ERP signal. In other words,\nthese techniques have poor spatial resolution. Other techniques such as PET and MRI have been\ndeveloped as a way to increase the spatial resolution of neuroimaging. 16 Chapter 1: Speaking in Tongues\nPositron Emission Tomography (PET)\nPET (positron emission tomography) uses radioactive substances as tracers to produce images of brain\nactivity. As the brain consumes a large amount of energy, injecting glucose into the body ensures that\nmost of it ends up in brain regions that are active in a cognitive task. If the glucose contains isotopes\nthat are radioactive, their emissions can be detected and transformed into images.\nFigure 1.7 Positron Emission Tomography Schema [Image description] 1.3 Research Methods in Psycholinguistics 17\nPET is employed both as a medical and research tool. As seen in Figure 1.8, a short-lived radioactive\nisotope is injected into the participant. The most commonly used is F-18 labeled fluorodeoxyglucose\n(FDG). After a waiting period for the active molecule to become concentrated in the brain tissue (one\nhour for FDG), the participant is placed inside the scanner. As the tracer decays, its emissions are\ncollected by the scanner. The scanner depends on detecting a pair of photons moving in opposite\ndirections. Photons that do not have a temporal pair are ignored. Computational reconstruction uses\nstatistical analysis and error correction to produce images such as Figure 1.8 which shows a scan of an\nunimpaired participant.\nFigure 1.8 A PET Scan of an Unimpaired Brain\nAs you can imagine, the main issue with PET is the injection of radioactive material into the body.\nVarious jurisdictions set standards on the maximum amount of radiation that a person can be exposed to\nin a year. This means that the same participant can only take part in a small number of PET scans\nwhich limits the amount of data collection possible in psychological studies. Another factor is the\nexpense of PET scanners and the radioactive tracers.\nFunctional Magnetic Resonance Imaging (fMRI)\nAn alternative to PET that doesn\u2019t use radioactive substances is Magnetic Resonance Imaging (MRI).\nThis employed powerful electromagnets to affect hydrogen atoms. Hydrogen atoms are abundant in\nhumans as water and fat. The atomic nuclei of hydrogen atoms are able to absorb radio frequency\nenergy when placed in a magnetic field. The resulting spin polarization can produce a radio frequency\nsignal that can be detected and analyzed. Varying the parameters of the radio pulse sequence can\nproduce different contrasts between brain tissues based on the properties of their constituent hydrogen\natoms. Computational processing of the signals can produce a highly detailed 3D image of the brain.\nHowever, this is a static image of the tissues without any indication of brain activity.\nRecently, fMRI (functional magnetic resonance imaging) has come to the forefront as a way to overlap 18 Chapter 1: Speaking in Tongues\nMRI scans with images of brain activity. This measures the energy released by hemoglobin in the\nblood. It is assumed that the areas of the brain that are most active would be the most likely to take in\nmore blood (for energy). Therefore, the measurement of blood flow with different brain regions can\nindirectly show us a measure of their activation during particular cognitive tasks. This type of scan\nprovides a better temporal and spatial resolution than PET. However, as there is a 1-5 second lag\nbetween brain activation and detection, the temporal resolution of fMRI is inferior to EEG.\nFigure 1.9 fMRI Activation in an Emotional Stroop Task [Image description]\nComparing Brain Imaging Technology\nNeuroimaging is at the forefront of psycholinguistic research into language processing in the brain.\nThey can tell us about the time course of various cognitive processes and the extent to which mental\nprocesses interact with each other. However, these techniques are still quite expensive and vary in\nterms of their temporal and spatial resolutions. As can be seen in Figure 1.10, different techniques vary\nin terms of how accurately they measure timing and active brain regions. EEG can detect brain activity\nwith high temporal resolution but cannot tell us exactly where they originated. As signals are all\ndetected on the surface of the head, we cannot be sure whether they originated in the cortex or areas\ndeeper inside the brain. On the other hand, PET and fMRI are quite good at providing spatial\ninformation. However, as they rely on the flow of fluids (blood), there is a temporal lag between when\na brain region become active and when the signal is detected by the scanner.\nMethodological limitations also exist as most of these techniques require the participant to be still 1.3 Research Methods in Psycholinguistics 19\nduring the scan. This limits the ability to study overt speech or other movement. In addition, the use of\npowerful magnets in fMRI means that participants with any metal implants cannot take part in such\nstudies (the metal would fly out of their body towards the scanner).\nFigure 1.10 Comparing Brain Imaging Techniques [Image description]\nA more serious limitation of any neuroimaging technique is the difficulty in interpreting the results.\nHow do we know what is causing a particular activity? We can see when or where something is\nhappening, but not necessarily how. Observing neural activity is not the same as observing mental\nactivity. Some studies often average out the results from multiple participants. How can we be sure that\nall of them are using the same brain regions for similar activities? However, even with such limitations,\nthese methods have opened us to a wide range of insights into the neurological basis of language. As\nnew methods are developed, we may even see these methods employed regularly for research and\nrehabilitation.\nImage descriptions\nFigure 1.5 Reaction Time Experiment\nA diagram showing the process of testing someone\u2019s reaction time to seeing a number on a computer\nscreen and pressing the number on their keyboard:\n1. Stimuli: The number 3 appears on the computer screen. The timer starts.\n2. Sensory: The eyes see the number 3.\n3. Cortical: The stimuli is processed by the brain.\n4. Motor: The brain tells the hand to press the number 3 on the keyboard.\n[Return to the place in text (Figure 1.5)] 20 Chapter 1: Speaking in Tongues\nFigure 1.7 Positron Emission Tomography Schema\nFunction of a PET machine. A scanner detects the emissions of the short-lived radioactive isotope in\nthe brain of the subject, transmits this information to a Coincidence Processing Unit, which is\nsubsequently used to reconstruct an image of the subject\u2019s brain activity.\n[Return to place in the text (Figure 1.7)]\nFigure 1.9 fMRI Activation in an Emotional Stroop Task\nfMRI scans of six brains. The first three images display the brain\u2019s response to expressions, while the\nlast three illustrate the brain\u2019s response to words. Coloured marks from red to yellow are used to\nqualitatively assess the strength of the brain\u2019s response, in addition to the location of brain activity.\n[Return to place in the text (Figure 1.9)]\nFigure 1.10 Comparing Brain Imaging Techniques\nA labeled, three-dimensional graph comparing the several brain imaging techniques on the axes of\nTemporal Resolution, Portability, and Spatial Resolution.\nWhole brain imaging techniques listed by spatial resolution from low to high:\n\u2022 Surface EEG: low spatial resolution, medium portability, high temporal resolution\n\u2022 MEG: low spatial resolution, high portability, high temporal resolution\n\u2022 PET: low spatial resolution, low portability, low temporal resolution\n\u2022 fNIRS: low spatial resolution, high portability, medium temporal resolution\n\u2022 fMRI: low spatial resolution, low portability, medium temporal resolution\n\u2022 Functional Ultrasound\nLocal brain imaging techniques listed by spatial resolution from low to high:\n\u2022 Optical imaging: high spatial resolution, high portability, high temporal resolution\n\u2022 Implanted EEG: high spatial resolution, high portability, high temporal resolution\n[Return to place in the text (Figure 1.10)]\nMedia Attributions\n\u2022 Figure 1.5 Reaction Time Experiment by Emily Willoughby is licensed under a CC BY-SA\n4.0 licence.\n\u2022 Figure 1.6 A Model Priming Web by Noahrob is licensed under a CC BY-SA 4.0 licence.\n\u2022 Figure 1.7 Positron Emission Tomography Schema by Jens Maus is in the Public Domain.\n\u2022 Figure 1.8 A PET Scan of an Unimpaired Brain by the US National Institute on Aging,\nAlzheimer\u2019s Disease Education and Referral Center is in the Public Domain. 1.3 Research Methods in Psycholinguistics 21\n\u2022 Figure 1.9 fMRI Activation in an Emotional Stroop Task by Shima Ovaysikia, Khalid A.\nTahir, Jason L. Chan and Joseph F. X. DeSouza is licensed under a CC BY 2.5 licence.\n\u2022 Figure 1.10 Comparing Brain Imaging Techniques by Thomas Deffieux, Charlie Demene,\nMathieu Pernot, Mickael Tanter is licensed under a CC BY 4.0 licence.  1.4 Themes and Variations\nLanguage is a multifaceted attribute of humanity. Indeed, while we consider language in terms of\nspeech, most of our use of language is in the form of an internal monologue within our own minds. In\naddition, sign language is also as much a of a language as spoken language. Sign language is not just a\nset of gestures any more than spoken language is just a set of sounds. The way in which the sounds are\norganised, how they fit together to form words and meaning as well as the order of the words in an\nutterance are all amazingly complex subjects that we will touch upon in this book.\nWe also need to contend with language in its visual form. The written word allows us not just to\ncommunicate as usual (across space) but also across time. I can understand (or at least try to\nunderstand) what a poet or scholar was thinking thousands of years ago by reading what they wrote.\nThis power to record language allows us to transcend the limitations of nature and transmit our ideas\nthrough the generations independent of biological constraints.\nLiving Language\n1. Make a list of the many ways in which you use language in daily life.\n2. Imagine how you might accomplish these tasks if language was not available to you.\n3. Consider how language may have helped us survive in our ancestral past.\nThis book will revolve around five overarching themes. First, we will try to immerse ourselves in the\nbasics of linguistic theories relevant to the exploration of psycholinguistics. Any understanding of the\ncognitive processes involved in language must first establish a thorough understanding of the linguistic\nideas that underpin its study. This theme will be divided across the various chapters but will mostly be\nfound in Chapter 2 and Chapter 3.\nThe second theme will explore the various processes involved in language processing and how they\ninteract. For example, does our ability to read influence how we speak? Does memory play a role in\nhow language comprehension and production occur?\nThe Third theme will be the exploration of the various theories and models that are employed by\npsychologists to understand language. For example, how do we understand language production? What\nare its stages? If we speak more than one language, does that mean we need to have separate\nmechanisms to process those languages or do they overlap? Do we use the same set of mechanisms to\nprocess words we know and novel words that we are learning? Models are a staple of the sciences,\nfrom the heliocentric model of the solar system to the various models of the atom. Psycholinguistics\nalso employs models to illustrate how different psychological processes interact to produce human\nbehaviour (in our case, language).\n23 24 Chapter 1: Speaking in Tongues\nFourth, we will explore what evidence exists to support these theories and model. Afterall, we can have\nan elegant model that explains some psychological process and while it may make sense to us, without\nevidence we have no idea whether it exists in the real world. Sometimes the model evolves from\nexisting data and sometimes the model precedes the evidence. For example, Copernicus proposed the\nheliocentric model for its elegance and simplicity but the real evidence to support the model didn\u2019t\narrive until much later with Kepler and Galileo Galilee. Similarly, psychologists may propose models\nthat appear to make sense and then modify them as the evidence appears from numerous studies. The\nevidence that we will look at will range from observational studies, experimental data, computational\nmodels and speech error analysis. This last type of evidence can come from the errors made in\neveryday speech (meticulously gathered over the years by tedious psycholinguists) or mistakes that\nappear in the speech of people who have suffered some impairment to their language system through\nbrain damage (such as a stroke). Analysing and combining these disparate sources of knowledge can\nyield fecund ground for new theories and models for psycholinguists.\nFinally, this book will explore how all of the preceding themes can be enriched by the inclusion of\ndiverse languages and particularly the Indigenous languages of Canada. Psycholinguistics has been\ndominated by the study of European languages as linguistics has its origins in the comparative studies\nbetween Western languages. Even though the recording and analysis of Indigenous languages was\nconducted in earnest by some linguists, this was always as a way to show the contrasts between these\nlanguages and the language of the colonizers. This is regrettable because the diversity of languages\nacross the world can provide us with new clues to how language and cognition work. For example, do\nthe languages we speak influence the way we think and behave? Analysing a small set of language with\nvery similar cultural and historical backgrounds (as is the case with the languages of Europe) may not\nallow us to answer such questions. By opening ourselves to the rich linguistic treasures that are spread\nacross Canada from English and French to the many languages of the First Nations, M\u00e9tis and Inuit\ncommunities, we can truly appreciate the possibilities of language as a human universal. Summary\nThis chapter introduced us to the subject of psycholinguistics and the major themes that pervade this\nbook. We explored the history of psycholinguistics and the classification of languages into language\nfamilies. We also saw the linguistic diversity that exists in Canada which presents us with new\nopportunities to explore the cognitive and linguistic possibilities of human language. We also\nconsidered some of the research techniques employed by psycholinguists to study language and their\nlimitations.\nKey Takeaways\n\u2022 Psycholinguistics is the scientific study if language based on psychology and linguistics.\n\u2022 Psycholinguistics has a long tradition in history but became a recognized field after the cognitive\nrevolution in the 1950s.\n\u2022 While the early study of language was mostly based on comparative linguistics with the\nclassification of language families, we have evolved to understand language as a common human\nattribute\n\u2022 Psycholinguists use a variety of research methods to explore language\nExercises in Critical Thinking\n1. What is the definition of language? What are its key characteristics?\n2. What are the differences between linguistics and psycholinguistics?\n3. What are some of the limitations that psycholinguists face in studying language?\n4. Can all the research techniques we discussed be used in all contexts?\n5. What are your thoughts on group studies versus individual case studies?\n6. What is the difference between cognitive neuropsychology and neuroscience?\n25  References\nChomsky, N. (1959). Review of \u201cVerbal behavior\u201d by B. F. Skinner. Language, 35, 26\u201358.\nFreud, S. (1901\/1975). The psychopathology of everyday life (Trans. A. Tyson). Harmondsworth, UK:\nPenguin.\nMeringer, R., & Mayer, K. (1895). Versprechen und Verlesen: Eine Pyschologisch-Linguistische Studie.\nStuttgart: G\u00f6ssen.\nOsgood, C. E., & Sebeok, T. A. (Eds.). (1954\/1965). Psycholinguistics: A survey of theory and research\nproblems. Bloomington: Indiana University Press.\nBod R. (2014). A new history of the humanities: The search for principles and patterns from antiquity\nto the present. Oxford University Press.\nShallice, T. (1988). From neuropsychology to mental structure. Cambridge: Cambridge University\nPress.\nStaal, J. F. (1986). The fidelity of oral tradition and the origins of science. North-Holland Publishing\nCompany.\n27  Chapter 2: The Sounds of Language\nLearning Objectives\n\u2022 Understand how sounds can be categorised based on how they are produced.\n\u2022 Explore how we produce the different sounds in our language\n\u2022 Describe the role of syllables and syllable structure in language\n\u2022 Explore the presence of phonological rules in various languages\nThis chapter is an introduction to various articulatory building blocks that make up human language:\nsounds and syllables. We will explore how we define the specific sounds of language and how we can\ndescribe them. You may encounter a lot of technical terminology and it may appear difficult at first to\nunderstand these terms. However, you will find it worthwhile as you will gain valuable insight into\nhow you speak. You will also find it easier to understand the rest of this book as the classification of\nsounds forms the basis for a lot of what we will be discussing later.\n29  2.1 Describing Sounds\nThe sounds we produce can be described in terms of their physical properties and in terms of how they\nare articulated. The acoustic details of speech sounds are studied as phonetics. The description of\nsounds in terms of how they are produced is known as phonology. Think about how to produce the \u2018t\u2019\nat the beginning of the word \u2018tin.\u2019 If you are native speaker of English, you will produce a small burst\nof air as you produce the \u2018t\u2019. This is not the case when you produce the \u2018t\u2019 in the word \u2018sit.\u2019 The \u2018t\u2019 in\n\u2018tin\u2019 is aspirated and the \u2018t\u2019 in \u2018sit\u2019 is unaspirated. Even if you produce the \u2018t\u2019 without aspiration, it\nmay sound odd but doesn\u2019t change the meaning of the word in English. We will call these different\nsounds phones. However, in some languages (such as Hindi), aspiration does change meaning.\nTherefore, in Hindi there is a distinction between unaspirated [b] in [b\u0251\u02d0lu\u02d0] \u2018sand\u2019 and aspirated [b\u02b0] in\n[b\u02b0\u0251\u02d0lu\u02d0] \u2018bear\u2019. As English doesn\u2019t differentiate between aspirated and unaspirated sounds, Mowgli\u2019s\nbear buddy in Rudyard Kipling\u2019s \u2018The Jungle Book\u2019 is simply called Baloo. Similarly, the \u2018gh\u2019 in\nBagheera is an aspirated [\u0261\u02b0] sound which is not pronounced as such in English. When we write out a\nphone in linguistics, we place them between two square brackets (as seen above).\nThe smallest sound unit in a language is known as a phoneme. In English, the aspirated and\nunaspirated \u2018t\u2019 sounds are both considered one phoneme as they are not distinguished by speakers of\nthat language. When such sounds occur without being differentiated by speakers of a languages, they\nare known as allophones. However, in Hindi the aspirated and unaspirated \u2018t\u2019 sounds are separate\nphonemes. When we write out phonemes in linguistics, we place them between two forward slashes.\nSo, a phonemic description of the word \u2018pin\u2019 would look like \/p\u026an\/, while a phonetic description would\nlook like [p\u02b0\u026an].\nIn order to discover all the phonemes in a language, we often employ minimal pairs. Two words that\ndiffer from each other in just one phoneme are know as minimal pairs. Consider \u2018kit\u2019 and \u2018kid\u2019.\nSubstituting \u2018t\u2019 for \u2018d\u2019 changes the meaning of the word, but changing [k\u026at] with [k\u026ath] would not.\nTherefore, \/t\/ and \/d\/ are phonemes in English and [t] and [th] are phones.\n31  2.2 The Articulatory System\nWe speak by moving parts of our vocal tract (See Figure 2.1). These include the lips, teeth, mouth,\ntongue and larynx. The larynx or voice box is the basis for all the sounds we produce. It modified the\nairflow to produce different frequencies of sound. By changing the shape of the vocal tract and airflow,\nwe are able to produce all the phonemes of spoken language. There are two basic categories of sound\nthat can be classified in terms of the way in which the flow of air through the vocal tract is modified.\nPhonemes that are produced without any obstruction to the flow of air are called vowels. Phonemes\nthat are produced with some kind of modification to the airflow are called consonants. Of course,\nnature is not as clear-cut as all that and we do make some sounds that are somewhere in between these\ntwo categories. These are called semivowels and are usually classified alongside consonants as they\nbehave similar to them.\nFigure 2.1 Parts of the Human Vocal Tract [Image description]\n33 34 Chapter 2: The Sounds of Language\nWhile vowels do not require any modifications to the airflow, the production of consonants requires it.\nThis obstruction is produced by bringing some parts of the vocal tract into contact. These places of\ncontact are known as places of articulation. As seen in Figure 2.2, there are a number of places of\narticulation for the lips, teeth, and tongue. Sometimes the articulators touch each other as in the case of\nthe two lips coming together to produce [b]. At other times, two articulators come into contact as when\nthe lower lip folds back into the upper teeth to produce [f]. The tongue can touch different parts of the\nvocal tract to produce a variety of consonants by touching the teeth, the alveolar ridge, hard palate or\nsoft palate (or velum).\nFigure 2.2 Places of Articulation [Image description]\nWhile these places of articulation are sufficient for describing how English phonemes are produced,\nother languages also make use of the glottis and epiglottis among other parts of the vocal tract. We will\nexplore these in more detail later.\nThe Vocal Tract\nAn interactive H5P element has been excluded from this version of the text. You can view it online here:\nhttps:\/\/opentextbc.ca\/psyclanguage\/?p=1203#h5p-15 2.2 The Articulatory System 35\nFill in the blanks with parts of vocal tract:\n\u2022 Hard palate \u2022 Glottis\n\u2022 Soft palate \u2022 Esophagus\n\u2022 Lips \u2022 Teeth\n\u2022 Tongue \u2022 Trachea\n\u2022 Epiglottis \u2022 Alveolar ridge\n\u2022 Nasal cavity \u2022 Vocal cords\n\u2022 Uvula\nTo check your answers, navigate to the above link to view the interactive version of this activity.\nPlaces of Articulation\nAn interactive H5P element has been excluded from this version of the text. You can view it online here:\nhttps:\/\/opentextbc.ca\/psyclanguage\/?p=1203#h5p-16 36 Chapter 2: The Sounds of Language\nFill in the blanks with places of articulation:\n\u2022 Alveolar \u2022 Glottal\n\u2022 Velar \u2022 Dental\n\u2022 Labial \u2022 Palatal\nTo check your answers, navigate to the above link to view the interactive version of this activity.\nImage description\nFigure 2.1 Parts of the Human Vocal Tract\nA labeled image of the anatomical components of the human vocal tract, including the nasal cavity,\nhard palate, soft palate or velum, alveolar ridge, lips, teeth, tongue, uvula, esophagus, trachea, and the\nparts of the larynx, which include the epiglottis, vocal cords, and glottis.\n[Return to place in the text (Figure 2.1)]\nFigure 2.2 Places of Articulation 2.2 The Articulatory System 37\nA labeled image illustrating the anatomical components of the human vocal tract that are involved in\nEnglish phonemes. These include the glottal, velar, palatal, dental, and labial structures.\n[Return to place in the text (Figure 2.2)]\nMedia Attributions\n\u2022 Figure 2.1 Parts of the Human Vocal Tract is an edited version of Mouth Anatomy by Patrick\nJ. Lynch, medical illustrator, is licensed under a CC BY 2.5 licence.\n\u2022 Figure 2.2 Places of Articulation is an edited version of Mouth Anatomy by Patrick J. Lynch,\nmedical illustrator, is licensed under a CC BY 2.5 licence.  2.3 Consonants\nConsonants, as we saw earlier, are produced with some obstruction to the airflow through the vocal\ntracts. This obstruction is created by brings a variety of articulators together which are called places of\narticulation. There can also be variation in how the airflow is controlled when travelling through the\nvocal tract and this is known as manner of articulation. For example, when we say [p], [t] or [k], the\nflow of air is stopped for a moment before being released. On the other hand, the flow of air is released\nwith some stricture when we produce [s], [f] or [\u0283] (the sound we write in English as \u2018sh\u2019). We call\nsounds that stop the flow of air for a moment stops or plosives. Sounds that are produced with some\nkind of frictions, such as [s] and [f], are called fricatives. When we also let the flow of air to travel\nthrough the nasal cavity, we produce nasal sounds such as [m] and [n]. Try holding your nostrils closed\nwith your fingers while saying \u2018ma\u2019. You will find it difficult to do so as the flow of air needs to travel\nthrough your nasal passage to produce it. There are other sounds we produce which bring the\narticulators together with some degree of approximation. These sounds are called approximants and\ninclude [l] and [w]. When two consonants are produced in close association as if they were one sound,\nwe call them affricates. English has two affricates which written in English as \u2018ch\u2019 and \u2018j\u2019. However,\nthe International Phonetic Alphabet or IPA transcribes them as [t\u0283] and [d\u0292]. This shows that the \u2018ch\u2019\nsound of \u2018chair\u2019 is produced by the combination of [t] and [\u0283]. Similarly, IPA uses [j] to refer to the\nsound written in English with \u2018y\u2019. The sound used to represent the \u2018j\u2019 sound of \u2018juice\u2019 is [d\u0292]. This\nshows that this affricate is produced with both [d] and [\u0292]. Another difference between consonants is\nwhether the vocal cords vibrate or not when they are produced. This called voicing and is seen in the\ndifference between the unvoiced [p] and the voiced [b].\n39 40 Chapter 2: The Sounds of Language\nTable 2.1 English Consonants1\nblank Place of Articulation\nManner of Articulation Labial Dental Alveolar Post-alveolar Palatal Velar Glottal\nm n \u014b\nNasal blank blank blank blank\n[audio] [audio] [audio]\np t k\nUnvoiced Stop blank blank blank blank\n[audio] [audio] [audio]\nb d g\nVoiced Stop blank blank blank blank\n[audio] [audio] [audio]\nt\u0283\nUnvoiced Affricate blank blank blank blank blank blank\n[audio]\nd\u0292\nVoiced Affricate blank blank blank blank blank blank\n[audio]\nf \u03b8 s \u0283 h\nUnvoiced Fricative blank blank\n[audio] [audio] [audio] [audio] [audio]\nv \u00f0 z \u0292\nVoiced Fricative blank blank blank\n[audio] [audio] [audio] [audio]\nl \u0279 j w\nApproximate blank blank blank\n[audio] [audio] [audio] [audio]\nTable 2.1 shows the full range of consonants found in English. The symbols used are from the IPA\nallowing us to describe and discuss these phonemes across different languages without confusion. Most\nof the symbols used will be familiar to those who write using the English alphabet though some will be\ndifferent. Let\u2019s explore this chart and see how we can describe these phonemes. Using the table given\nin Table 2.1 can classify [m] as a bilabial nasal meaning that it is produced with the two lips coming\ninto contact and the airflow directed through both the mouth and the nasal passage. [p] is an unvoiced\nbilabial stop. This means that it is produced with the two lips coming into contact with the airflow\nstopped briefly before release. When the airflow is released, the vocal cords do not vibrate (unvoiced).\n[b] on the other hand is produced with similar place and manner of articulation but with the vocal cords\nvibrating; so, it is called a voiced bilabial stop.\nTable 2.2 shows you examples of English words for each consonant. You can see the need for IPA\nsymbols as the English alphabet doesn\u2019t have separate graphemes for such phonemes. For example,\n\u2018thin\u2019 and \u2018this\u2019 both begin with a grapheme \u2018th\u2019 but are produced differently. The \u2018th\u2019 in \u2018thin\u2019 is an\nunvoiced dental fricative while the \u2018th\u2019 in \u2018this\u2019 is a voiced dental fricative. Similarly, we don\u2019t have a\ngrapheme to represent the voiced post-alveolar fricative seen in the \u2018s\u2019 of \u2018pleasure\u2019 and \u2018measure.\u2019 The\nvelar nasal is written with two letters \u2018ng\u2019 found in \u2018sing\u2019, \u2018ring\u2019 and \u2018walking.\u2019 Some dialects may\npronounce the \u2018g\u2019 while others may not.\n1. Listen to the audio clips at https:\/\/opentextbc.ca\/psyclanguage\/chapter\/consonants\/ 2.3 Consonants 41\nTable 2.2 English Consonants with Examples\n\u2022 \/p\/ pin \u2022 \/b\/ bin \u2022 \/m\/ map\n\u2022 \/t\/ tin \u2022 \/d\/ dog \u2022 \/n\/ nap\n\u2022 \/k\/ kin \u2022 \/g\/ gap \u2022 \/\u014b\/ sing\n\u2022 \/t\u0283\/ chin \u2022 \/d\u0292\/ jeep \u2022 \/j\/ yes\n\u2022 \/f\/ fin \u2022 \/v\/ vat \u2022 \/w\/ well\n\u2022 \/\u03b8\/ thin \u2022 \/\u00f0\/ this \u2022 \/\u0279\/ rose\n\u2022 \/s\/ sin \u2022 \/z\/ zap \u2022 \/l\/ lip\n\u2022 \/\u0283\/ shin \u2022 \/\u0292\/ pleasure \u2022 \/h\/ hip\nWe can compare English phonology to Table 2.3 where we see the arrangement of French consonants.\nWe see a lot of similarities with some variations. For example, French has a palatal nasal consonant\nwhich may be familiar to you as the \u00f1 in Spanish se\u00f1or. The velar nasal is not native to French but seen\nin loan words such as \u2018camping.\u2019\nSounds of English\nAn interactive H5P element has been excluded from this version of the text. You can view it\nonline here:\nhttps:\/\/opentextbc.ca\/psyclanguage\/?p=1205#h5p-17 42 Chapter 2: The Sounds of Language\nTable 2.3 French Consonants2\nblank Place of Articulation\nManner of Dental\/\nLabial Post-alveolar Palatal Velar Uvular\nArticulation Alveolar\nm n \u0272 (\u014b)\nNasal blank blank\n[audio] [audio] [audio] [audio]\nUnvoiced p t k\nblank blank blank\nStop [audio] [audio] [audio]\nb d g\nVoiced Stop blank blank blank\n[audio] [audio] [audio]\nUnvoiced f s \u0283\nblank blank blank\nFricative [audio] [audio] [audio]\nVoiced v z \u0292 \u0281\nblank blank\nFricative [audio] [audio] [audio] [audio]\nPlain l j \u0281\nblank blank blank\nApproximant [audio] [audio] [audio]\nLabial \u0265 w\nblank blank blank blank\nApproximant [audio] [audio]\nTable 2.4 and Table 2.5 show the phonology of languages found in other parts of Canada. Secwepemc\n(also known as Shuswap) is a language spoken in the Canadian province of British Columbia. It is the\nnorthernmost of the Interior Salish languages and is spoken by over 1600 people. We can see in Table\n2.4 a number of new sounds. In particular, we see glottalized phonemes (with a superscript symbol like\na questions mark) as well as rounded phonemes (with a superscript w). The glottal sounds are produced\nwith stricture of the glottis. Some dialects of British English produce this sound in the pronunciation of\nthe \u2018t\u2019 in \u2018bottle.\u2019\n2. Listen to the audio clips at https:\/\/opentextbc.ca\/psyclanguage\/chapter\/consonants\/ 2.3 Consonants 43\nTable 2.4 Secwepemc Consonants3\nblank Place of Articulation\nVelar\nManner of Palatal Palatal \u2013 Velar \u2013 Uvular Uvular \u2013 Laryngeal Laryngeal\nLabial Dental Alveolar \u2013\nArticulation \u2013 Plain Velarized Rounded \u2013 Plain Rounded \u2013 Plain \u2013 Rounded\nPlain\nm n blank blank blank blank blank blank blank blank blank\nNasal \u2013 Plain\n[audio] [audio]\nNasal \u2013 m\u02c0 n\u02c0 blank blank blank blank blank blank blank blank blank\nGlottalized\np t blank blank blank k k\u02b7 q q\u02b7 \u0295 \u0295\u02b7\nStop \u2013 Plain\n[audio] [audio] [audio] [audio] [audio]\nStop \u2013 p\u02c0 t\u026c\u02c0 blank blank blank k\u02c0 k\u02b7\u02c0 q\u02c0 q\u02b7\u02c0 \u0294 \u0295\u02b7\u02c0\nGlottalized [audio]\nAffricate \u2013 blank blank t\u0283 t\u0283 blank blank blank blank blank blank blank\nPlain [audio] [audio]\nAffricate \u2013 blank blank t\u0283\u02c0 t\u0283\u02c0 blank blank blank blank blank blank blank\nGlottalized\nblank \u026c blank \u0283 blank x x\u02b7 \u03c7 \u03c7\u02b7 h blank\nFricative\n[audio] [audio] [audio] [audio] [audio]\nApproximant blank blank l j \u0270 \u0270 blank blank blank blank w\n\u2013 Plain [audio] [audio] [audio] [audio] [audio]\nApproximant blank blank l\u02c0 j\u02c0 \u0270\u02c0 \u0270\u02c0 blank blank blank blank w\u02c0\n\u2013 Glottalized\nTable 2.5 shows the consonants of the Inuit languages. These languages are spoken by Indigenous\ncommunities in the northernmost parts of north America and parts of Greenland. We will talk more\nabout these languages in later discussions about their writing systems. As you can see these languages\nhave quite a lot of familiar consonants. We also see the uvular rhotic that is found in French along with\na uvular stop produced at the very back of the mouth. The consonants in parentheses are language\nspecific within the language family. The retroflex \/\u0282\/ and \/\u0290\/ appear only in Inupiatun. Retroflex\nconsonants are produced with the tongue rolled back to touch the hard palate. You will be familiar with\nthese consonants from their appearance in Indian languages. The unvoiced palatal fricative \/\u025f\/ appears\nonly in Natsilingmiutut having merged with \/j\/ in other languages. One other aspect of these languages\nis the lack of minimal pairs for voicing for most consonants. They only have unvoiced [p], [t] and [s]\nwith no contrast with voiced [b], [d] or [z]. There is a contrast between velar stops for unvoiced [k] and\nvoiced [\u0261].\n3. Listen to the audio clips at https:\/\/opentextbc.ca\/psyclanguage\/chapter\/consonants\/ 44 Chapter 2: The Sounds of Language\nTable 2.5 Inuit Consonants4\nblank Place of Articulation\nManner of Alveolar \u2013 Alveolar \u2013\nLabial Retroflex Palatal Velar Uvular\nArticulation Central Lateral\nm n \u014b\nNasal blank blank blank blank\n[audio] [audio] [audio]\nUnvoiced p t k q\nblank blank blank\nStop [audio] [audio] [audio] [audio]\ng\nVoiced Stop blank blank blank blank blank blank\n[audio]\nUnvoiced s (\u0282) (\u025f)\nblank blank blank blank\nFricative [audio] [audio] [audio]\nVoiced v (\u0290)\nblank blank blank blank blank\nFricative [audio] [audio]\nUnvoiced \u026c\nblank blank blank blank blank blank\nApproximant [audio]\nVoiced l j \u0281\nblank blank blank blank\nApproximant [audio] [audio] [audio]\nThe examples from these four languages shows us the diversity of consonants that is available in\nhuman languages. Not all languages need to have all these phonemes. As languages evolve and change,\nthere is a constant pull in two directions: economy of production (not wanting to take too much effort\nin producing a sound) versus distinctiveness (having enough distinct sounds to produce all the\ndifferences necessary for distinguishing words or minimal pairs). This competition exists in all\nlanguages from generation to generation and has resulted in the diversity we see in modern languages.\n4. Listen to the audio clips at https:\/\/opentextbc.ca\/psyclanguage\/chapter\/consonants\/ 2.4 Vowels\nVowels are produced without any obstruction to the articulatory tract (Ladefoged & Maddieson, 1996).\nUnlike consonants which result from the contact between articulators, vowels allow for a free flow of\nair. Therefore, we cannot define vowels in terms of place and manner of articulation. Rather, we define\nvowels in terms of the shape and position of the tongue. This means that while consonants in different\ndialects of a language remain relatively constant, vowels can differ widely. The defining terms for\nvowels are height, backness and roundness.\nHeight refers to the vertical position of the tongue. Try saying \u2018ee\u2019 and \u2018aa\u2019 repeatedly. You will notice\nyour tongue moving up and down. Therefore, we say that the vowel produced in saying \u2018ee\u2019 is a high\nvowel and that produced in saying \u2018aa\u2019 is a low vowel. Backness is based on the tongues horizontal\nposition and shape. This is can noticed in saying \u2018ee\u2019 and \u2018oo\u2019 where the latter makes the tongue go\nback. Roundness is not a property of the tongue but of the lips which you will notice in making sounds\nsuch as \u2018oo.\u2019 Table 2.6 shows you the vowels found in English.\nTable 2.6 Vowels of Canadian English1\nblank Front Central Back\ni u\nblank\n[audio] [audio]\nClose\n\u026a \u028a\nblank\n[audio] [audio]\ne (\u025c) o\n[audio] [audio] [audio]\nMid\n\u025b \u0259 (\u0254)\n[audio] [audio] [audio]\n\u0251\nblank blank\n[audio]\nOpen\n\u00e6 \u028c\nblank\n[audio] [audio]\nSome languages such as French and Hindi also have nasalized vowel. Consider beau \/bo\/ \u2018beautiful\u2019\nand bon \/b\u0254\u0303 \/ \u2018good\u2019 in French being minimal pairs in terms of nasalization of the vowel. When two\nvowels are combined within a syllable, they form diphthongs. These can be seen in words such as cow\n\/ka\u028a\/, pie \/pa\u026a\/, and boy \/b\u0254\u026a\/.\n1. Listen to the audio clips at https:\/\/opentextbc.ca\/psyclanguage\/chapter\/vowels\/\n45 46 Chapter 2: The Sounds of Language\nTable 2.7 Monophthongs2\nIPA Symbol Name Example\n\/\u00e6\/ Near-open front unrounded vowel trap [audio]\n\/\u0251\/ Open back unrounded vowel lot [audio]\n\/\u0254\/ \/\u0251\/ Open-mid back rounded vowel caught [audio]\n\/\u026a\/ Near-close front unrounded vowel bit [audio]\n\/i\/ Close front unrounded vowel geese [audio]\n\/\u0258\/ Close-mid central unrounded vowel about [audio]\n\/\u028c\/ Open-mid back unrounded vowel gut [audio]\n\/\u025b\/ Open-mid front unrounded vowel bet [audio]\n\/\u028a\/ Near-close near-back rounded vowel foot [audio]\n\/u\/ Close back rounded vowel moose [audio]\nTable 2.8 Diphthongs3\nIPA Symbol Example\n\/e\u026a\/ face [audio]\n\/o\u028a\/ goat [audio]\n\/a\u026a\/ nice [audio]\n\/\u0254\u026a\/ choice [audio]\n\/a\u028a\/ south [audio]\nWatch the video Diphthongs (3 minutes).\nOne or more interactive elements has been excluded from this version of the text. You can view them online here:\nhttps:\/\/opentextbc.ca\/psyclanguage\/?p=1207#oembed-1\nTable 2.7 and Table 2.8 show us the vowels found in most varieties of Canadian English with\nexamples. While consonants tend to be similar across dialects, vowels can vary greatly between\ndialects and countries. Therefore, you will find that the English spoken in the United Kingdom,\nAustralia and New Zealand will have very different vowels when producing the same words.\n2. Listen to the audio clips at https:\/\/opentextbc.ca\/psyclanguage\/chapter\/vowels\/\n3. Listen to the audio clips at https:\/\/opentextbc.ca\/psyclanguage\/chapter\/vowels\/ 2.4 Vowels 47\nMedia Attributions\n\u2022 2.8 Dipthongs video by Essentials of Linguistics is licensed under a CC BY 4.0 Licence.  2.5 Syllables\nWhile phonemes are the smallest units of sound, we don\u2019t actually speak in phonemes. If I say the word\n\u2018cat\u2019 \/k\u00e6t\/ and record it, I won\u2019t be able to break it into three units of \/k\/, \/\u00e6\/ and \/t\/. Therefore, the\nsmallest unit of articulation is not the phoneme but rather the syllable. Most native speakers of a\nlanguage will know how many syllables are in a word in their language. You can try this in English by\nsaying a word slowly. For example, the word \u2018elephant\u2019 has three syllables: e-li-phant. As seen in\nFigure 2.3, all syllables must have a mandatory nucleus or peak. This is usually a vowel. Some\nlanguages can also have a syllabic consonant as a nucleus of a syllable as in the English word \u2018button\u2019\n[b\u028ctn\u0329 ] where there are two syllables [b\u028c] and [tn\u0329 ]. You can see that the second syllable has no vowels\nbut a syllabic [n\u0329 ] as the nucleus.\nConsonants that come before the nucleus of a syllable are know as onsets and those that come after it\nare called codas. The nucleus and coda of a syllable form a group called a rime. These onsets and\ncodas can be complicated or simple depending on what is allowed in a language. English allows up to\nthree consonants in the onset and at least as much in the coda. Consider the word \u2018twelfths\u2019 \/tw\u025blf\u03b8s\/. It\nhas two consonants in the onset and four consonants in the coda. Generally, the onset is more restricted\nin what is consonants are allowed.\nFigure 2.3 Syllable Structure\nIn English, you can have almost all consonants other than the velar nasal \/\u014b\/ as an onset. If there are\ntwo consonants in the onset and the first one isn\u2019t \/s\/ then the second has to be either \/l\/, \/r\/, \/w\/, or \/j\/.\nif there are three consonants in the onset, then the first has to be an \/s\/, the second has to be either \/p\/,\n\/t\/ or \/k\/, and the third has to be either \/l\/, \/r\/ or \/w\/.\n49 50 Chapter 2: The Sounds of Language\nLiving Language\nConsider some words in your language and try to syllabify them. Think of what phonemes occur in the onset,\nnucleus and coda of these syllables. Can you come up with long onsets and codas in your language? Ask a\nfriend who speaks another language to do the same. Are there any differences between your languages\u2019\nsyllable structure?\nAs we saw earlier, what is allowed in the onset, nucleus and coda of a language can be different across\nlanguages. While a sequence such as \/pl\/ is allowed in English, \/ps\/ would not be allowed. However,\n\/ps\/ is a legal sequence in Greek which is why we still spell \u2018psychology\u2019 with the \u2018ps\u2019 sequence even\nthough English speakers don\u2019t pronounce the \u2018p\u2019. Similar examples of Greek onsets include \/mn\/ as in\n\u2018mnemonic\u2019. Figure 2.4 illustrates the syllable structure of the word Tk\u2019eml\u00faps \u2018Kamloops\u2019 in\nSecwepemc. As we can see, Secwepemc allows the sequence of an unvoiced dental stop and a\nglottalized velar stop \/tk\u02c0\/ in the onset of its syllable. The sequence \/ml\/ is not a legal onset in\nSecwepemc, so it gets separated between two syllables, the \/m\/ becoming the coda of the first syllable\nand the \/l\/ becoming the onset of the second.\nFigure 2.4 Syllable Structure of the word Tk\u2019eml\u00faps\nAs syllables are the smallest units of articulation, they provide the rhythmic patterns of a language. In\nlanguages such as English, syllables carry features such as stress. This determines which syllable in a\nword receives emphasis. Try saying \u2018I am recording a song.\u2019 You will stress the second syllable in the\nword \u2018recording.\u2019 Now say \u2018That was a record.\u2019 You will find yourself placing more stress on the first\nsyllable of the word \u2018record.\u2019 Languages that place equal time periods for stressed syllables are called\nstress-timed languages. English is a stress-timed language and we can see how this is employed in\nShakespeare\u2019s sonnets with iambic pentameters. Each line consists of five iambs and each iamb\nconsists of two syllables with the second one more stressed that the first. As we see in Figure 2.5, this 2.5 Syllables 51\ncreates a beautiful pattern of unstressed and stressed syllables that may even go across word\nboundaries. Read the sonnet out loud and you will notice the stress patterns.\nFigure 2.5 Stress Patterns in a Shakespearian Sonnet\nUnlike English, other languages may produce each syllable with equal time. These are called syllable-\ntimed languages. French is a good example of such a syllable-timed language. Poetry in syllable-timed\nlanguages will make less use of stress and will take into account what consonants appear in the coda of\nthe syllable to determine the structure of their poems.\nSyllables in Poetry (Shakespeare)\nAn interactive H5P element has been excluded from this version of the text. You can view it online here:\nhttps:\/\/opentextbc.ca\/psyclanguage\/?p=1212#h5p-18\nIdentify the two-syllable words in this poem.\nShall I compare thee to a summer\u2019s day?\nThou art more lovely and more temperate:\nRough winds do shake the darling buds of May,\nAnd summer\u2019s lease hath all too short a date;\nSometime too hot the eye of heaven shines,\nAnd often is his gold complexion dimm\u2019d;\nAnd every fair from fair sometime declines,\nBy chance or nature\u2019s changing course untrimm\u2019d;\nBut thy eternal summer shall not fade, 52 Chapter 2: The Sounds of Language\nNor lose possession of that fair thou ow\u2019st;\nNor shall death brag thou wander\u2019st in his shade,\nWhen in eternal lines to time thou grow\u2019st:\nSo long as men can breathe or eyes can see,\nSo long lives this, and this gives life to thee.\nTo check your answers, navigate to the above link to view the interactive version of this activity.\nSyllables in Poetry 2\nAn interactive H5P element has been excluded from this version of the text. You can view it online here:\nhttps:\/\/opentextbc.ca\/psyclanguage\/?p=1212#h5p-19\nIdentify the three-syllable words in this poem.\nOnce upon a midnight dreary, while I pondered, weak and weary,\nOver many a quaint and curious volume of forgotten lore\u2014\nWhile I nodded, nearly napping, suddenly there came a tapping,\nAs of some one gently rapping, rapping at my chamber door.\n\u201c\u2019Tis some visitor,\u201d I muttered, \u201ctapping at my chamber door\u2014\nOnly this and nothing more.\u201d\nAh, distinctly I remember it was in the bleak December;\nAnd each separate dying ember wrought its ghost upon the floor.\nEagerly I wished the morrow;\u2014vainly I had sought to borrow\nFrom my books surcease of sorrow\u2014sorrow for the lost Lenore\u2014\nFor the rare and radiant maiden whom the angels name Lenore\u2014\nNameless here for evermore.\nTo check your answers, navigate to the above link to view the interactive version of this activity.\nMedia Attributions\n\u2022 Figure 2.3 Syllable Structure by Dinesh Ramoo, the author, is licensed under a CC BY 4.0\nlicence. 2.5 Syllables 53\n\u2022 Figure 2.4 Syllable Structure of the word Tk\u2019eml\u00faps by Dinesh Ramoo, the author is licensed\nunder a CC BY 4.0 licence.\n\u2022 Figure 2.5 Stress Patterns in a Shakespearian Sonnet contains an edited version of The\nDroeshout portrait of William Shakespeare, and is a public domain work of art.  2.6 Phonological Rules\nWe learned about how English speakers will aspirate some phonemes. Is this a random act or can we\nfigure out a pattern in this type of production? When considered carefully, we can notice that we only\ndo it with \/p\/, \/t\/ and \/k\/. In addition, this only happens when these phonemes appear at the beginning of\na syllable. When linguists figure out such a pattern, they can formally write it as a phonological rule.\nGenerally, phonological rules map between two levels of representation: phonemes and phones\n(Goldsmith, 1995). Such rules define how we go from the abstract representation of phonemes in our\nmind to the actual articulation of phones. They start with an underlying representation (the string of\nphonemes) and produce a surface form (what is actually said).\nThe rule for aspiration in English could be stated as \u201cAll unvoiced stops will be aspirated when they\nappear as the onset of a syllable.\u201d Each language varies in how phonological rules are applied and in\nhat circumstances they appear. For example, Germans will devoice (remove the voicing) of an\nobstruent if it appears as the coda of a syllable. So, they may pronounce \u2018hund\u2019 as [h\u028ant] devoicing the\n[d] to a [t].\nLiving Language\nConsider how to pronounce the \/t\/ when it appears between two vowels as in \u2018butter\u2019 or \u2018notable.\u2019 You will\nnotice that most people in North America will not produce a hard [t] sound but a flap consonant [\u027e]. So \/b\u028ct\u025a\/\nbecomes [b\u028c\u027e\u025a] (the [\u025a] is a vowel with a rhotic or \u2018r\u2019 quality).\nWhat other examples can you think of in how you make systematic changes to phonemes when you speak?\n55  Summary\nIn this chapter, we learned about the basics of describing the sound forms of language. We saw that\nphonemes are the smallest units of sound and syllables are the smallest units of articulation in a\nlanguage. We also learned how to classify consonants and vowels based on how they are produced in\nthe vocal tract. Finally, we explored how these can be brought together to figure out recurring patterns\nin spoken language and formalized as phonological rules.\nKey Takeaways\n\u2022 Phonemes are the smallest units of sound in a language\n\u2022 Phones are the acoustic analysis of sounds\n\u2022 Phonemes can be broadly divided into consonants and vowels\n\u2022 Vowels are produced with an unobstructed airflow through the vocal tract while consonants are\nproduced with some kind of stricture to the airflow\n\u2022 Consonants are classified using place and manner of articulation. They are also classified\naccording to voicing and aspiration in some languages\n\u2022 Vowels are classified using tongue height, backness and roundness\n\u2022 Syllables are the smallest units of articulation\n\u2022 The most basic syllable structure found in all languages is the CV syllable\n\u2022 Syllables consist of a mandatory nucleus or peak and optional onsets and codas\n\u2022 Phonological rules are rules of phonology that are applied by native speakers without conscious\nawareness\nExercises in Critical Thinking\n1. Think about the different languages that you know. How are they similar and different?\n2. What is the particular dialect that you speak? How is it different from the standard form of your\nlanguage?\n3. Consider how artificial language systems such as Amazon\u2019s Alexa and Apple\u2019s Siri produce\nspeech sounds. Do you think they make use of phonological rules to make their speech sound\nmore natural?\n57  References\nGoldsmith, J. A. (1995). The handbook of phonological theory. Oxford: Blackwell.\nLadefoged, P. & Maddieson, I. (1996). The sounds of the world\u2019s languages. Oxford: Blackwell\n59  Chapter 3: The Parts of Speech\nLearning Objectives\n\u2022 Understand the definition of morphemes\n\u2022 Explore the typology of morphology across the world\u2019s languages\n\u2022 Define syntax and syntactic categories\nThis chapter is an introduction to words and their meaning. We will explore meaningful units of\nlanguage and their typology across different languages. This includes inflectional, isolating,\nagglutinative and polysynthetic morphologies. We will also look at inflectional versus derivational\nmorpheme translations as well as unusual nonconcatenative morphology in Semitic languages. We will\nalso look at syntax and the parts-of-speech that make up sentences or utterances. We will end this\nchapter with a look at word order and how they differ across languages.\n61  3.1 Words and Their Meaning\nIt may seem a superficial question to ask \u201cwhat is a word?\u201d However, this question has stymied some\nof the greatest minds on history. Ferdinand de Saussure once said that a word is like a coin. It has two\nsides in that it has form (the sounds that make up a word) and meaning (the concept associated with\nit). In this sense, we could say that a word links form with meaning.\nWords also have some properties that go beyond these observations. For example, words are free as\nthey can appear in isolation. \u201cHow was the hamburger?\u201d \u201cDelicious\u201d. A perfectly sensible word that\nprovides meaning on its own. Words are also movable. They are not bound to a particular position in a\nsentence. Consider these examples:\n\u2022 John is making a hamburger.\n\u2022 Hamburger is delicious.\n\u2022 Jenny loves to eat hamburgers for dinner.\nThe word hamburger can appear as the first, last or middle word in a sentence. However, now consider\nwhether the meaning of words is inseparable from the form. We know we can break up a word\u2019s form\ninto phonemes. Can me break up a word\u2019s meaning in the same way?\n63  3.2 Morphemes\nIf we consider meaningful units in a language, we come to a unit beyond which we cannot derive\nfurther meaning. This smallest unit of meaning is known as a morpheme. Consider the word \u2018dogs.\u2019 It\nis composed of two morphemes: \u2018dog\u2019 and \u2018s\u2019 with the latter conveying the plural number. Here we see\nthat while \u2018dog\u2019 can be a free morpheme, \u2018s\u2019 cannot. Such a morpheme which always needs to be\nconnected to other morphemes is known as a bound morpheme.\nOne important issue to keep in mind is that while some words are morphemes, not all morphemes are\nwords. Words can be made up of numerous morphemes. In a sentence such as \u201cJon found the box to be\nunbreakable\u201d we know there are seven words. However, we can break that sentence into nine\nmorphemes as: \u201cJon found the box to be un-break-able\u201d.\nFigure 3.1 Examples of Morphemes\nIn Figure 3.1 we see examples of free and bound morphemes. The -er and -ing in writer and talking are\nknown as suffixes. These are morphemes that attached to the ends of other morphemes. Examples\ninclude the plural suffix -s and the past tense -ed. English also has prefixes as in reheat, invisible and\ndisagree.\nAllomorphs\nPreviously we came across the concept of an allophone. These were variations of the smallest sound\nunit in a language or phoneme. Similarly, the smallest unit of meaning in a language, the morpheme,\ncan also have variations called allomorphs. These allomorphs often vary depending on the\nenvironment. The most common example of this is the indefinite article \u2018a\u2019. It comes from the Old\nEnglish \u0101n meaning one or alone. Gradually, the n was lost before consonants by the 15th century so\nyou get the allomorphs a and an. So, you say \u2018a book\u2019 but \u2018an apple\u2019. Some allomorphs actually change\nthe form of words due to over analysis. For example, a norange overtime became an orange because\npeople thought the initial n was part of the indefinite article. Similarly, an ekename \/i\u02d0kne\u026am \/ (from\n65 66 Chapter 3: The Parts of Speech\nMiddle English eke or suppliment) was analysed as a nickname. This time the n in an became attached\nto the following word.\nAnother example of an allomorph in English is the plural suffix -s. This comes in three variations: [s],\n[z], and [\u0259z]. So, after a unvoiced consonants we get [s] as in carrots and books. It is pronounced [z]\nafter voiced segments as in friends and iguanas. It is also pronounced (and written) differently in words\nsuch as churches and bushed.\nMedia Attributions\n\u2022 Figure 3.1 Examples of Morphemes by Dinesh Ramoo, the author, is licensed under a CC BY\n4.0 licence. 3.3 Morphology of Different Languages\nThe way in which morphemes are employed to modify meaning can vary between languages.\nMorphological typology is a method used by linguists to classify languages according to their\nmorphological structure. While a variety of classification types have been identified, we will look at a\ncommon method of classification: analytic, agglutinative and fusional. Figure 3.2 give some examples\nof morphological typology across the world\u2019s languages.\nAnalytic languages have a low ratio of morphemes to words. They are often isolating languages in\nthat each morpheme is also a word and vice versa. These languages create sentences with independent\nroot morphemes with grammatical relations between words being expressed with separate words.\nExamples of analytics or isolating languages include Chinese languages and Vietnamese. While in\nEnglish we inflect numbers: one day, two days, an analytic language such as Mandarin Chinese has no\ninflection: \u4e00\u5929, y\u00ec ti\u0101n \u201cone day\u201d, \u4e09\u5929, s\u0101n ti\u0101n \u201cthree day\u201d. The Canadian linguist and translator\nSonja Lang has created an analytic language, Toki Pona, as a minimalist creative endeavour.\nFigure 3.2 Examples of Morphological Typology [Image description]\nUnlike analytic languages, synthetic languages employ inflection or agglutination to express syntactic\nrelationships. Agglutinative languages combine one or more morphemes into one word. The\ndistinguishing feature of these languages is that each morpheme is individually identifiable as a\nmeaningful unit even after combining into a word. Examples of agglutinative languages include Tamil,\nSecwepemc, Turkish, Japanese, Finnish, Basque and Hungarian. Figure 3.3 shows you an example of\nagglutination in Turkish. Each coloured morpheme is also given an approximate English translation.\nFigure 3.2 give another example from Tamil.\n67 68 Chapter 3: The Parts of Speech\nFigure 3.3 Example from Turkish, an Agglutinative Language [Image description]\nAnother type of synthetic languages are fusional languages. Like agglutinative languages, fusional\nlanguages also combine morphemes to modify meaning. However, these combinations often do not\nremain distinct and fuse together. In addition, these languages also have a tendency to use a single\ninflectional morpheme to denote numerous grammatical or syntactic features. For example, the suffix -\u00ed\nin Spanish com\u00ed (\u201cI ate\u201d) denotes both first-person singular agreement and preterite tense. Examples of\nfusional languages include Indo-European languages such as Sanskrit, Spanish, Romanian, and\nGerman. Modern English could also be considered fusional; although it has tended to evolve to be\nmore analytic. J. R. R. Tolkien\u2019s fictional language Sindarin is fusional (another elvish language,\nQuenya, is agglutinative).\nFigure 3.2 shows an additional morphological type named polysynthetic. These languages tend to a\nhigh morpheme-to-word ratio as well as regular morphology. They often combine a large number of\nmorphemes to form words that are the equivalent of entire sentences in other languages. Many\nlanguages in North America such as Mohawk tend to have this type of morphology.\nInflectional Morphology\nInflectional morphemes add grammatical information to a word while retaining its core meaning and\nits grammatical category. The tense of a verb is indicated by inflectional morphology. You add -ed to\nwalk to make walked. You can also make a past tense inflection through the change of a vowel as in\nsang or wrote. Some languages have inflections for the future tense as well (which English does not\nhave). Another example is when you indicate number in English by adding -s to a word you add the\nmorpheme to the end of a singular noun. So, book can be made a plural by adding -s to make it books.\nThe original stem doesn\u2019t change in meaning and it remains a noun. While English only has singular\nand plural numbers, some languages have a dual number. Consider the following example from\nAncient Greek (Weir, 1920): 3.3 Morphology of Different Languages 69\n\u1f41 \u03b8\u03b5\u03cc\u03c2 (ho the\u00f3s) \u201cthe god\u201d (singular)\n\u03c4\u1f7c \u03b8\u03b5\u03ce (t\u1e51 the\u1e53) \u201cthe two gods\u201d (dual)\n\u03bf\u1f31 \u03b8\u03b5\u03bf\u03af (hoi theo\u00ed) \u201cthe gods\u201d (plural)\nInuktitut spoken in the territory of Nunavut also has a dual number (Anderson, 2018):\nSingular, Dual and Plural Numbers in Inuktitut\nInuktitut English translations\nmatu door\nmatuuk doors (two)\nmatuit doors (three or more)\nnuvuja cloud\nnuvujaak clouds (two)\nnuvujait clouds (three or more)\nqarasaujaq computer\nqarasaujaak computers (two)\nqarasaujait computers (three or more)\nDerivational Morphology\nAnother way in which morphemes modify meaning is through derivation. Here the original word is\nmodified by the derivation and often changes its word category. Form example, adding -er to the verb\nwrite will modify it into a noun: writer. The same is seen in teacher, walker and baker. In the same way,\nan adjective can be changed into a noun as in sad and \u2013ness becoming sadness.\nDerivation often leads to the creation of new words. These new words can in turn serve as a base for\nfurther derivation. This can lead to some rather complex morphological forms. For example, a machine\nthat computes may be called a computer (compute and -er). When we use a computer to complete a\ntask, we could say they computerize (computer and -ize) which in turn can be called computerization\n(computerize and -ation). One interesting observation is that inflecting a base makes further derivation\nimpossible. So, making a plural our of computer into computers (computer and -s) means we cannot\nmake it into *computersize.\nNonconcatenative Morphology\nMost of the morphological types we have seen make use of prefixes and suffixes to make changes in\nmeaning. These involve making sequential changes to the stem. However, there are some languages 70 Chapter 3: The Parts of Speech\nthat make morphological modifications to a word-root using non-sequential methods. This is known as\nnonconcatenative morphology, discontinuous morphology or introflection. This type of change is also\nseen in English foot \/f\u028at\/ \u2192 feet \/fi\u02d0t\/ as well as freeze \/\u02c8fri\u02d0z\/ \u2192 froze \/\u02c8fro\u028az\/, frozen \/\u02c8fro\u028az\u0259n\/.\nWhile these rare cases exist in other Indo-European languages as well, this is very well developed in\nSemitic languages such as Arabic. Consider some derivation of the Semitic root k-t-b in Arabic (Wehr,\n1994) and Hebrew. This root is transposed into other segments to create these morphological\nderivations.\nNonconcatenative Morphology in Arabic and Hebrew\nArabic Transliteration Hebrew Transliteration Translation\nkataba \u05d1\u05ea\u05db kata\u1e07 \u2018he wrote\u2019\n\u0628\u062a\u0643\n\u062a\u064f \u0628\u0652\u062a\u064e\u064e\u0643 katabtu \u05d9\u05ea\u05d1\u05ea\u05db k\u0101\u1e6fa\u1e07ti \u2018I wrote\u2019\nk\u0101tib \u05d1\u05ea\u05d5\u05db kote\u1e07 \u2018writer\u2019\n\u0628\u062a\u0627\u0643\n\u02beaktaba \u05d1\u05d9\u05ea\u05db\u05d4 hi\u1e35ti\u1e07 \u2018he dictated\u2019\n\u0628\u062a\u0643\u0623\u0623\nmaktab \u05d1\u05ea\u05db\u05de mi\u1e35ta\u1e07 \u2018office\u2019 (Arabic), \u2018letter\u2019 (Hebrew)\n\u0628\u062a\u0643\u0645\n\u2018he made (them) write\u2019 (Arabic),\nistaktaba \u05d1\u05ea\u05db\u05ea\u05d4 hitkatte\u1e07\n\u0628\u062a\u0643\u062a\u0633\u0627 \u2018he corresponded\u2019 (Hebrew)\nAs we can see, the morphemes do not attach to the ends but infuse within the triconsonantal roots as\ninfixes. Figure 3.4 and Figure 3.5 illustrate how this can be visualized from a language production\nstandpoint. We see the consonantal roots act as separate morphemes from the infixes which intertwine\nto form the final segmental sequence that is syllabified and spoken. This shows us that morphology can\nbe more complex than simple additions to a stem.\nFigure 3.4 Non-concatenative Morphology in Arabic 3.3 Morphology of Different Languages 71\nFigure 3.5 Non-concatenative Morphology in Arabic\nMorphologies around the World\nAn interactive H5P element has been excluded from this version of the text. You can view it online here:\nhttps:\/\/opentextbc.ca\/psyclanguage\/?p=1231#h5p-20 72 Chapter 3: The Parts of Speech\n1. Isolating Language: Mandarin\n2. Agglutinative Language: Tamil\n3. Fusional Language: Spanish\n4. Polysynthetic Language: Mohawk or Kanien\u02bck\u00e9ha\nNavigate to the above link to view the interactive version of this graph.\nImage description\nFigure 3.2 Examples of Morphological Typology\nProvides examples of the morphological typology of Mandarin, isolating language, Tamil, an\nagglutinative language, Spanish, a fusional language, and Mohawk, a polysynthetic language. The\nimage illustrates the meanings of the morpheme components of the words or phrases, and how they\ncombine to express meaning.\n\u2022 Isolating language (Mandarin): m\u011bi (America), gu\u00f3 (country), and r\u00e9n (person) combined\ninto m\u011bi gu\u00f3 r\u00e9n which means \u201cAmerican\u201d.\n\u2022 Agglutinative language (Tamil): pe\u02d0su (speak), kir (present), and e\u02d0n (1st person singular)\ncombined into pe\u02d0su kir e\u02d0n which means \u201cI am speaking\u201d.\n\u2022 Fusional (Spanish): ind (present indicative), hablar (speak) and yo (1st person singular)\ncombined into hablo which means \u201cI speak\u201d. 3.3 Morphology of Different Languages 73\n\u2022 Polysynthetic (Mohawk): s (again), a (past), h\u0173wa(she\/him), nho (door), t\u0173 (close), kw (un),\nahs (for), e\u0294 (perfective) combined into sah\u0173wanhot\u0173kwahse\u0294 which means \u201cshe opened the\ndoor for him again\u201d.\n[Return to place in text (Figure 3.2)]\nFigure 3.3 Example from Turkish, an Agglutinative Language\nTwo examples of agglutination from the Turkish language broken down into their morphological\ncomponents.\n1. Adamla tan\u0131\u015ft\u0131m \u2013 \u201cI met with the man\u201d\n\u25e6 Adam \u2013 indirect object \u25e6 t\u0131 \u2013 past tense suffix\n\u25e6 la \u2013 instrumental case suffix \u25e6 m \u2013 indicator of subject\n\u25e6 tan\u0131\u015f \u2013 verb stem\n2. Adam\u0131n kitab\u0131 \u2013 \u201cMan\u2019s book\u201d\n\u25e6 Adam \u2013 possessor \u25e6 kitab \u2013 possessed noun\n\u25e6 \u0131n \u2013 genitive suffix \u25e6 \u0131 \u2013 possessive ending\n[Return to place in text (Figure 3.3)]\nMedia Attributions\n\u2022 Figure 3.2 Examples of Morphological Typology by Dinesh Ramoo, the author, is licensed\nunder a CC BY 4.0 licence.\n\u2022 Figure 3.3 Example from Turkish, an Agglutinative Language by Dinesh Ramoo, the author,\nis licensed under a CC BY 4.0 licence.\n\u2022 Figure 3.4 Non-concatenative Morphology in Arabic by Dinesh Ramoo, the author, is\nlicensed under a CC BY 4.0 licence.\n\u2022 Figure 3.5 Non-concatenative Morphology in Arabic by Dinesh Ramoo, the author, is\nlicensed under a CC BY 4.0 licence.  3.4 Syntax\nNow that we are familiar with the units of sound, articulation and meaning, let us explore how these are\nput together in connected speech. Syntax is the set of rules and process that govern sentence structure\nin a language. A basic description of syntax would be the sequence in which words can occur in a\nsentence. One of the earliest approaches to syntactic theory comes from the works of the Sanskrit\ngrammarian P\u0101\u1e47ini (c. 4th century BC) and his seminal work: A\u1e63\u1e6d\u0101dhy\u0101y\u012b. While the field has\ndiversified into many schools, we will look at some basic issues of syntax and look at the contributions\nof Noam Chomsky.\nLiving Language\nLook at these two sentences and decide which one seems normal to you:\n1. Paul gave Mary a new book.\n2. Paul new a book Mary gave.\nWhy is one not considered correct even though it contains all the same words? Can you articulate the rules\nthat govern your decision or are they intuitive?\nGrammar employs a finite set of rules to generate the infinite variety of output in a language. This is\nthe basis for generative grammar. Chomsky argued for a system of sentence generation that took into\naccount the underlying syntactic structure of sentences. He emphasised the native intuition of any\nnative speaker of a language to identity ill-formed sentences in that language. The speaker may not be\nable to provide a rationale for why some sentences are acceptable and other are not. However, it cannot\nbe denied that such intuitions exist in every person. While Chomsky\u2019s ideas have evolved over the\nyears, the main conclusions appear to be that language is a rule-based system and a finite set of\nsyntactic rules can capture our knowledge of syntax.\nA key aspect of language is that we can construct sentences with words using a set of finite rules.\nPhrase-structure rules are a way to describe how words can be combined into different structures.\nSentences are constructed from smaller units. If s sentence is designated as S, we can use rewrite rules\nto translate other symbols such as noun phrases (NP) and verb phrases (VP) as in:\nS \u2192 NP + VP\nPhrase-structure grammar has word (terminal elements) and other constituent parts (non-terminal\nelements). This means that words usually form the lowest part of a sentences building up towards a\nsentence. The rules that we use to construct these sentences do not deal with individual words but\nclasses of words. Such classes include words that name objects (nouns), words for actions (verbs),\nwords that describe nouns (adjectives), and words that qualify actions (adverbs). We can also think of\n75 76 Chapter 3: The Parts of Speech\nwords that determine number such as \u2018the\u2019, \u2018a\u2019 and \u2018some\u2019 (determiners), words that join constituents\nsuch as \u2018and\u2019 and \u2018because\u2019 (conjunctions), words that substitute for a noun or noun phrase as in \u2018I\u2019\nand \u2018she\u2019 (pronouns), and words that express spatial or temporal relations as in \u2018on\u2019 and \u2018on\u2019\n(prepositions).\nThese types of words combine to form phrases. Such phrases that can take the part of nouns in\nsentences are called noun phrases. So \u2018dog,\u2019 \u2018the dog\u2019 or \u2018the naughty dog\u2019 are all noun phrases\nbecause they can fill the gap in a sentence such as \u2018_____ ran through the park\u2019. Phrases combine to\nform clauses. These contain a subject (what we are talking about) and a predicate (information about\nthe subject). Every clause has to have a verb and sentences can consist of one or more clauses. As we\nsee in Figure 3.6, the sentence \u2018the dog likes John\u2019 consists of one clause composed of a noun phrase\nand a verb phrase. It contains a subject \u2018the dog,\u2019 a verb \u2018likes,\u2019 and an object \u2018John.\u2019\nOne way to think about how sentences are organized in the mind is through a notation called a tree\ndiagram. They are called tree diagrams because they branch from a single point into phrases which in\nturn branch into words. Each place where the branches come together is called a node. A node\nindicates a set of words that act together as a unit or constituent. Consider Figure 3.6 which illustrates\nhow a sentence can be depicted in a tree diagram.\nFigure 3.6 Sentence Structure in English [Image description] 3.4 Syntax 77\nWord Order in Different Languages\nThe order of the syntactic constituents varies between languages. When talking about word order,\nlinguists generally look at 1) the relative order of subject, object and verb in a sentence (constituent\norder), 2) the order modifiers such as adjectives and numerals in a noun phrase, and 3) the order of\nadverbials. Here we will focus mostly on constituent word order.\nEnglish sentences generally display a word order consisting of subject-verb-object (SVO) as in \u2018the\ndog [noun] likes [verb] John [object]\u2019. Mandarin and Swahili are other examples of SVO. About a third\nof all languages have this type of word order (Tomlin, 1986). About half of all languages employ\nsubject-object-verb (SOV). Japanese, Turkish as well as the Indo-Aryan and Dravidian languages of\nIndia are examples of SOV word order. Classical Arabic and Biblical Hebrew as well as the Salishan\nlanguages of British Columbia employ verb-subject-object (VSO). Rarer are typologies such as verb-\nobject-subject (VOS) as is found in Algonquin. Unusual word ordering can be employed for dramatic\neffect as in the object-subject-verb (OSV) word order of Yoda from Star Wars: \u2018Powerful (object) you\n(subject) have become (verb). The dark side (O) I (S) sense (V) in you.\u2019\nThe Neurolinguistics of Syntax and Semantics\nWe know that a sentence\u2019s syntax has an influence on how its meaning is interpreted (semantics of the\nsentence). Any given string of words can have different meanings if they have different syntactic\nstructures. However, syntax doesn\u2019t necessarily need to be in line with semantics. Chomsky (1957)\nfamously composed a sentence that was syntactically correct but semantically meaningless: \u201ccolorless\ngreen ideas sleep furiously.\u201d The sentence is devoid of semantic content, but it is a perfectly\ngrammatical sentence in English. The words \u201c*Furiously sleep ideas green colorless\u201d are the same but\ntheir order would not be considered grammatical by a native English speaker.\nWe have psycholinguistic evidence from electroencephalography to support the idea that syntax and\nsemantics are processed independent of each other. In measuring event related potentials (ERPs) for\nsentences there are some interesting observations. For example, the sentence \u201cHe eats a ham and\ncheese \u2026\u201d sets up a very strong expectation in your mind about what words comes next. If the word\nthat comes next is in line with your expectations, the ERP signal will be a baseline condition. However,\nif the next word violates your expectations, then we often see a sudden negative spike in the EEG\nvoltage around 400ms after the unexpected word. This ERP signal is called an N400 (where the N\nstands for negative and 400 indicates the approximate timing of the ERP after the stimulus). Numerous\nstudies have found an N400 response when a semantically unexpected word is inserted into a sentence.\nHowever, not every unexpected word elicits an N400 response. In some cases, where the unexpected\nword belongs to an unexpected word category (for example, a verb instead of a noun), we see a positive\nvoltage around 600ms after the unexpected word. This is known as a P600. Therefore, we see that\nviolations of semantic expectations elicit an N400 while violations of syntactic expectations elicit a\nP600. This suggests that syntax and semantics are independently processed n our brains. 78 Chapter 3: The Parts of Speech\nWord Order around the World 3.4 Syntax 79 80 Chapter 3: The Parts of Speech\nImage description\nFigure 3.6 Sentence Structure in English\nThe sentence \u201cthe dog likes John\u201d consists of a noun phrase \u201cthe dog,\u201d and a verb phrase \u201clikes John.\u201d\nThe noun phrase is consisted of a determiner \u201cthe\u201d and a noun \u201cdog.\u201d The verb phrase is consisted of a\nverb \u201clikes,\u201d and a noun phrase \u201cJohn.\u201d\n[Return to place in the text (Figure 3.6)]\nMedia Attribution\n\u2022 Figure 3.6 Sentence Structure in English by Dinesh Ramoo, the author, is licensed under a\nCC BY 4.0 licence. Summary\nIn this chapter we learned about the smallest units of meaning in a language: morphemes. We saw how\nmorphemes can be employed in different ways to modify meaning in different languages. We also saw\nthe differences between inflectional and derivational morphology. The order in which constituents of a\nsentences can be arranged can be flexible in some languages but very strict in others (such as English).\nWhile subject-object-verb (SOV) is the most common word order in the world\u2019s languages, there are\nother variations as is found in English (SVO).\nKey Takeaways\n\u2022 Morphemes are the smallest units of meaning in a language.\n\u2022 Languages differ in how they employ morphemes to modify meaning.\n\u2022 Some languages (such as Arabic and Hebrew) also use infixes which infuse in-between segments\nrather than affixing to the front or back of other morphemes.\n\u2022 Syntax is the set of rules and process that govern sentence structure in a language.\n\u2022 Subject-object-verb is the most common word order in the world\u2019s languages.\n\u2022 English has a subject-verb-object word order as do a third of the world\u2019s languages.\nExercises in Critical Thinking\n1. To what extent do linguistics and psycholinguistics compare and differ from one another?\n2. If you are developing an artificial intelligence system to process natural language, would you\nconsult a linguist or a psycholinguist?\n3. Is there a limit to how different human languages can be? Are there things no human language\ncan do?\n81  References\nAnderson, C. (2018). Essentials of linguistics. Canada: McMaster University\nChomsky, N. (1957). Syntactic structures. The Hague: Mouton.\nChomsky, N. (1965). Aspects of the theory of syntax. Cambridge, MA: MIT Press.\nChomsky, N. (1981). Lectures on government and binding. Dordrecht: Foris.\nChomsky, N. (1995). Bare phrase structure. In G. Webelhuth (Ed.), Government and binding theory\nand the minimalist programme (pp. 383\u2013400). Oxford: Blackwell.\nSmyth, H. W. (1920). \u201cPart II: Inflection\u201d. A Greek grammar for colleges. Cambridge: American Book\nCompany.\nTomlin, R. S. (1986). Basic word order: Functional principles. London: Croom Helm.\nWehr, H. (1994) A dictionary of modern written Arabic: (Arabic-English). 4th edition, Ithaca, NY:\nSpoken Language Services.\n83  Chapter 4: The Biological Basis of Language\nLearning Objectives\n\u2022 Understand the nature of human language and animal communication.\n\u2022 Describe the defining features of human language.\n\u2022 Describe the neuroanatomy of language in the human brain.\n\u2022 Understand the concept of linguistic relativity and the evidence for and against it.\nLiving Language\nAs you may have heard, two people heard the humming noise of ducks and started an argument over whether the\nsound came from the air passing through their beak or their wings. The chief calls a great council to settle the matter.\nThe people from all the nearby villages attend and again they argue and cannot agree. Eventually, the argument leads\nto some people moving far from this land and they began to speak differently. Eventually, other languages formed\nand we cannot understand each other.\nA tale from the Salishan (Boas, 1917)\nLong ago, Taikomol, He who goes alone, made the earth from a piece of coiled basket. Taikomol the creator walked\nwith Coyote throughout the land. The creator laid out sticks at night which turned into people upon daybreak. As\nTaikomol made different people, they were given different customs, modes of life and a different language. Finally,\nthe creator ascended to the sky where he still is.\nA take from the Yuki people of California (Kroeber, 1907)\nThese stories show us the centrality of language to human existence. All human societies have\ndeveloped stories about the origins of language and how it is linked to their identity. We will explore\nsome of the ideas about human language, its origins and current views on the biological basis of\nlanguage in this chapter.\n85  4.1 Animal Communication\nIs human language an extension of other forms of communication, or is it a unique attribute of humans?\nIn investigating animal communication, we explore the extent to which aspects of language may be\ninnate. Animals have a variety of communication systems that go beyond the scope of this book. We\nwill explore just a small set of interesting systems. Communication is the transmission of a signal to\ncovey information (Pearce, 2008). Communication has an element of intention that differentiates it\nfrom mere informative signals. A sneeze is a signal that may mean someone has a cold, but it was not\ncommunication. However, telling someone that you have a cold is communication.\nFigure 4.1 Bees Dance\nPerhaps one the most intriguing communication methods found in nature is the complex system of\ndances in honey bees. As seen in Figure 4.1, a bee waggles in a figure-of-eight shape to communicate\nthe direction of sources of nectar relative to the sun. The rate of the waggle represents distance (von\nFrisch, 1950, 1974). This behavior suggests that complex neural networks are not a necessity for\ncommunication to occur.\nMore complex brains such as primates use a variety of signals from visual and auditory signals to\nolfactory and tactile sensations. Vervet monkeys have been observed to make sounds to that\ndifferentiate between predators on the ground and those coming from above. The difference is seen in\nthe interpretation of these calls by other monkeys in terms of whether they rush into the trees or the\nground (depending on the type of predator).\n87 88 Chapter 4: The Biological Basis of Language\nBoth of the above-mentioned methods of communication differ from language in that they are\ntemporally linked to particular stimuli. Signals are linked to particular stimuli (nectar or predators) and\nproduced only in their presence. Therefore, what features of language can be used to distinguish it from\nanimal communication? How do we define language?\nMedia Attributions\n\u2022 Figure 4.1 Bees Dance by J\u00fcppsche is licensed under a CC BY-SA 2.5 Generic licence. 4.2 Defining Language\nLanguage is difficult to define. Indeed, most books on language actually avoid giving a definition. In\ntrying to tackle this tricky topic, Hockett (1960) set out a list of 16 design features of human language.\nHe focused on the physical features of language rather than cognition. While this is not a perfect\nattempt, it is a useful frame to start our exploration.\n1. Vocal-auditory channel: Communication happens by vocalization by the sender and\naudition by the receiver.\n2. Transmission and directional reception: The signal travels in all directions but can be\nlocalized by the receiver.\n3. Rapid fading: Once produced, the signal disappears.\n4. Interchangeability: An individual can be both the transmitter and the receiver.\n5. Complete feedback: Producers of the signal have access to everything about their\nproductions.\n6. Specialization: Weather whispered or shouted; the signal is the same.\n7. Semanticity: The signal contains meaning that related to the external world.\n8. Arbitrariness: The symbols are abstract and do not resemble the things they represent.\n9. Discreteness: The words are made up of discrete units.\n10. Displacement: The system can be used to reference things across time and space.\n11. Openness: The system can expand to invent new messages.\n12. Tradition: The system can be passed from one generation to the another.\n13. Duality of patterning: From phonemes, to morphemes, to words and sentences, the\ncombination of meaningless units creates meaning.\n14. Prevarication: Humans use language to lie and deceive.\n15. Reflectiveness: Language can be used to discuss language.\n16. Learnability: Anyone who speaks a language can learn another\nNow consider these design features in terms of animal communication. Do animals lack all of these\nfeatures? Language is obviously about meaning and we may even add other features to human\nlanguage such as creativity. But some animals have also shown the ability to lie as well as control their\ncommunication methods. Recently, Chomsky and his colleagues have argued for the syntactic\ncreativity of language as its defining feature. The way in which we can use finite symbols to create\ninfinite variations through iteration and recursion has been stated as unique t human languages. Kako\n(1999) and Pinker (2002) have listed five properties of our syntactic system:\n\u2022 Language has the ability to use a discrete combinatorial system to create new meaning. In\n89 90 Chapter 4: The Biological Basis of Language\nother words, when we use words, they remain distinct and do not blend together.\n\u2022 Sentences need to be in a correct sequence (well-ordered) based on the syntactic category of\nwords (e.g., nouns and verbs)\n\u2022 Sentences are built around action words (verbs).\n\u2022 There is a distinction between words that relate to meaning (semantics) and words that assist\nin syntactic structuring (function words).\n\u2022 Sentences can be recursive. We can create phrases that contain other phrases that relate to the\ncontaining phrase.\nAnimal communication doesn\u2019t appear to have these features. In addition, we communicate about\nthings that are separated in time and space (unlike animals). Monkeys, for example, make signals about\nimmediate threat such as snakes and leopards. They don\u2019t discuss the snake they saw last summer.\nAnimals cannot discuss their own communication system using their communication system.\nTherefore, while animals possess a rich communication system that they use to convey messages\nbetween members of their group, they do not bear much similarity with human language. Our (perhaps)\nlimitless ability to employ language to discuss anything and everything is mind boggling. In essence,\nall non-human communication systems are different from human language. 4.3 The Origins of Language\n\u201cI cannot doubt that language owes its origin to the imitation and modification, aided by signs and gestures,\nof various natural sounds, the voices of other animals, and man\u2019s own instinctive cries\u201d\n(Darwin, 1871, p. 56).\nIn 1866, the Linguistic Society of Paris (Soci\u00e9t\u00e9 de Linguistique de Paris) banned any debate on the\norigins of language. This was based on the lack of empirical evidence for pursuing the topic. However,\nDarwinian ideas of human evolution by natural selection fueled continuous debate on the issue. It\nwasn\u2019t until the early twentieth century that the topic regained scientific scrutiny. Speculations on the\ntopic can be broadly divided into the following camps:\n\u2022 Continuity theories: language as a continuity of pervious communication systems in our\nprimate ancestors (Pinker & Bloom, 1990).\n\u2022 Discontinuity theories: language as a unique attribute of human beings with no comparable\nparallel to any other animal communication system (Chomsky, 1996).\nThese can be further divided into theories that promote language as an innate faculty with a genetic\nbasis and theories that consider language as a cultural system. It has been noted that some words are\nonomatopoeic: they sound like the things to which they refer. Examples include cuckoo (the sounds of\nthat bird) and hiss (the sound of a snake). However, the idea that language has its origins in mimicry is\nchallenged by the vast number of words that are not onomatopoeic with variations between languages.\nThe two main ideas about the evolution of language are that it was either a beneficial adaptation shaped\nby natural selection, or that it arose as a side effect of other evolved features of cognition (Hauser,\nChomsky, & Fitch, 2002). The \u2018language as a side-effect\u2019 hypothesis is claimed to by its proponents as\njustified because language is too complex to have evolved within the short evolutionary period since\nour divergence from other apes. They also point out that an intermediate grammar system isn\u2019t really\npossible and the complex grammatical systems in human language doesn\u2019t appear to confer any\nselective advantage. However, the idea of language as a product of natural selection has gained ground\nin recent years. There is now evidence for there being enough time for grammar to have evolved to\ncommunicate existing cognitive representations (Pinker, 2003; Pinker & Bloom, 1990; Pinker &\nJackendoff, 2005). The rapid increase in brain capacity and complexity would also have played a large\nrole in the evolution of language. Fossil evidence suggests that brain regions associated with language,\nsuch as Broca\u2019s area, were present in hominids as far back as 2 millions years ago.\nThe evolution of language did have its costs. The larynx is the organ in the neck containing the vocal\nfolds. In humans, this organ is descended. This is not unique to humans as some animals (such as goats\nand dogs) temporarily descend the larynx to produce loud noises (Fitch, 2000). However, in these\ncases, the hyoid remains undescended and so the tongue remains horizontal. The descent of both the\nlarynx and the hyoid bone in humans is taken by some researchers as significant (Lieberman, 2007).\nThis leads to simple contact between the epiglottis and velum being no longer possible. Therefore, the\nrespiratory and digestive tracts are no longer separate during swallowing in humans resulting in a\n91 92 Chapter 4: The Biological Basis of Language\nchoking hazard. It appears possible that the descent of the larynx and resultant ability to speak\noutweighed the potential for choking in early hominids. One argument against this is that the descent of\nthe larynx and hyoid takes longer to evolve compared to the evolution of speech, a more recent\ncomponent of human evolution.\nFigure 4.2 Parts of the Human Larynx [Image description]\nThe idea that language evolved in one giant leap or the mutation of a single gene is unlikely. However,\nthere is evidence that certain genes such as FOXP2 may play an important role in linguistic attributes\nsuch as grammar. This gene is associated with sensory and motor coordination in animals (Fisher &\nMarcus, 2006). However, in humans this gene has evolved to be vital for grammatical processing. If\nthis gene is damaged in humans, it can lead to language acquisition problems. It is possible therefore,\nthat other genes may be discovered in the future and the evolution of language may have involved the\nreconfiguration or appropriation of a number of brain structures.\nImage description\nFigure 4.2 Parts of the Human Larynx\nHuman larynx includes hyoid bone, lateral thyrohyoid ligament, thyrohyoid membrane, median 4.3 The Origins of Language 93\nthyrohyoid ligament, superior cornu, larygeal incisure, thyroid cartilage, oblique line, median\ncricothyroid ligament, conus elasticus, cricothyroid muscle, inferior cornu, cricoid cartilage,\ncricothyroid joint and trachea.\n[Return to place in the text (Figure 4.2)]\nMedia Attributions\n\u2022 Figure 4.2 Parts of the Human Larynx by Olek Remesz is licensed under CC BY-SA license.  4.4 Language in the Brain\nThe specialization of various parts of the brain would have been a concept you may have come across\nin other psychology courses. While people have often speculated on these issues in the past, it wasn\u2019t\nuntil the 19th century that we really started to gain a scientific understanding of this concept. Now we\nhave even more advanced neuroimaging techniques that have opened new avenues for exploring\nlanguage. We know that the brain is divided into two hemispheres which are specialized for different\nfunctions. In most right-handed people, the left hemisphere is specialized for language processing and\nproduction. This is even true of people who used sign-language (Corina et al., 2003).\nThe earliest record of brain damage leading to language loss or aphasia is in an Ancient Egyptian\nmedical texts now known as the Edwin Smith surgical papyrus from 1700 BCE (Minagar et al., 2003).\nCases 20 and 22 of the papyrus talk about an individual with an injury on the left side of their skull. He\nis described as speechless, \u201can ailment not to be treated.\u201d Such an impairment to language production\nwas not investigated in detail again until Paul Broca explored such issues in the 1860s. Broca observed\nseveral patients who had speech disorders resulting from damaged to the left frontal lobe. Later post-\nmortem examination revealed damaged to an area now known as Broca\u2019s region (see Figure 4.3a). In\n1874, a German neurologist Carl Wernicke observed language comprehension issues that arose from\ndamage to the left temporal lobe. The region is now known as Wernicke\u2019s region (see Figure 4.3b). He\nalso proposed the first neurological model of language. As seen in Figure 4.4, we now know that the\ninterpretation of language is associated with Wernicke\u2019s region and it is connected to Broca\u2019s region via\na group of nerve fibres known as the arcuate fasciculus. Broca\u2019s region itself is associated with\narticulation and the controlling of speech. Geschwind (1972) further elaborated on this to describe the\nWernicke\u2013Geschwind model. This model brings together what was known about language at the time\nto describe language production (Broca\u2019s region), comprehension (Wernicke\u2019s region), reading (visual\ncortex) and spelling (angular gyrus).\nFigure 4.3 Broca\u2019s Area (a) and Wernicke\u2019s Area (b)\n95 96 Chapter 4: The Biological Basis of Language\nThis view of the neuroanatomy of language is too simplistic and las its limitations. Language is not\nalways localized to the left hemisphere and the right hemisphere is known to carry out some language\nfunctions. Subcortical regions may also have a role to play in language. Even within the cortex, areas\nother than Broca\u2019s and Wernicke\u2019s region appear to play a role in language processing. With advances\nin neuroimaging techniques, our understanding of the neuroanatomy of the brain will continue to\nexpand.\nFigure 4.4 Language Areas of the brain\nThe Neuroanatomy of Language\nAn interactive H5P element has been excluded from this version of the text. You can view it online here:\nhttps:\/\/opentextbc.ca\/psyclanguage\/?p=1252#h5p-22 4.4 Language in the Brain 97\n1. Broca\u2019s area\n\u25e6 This region is linked to speech production\n\u25e6 Pars opercularis and pars triangularis of the inferior frontal gyrus\n\u25e6 Brodmann area 44 and Brodmann area 45\n2. Arcuate fasciculus\n\u25e6 A bundle of axons that generally connects the Broca\u2019s area and the Wernicke\u2019s area\n\u25e6 An association fiber tract connecting caudal temporal cortex and inferior frontal\nlobe\n3. Auditory cortex\n\u25e6 Area responsible for auditory processing (hearing)\n\u25e6 Parts of the transverse temporal gyri, and the superior temporal gyrus\n\u25e6 Brodmann areas 41 and 42, and partially 22\n4. Wernicke\u2019s area\n\u25e6 This region is linked to speech compreheion\n\u25e6 Superior temporal gyrus 98 Chapter 4: The Biological Basis of Language\n\u25e6 Brodmann area 22\n5. Angular gyrus\n\u25e6 Area involved in language processing and number processing\n\u25e6 Brodmann area 39\n6. Visual cortex\n\u25e6 Area responsible for visual processing\n\u25e6 Visual area 1 (V1): Brodmann area 17\n\u25e6 Visual areas 2, 3, 4, and 5 (V2, V3, V4, and V5): Brodmann area 18 and Brodmann\narea 19\nNavigate to the above link to view the interactive version of this activity.\nMedia Attributions\n\u2022 Figure 4.3 Broca\u2019s Area (a) and Wernicke\u2019s Area (b) by the Database Center for Life\nScience(DBCLS) is licensed under a CC BY-SA 2.1 Japan licence.\n\u2022 Figure 4.4 Language Areas of the Brain by Dinesh Ramoo, the author, is an adapted version\nof Human Brain by Injurymap and Three Segments of the Arcuate Fasciculus by Marco\nCatani et al., is licensed under a CC BY 4.0 licence. 4.5 Language and Thought\nGeorge Orwell\u2019s novel 1984 presents a dystopian world where an authoritarian regime imposes\nabsolute control over all aspects of human life. The rulers of the state use Newspeak as a language\nmodification system to modify people\u2019s thought. The idea is that if people don\u2019t have a word for a\nconcept such as freedom, then they can\u2019t think it. This idea of thought being directly influenced by\nlanguage is an extension of the Sapir-Whorf hypothesis.\nThe central idea of the Sapir-Whorf hypothesis is that the characteristics of a language influences the\nthought forms of that language community. Indeed, it goes even further and states that the way people\nview and understand the world is influenced by their language. Originally proposed by Edward Sapir, a\nlinguist, and supported by an amateur linguist Benjamin Lee Whorf (Whorf, 1956a, 1956b). Whorf\nstudied the Indigenous languages in America to collect evidence this hypothesis which extends into two\nideas: linguistic determinism and linguistic relativism.\nLinguist determinism states that the form and characteristics of a language determine the way we\ncogitate, remember and understand the world. Linguistic relativism is the idea that different cognitive\nstructures emerge from the way languages map words onto things in the real world. Some have\ndifferentiated these ideas into three versions:\n\u2022 The strong version: language determines thought\n\u2022 The weak version: language affects how we perceive the world\n\u2022 The weakest version: language affects differences in processing in certain tasks where\nlanguage is a factor.\nWhorf analysed Indigenous languages such as Hopi, Apache, and Aztec to differentiate what he termed\ntheir \u2018world view.\u2019 He found that Hopi have no words that refer to time and therefore they must have a\ndifferent concept of time compared to Europeans. These observations are now considered suspect\n(Malotki, 1983). Whorf used rather idiosyncratic translation methods that failed to capture the\ncomplexity of Indigenous languages. A more direct evidence is in the form of vocabulary.\nIt was observed that some cultures have only a few words for particular concepts compared to others. A\nfamous example is that the Inuit have four different words for snow (Boas, 1911). The idea being that\nas the Inuit spend more time in the snow, they would develop more nuanced ways of differentiating this\nelement and have a different perception of it. In fact, later observations only turned up two root words\nfor snow in Inuktut: ganik for \u2018snow in the air,\u2019 and aput for \u2018snow on the ground.\u2019 Indeed, English has\nat least four words for snow: snow, slush, sleet, and blizzard. Does this mean English speakers are now\nmore advanced in snow-classification compared to the Inuit? In fact, differences in vocabulary only\nindicate familiarity with a concept and not differences in perception. Another example that is often\nbrought into bear in this discussion is that of colour hierarchy.\nLanguages differ in terms of how many basic colour terms they possess. By colour terms, I don\u2019t mean\nmagenta and mauve, but words like red, green, and blue. Berlin and Kay (1969) explored the basic\n99 100 Chapter 4: The Biological Basis of Language\ncolour terms in various languages. Basic is defined by words made up on one morpheme (such as blue\nrather than marine blue) and not being contained within another colour (blue rather than azure). These\nare also terms that are generally known. What cross-linguistic exploration of these basic colour terms\nhas shown is that there is an actual progression in languages acquiring basic colour terms.\nFigure 4.5 Visualizing the Colour Hierarchy\nAs seen in Figure 4.5, all languages have two basic colour terms: black and white. Some languages\nonly have these two terms. If a language has three colour terms, then it will have terms for black, white\nand red. If a language has four basic colour terms, then it will have these three and either yellow or\ngreen. If a language has five colour terms, then it will have all five and so forth along the hierarchy.\nEnglish has names for eleven basic colour terms. Does this mean that people see colours differently\nbased on what terms they have in their language? Not very likely. For one thing, languages expand\ntheir colour vocabulary all the time. For example, Telugu expanded the term for yellow\/green:\n\u0c2a\u0c1a\u0c1a\u0c4d\n\/p\u0259\u0361t\u0283\u0361t\u0283\u0259\/ into two terms: yellow\n\u0c2a\u0c38\u0c41\u0c2a\u0c2a\u0c4d\u0c1a\u0c1a\u0c4d\n\/p\u0259s\u032aupp\u0259\u0361t\u0283\u0361t\u0283\u0259\/ and green\n\u0c06\u0c15\u0c41\u0c2a\u0c1a\u0c1a\u0c4d\n\/\u0251\u02d0kup\u0259\u0361t\u0283\u0361t\u0283\u0259\/. English has\nhad recent additions such as orange. Before this term came into English, English speakers used the\nterm red for things that were orange such as red deer, red robin, and red fox. However, once the fruit\nwas introduced into Europe, the colour of the fruit became associated with the colour. As seen in Figure\n4.6, the colours form not a set of discreet units but a spectrum. We can cut up this spectrum into\nindividual units and sometimes divide them further as the need arises. So, English-speakers used red to\ncover a larger area of the spectrum until they came across the term orange to divide it further. Telugu\nspeakers used one term to refer to a unit spanning what we consider yellow and green. 4.5 Language and Thought 101\nFigure 4.6 The Colour Hierarchy as a Spectrum\nWhat is interesting about the colour hierarchy is that participants in memory tasks often have difficulty\nwith colours for which they don\u2019t have differentiating terms. Brown and Lenneberg (1954) as well as\nLantz and Stefflre (1964) used colour chips of different hues, brightness and saturation to test people\u2019s\nmemory for them. They found that participants were able to remember the chips more easily if they had\nthe basic colour terms for them in their language. This appeared to support the Sapir-Whorf hypothesis.\nHeider (1972) explored this further by working with the Dani. They only have two basic colour terms\nfor dark and light colours (see Figure 4.6). However, when Heider taught them come made-up colour\nterms they learned the names for basic colour terms more easily than for other colours. They also\nremembered basic colours more easily than non-basic ones even though they have no names for them.\nAs we saw earlier, the division of the colour spectrum is not arbitrary. It is done by dividing the\nspectrum along physiological lines. These observations suggest that while there are some biological\nand linguistic constraints in remembering colours, this is not the strongest evidence for the Sapir-Whorf\nhypothesis. Colour perception is not influenced by linguistic constraints on colour terms.\nMedia Attributions\n\u2022 Figure 4.5 Visualizing the Colour Hierarchy by Dinesh Ramoo, the author, is licensed under\na CC BY 4.0 licence.\n\u2022 Figure 4.6 The Colour Hierarchy as a Spectrum by Dinesh Ramoo, the author, is licensed\nunder a CC BY 4.0 licence.  Summary\nIn this chapter we explored the differences between animal communication and language. We also\nlooked at speculations about the origins and language as well as some design features that help to\ndifferentiate human language from animal communication. We saw that the brain has specialized\nregions for language production and comprehension. We also looked at how language has been thought\nto determine cognitive processing and how there is limited evidence to support this view.\nKey Takeaways\n\u2022 Human language is unique and different from animal communication.\n\u2022 Defining language is difficult. However, we can define it in terms of key design features.\n\u2022 The origins of language through evolution by natural selection has gained ground within\npsychology and biology in recent years.\n\u2022 Lesion studies have shown Broca\u2019s region to be associated with articulation and Wernicke\u2019s\nregion to be associated with language comprehension.\n\u2022 The idea that language determines thought has been challenged by further exploration of various\nlanguages.\nExercises in Critical Thinking\n1. Consider how language might have provided our ancestors with an evolutionary advantage.\n2. Could language have emerged as an artifact of sexual selection for higher cognition?\n3. What would an animal such as a chimpanzee or gorilla need to accomplish for us to consider it\nproficient in language?\n103  References\nBerlin, B., & Kay, P. (1969). Basic color terms: Their universality and evolution. Berkeley: University\nof California Press.\nBoas, F. (1911). Introduction to the handbook of North American Indians (Vol. 1). Bureau of American\nEthnology Bulletin, 40 (Part 1).\nBoas, F. (ed.) (1917) \u201cThe origin of the different languages\u201d. Folk-Tales of Salishan and Sahaptin\nTribes (New York: American Folk-Lore Society)\nBrown, R., & Lenneberg, E. H. (1954). A study in language and cognition. Journal of Abnormal and\nSocial Psychology, 49, 454\u2013462.\nChomsky, N, 1996. Powers and prospects. Reflections on human nature and the social order. London:\nPluto Press.\nCorina, D. P., Jose-Robertson, L., Guillermin, A., High, J., & Braun, A. R. (2003). Language\nlateralization in a bimanual language. Journal of Cognitive Neuroscience, 15, 718\u2013730.\nDarwin, C. (1871). The descent of man, and selection in relation to sex. London: Murray.\nFisher, S. E., & Marcus, G. F. (2006). The eloquent ape: Genes, brains and the evolution of language.\nNature Reviews Genetics, 7, 9\u201320.\nFitch, WT. (2000). The phonetic potential of nonhuman vocal tracts: comparative cineradiographic\nobservations of vocalizing animals. Phonetica. 57 (2\u20134): 205\u201318.\nGeschwind, N. (1972). Language and the brain. Scientific American, 226, 76\u201383.\nHauser, M. D., Chomsky, N., & Fitch, W. T. (2002). The faculty of language: What is it, who has it, and\nhow did it evolve? Science, 298, 1569\u20131579.\nHeider, E. R. (1972). Universals in colour naming and memory. Journal of Experimental Psychology,\n93, 10\u201320.\nHockett, C. F. (1960). The origin of speech. Scientific American, 203, 89\u201396.\nKako, E. (1999). Elements of syntax in the systems of three language-trained animals. Animal Learning\nand Behavior, 27, 1\u201314.\nKroeber, A. L. (1907) Indian myths of south central California, American Archaeology and Ethnology,\n4(4), 183-186.\nLantz, D., & Stefflre, V. (1964). Language and cognition revisited. Journal of Abnormal Psychology,\n69, 472\u2013481.\n105 106 Chapter 4: The Biological Basis of Language\nLieberman, P. (2007). The evolution of human speech: Its anatomical and neural bases. Current\nAnthropology. 48 (1): 39\u201366.\nMalotki, E. (1983). Hopi time: A linguistic analysis of temporal concepts in the Hopi language. Berlin:\nMouton.\nMinagar A, Ragheb J, Kelley RE. (2003) The Edwin Smith surgical papyrus: description and analysis\nof the earliest case of aphasia. Journal of Medical Biography. 11(2), 114-117.\nPearce, J. M. (2008). Animal learning and cognition (3rd ed.). Hove, UK: Lawrence Erlbaum\nAssociates.\nPinker, S. (2002). The blank state. Harmondsworth: Penguin.\nPinker, S. (2003). Language as an adaptation to the cognitive niche. In M. H. Christiansen & S. Kirby\n(Eds.), Language Evolution (pp. 16\u201337). Oxford: Oxford University Press.\nPinker, S., & Bloom, P. (1990). Natural language and natural selection. Behavioral and Brain Sciences,\n13, 707\u2013784.\nPinker, S., & Jackendoff, R. (2005). The faculty of language: What\u2019s special about it? Cognition, 95,\n201\u2013236.\nVon Frisch, K. (1950). Bees, their vision, chemical senses, and language. Ithaca, NY: Cornell\nUniversity Press.\nVon Frisch, K. (1974). Decoding the language of bees. Science, 185, 663\u2013668.\nWhorf, B. L. (1956a). Language, thought, and reality: Selected writings of Benjamin Lee Whorf. New\nYork: Wiley.\nWhorf, B. L. (1956b). Science and linguistics. In J. B. Carroll (Ed.), Language, thought and reality:\nSelected writings of Benjamin Lee Whorf (pp. 207\u2013219). Cambridge, MA: MIT Press. Chapter 5: Learning to Speak\nLearning Objectives\n\u2022 Describe the stages of language development in children.\n\u2022 Explore the theories associated with language development.\n\u2022 Understand how the development of creoles from pidgins influence our understanding of the\nlanguage acquisition device.\nThe mystery of language acquisition was tackled by philosophers and linguists from ancient times.\nPlato proposed that words mapped onto objects in the external world from some innate knowledge.\nSanskrit grammarians debated on whether the semantics of a word came from innate knowledge or\ntradition passed on from one generation to the next (Matilal, 1990).\nIn The Twilight Zone episode \u201cMute\u201d (1963), several children are raised without exposure to language\nin an effort to foster telepathic abilities. It may surprise you to know that such experiments have\nactually been carried out, albeit not to foster telepathy but to study language acquisition. This\nexperiment is now known as \u201cthe forbidden experiment\u201d (Shattuck, 1980\/1994).\nHerodotus (ca. 485 \u2013 425 BCE) reports in his Histories (II.2 \u201cAn Account of Egypt\u201d) the Egyptian\npharaoh Psamtik I carried out an experiment where a child was brought up without exposure to\nlanguage in an effort to see what they spoke. The hypothesis being that whatever words came out\nwould be the primordial language. They apparently concluded that the original language of humanity\nwas Phrygian because the child said bekos, the Phrygian word for bread. Salimbene di Adam in his\nChronicles reports a similar experiment carried out by the Holy Roman Emperor Frederick II in the\n13th century. James IV of Scotland did a similar experiment where the child apparently spoke good\nHebrew.\nWhile these previous experiments seem to be based on the assumption that some original language\nwould emerge from the subjects, an alternative hypothesis was postulated by the Mughal emperor\nAkbar. He claimed that language came from hearing and a similar experiment by his found the child to\nbe mute (Campbell & Grieve, 1981). Such experiments are obviously highly unethical and should not\nbe attempted under any circumstances.\nFrom the descriptions above, you may have discerned two major themes: language acquisition as innate\nand as a socially acquired skill. The former was supported by rationalists such as Plato and Descartes\nwhile the latter was adopted by empiricists such as Locke and Hume. Locke (1690\/1975) argued that\nknowldeg was acquired from experience with the famous image of the mind as a tabula rasa or blank\nslate onto which experience writes through sensations. The debate is alive and well today with the\n107 108 Chapter 5: Learning to Speak\nempirical camp being supported by the works of Piaget and the rationalist views supported by\nChomsky. Perhaps the most influential voice today in this debate is Chomsky\u2019s. He argued against the\nviews of the Behaviourists who claimed all behaviour was a product of rewards of punishments\n(operant conditioning). B. F. Skinners Verbal Behavior (1957) was perhaps the seminal work of the\nempiricist view on language acquisition. Skinner suggested that the successful use of a sign or symbol\n(such as a word) by a child elicits positive reinforcement from the listening adults resulting in the\nbehaviour of linking the sign with an object more likely. This association of a word with an object gets\nreinforced over time to develop as language. This view was attached by Chomsky (1959) in his review\nof Skinner\u2019s book. He argued that children often ignore language corrections from adults and Skinner\nfails to explain the fundamental role of syntactic knowledge on language competence. 5.1 Language Development\nChomsky and the Poverty of the Stimulus\nChomsky demonstrated that children acquire linguistic rules or grammar without an inexhaustive\nsample of the acquired language. In other words, children cannot learn the rules of grammar by mere\nexposure to a language (Chomsky, 1965). For one thing, children hear an imperfect input. Adult speech\nis full of slips-of-the-tongue, false starts and errors. Sometimes there are contractions such as gonna\nand wanna and words are not necessarily separated in continuous speech. There is also a lack of\nexamples of all the grammatical structures in a language for children to derive all linguistic rules from\nanalysing the input. All of these phenomena are often labelled the \u201cpoverty of the stimulus\u201d (Berwick,\nPietroski, Yankama, & Chomsky, 2011). Poverty of the stimulus is often used as an argument for\nuniversal grammar. This is the claim that all languages have some underlying common structure within\nwhich all surface structures of language emerge.\nLanguage Development\nLanguage development is perhaps one of the greatest mysteries in psycholinguistics. The rapidity of\nfirst language acquisition is astounding to anyone who has tried to learn a second language as an adult.\nThis process can be broadly divided into stages based on the characteristics of the infants\u2019 output.\nHowever, we must note that output doesn\u2019t always assure us a clear picture of the cognitive processes\nthat are going on within the infants\u2019 minds.\nAs seen in Figure 5.1, infants make vegetative sounds from birth. These include crying, sucking noises\nand burps. At around 6 weeks, we start getting cooing sounds followed by vocal play between 16\nweeks and 6 months (Stark, 1986). This vocal play involves sounds that appear similar to speech but\ncontaining no meaning. Babbling is observed between 6 to 9 months. This is different from vocal play\nin that it contains true syllables (generally CV syllables as in \u2018wa wa\u2019 for \u2018water\u2019). Children produce\nsingle-word utterances around 10 to 11 months followed by an extraordinary expansion of\nvocabulary around 18 months. At the same time, we start to get two-word utterances. We also start to\nget telegraphic speech. These are utterances which lack grammatical elements (Brown & Bellugi,\n1964). Grammatically complex utterances emerge around two and a half years.\n109 110 Chapter 5: Learning to Speak\nFigure 5.1 Language Acquisition Milestones\nResearch methods that we can employ with adults is not always possible with infants. One technique is\nthe sucking habituation paradigm. This paradigm measures the rate of sucking an artificial pacifier as\na measure of interest by the infant in a novel stimulus. It has been observed that babies prefer novel\nstimuli as opposed to stimuli that are familiar. If they are presented with habituated (or familiar) stimuli\nand then a novel stimulus pops up, the rate of sucking increases. This can be used to see whether an\ninfant can detect the difference between who stimuli. Another technique is the preferential looking\ntechnique. Here children look longer at scene that are consistent with what they are hearing. Using\nsuch techniques (and others), psycholinguists try to determine at what age children understand the\ndifference between phonemes, morphemes and understand syntax.\nImitation\nThe simplest form of language acquisition would be simple imitation of adult language. While\nchildren do imitate adult behaviour to some extent, this alone cannot account for language\ndevelopment. The sentences produced by children acquiring language do not show imitation of adults.\nChildren often make errors that adults don\u2019t make. However, imitation may play a role in the\nacquisition of accents, speech mannerisms and specialized vocabulary.\nConditioning\nSkinner (1957) argued that language acquisition happens through the same mechanisms of operant\nconditioning that operated on other human and animal behaviour. However, adults generally do not\nencourage children to speak like them. On the contrary, adults often imitate the childish speech of\nchildren when speaking to them. If any correction is made, it is regarding the accuracy of the\nstatements rather than their syntax.\nAnother observation that learning theories cannot predict is the pattern of acquisition of irregular verb\nand noun forms. Saying *gived instead of gave or *gooses instead of geese are some examples of this.\nChildren generally show a pattern of correct imitation of the stem but then incorrect production. These\nincorrect productions are usually because of over-regularization of the past tense or plural forms of the 5.1 Language Development 111\nstems. Finally, children produce the correct forms. This is an example of U-shaped development:\nperformance starting off well, then deteriorating before improving. In essence, language acquisition\nappears to be based on learning rules rather than learning associations.\nThe Language Acquisition Device\nChomsky (1965) argued for the existence of a language acquisition device (LAD). This is\nhypothesized to be an innate structure separate from intellectual ability or cognition. If the poverty of\nthe stimulus is true, then children need something in additional to language exposure to arrive at\nlanguage competency. The language acquisition device was later replaced by the concept of universal\ngrammar. According to this idea, the child has innate rules of inference that enable them to learn a\nlanguage. This would be a set of parameters that constrain and guide language acquisition. As\nlanguages vary in terms of their grammar, syntax and morphology, Chomsky hypothesized that\nlanguage learning was essentially setting parameters using input from exposure to a language that in\nturn set other parameters automatically. In other words, languages cannot vary in any way possible with\ninfinite variety. There are basic parameters that influence each other.\nWe can look at some examples of parameter setting across language. For example, if a language has\nsubject-verb-object (SVO) word order, then question words (what, where, who, how) would come at\nthe beginning of the sentence while a language that is subject-object-verb (SOV) would put them at the\nend.\n\u2022 English (SVO): \u201cWhat is your name?\u201d\n\u2022 Tamil (SOV): \u201c\u0b89\u0b99\u0bcd\u0b95\u0bb3\u0bcd \u0bc6\u0baa\u0baf\u0bb0\u0bcd \u0b8e\u0ba9\u0bcd\u0ba9?\u201d Your name what?\nSome universals may be an innate part of grammar. For example, there is not obvious rationale for\nhaving all SVO languages putting question words at the beginning of their sentences. It is also possible\nthat the external environment in which we evolved may play a role in the development of universals.\nLanguages often note a difference between animate and inanimate object of sentient and non-sentient\nbeings. However, there is some criticism about the idea that true universals, common to all languages,\nmight exist.\nLanguage Development\nAn interactive H5P element has been excluded from this version of the text. You can view it online here:\nhttps:\/\/opentextbc.ca\/psyclanguage\/?p=1265#h5p-23\nLet\u2019s look at the language development of a child born on the 1st of January. Reflect on each stage and\nthe physical and cognitive changes that must occur in order for a child to reach these milestones.\n\u2022 January 1, 2022 \u2014 February 12, 2022, Vegetative Sounds\n\u25e6 Infants make vegetative sounds from birth. These include crying, sucking noises\nand burps. 112 Chapter 5: Learning to Speak\n\u2022 February 12, 2022 \u2014 April 16, 2022, Cooing\n\u25e6 At around 6 weeks, we start getting cooing sounds\n\u2022 April 16, 2022 \u2014 June 30, 2022, Vocal play\n\u25e6 Vocal play is observed between 16 weeks and 6 months. This vocal play involves\nsounds that appear similar to speech but containing no meaning.\n\u2022 June 30, 2022 \u2014 September 30, 2022, Babbling\n\u25e6 Babbling is observed between 6 to 9 months. This is different from vocal play in\nthat it contains true syllables (generally CV syllables as in \u2018wa wa\u2019 for \u2018water\u2019).\n\u2022 October 1, 2022 \u2014 November 30, 2022, Single-word utterances\n\u25e6 Children produce single-word utterances around 10 to 11 months\n\u2022 November 30, 2022 \u2014 June 1, 2023, Two-word utterances\n\u25e6 An extraordinary expansion of vocabulary occurs around 18 months. At the same\ntime, we start to get two-word utterances.\n\u2022 June 1, 2023 \u2014 January 1, 2024, Telegraphic speech\n\u25e6 We start to get telegraphic speech around the second year. These are utterances\nwhich lack grammatical elements.\n\u2022 January 1, 2024 \u2014 June 30, 2024, Full sentences\n\u25e6 Grammatically complex utterances emerge around two and a half years.\nNavigate to the above link to view the interactive version of this timeline.\nMedia Attributions\n\u2022 Figure 5.1 Language Acquisition Milestones by Dinesh Ramoo, the author, is licensed under\na CC BY 4.0 licence. 5.2 Pidgins and Creoles\nA pidgin language is a grammatically simplified communication method. It usually develops when two\nor more groups have to develop a system of communication when a common language doesn\u2019t exist. It\nis common when communities come together for trade and they are not considered complete languages.\nPidgins are not native to any speech community. It is built from the words and sounds from a number\nof languages with a limited core vocabulary.\nPidgins usually have the following characteristics:\n\u2022 Their morphology is usually isolating\n\u2022 They tend not to have complicated phrase structures\n\u2022 Syllables tend to be simple and often lack codas\n\u2022 Consonant clusters are simplified\n\u2022 Linguistic characteristics such as gender and number (singular and plural) are excluded\nAs Canada has a long history of contact between various language communities, it has had a large\nshare of pidgins developing over the centuries. To facilitate transactions between their communities,\nthe Inuvialuit, or Mackenzie River Inuit, and the Indigenous Athabaskan speakers used an Inuit trade\njargon. Inuktitut-English Pidgin was used in Quebec and Labrador. Algonquian\u2013Basque pidgin was\nused by Basque whalers and Algonquin communities the Gulf of Saint Lawrence up to the 1710s.\nLabrador Inuit Pidgin French was a pidgin heavily influenced by French and spoken in Labrador\nuntil the 1760s.\nThe reason we are discussion pidgins here is to explore the extraordinary drive towards language in\nhuman beings. While pidgins exist as second languages for adult speakers, if the children of those\nadults are exposed to a pidgin, they do not grow up speaking it. Instead, they develop a complete\nlanguage known as creole. A creole is a pidgin language that has become the native language of the\nchildren of adult pidgin speakers. Unlike the simplified pidgins, creoles are syntactically rich and\ncomplete languages. This indicates that human beings have some in-build language mechanism that can\ndevelop a language with the mere exposure to linguistic structures. A creole that developed Scottish\nRed River M\u00e9tis in present-day Manitoba is Bungi Creole. It developed from pidgins of Scottish\nEnglish, Scottish Gaelic, French, Norn, Cree, and Ojibwe.\nMichif is another example of a fully developed creole language. Michif combines Cree and M\u00e9tis\nFrench with words borrowed from English, and some neighbouring Indigenous languages. Michif noun\nphrase phonology, lexicon, morphology, and syntax as well as articles, adjectives are derived from\nM\u00e9tis French. Its verb phrase phonology, lexicon, morphology and syntax as well as demonstratives are\nfrom Cree.\nExploring the emergence of creoles from pidgins show the inherent instinct for language in human\nbeings. If language is merely a socially transmitted communication system, then children could grow\n113 114 Chapter 5: Learning to Speak\nup speaking pidgin as their language. The fact that they develop a complete syntactically rich language\neven when exposed to pidgins suggests an internal language acquisition mechanism that takes in the\ninput of linguistic structures and develops it into a language using some universal grammar. Summary\nKey Takeaways\n\u2022 Language acquisition has been studied extensively, but there are many mysteries to this subject.\n\u2022 The two main sides of the language acquisition debate are the rationalists and the empiricists.\n\u2022 The rationalists claim language has (at least to some extent) some innate structures independent\nof experience\n\u2022 The empiricists claim that language is acquired from exposure to linguistic input from the\nenvironment\n\u2022 Chomsky introduced the idea that children do not receive enough input and samples of a language\nto learn linguistic rules by mere exposure (the poverty of the stimulus)\n\u2022 The concept of innate structures (either a language acquisition device or universal grammar) is\nsupported by the development of creoles as complete languages from children\u2019s exposure to\npidgin\n115  References\nBerwick, R. C., Pietroski, P., Yankama, B., & Chomsky, N. (2011). Poverty of the stimulus revisited.\nCognitive Science, 35, 1207\u20131242.\nBrown, R., & Bellugi, U. (1964). Three processes in the acquisition of syntax. Harvard Educational\nReview, 34, 133\u2013151.\nCampbell, R. N. & Grieve, R. (1981). Royal investigations of the origin of language. Historiographia\nLinguistica 9(1-2), 43-74.\nChomsky, N. (1959). A review of B. F. Skinner\u2019s \u201cVerbal behavior\u201d. Language. 35(1), 26\u201358.\nChomsky, N. (1965). Aspects of the theory of syntax. Cambridge, MA: MIT Press.\nLocke, J. (1690). Essay concerning human understanding (Ed. P. M. Nidditch, 1975). Oxford:\nClarendon.\nMatilal, Bimal Krishna (1990). The word and the world: India\u2019s contribution to the study of language.\nOxford: Oxford University Press.\nShattuck, Roger (1980\/1994). The forbidden experiment: The story of the wild boy of Aveyron.\nKodansha International.\nSkinner, B. F. (1957). Verbal behavior. New York: Appleton-Century-Crofts.\nStark, R. E. (1986). Prespeech segmental feature development. In P. Fletcher & M. Garman (Eds.),\nLanguage acquisition (2nd ed., pp. 149\u2013173). Cambridge: Cambridge University Press.\n117  Chapter 6: Bilingualism\nLearning Objectives\n\u2022 Understand the definitions for bilingualism and its variations.\n\u2022 Discuss the advantages of bilingualism.\n\u2022 Elaborate the evidence for and against bilingual language models.\nBilinguals are people who are fluent in two languages. It is not particularly necessary for bilinguals to\nbe equally fluent in both languages. Fluency need not to be a binary classification but rather a\ncontinuum. While people often speak of first language or mother tongue and second language,\npsycholinguists refer to the language learned first as L1 and the language learned after that as L2.\nSometimes the language learned second may become the primary language of use in everyday life and\nthe language learned first may become the secondary language in later life. Bilingualism can also be\ncategorised as follows:\n\u2022 Simultaneous bilingualism: L1 and L2 learned simultaneously\n\u2022 Early sequential bilingualism: L1 is learned first and L2 is learned in childhood\n\u2022 Late sequential bilingualism: L1 is learned first and L2 is learned in adolescence or later\nBilingualism is not always a matter of choice. Some societies have a history of attempting to impose a\nlanguage on others. In others, one language may be held as having higher prestige or allowing for\nbetter opportunities. On the other hand, bilingualism (or multilingualism) was the norm throughout\nmost of human history until the rise of linguistically and ethnically divided states in Europe. Most\nhuman beings lived in multilingual societies or used one language in common use while learning\nanother as a language of higher education (as with Latin in Europe, Sanskrit in India, Classical Chinese\nin China and English in the modern world).\n119  6.1 The Advantages of Bilingualism\nBilingualism doesn\u2019t appear to have any linguistic disadvantages (Snow, 1993). There have be cases of\ninitial delay in vocabulary acquisition in one language but this soon passes. Bilinguals tend to have a\nslight deficit in working memory tasks in L2. However, they have greater metalinguistic awareness and\nverbal fluency (Ben-Zeev, 1977; Bialystock, 2001; Cook, 1997). For example, children in Canadian\nFrench immersion programs tended to score highly on creativity tests than monolinguals (Lambert,\nTucker & d\u2019Anglejan, 1973).\nBeing a bilingual gives you the awareness that words are arbitrary symbols for things. There are some\nresearchers who have found interference between L1 and L2 (Harley & Wang, 1997). However, there\nis evidence to suggest that bilingualism provides a general cognitive advantage. There is even some\ndata that indicates that bilingualism protects individuals from the development of Alzheimer\u2019s disease\nby slowing down cognitive aging (Bialystok, Craik, & Luk, 2012).\n121  6.2 Bilingual Language Processing\nThe issue of how we switch between two languages is an interesting topic for bilingual research. Kroll\nand Stewart (1994) proposed a model of asymmetric translation between L1 and L2. The Word\nAssociation Model (see Figure 6.1) has the L1 word directly associated with its L2 equivalent. In order\nto access the concept of a word, L2 words must first activate their L1 equivalent.\nFigure 6.1 Word Association Model\nIn contrast to this, the Concept Mediation Model (see Figure 6.2) has words in L1 and L2 directly\nassociated with the concepts. However, there are no direct links between the words in L1 and L2. Potter\net al. (1984) tested these models by comparing the time it took bilinguals to translate between L1 and\nL2 and L2 picture-naming. The assumption is that picture naming requires conceptual processing. The\nWord Association Model predicts that picture-naming in L2 should take longer than translation as it has\ntwo steps (link to L1 and then link to the concept). The Concept Mediation Model on the other hand\npredicts that both tasks should take more or less the same amount of time as the concept is linked to the\nwords in L1 and L2. The results favoured the Concept Mediation Model.\n123 124 Chapter 6: Bilingualism\nFigure 6.2 Concept Mediation Model\nKroll and Curley (1988) and Chen and Leung (1989) replicated the results of Potter et al. (1984) using\nparticipants of lower proficiency in L2. They found that learners at an earlier stage of acquisition were\nquicker in translation from L1 to L2 than L2 picture-naming. This supported the Word Association\nModel. While Kroll and Curley (1988) and Chen and Leung (1989) did replicate the findings of Potter\net al. (1984) for highly proficient bilinguals, they did identify a transition phase which relied on\ntranslating between L1 and L2 with possible mediation of the concept. Therefore, Kroll and Stewart\n(1994) proposed the Revised Hierarchical Model (see Figure 6.3) which integrated the connections\nfrom the Word Association Model and the Concept Mediation Model.\nFigure 6.3 The Revised Hierarchical Model\nThe Revised Hierarchical Model make two assumptions:\n1. L1 words are more strongly connected to concepts than L2 words, and\n2. L2 words are more strongly connected to their translations in L1 than vice versa.\nAs learners become more proficient in L2, they begin to develop the ability to process L2 words\ndirectly. However, the connections for L1 remain stronger than for L2. 6.2 Bilingual Language Processing 125\nMedia Attributions\n\u2022 Figure 6.1 Word Association Model by Dinesh Ramoo, the author, is licensed under a CC BY\n4.0 licence.\n\u2022 Figure 6.2 Concept Mediation Model by Dinesh Ramoo, the author, is licensed under a CC\nBY 4.0 licence.\n\u2022 Figure 6.3 The Revised Hierarchical Model by Dinesh Ramoo, the author, is licensed under\na CC BY 4.0 licence.  6.3 Models of Bilingualism\nThe most influential model of bilingualism is the Bilingual Interactive Activation Plus (BIA+) model\n(Dijkstra & van Heuven, 2002; Dijkstra, van Heuven, & Grainger, 1998). The model tries to bring\ntogether evidence from bilingual orthographic processing as well as the recognition of words that look\nthe same in two languages (cognates). The model is composed of a network of nodes at every level of\nrepresentation from segmental (orthographic\/phonemic), sub-lexical, to lexical. As seen in Figure 6.4,\nthe model is bottom-up. Word recognition isn\u2019t affected by whether the task is naming or reading.\nFigure 6.4 The Bilingual Interactive Activation Plus (BIA+) model [Image description]\nThe model assumes a distinction between word identification and task-based sub-systems. The lexicon\nis integrated with parallel access as well as temporal decay of L2. This decay is based on the\nassumption that word frequency affects the resting potential of the nodes for particular words. The\nmodel is supported by neuroimaging studies. The Semantic, Orthographic, Phonological Interactive\nActivation (SOPHIA) model is the implemented version of the BIA+ model. It adds phonology and\nsemantics with layers for letters\/phonemes, clusters\/ syllables\/words and semantics. In SOPHIA, the\nlanguage nodes no longer inhibit the non-target language. The model still uses orthographic\ninformation as input.\n127 128 Chapter 6: Bilingualism\nFigure 6.5 The Semantic, Orthographic, Phonological Interactive Activation (SOPHIA) model [image\ndescription]\nImage description\nFigure 6.4 The Bilingual Interactive Activation Plus (BIA+) model\nThe BIA+ model is composed of three levels of representation. From bottom up the levels are\northographic or phonological features, followed by sub-lexical units, and then lexical orthography or\nlexical phonology, eventually lead to the semantic meaning of the language.\n[Return to place in the text (Figure 6.4)]\nFigure 6.5 The Semantic, Orthographic, Phonological Interactive Activation (SOPHIA) model\nThe SOPHIA model is composed of four layers of representation. From bottom up, the first layer of\nrepresentation is letters or phonological features, followed by orthographic or phonological clusters,\nthen orthographic or phonological syllables, and moving up to orthographic or phonological words,\nthen eventually lead to the semantic meaning of the language.\n[Return to place in the text (Figure 6.5)]\nMedia Attributions\n\u2022 Figure 6.4 The Bilingual Interactive Activation Plus (BIA+) model by Dinesh Ramoo, the\nauthor, is licensed under a CC BY 4.0 licence.\n\u2022 Figure 6.5 The Semantic, Orthographic, Phonological Interactive Activation (SOPHIA)\nmodel by Dinesh Ramoo, the author, is licensed under a CC BY 4.0 licence. 6.4 Second Language Acquisition\nSecond language acquisition is the attempt to acquire a language while already competent in another.\nThere is a distinction between a child being naturally exposed to two languages and a child or adult\nlearning in a classroom setting. In terms of second language acquisition itself, linguistic structures such\nas syntax may be harder to grasp after a critical period. People also have less time and motivation to\npursue language learning in earnest. In addition, the contrasts between L1 and L2 may aid or hinder\nacquisition. Generally, the more different L2 is from L1 in some feature, the more difficult it will be to\nlearn.\nInitial learning of L2 is good and then declines before the learner becomes more proficient\n(McLaughlin & Heredia, 1996). This decline is explained by the substitution of less complex internal\nrepresentations with more complex ones. For example, the learner acquires the use of syntactic rules as\nopposed to repeating sentences by rote. The traditional method for second language teaching is based\non translating from one language into another. On the other hand, direct learning involves learning\nconversational skills in L2. Some methods prefer speaking and listening over reading and writing.\nImmersive learning is a technique where all learning is conducted in L2.\nIn addition to various teaching methods, the characteristics of the individual learner also play a role in\nsecond language acquisition. Carroll (1981) identified four sources of variations:\n\u2022 Phonetic coding ability: the ability to identify new phonemes in L2\n\u2022 Grammatical sensitivity: the ability to recognise words in terms of their grammatical function\n\u2022 Rote learning ability: the ability to learn through memorization and recall\n\u2022 Inductive leaning ability: the ability to infer linguistic rules from the language\nPidgins and Creoles of Canada\nMichif\nThe language of the M\u00e9tis people of Canada and the United States. The M\u00e9tis people are descendants\nof European fur traders (mainly French and Scottish) and First Nations women (mainly Cree, Nakota,\nand Ojibwe). It emerged in the 19th century as a mixed language. Michif is a mixture of Cree and\nFrench with additional borrowings from English, Ojibwe and Assiniboine. It has the noun phrase\nphonology, lexicon, morphology, and syntax of French and the verb phrase phonology, lexicon,\nmorphology, and syntax of Plains Cree.\n\u2022 Native to\n\u25e6 Canada\n\u2022 Region\n\u25e6 Manitoba, Alberta, Saskatchewan and Northwestern Ontario, Turtle Mountain\n129 130 Chapter 6: Bilingualism\nIndian Reservation in North Dakota\n\u2022 Native speakers\n\u25e6 730\n\u2022 Language family\n\u25e6 Mixed Cree\u2013M\u00e9tis French\n\u2022 Language codes\n\u25e6 ISO 639-3: crg\n\u25e6 Glottolog: mich1243\n\u25e6 ELP: Michif\nLabrador Inuit Pidgin French\nA French Pidgin spoken by Breton and Basque fisherman and the Inuit of Labrador.\n\u2022 Native to\n\u25e6 Canada\n\u2022 Region\n\u25e6 Straits of Belle Isle\n\u2022 Native speakers\n\u25e6 Extinct\n\u2022 Language family\n\u25e6 French Pidgin\n\u2022 Language codes\n\u25e6 ISO 639-3: None\n\u25e6 Glottolog bell: 1264\n\u25e6 ELP: None\nChiac\nA variety of Acadian French noted for its code-mixing with English, archaic phrases from Middle\nFrench and loan words from the Eastern Algonquian languages.\n\u2022 Native to\n\u25e6 Canada\n\u2022 Region\n\u25e6 Maritime provinces, mainly in southeastern New-Brunswick\n\u2022 Native speakers 6.4 Second Language Acquisition 131\n\u25e6 Unknown\n\u2022 Language family\n\u25e6 Indo-European\n\u2022 Language codes\n\u25e6 ISO 639-3: None\n\u25e6 Glottolog bell: none\n\u25e6 ELP: None\n\u25e6 Linguasphere: 51-AAA-am\nBungi dialect\nA dialect of English influenced by Scottish English, the Orcadian dialect of Scots, Norn, Scottish\nGaelic, French, Cree, and Ojibwe. Spoken in modern-day Manitoba. In 1870, about 5,000 M\u00e9tis were\nnative speakers of Bungi but it has diminished to only a few speakers today making it potentially\nextinct.\n\u2022 Native to\n\u25e6 Canada\n\u2022 Region\n\u25e6 Red River Colony and Assiniboia, present-day Manitoba\n\u2022 Native speakers\n\u25e6 approximately 5,000 in 1870; estimated less than 200 in 1993; possibly extinct\n\u2022 Language family\n\u25e6 Indo-European\n\u2022 Language codes\n\u25e6 ISO 639-3: None\n\u25e6 Glottolog: None\n\u25e6 ELP: None\nSlavey Jargon\nA traders language used in the Yukon region. This pidgin is based on the Slavey language with\nelements from French, Cree as well as aspects of English. The nouns generally consist of English,\nChipewyan, and Slavey and the verbs and pronouns are from French.\n\u2022 Native to\n\u25e6 Canada\n\u2022 Region 132 Chapter 6: Bilingualism\n\u25e6 Yukon (Liard and Mackenzie rivers)\n\u2022 Native speakers\n\u25e6 Extinct\n\u2022 Language family\n\u25e6 Slavey-based pidgin\n\u2022 Language codes\n\u25e6 ISO 639-3: None\n\u25e6 Glottolog: brok1250\n\u25e6 ELP: None\nAlgonquian\u2013Basque pidgin\nA pidgin based on Basque and Algonquin spoken around the Gulf of Saint Lawrence. It was last\nrecored in the early 18th century.\n\u2022 Native to\n\u25e6 Canada\n\u2022 Region\n\u25e6 Gulf of Saint Lawrence\n\u2022 Native speakers\n\u25e6 Extinct since the 18th century\n\u2022 Language family\n\u25e6 Basque-based pidgin\n\u2022 Language codes\n\u25e6 ISO 639-3: None\n\u25e6 Glottolog: basq1252\n\u25e6 ELP: None\nChinook Jargon\nA language originating from a pidgin trade language in the Pacific Northwest. It is partially descended\nfrom Chinook with loan words from French and English. British Columbian English and Pacific\nNorthwest English have several words still in current use which are loanwords from the Chinook\nJargon.\n\u2022 Native to\n\u25e6 Canada, United States\n\u2022 Region 6.4 Second Language Acquisition 133\n\u25e6 Pacific Northwest (Interior and Coast): Alaska, British Columbia, Washington\nState, Oregon, Idaho, Montana, Northern California\n\u2022 Native speakers\n\u25e6 More than 640 with at least 3 native speakers\n\u2022 Language family\n\u25e6 Wakashan, Chinookan, and Indo-European\n\u2022 Language codes\n\u25e6 ISO 639-3: chn\n\u25e6 Glottolog: pidg1254, chin1272\n\u25e6 ELP: Chinook Wawa  Summary\nThis chapter explored the definition of bilingualism in its various forms. It also considered the\nadvantages and disadvantages of bilingualism and various models for translating between L1 and L2.\nWe also looked at computational models for bilingual reading and auditory comprehension. Finally, we\nexplored some of the evidence-based methods for second language learning.\nKey Takeaways\n\u2022 Bilingualism is the ability to be fluent in two languages.\n\u2022 Second language acquisition becomes harder after the critical period of language acquisition has\npassed.\n\u2022 Whether we translate between words within our mental lexicon is still a matter of debate.\nExercises in Critical Thinking\n1. Consider the advantages and disadvantages of using more than one language.\n2. If you are bilingual, think of instances where you found it easier to come up with a term in one\nlanguage and not the other. Was it your L1 or L2?\n3. How would you go about teaching a new language to a two-year-old versus a 20-year-old?\n135  References\nBen-Zeev, S. (1977). The influence of bilingualism on cognitive strategy and cognitive development.\nChild Development, 48, 1009\u20131018.\nBialystock, E. (2001). Metalinguistic aspects of bilingual processing. Annual Review of Applied\nLinguistics, 21, 169\u2013181.\nBialystok, E., Craik, F. I. M., & Luk, G. (2012). Bilingualism: Consequences for mind and brain.\nTrends in Cognitive Sciences, 16, 240\u2013250.\nBickerton, D. (1981). Roots of language. Ann Arbor, MI: Karoma.\nBickerton, D. (1984). The language bioprogram hypothesis. Behavioral and Brain Sciences, 7,\n173\u2013221.\nCarroll, J. B. (1981). Twenty-five years of research on foreign language aptitude. In K. C. Diller (Ed.),\nIndividual differences and universals in language learning aptitude (pp. 83\u2013118). Rowley, MA:\nNewbury House.\nChen, H.-C., & Leung, Y.-S. (1989). Patterns of lexical processing in a nonnative language. Journal of\nExperimental Psychology: Learning, Memory, and Cognition, 15, 316\u2013325.\nCook, V. (1997). The consequences of bilingualism for cognitive processing. In A. M. B. de Groot & J.\nF. Kroll (Eds.), Tutorials in bilingualism: Psycholinguistic perspectives (pp. 279\u2013299). Mahwah, NJ:\nLawrence Erlbaum Associates, Inc.\nDijkstra, A., & Van Heuven, W. J. B. (2002). The architecture of the bilingual word recognition system:\nFrom identification to decision. Bilingualism: Language and Cognition, 5, 175\u2013197.\nDijkstra, T., van Heuven, W. J. B., & Grainger, J. (1998). Simulating cross-language competition with\nthe bilingual interactive activation model. Psychologica Belgica, 38, 177\u2013196.\nHarley, B., & Wang, W. (1997). The critical period hypothesis: Where are we now? In A. M. B. de\nGroot & J. F. Kroll (Eds.), Tutorials in bilingualism: Psycholinguistic perspectives (pp. 19\u201351).\nMahwah, NJ: Lawrence Erlbaum Associates, Inc.\nKroll, J. F., & Curley, J. (1988). Lexical memory in novice bilinguals: The role of concepts in\nretrieving second language words. In M. Gruneberg, P. Morris, & R. Sykes (Eds.), Practical aspects\nof memory (Vol. 2, pp. 389\u2013395). London: Wiley.\nKroll, J. F., & Stewart, E. (1994). Category interference in translation and picture naming: Evidence for\nasymmetric connections between bilingual memory representations. Journal of Memory and\nLanguage, 33, 149\u2013174.\n137 138 Chapter 6: Bilingualism\nLambert, W., Tucker, G., & d\u2019Anglejan, A. (1973). Cognitive and attitudinal consequences of bilingual\nschooling. Journal of Educational Psychology, 65, 141-159.\nMcLaughlin, B., & Heredia, R. (1996). Information processing approaches to research on second\nlanguage acquisition and use. In W. C. Ritchie & T. K. Bhatia (Eds.), Handbook of second language\nacquisition (pp. 213\u2013228). London: Academic Press.\nPotter, M. C. (1979). Mundane symbolism: The relations among objects, names, and ideas. In N. R.\nSmith&M. B. Franklin (Eds.), Symbolic functioning in childhood (pp. 41\u201365). Hillsdale, NJ:\nErlbaum.\nSnow, C. E. (1993). Bilingualism and second language acquisition. In J. B. Gleason & N. B. Ratner\n(Eds.), Psycholinguistics (pp. 391\u2013416). Fort Worth, TX: Harcourt Brace Jovanovich. Chapter 7: Visual Language\nLearning Objectives\n\u2022 Describe the nature of different writing systems\n\u2022 Differentiate the rules that govern grapheme-to-phoneme conversion\n\u2022 Describe the standard reading model as a basis for further exploration\nIn this chapter we will explore the basics of the written word. Writing involves the representation of\nlanguage with written symbols. A system of writing is not in itself a language. It is a way to render\nlanguage in a manner that is retrievable across space and time. Writing is not a natural part of language\nand most languages have not had a writing system for most of their history. We will not explore the\nhistory of writing in much detail. We will however look at some prominent writing systems that will\ngive you some idea about how it may have developed in human societies. Look through the sentences\nbelow and think of how they differ from one another. Each of them represents a different writing\nparadigm which we will be exploring.\n139 140 Chapter 7: Visual Language\nFigure 7.1 The Universal Declaration of Human Rights in Different Scripts\nMedia Attributions\n\u2022 Figure 7.1 The Universal Declaration of Human Rights in Different Scripts by Dinesh Psychology of Language 141\nRamoo, the author, is licensed under a CC BY 4.0 licence.  7.1 Writing Systems\nWe are already familiar with the concept of the phoneme as a basic unit of sound in a language from\nthe second chapter. We often think of a writing system of a language as consisting of letters. However,\nfor our purposes here, we will use the term grapheme to refer to the smallest unit of writing. A\ngrapheme is a letter or combination of letters that represent a phoneme. Just as we use the forward\nslashes \/\/ to indicate phoneme as use the less than and greater than symbols < > to indicate graphemes.\nFor example, the word \u2018dog\u2019 has three phonemes <d>, <o> and <g> that correspond to three phonemes.\nThat seems pretty straightforward. Now think of the word \u2018ship.\u2019 The <i> and <p> represent two\nphonemes but the <sh> combine to form a grapheme to represent the voiceless palato-alveolar fricative\n\/\u0283\/. This phoneme is different from a grapheme in that different languages use different graphemes to\nindicate it. For example, Basque <x>, Turkish, Azerbaijani, Romanian <\u015f>, French <ch>, Shuswap\n<s>, and German <sch>.\nThe examples we saw in terms of graphemes will be familiar to English speakers as they are all from\nalphabets. In alphabets, the basic correspondence for a grapheme is a phoneme. This is not the case for\nother writing systems. In addition, not all languages have a transparent connection between graphemes\nand phonemes. Italian and Spanish tend to be transparent while English and French tend not to be so\nclear in how the graphemes represent phonemes. For example, think of the variations for the grapheme\n<a> in the words \u2018apple,\u2019 \u2018father,\u2019 and \u2018gate.\u2019 There are also writing systems where graphemes\nrepresent not phonemes but syllables, morphemes or even words. As you will see, these variations have\nimplications for psycholinguistic models as most research is done in languages with alphabetic writing\nsystems.\nLogography\nThe earliest writing systems in the world developed from logograms. In this type of writing system,\neach grapheme represents a word or morpheme. Examples of logographic systems include Chinese\ncharacters, Egyptian hieroglyphs, and Sumerian cuneiforms. You can imagine how it would be\nimpractical to have a separate symbol for every word or morpheme. Therefore, these systems take\nadvantage of the rebus principle. For example, in English the word \u2018bee\u2019 and \u2018leaf\u2019 can be represented\nwith separate pictures as graphemes. However, when it comes to writing \u2018belief,\u2019 instead of creating\nanother picture, we could combine the two pictures to for BEE+LEAF which can be sounded out when\nreading. A modern development of a logographic system would be the use of emojis. However, emojis\nare not formalized for any language and so cannot act as a writing system on their own.\nThere are some interesting examples of logographic writing systems in Canada. Examples include the\nOjibwe wiigwaasabakoon. These are bark scrolls with symbols now known as Ojibwe hieroglyphs.\nThey have not been deciphered although it is said that some elders still know what they mean (Geniusz,\n2009). They are supposed to contain songs and details of religious rituals and medicine. Another\nexample is the Mi\ua78ckmaw hieroglyphic writing system used in the east coast and islands of Canada.\nThese are known as komqwejwi\u2019kasikl, or \u201csucker-fish writings\u201d as they resemble the tracks left on the\n143 144 Chapter 7: Visual Language\nmud by sucker fish. It is possible that they evolved from mnemonic symbols that were used to aid in\nrecalling information. As seen in the example in Figure 7.2 from 1880, later missionaries used the\nsystem to write prayers while they also destroyed older scrolls that contained information from the\nMi\ua78ckmaw religion.\nFigure 7.2 The Lord\u2019s Prayer in Mi\ua78ckmaw Hieroglyphs\nSyllabary\nWhile a logogram represents an entire word or morpheme, a syllabary is a system where a grapheme\nrepresents an entire syllable. Typically, syllabaries use a system whereby there are symbols for\nindividual vowels and consonant-vowel combinations. In most syllabaries, phonetically related\nsyllables would not look similar. For example, the grapheme for \/pa\/ would not look similar to the\ngrapheme for \/pi\/. Syllabaries are quite natural in that they represent the smallest units of articulation.\nSyllabaries are generally used by languages that have relatively simple syllable structures. Examples of\nsyllabaries include the hiragana and katakana syllabaries used for Japanese and Linear B used for\nMycenaean Greek. An amazing example of a syllabary being invented is the Cherokee syllabary\n(Figure 7.3) invented by Sequoyah in the 1810s to 1820s. While the graphemes were borrowed from\nthe symbols seen by Sequoyah in European alphabets, they represent different phonemes and unlike 7.1 Writing Systems 145\nEuropean writing systems, it is a true syllabary. The stories about Sequoyah\u2019s extraordinary\nachievement is that he attempted to create graphemes for each word. Finding this too difficult, he went\non to develop graphemes for each syllable. It was so successful that it led to the Cherokee Nation\u2019s\nliteracy rate in the 1830s surpassed that of European settlers.\nFigure 7.3 Cherokee Syllabary\nAbjad\nSyllabaries seem a very natural way to represent spoken language in writing. They are easily\ndiscernable as they represent the smallest unit of articulation. However, some of the earliest systems of\nwriting invented by mankind may appear quite unusual. These are abjads which only have symbols for\nconsonants and not vowels. Why might this be? Try the following exercise.\nLiving Language\nConsider the language that you speak and think of the various dialects that might exist for it. In English, for\nexample, you can think of how people speak in Western parts of North America versus the East Coast. Now\ncompare these against the dialects of English in the United Kingdom, Australia, India, and New Zealand.\nNow in imagining how these dialects sound (you can look at some movie clips from various regions), what\nare the phonemes that are common across them. Do they change a lot in terms of consonants or vowels?\nIf you went through this exercise, you will realize that vowels tend to be the most varied across dialects\nof a language. While it may seem natural to us to write vowels down, think of how a person coming up 146 Chapter 7: Visual Language\nwith a system to represent sounds would approach it. As long as you have only a few vowels in your\nlanguage, you can get the gist of the word by simply writing the consonants. Such systems were used\nby the people of Ancient Egypt which may have influenced the Phoenicians. The Phoenician abjads\nlead to Hebrew and Arabic abjads as well as the eventual invention of the alphabet by the Ancient\nGreeks. As in most writing systems, abjads don\u2019t always remain true to their definition and often\nemploy diacritic marks and some consonant graphemes to represent vowels in some contexts.\nFigure 7.4 The Persian Writing System\nFigure 7.4 gives some examples of the Persian abjad system. Persian has adapted the Arabic abjad to\nrepresent its own unique sound inventory. As vowels are quite prominent, Persian employs the aleph\nsymbol from Arabic (originally used to represent a glottal consonant) for vowels. The difference\nbetween short and long vowels is indicated by adding a particular consonant for long vowels. Finally,\nwe see a complete word (written right-to-left) with just consonants. Sometimes, diacritics are employed\nto indicate geminates (overly long consonants). The word itself is a Arabic word (ma\u1e25abba) adapted\ninto Persian as \/moh\u00e6bb\u00e6t\/ as well as Urdu and Hindi \/muhabbat \/.\nAlphabet\nWe saw in Chapter 2 that syllables are the smallest units of articulation. Therefore, it is quite natural to\nrepresent syllables and words in writing. The alphabet, which represents individual vowels and\nconsonants with separate graphemes is a unique invention of the Ancient Greeks. Taking the abjad\nsystem of the Phoenicians, the Greeks adapted it to represent their own language at around the 8th\ncentury. As vowels played a more prominent role in Greek, they needed to indicate them with new\nsymbols. The Greek alphabet is the ancestor of all modern European scripts. This is either through its\nadoption by the Romans for Latin (in the West) and Cyrillic (in the East). Canadian examples of 7.1 Writing Systems 147\nalphabets include Secwepemc (Secwepemcts\u00edn), Squamish (S\u1e35wx\u0331 w\u00fa7mesh sn\u00edchim), Thompson \/\nNlaka\u2019pamux (N\u0142e\u0294kepmxc\u00edn), Okanagan (n\u0313 s\u0259l\u0313xcin\u0313 ) and Algonquin (Anicin\u00e2bemowin).\nAbugida\nUnlike an alphabet where the consonant and vowel share equal prominence, an abugida uses segments\nof consonant-vowel sequences where the consonant is prominent when preceding a vowel. The vowel\nis usually indicated by secondary notations. This may sound like a syllabary. However, unlike\nsyllabaries, abugida segments can be split into consonants and vowels. In addition, similar segments\nshare visual features.\nMost of the writing systems of South Asia, Southeast Asia and Tibet are abugidas. This system is also\nprevalent in Ethiopian and the Canadian Aboriginal syllabics. Figure 7.5 gives an example of an\nabugida in the form of the Devanagari script used to write Sanskrit, Hindi, Marathi, and Nepali.\nGenerally, you find separate graphemes for individual vowels and consonants. All consonant grapheme\nare pronounced with an inherent schwa vowel. If a consonant is followed by a vowel, then it is not\nwritten with the primary symbol (as in an alphabet), but with a secondary notation that can appear\nbefore, after, under or above the consonant\u2019s grapheme. This is all well and good for simple CV\nsyllables, but what about more complicated syllable structure and syllables that end with a consonant?\nVarious strategies are employed for these scenarios. One is to fuse two consonant graphemes together\nto form the complex structure (as in the examples for \/tr\/ and \/kj\/). We can see that sometimes this\nfusion results in a new symbol (as in \/tr\/) or the graphemes for each consonant remain more or less the\nsame (as in \/kj\/). Another method employed In Hindi is that the final vowel in a word is intuitively\ndeleted based on context. In other languages (for example Sanskrit), there is a special vowel nullifier\nthat is used to indicate that the inherent vowel should not be pronounced.\nFigure 7.5 The Devanagari Writing System\nFigure 7.6 gives us a nice comparison between alphabets, syllabaries and abugidas. The alphabet is the\nLatin script used in English or Secwepemc. Each consonant and vowel have a separate grapheme. 148 Chapter 7: Visual Language\nHowever, while in Secwepemc each grapheme represents a phoneme, in English they can represent\ndifferent phonemes (making the English script less transparent). The syllabary is the Japanese Hiragana\nequivalents for the Latin graphemes. As you can see, while they represent variations of \/k\/ with\ndifferent vowels, they graphemes show no indication of this and are separate symbols. The examples of\nan abugida are from the Tamil script. Here, we can see the same symbol for \/ka\/ (in black). However,\nevery other vowel (long \/a\u02d0\/, \/i\/, \/u\/, \/e\/ and \/o\/) are indicated with secondary vowel notations (in red).\nThis means you need fewer symbols in this writing system as you don\u2019t need a separate symbol for\nevery consonant-vowel combination (as in a syllabary).\nFigure 7.6 Comparing the Latin, Japanese and Tamil Scripts 7.1 Writing Systems 149\nAn abugida that is prevalent in Canada is a family of writing systems known as Canadian Aboriginal\nsyllabics (see Figure 7.7). Created by James Evans based on his knowledge of Devanagari and\nshorthand, it is used to write a number of Indigenous Canadian languages. They are used by Cree,\nInuktitut and Ojibwe. As seen in Figure 7.7, unlike most abugidas which use secondary graphemes for\ndifferent vowels, Canadian syllabics are unique in employing the orientation of the grapheme to\nindicate vowels. If a consonant appears on its own without an inherent vowel, then it is written as a\nsuperscript.\nFigure 7.7 Canadian Aboriginal Syllabics 150 Chapter 7: Visual Language\nFeatural Script\nWe have seen how phonemes can be classified according to their place and manner of articulation as\nwell as voicing. A featural script notates these aspects of phonemes in a consistent manner in\ngraphemes (Sampson, 1990). For example, all labials (phonemes produced with the lips) may have\ncommon visual elements in all graphemes that represent them. A writing system developed with just\nsuch featural elements is Korean hangul (see Figure 7.8).\nFigure 7.8 The word \u201cHangul\u201d, written in the Korean alphabet\nAs seen in Figure 7.8, the Korean graphemes are written in blocks arranged in two dimensions.\nTherefore, words are not written in a linear fashion. Hangul\u2019s featural system is not always evident to\nits users as the graphemes are used like an alphabetic writing system. Another featural writing system\nwould be Pitman\u2019s shorthand. Here the thickness of the lines indicates featural differences. The\nfictional script invented by Tolkien for Tengwar also employs featural notations. In it stops look similar\nto each other with minor variations as do sibilants, fricatives and nasals.\nMedia Attributions\n\u2022 Figure 7.2 The Lord\u2019s Prayer in Mi\ua78ckmaw Hieroglyphs is an adapted version of Micmac pater\nnoster by Carl Faulmann that is in the public domain. The original German has been\ntranslated into English by Dinesh Ramoo.\n\u2022 Figure 7.3 Cherokee Syllabary by Sakurambo is in the public domain.\n\u2022 Figure 7.4 The Persian Writing System by Dinesh Ramoo, the author, is licensed under a CC\nBY 4.0 licence.\n\u2022 Figure 7.5 The Devanagari Writing System by Dinesh Ramoo, the author, is licensed under\na CC BY 4.0 licence.\n\u2022 Figure 7.6 Comparing the Latin, Japanese and Tamil Scriptsis by Dinesh Ramoo, the\nauthor, is licensed under a CC BY 4.0 licence.\n\u2022 Figure 7.7 Canadian Aboriginal Syllabics by Timwi is in the public domain.\n\u2022 Figure 7.8 The word \u201cHangul\u201d, written in the Korean alphabet by Johannes Barre iGEL (Idea 7.1 Writing Systems 151\nby Immanuel Giel) and is licensed under a CC BY-SA 3.0 Unported license.  7.2 A Standard Reading Model\nUnlike speech, reading is not a biologically evolved mechanism. Writing emerged in different cultures\nstarting around 5000\u20136000 years ago unlike speech which may go back as far as 2 million years.\nTherefore, the mechanisms that we employ for reading and writing would be those which evolved for\nother cognitive tasks but adapted for this new purpose. As we see in Figure 7.9, various brain regions\nwhich evolved to form associations between different modes of sensation and perception have been\nadapted to engage in reading.\nFigure 7.9 Brain Areas and Visual Language\n153 154 Chapter 7: Visual Language\nThe scientific study of reading is therefore a multidimensional area exploring the everything from the\nlinguistic aspects of reading (as we did in this chapter) to the psychological mechanisms and neural\ncircuits involved. To begin our exploration of various psychological models of reading and the\nevidence for supporting them, let us start with the Simple View of Reading. This view is based on the\nidea that reading requires word recognition and linguistic comprehension which need to interact in\norder for reading to develop (Catts et al., 2016; Savage, 2001). This view also classifies readers into\nfour broad categories: typical readers; poor readers (general reading disability); dyslexics; and\nhyperlexics (see Figure 7.10).\nFigure 7.10 The Simple View of Reading [Image description]\nAs we are dealing with a variety of writing systems from around the world, we need to familiarize\nourselves with some basic concepts associated with reading. For example, we know that reading\nrequires some way of associating graphemes with phonemes to build meaningful units (words and\nmorphemes). In some cases, this is pretty straightforward in that graphemes map onto phonemes in a\nregular manner (as in the word \u201cfeet\u201d). We don\u2019t need special knowledge to pronounce the word. Even\nif we were to be presented with a non-word such as \u2018pont,\u2019 we don\u2019t need any special knowledge to\nknow how to pronounce them. However, not all words are regular. There are irregular or exception\nwords. Consider place names such as \u2018Leicester\u2019 (pronounced \/l\u025bst\u0259r\/) or surnames such as\nFeatherstonhaugh (pronounced \/f\u00e6n\u0283\u0254\u02d0\/). These are irregular in that the graphemes don\u2019t map clearly\nonto the phonemes they are supposed to represent. More familiar exceptions would be \u2018have\u2019 as\nopposed to \u2018gave.\u2019 English has a plethora of these irregular words which make it difficult for learners\nof English as a second language.\nThe fact that we can understand how to pronounce regular words and regularly spelled non-words\nsuggests we must have a mechanism for storing and decoding regular rules for spelling. Our ability 7.2 A Standard Reading Model 155\nrecognize irregularly spelled words suggests that there must be another route for retrieving their\npronunciation. In other words, there is the suggestion for a dual-route model of reading. The classic\ndual-route model is based on the assumption of two routes for pronouncing words. There is direct\naccess or lexical route where the word-form needs to be retrieved from the lexicon along with its\npronunciation. There must also be a non-lexical route which has a grapheme-to-phoneme converter\n(GPC) that maps each grapheme to its corresponding phoneme using regular rules (Gough, 1972;\nRubenstein, Lewis, & Rubenstein, 1971). The non-lexical route is also evident when children are\nlearning to read letter by letter. In most versions of the dual-route model, whenever a word is\nencountered, there is a race between the two routes to access the pronunciation. Whichever route gets\nthe final word-form out produces the output. Whether these two routes are necessary for understanding\nreading is a primary question in most psycholinguistic research. In addition, not all writing systems are\nthe same and may need to employ different strategies for decoding their graphemes. We will explore\nthe evidence for these various models in the next chapter.\nImage description\nFigure 7.10 The Simple View of Reading\nThe simple view of reading classifies readers in four broad categories based on the language\ncomprehension and the word recognition. These categories are:\n\u2022 Typical reading ability: good language comprehension, good word recognition\n\u2022 Dyslexia: good language comprehension, poor word recognition\n\u2022 Hyperlexia: poor language comprehension, good word recognition\n\u2022 General reading disability: poor language comprehension, poor word recognition\n[Return to the place in text (Figure 7.10)]\nMedia Attributions\n\u2022 Figure 7.9 Brain Areas and Visual Language by Pegado F, Nakamura K and Hannagan T is\nlicensed under a CC BY 3.0 Unported license.\n\u2022 Figure 7.10 The Simple View of Reading by Smilingpolitely is licensed under a CC BY-SA\n4.0 International license.  Summary\nThis chapter explored the basic concepts of graphemes in different writing systems. We saw how\nlogograms, syllabaries, abjads, alphabets, abugidas and featural writing systems can all be useful in\nrepresenting different languages across the world. This chapter also explored how the two basic types\nof spelling (regular and irregular) have led to the assumption of dual-route models for reading.\nKey Takeaways\n\u2022 Graphemes are the smallest units used to represent a phoneme in a writing system.\n\u2022 Logograms are symbols that represent words or morphemes.\n\u2022 Syllabaries have graphemes for individual syllables.\n\u2022 Abjads generally have graphemes for consonants and not vowels.\n\u2022 Alphabets have separate symbols for consonants and vowels.\n\u2022 Abugidas use graphemes for consonants with an inherent vowel. Other vowels are indicated by\nsecondary notations.\n\u2022 Featural writing systems organize graphemes with similar features to indicate phonological\nparallels.\nExercises in Critical Thinking\n1. Think of how you came to learn the writing system of your language.\n2. What methods did your teachers use to help you make the connection between visual symbols and\nphonological symbols?\n3. Given what you know about writing systems and reading, do your teachers could have employed\nother methods based on the writing system they used?\n4. Try to think about ways to write your language in a different writing system than what is used for\nit. What advantages and disadvantages can you see in it?\n157  References\nCatts, Hugh W.; Hogan, Tiffany P.; Fey, Marc E. (2016). \u201cSubgrouping poor readers on the basis of\nindividual differences in reading-related abilities\u201d. Journal of Learning Disabilities. 36(2), 151\u2013164.\nGeniusz, W. D. (2009). Our knowledge is not primitive: Decolonizing botanical Anishinaabe teachings.\nSyracuse, N.Y: Syracuse University Press.\nGough, P. B. (1972). One second of reading. In J. F. Kavanaugh & I. G. Mattingly (Eds.), Language by\near and by eye (pp. 331\u2013358). Cambridge, MA: MIT Press.\nRubenstein, H., Lewis, S. S., & Rubenstein, M. A. (1971). Evidence for phonemic recoding in visual\nword recognition. Journal of Verbal Learning and Verbal Behavior, 10, 645\u2013658.\nSampson, G. (1990). Writing systems. Stanford University Press\nSavage, R. (2001). The simple view of reading: Some evidence and possible implications. Educational\nPsychology, 17, 17-33.\n159  Chapter 8: Reading\nLearning Objectives\n\u2022 Describe the various pieces of evidence that is used by researchers of reading.\n\u2022 Evaluate the difference between different types of reading disorders.\n\u2022 Understand the basics of the dual-route and connectionist models of reading.\nIn this chapter, we will explore the evidence that informs reading research within psycholinguistics. We\nwill look at the neurological disorders associated with reading. These include various types of dyslexia\nand their specific deficit types have the potential to provide new insights onto the process of normal\nreading. We will then look at some models of reading and the evidence they use to inform their stages\nand information processing.\n161  8.1 Reading Models\nThe Logogen Model\nProposed by Morton (1969, 1970), the Logogen model assumes units called logogens which are used\nto understand words that are heard and read. Logogens are specialized recognition units that are used\nfor word recognition. Logogen is from the Greek \u03bb\u03cc\u03b3\u03bf\u03c2 (logos, word) and \u03b3\u03ad\u03bd\u03bf\u03c2 (genos, origin). So,\nevery word we know has its own logogen which contains phonemic and graphemic information about\nthat word. As we encounter a word, the logogen for that word accumulates activation until a given\nthreshold is reached upon which the word is recognized. An important issue to remember is that the\nlogogen itself doesn\u2019t contain the word. Rather, it contains information that can be used to retrieve the\nword. Accessing words is direct and parallel for all words.\nEach logogen has a resting activation level. As it receives more evidence that corresponds to its word,\nthis activation level increases up to a threshold. For example, if the input contains the grapheme <p>,\nthen all logogens containing that visual input get an increase in activation. Once enough graphemes are\nthere to fully activate the logogen it fires and word recognition occurs. The model is particularly good\nas including contextual information in recognizing words. One of the problems with this model was\nthat it equated visual and auditory input for a word as using the same logogen process. A prediction of\nthis model would be that a spoken prime should facilitate a written word just as much as a visual prime.\nHowever, experimental evidence contradicted this prediction (Winnick & Daniel, 1970). Following his\nown observation that confirms these findings, Morton divided the model into different sets of logogens\n(see Figure 8.1).\nFigure 8.1 Logogen Model\nWhile the logogen model is quite successful in explaining word recognition in terms of semantics, there\n163 164 Chapter 8: Reading\nare some limitations to this model. There have been challenges to the existence of the logogen as a unit\nof recognition. Given that different pathways process information on the way to word recognition, is it\nreally necessary to have such centralized units? The model\u2019s limited scope for word recognition that\nignores innate syntactic rules and grammatical construction is also a limitation.\nInteractive Activation Model\nMcClelland and Rumelhart (1981) and Rumelhart and McClelland (1982) developed the Interactive\nactivation and competition (IAC) model. The model accounted for word context effects. This means\nthat letters are easier to recognize if they are in words rather than as isolated letters (also known as the\nword superiority effect). As seen in Figure 8.3, the model consists of three levels: visual feature units,\nindivudla letter units, and word units. Each unit is connected to units in the level immediately before\nand after it with connections that are excitatory (if appropriate) or inhibitory (if inappropriate).\nLet\u2019s look at the example in Figure 8.3 for the word leap. First, the individual features are recognized.\nFor example, the vertical line feature excites <E>, <P>, and <L> but combined with the horizontal line\nfeature, it only excites <L>. All the letter units in turn excite words that contain them, but the words\nthat do not contain the letters act as inhibitory signals in the opposite direction. Once enough letter\nunits have accumulated activation of the word <LEAP>, then that word is recognized. The inhibition of\nunits lower down the model if a positive recognition is not made accounts for the word superiority\neffect. Obviously, if no words are activated (if the letter is on its own), they will act as inhibitors in\nletter recognition. However, if the letter is within a word, then the words facilitate recognition.\nFigure 8.2 The Interactive Activation Model 8.1 Reading Models 165\nSeidenberg and McClelland\u2019s Model of Reading\nSeidenberg and McClelland (1989) proposed a model (also known as SM) that accounts for letter\nrecognition and pronunciation. Reading and speaking involve three features: orthographic, semantic\nand phonological coding. In the SM model, these features are connected with feedback connections. As\nseen in Figure 8.2, the model is captured in a triangular shape. There is a route from orthography to\nphonology via semantics. However, there are no routes for grapheme-to-phonemes correspondence.\nThe model has three levels containing a number of simple units. These are the input, hidden and output\nlayers. Each unit has an activation level and is connected to other units by weighted connections which\ncan excite or inhibit activation. The main feature of these connections is that they are not set by anyone,\nbut learned through back-propagation. This is an algorithmic method whereby the discrepancy\nbetween the actual output and the desired output is reduced by changing the weights between the\nconnections. This model also does not have lexical entries for individual words. They are connections\nbetween phoneme or grapheme units.\nFigure 8.3 Seidenberg and McClelland\u2019s model of reading [Image description]\nColtheart et al. (1993) criticized the SM model for not accounting for how people read exception\nwords, and non-words. They also stated that the model doesn\u2019t account for how people perform visual\nlexical decision tasks as well as failing to account for data from reading disorders\nsuch as dyslexia. Forster (1994) pointed out that just because a model can successfully replicate reading\ndata using connectionist modelling doesn\u2019t mean that it reflects how reading occurs in human beings.\nNorris (1994) argued that the model doesn\u2019t reflect how readers can shift strategically between lexical\nand non-lexical information when reading. 166 Chapter 8: Reading\nDual-Route Model\nThe dual-route model is perhaps the most widely studied model for reading aloud. It assumes two\nseparate mechanisms for reading: the lexical route and the non-lexical route. As seen in Figure 8.4, the\nlexical route is most effective with skilled readers who can recognize words that they already know.\nThis is like looking for words in a dictionary. When a reader sees a word, they access the word in their\nmental lexicon and retrieve information about its meaning and pronunciation. However, this route\ncannot provide any help if you come across a new word for which there is not entry in the mental\nlexicon. For this you would need to use the non-lexical route.\nThe non-lexical or sub-lexical route is a mechanism for decoding novel words using existing\ngrapheme-to-phoneme rules in a language. This mechanism operates through the identification of a\nword\u2019s constituent parts (such as graphemes) and applying linguistic rules to decoding. For example,\nthe grapheme <ch> would be pronounced as \/t\u0283\/ in English. This route can be used to read non-words\nor regular words (that have regular spelling).\nFigure 8.4 Dual-Route Model [Image description]\nReading with the Dual-Route Model\nAn interactive H5P element has been excluded from this version of the text. You can view it online here:\nhttps:\/\/opentextbc.ca\/psyclanguage\/?p=1318#h5p-25 8.1 Reading Models 167\nEnglish: Alphabet \u201cBright\u201d\n1. \u201cBRIGHT\u201d \u2013 Print text\n2. Orthographic Analysis\n\u25e6 <B>, <R>, <IGH> and <T> are analysed as separate graphemes.\n3. Grapheme-to-Phoneme Rule System\n\u25e6 <B>, <R>, <IGH> and <T> are analysed according to the spelling rules of the\nEnglish language.\n4. Response Buffer\n5. <BRIGHT> Orthographic Input Lexicon\n6. Phonological Output Lexicon\n\u25e6 The phonological form of the word is accessed\n7. Semantic System\n\u25e6 The meaning of the word is accessed 168 Chapter 8: Reading\n8. Output\n\u25e6 The word is read out loud as [b\u0279a\u026at]\nInuktitut: Abugida \u201c\u1583\u1405\u14aa\u1466\u201d\n1. \u201c \u201d \u2013 Print text\n2. Orthographic Analysis\n\u25e6 are analysed as separate graphemes.\n3. Grapheme-to-Phoneme Rule System\n\u25e6 are analysed according to the spelling rules of the\nInuktitut language. Here the orientation of the grapheme indicate what vowel\nshould follow the consonant. For is read as \/ma\/, as \/mi\/, as \/me\/ and as\n\/mo\/. If it appears as a superscript is stands as a single consonant \/m\/.\n4. Response buffer 8.1 Reading Models 169\n5. < > Orthographic Input Lexicon\n6. Phonological Output Lexicon\n\u25e6 The phonological form of the word is accessed\n7. Semantic System\n\u25e6 The meaning of the word is accessed\n8. Output\n\u25e6 The word is read out loud as [qaumat]\nCherokee: Syllabary \u201c\u13a4\u13cd\u13aa\u13cd\u13d7\u201d\n1. \u201c\u13a4\u13cd\u13aa\u13cd\u13d7\u201d \u2013 Print text\n2. Orthographic Analysis\n\u25e6 <\u13a4><\u13cd><\u13aa><\u13cd><\u13d7> are analysed as separate graphemes. 170 Chapter 8: Reading\n3. Grapheme-to-Phoneme Rule System\n\u25e6 <\u13a4><\u13cd><\u13aa><\u13cd><\u13d7> are analysed according to the spelling rules of the\nEnglish language. While some symbols may look similar to letters we find in the\nLatin alphabet, this is a purely syllabic script. So A represents the syllable \/go\/. In a\nsyllabary, there is no visual similarity between similar syllables. So, \/gi\/ is <\u13a9> and\n\/go\/ is <\u13ab>.\n4. Response buffer\n5. Orthographic Input Lexicon\n6. Phonological Output Lexicon\n\u25e6 The phonological form of the word is accessed\n7. Semantic System\n\u25e6 The meaning of the word is accessed\n8. Output\n\u25e6 The word is read out loud as [usgosdi] 8.1 Reading Models 171\nMandarin: Logogram \u201c\u660e\u201d\n1. \u201c\u660e\u201d \u2013 Print text\n2. Orthographic Analysis\n\u25e6 <\u660e> are analysed as one grapheme.\n3. Grapheme-to-Phoneme Rule System\n\u25e6 As the entire grapheme represents one whole morpheme (or word), it cannot\nemploy the grapheme-to-phoneme system.\n4. Response buffer\n5. Orthographic Input Lexicon\n\u25e6 The word for \u201cbright\u201d is made up of two graphemes: <\u65e5> meaning sun and <\u6708>\nmeaning moon. Together they make up the word for \u201cbright\u201d\n6. Phonological Output Lexicon\n\u25e6 The phonological form of the word is accessed 172 Chapter 8: Reading\n7. Semantic System\n\u25e6 The meaning of the word is accessed\n8. Output\n\u25e6 The word is read out loud as [m\u00ed\u014b]\nNavigate to the above link to view the interactive version of these models.\nImage descriptions\nFigure 8.3 Seidenberg and McClelland\u2019s model of reading\nThe SM model is in a triangular shape. The three corners are:\n\u2022 Context processor: processes concepts and information, sentence context and text structure,\nrelates to the fluency of reading.\n\u2022 Phonological processor: processes language input and output, relates to phonemic awareness.\n\u2022 Orthographic processor: processes reading input and writing output, relates to letter memory.\nPhonological processor and orthographic processor are connected by phonics, all three processors are\nconnected by the meaning processor.\n[Return to place in the text (Figure 8.3)]\nFigure 8.4 Dual-Route Model\nA flow chart of the dual-route model that has a lexical route and a sub-lexical route for reading aloud.\n\u2022 The lexical route: when a reader sees a print word they recognize, they start by orthographic\nanalysis, then retrieve information from their orthographic input lexicon, semantic system,\nand phonological output lexicon, leading to a response buffer, and produce the speech.\n\u2022 The sub-lexical route: when the reader sees a novel word, they start by orthographic analysis,\nthen use the grapheme-phoneme rule system to decode the word, leading to a response buffer,\nand produce the the speech.\n[Return to place in the text (Figure 8.4)]\nMedia Attributions\n\u2022 Figure 8.1 Logogen Model by Dinesh Ramoo, the author, is licensed under a CC BY 4.0\nlicence.\n\u2022 Figure 8.2 The Interactive Activation Model by Dinesh Ramoo, the author, is licensed under\na CC BY 4.0 licence.\n\u2022 Figure 8.3 Seidenberg and McClelland\u2019s model of reading by Dinesh Ramoo, the author, is 8.1 Reading Models 173\nlicensed under a CC BY 4.0 licence.\n\u2022 Figure 8.4 Dual-Route Model by Dinesh Ramoo, the author, is licensed under a CC BY 4.0\nlicence.  8.2 Reading Disorders\nReading models can often be informed by data from people with reading disorders. In studying such\ndisorders, we must differentiate between acquired disorders (those that arise from brain trauma, stroke\nor injury), and developmental disorders (those that may arise from disruption to the developmental of\nreading faculties). These dyslexias generally result from injury to the left hemisphere. If the dual-route\nmodel is accurately capturing the reading process, then we should be able to find patients who have\ndamaged one route without impairing the other. The evidence for such double disassociations in\nreading aloud task shows strong support for dual-route models.\nSurface Dyslexia\nPatients with surface dyslexia have an impairment in reading irregular words. For example, they\nwould have difficulty reading \u201cquay\u201d but can read regularly spelled words such as \u201cdog.\u201d They often\nover-regularize when reading aloud but can read regular words and regularly spelled non-words easily.\nIn other words, the dual-route model would predict that their lexical route is impaired while the non-\nlexical route is intact.\nPhonological Dyslexia\nPatients with phonological dyslexia are unable to read regularly spelled nonwords. However, they are\nable to read equivalent words. This suggests an impairment with the non-lexical (grapheme-to-\nphoneme) route.\nDeep Dyslexia\nDeep dyslexics often resemble phonological dyslexics in that these patients have difficulty with non-\nwords. However, they also make semantic errors where they produce words that are related in meaning\nwith the word they were supposed to read. Coltheart (1980) lists 12 characteristics of this disorder:\n1. Semantic errors\n2. Visual errors\n3. Substitution of incorrect function words\n4. Derivational errors\n5. Inability to pronounce non-words\n6. Imageability effect\n7. Ability to read nouns more easily than adjectives\n175 176 Chapter 8: Reading\n8. Ability to read adjectives more easily than verbs\n9. Ability to read content words more easily than function words\n10. Writing impairment\n11. Impaired auditory short-term memory\n12. Context-dependant reading ability\nReading in Other Languages\nLanguages with transparent scripts, such as Italian and Spanish, exhibit phonological and deep dyslexia\nbut not surface dyslexia (Patterson, Marshall, & Coltheart, 1985a, 1985b). However, interesting\nobservations can be made in language that have more than one script. Take Japanese, for instance,\nwhich has a syllabary (kana) and a logographic script (kanji). In the latter, no information is available\nabout pronunciation as the symbols stand for the word. As seen in Figure 8.5, while kana can allow for\nnon-lexical grapheme-to-phoneme processing, kanji would only access the lexical route. Therefore, a\ntype of surface dyslexia is found in Japanese where patients cannot read kanji but can process kana.\nPhonological dyslexia in Japanese results in patients being able to read both kana and kanji but bot able\nto process non-words written in kana. This suggests that while the neuropsychological mechanisms for\nreading are common to all human beings, there may be contextual differences brought out by the\nfeatures inherent in a particular language\u2019s writing system.\nFigure 8.5 Using the Dual-route Model in Japanese 8.2 Reading Disorders 177\nLiving Language\nCanada has its own syllabic writing system used to write languages such as Algonquian and Inuit. In this\nwriting system, the orientation and size of the letters is what modifies the pronunciation rather than other\ndiacritics.\n1. Think of which route would be used to read words and non-words in these languages.\n2. How would you recognize surface and phonological dyslexia in these languages?\n3. What mechanisms may be needed to process size and orientation in the grapheme-to-phoneme\nsystem?\nMedia Attributions\n\u2022 Figure 8.5 Using the Dual-route Model in Japanese by Dinesh Ramoo, the author, is licensed\nunder a CC BY 4.0 licence.  Summary\nKey Takeaways\n\u2022 Reading models include the logogen model, The Interactive Activation Model, Seidenberg and\nMcClelland model and the Dual-route model.\n\u2022 Evidence from reading disorders have shown support for the dual-route model.\n\u2022 Patients with surface dyslexia have an inability to read irregularly spelled words.\n\u2022 Patients with phonological dyslexia have difficulty with regularly spelled non-words\nExercises in Critical Thinking\nThink of how you read words in your language.\n1. Is there a moment when you just know what a word means or do you need time to process it?\n2. Keep track of mistakes you make when you read. Are these grammatical, phonological, or\nsemantic?\n3. Do you make mistakes when you read silently? What about when you are speaking to yourself?\n179  References\nColtheart, M. (1980). Deep dyslexia: A right hemisphere hypothesis. In M. Coltheart, K. E. Patterson,\n& J. C. Marshall (Eds.), Deep dyslexia (pp. 326\u2013380). London: Routledge & Kegan Paul.\nColtheart, M., Curtis, B., Atkins, P., & Haller, M. (1993). Models of reading aloud: Dual-route and\nparallel-distributed-processing approaches. Psychological Review, 100, 589\u2013608.\nForster, K. I. (1994). Computational modeling and elementary process analysis in visual word\nrecognition. Journal of Experimental Psychology: Human Perception and Performance, 20,\n1292\u20131310.\nMcClelland, J. L., & Rumelhart, D. E. (1981). An interactive activation model of context effects in\nletter perception: Part 1. An account of the basic findings. Psychological Review, 88, 375\u2013407.\nMorton, J. (1969). Interaction of information in word recognition. Psychological Review, 76, 165\u2013178.\nMorton, J. (1970). A functional model for human memory. In D. A. Norman (Ed.), Models of human\nmemory (pp. 203\u2013260). New York: Academic Press.\nNorris, D. (1994b). Shortlist: A connectionist model of continuous speech recognition. Cognition, 52,\n189\u2013234.\nPatterson, K. E., Marshall, J. C., & Coltheart, M. (1985a). Surface dyslexia in various orthographies:\nIntroduction. In K. E. Patterson, J. C. Marshall, & M. Coltheart (Eds.), Surface dyslexia:\nNeuropsychological and cognitive studies of phonological reading (pp. 209\u2013214). Hove, UK:\nLawrence Erlbaum Associates.\nPatterson, K. E., Marshall, J. C., & Coltheart, M. (Eds.). (1985b). Surface dyslexia:\nNeuropsychological and cognitive studies of phonological reading. Hove, UK: Lawrence Erlbaum\nAssociates.\nRumelhart, D. E., & McClelland, J. L. (1982). An interactive activation model of context effects in\nletter perception: Part 2. The contextual enhancement effect and some tests and extensions of the\nmodel. Psychological Review, 89, 60\u201394.\nSeidenberg, M. S., & McClelland, J. L. (1989). A distributed, developmental model of word\nrecognition and naming. Psychological Review, 96(4), 523-568.\nWinnick, W. A., & Daniel, S. A. (1970). Two kinds of response priming in tachistoscopic recognition.\nJournal of Experimental Psychology, 84, 74\u201381.\n181  Chapter 9: Speaking\nLearning Objectives\n\u2022 Describe the different types of evidence for exploring speech production\n\u2022 Explore the various stages of speech production and the evidence used for their existence\n\u2022 Understand the rationale for three prominent speech production models\nLiving Language\nFigure 9.1 \u201cRaven and the First Men\u201d by Bill Reid\nAs everyone knows, a long time ago, the world was full of water. As the floods receded, Raven flew over the\nwaters. He saw a gigantic clam shell and feeling bored, flew over and landed on it. He heard strange sounds\n183 184 Chapter 9: Speaking\nemerging from the clamshell: \u201cyakity yak-yak\u201d. Having never heard such sounds Raven was curious and\nknowing that he had to soothe the fears of whatever was inside, he started to sing. After singing in a soothing\nvoice, Raven called out \u201ccome out! I am Raven the creator and will not hurt you.\u201d Finally, after more singing,\nthe clamshell opened and out came little beings with two legs, two arms, two hands and no feathers. These\nbeing were our ancestors. While they were frightened at first, they spoke to Raven and ate what he brought to\nfeed them. In this way, they became the ancestors of all of us (Kenny, 1994).\nThis Haida legend is an illustration of the centrality of speech in creating the universe. In every culture\nwe see this repeated from \u2018let there be light\u2019 in the bible to \u2018let it be and it was so\u2019 ( ) in the\n\u0646\u0648\u0643\u064a\u0641 \u0646\u0643\nQur\u2019an. These examples illustrate the centrality of speech to making sense of the universe, indeed\ncreating it from our mind.\nIn this chapter, we will explore the manner in which we produce speech. We will consider the various\nstages of speech production and the evidence used to assume their existence. We will organize these\nstages into a standard model to serve as a basis for our discussion. Then we will explore three\nprominent speech production models from current psycholinguistic research and see where they agree\nand disagree in terms of how speech production occurs. The evidence that they use to justify their\nunderstanding of speech production will serve as a basis for understanding how researchers employ\nevidence in modelling psycholinguistic models.\nMedia Attributions\n\u2022 Figure 9.1 \u201cRaven and the First Men\u201d by Bill Reid, Museum of Anthropology, UBC,\nVancouver, British Columbia, is licensed under a CC BY-SA 3.0 Unported license. 9.1 Evidence for Speech Production\nThe evidence used by psycholinguistics in understanding speech production can be varied and\ninteresting. These include speech errors, reaction time experiments, neuroimaging, computational\nmodelling, and analysis of patients with language disorders. Until recently, the most prominent set of\nevidence for understanding how we speak came from speech errors. These are spontaneous mistakes\nwe sometimes make in casual speech. Ordinary speech is far from perfect and we often notice how we\nslip up. These slips of the tongue can be transcribed and analyzed for broad patterns. The most\ncommon method is to collect a large corpus of speech errors by recording all the errors one comes\nacross in daily life.\nPerhaps the most famous example of this type of analysis are what are termed \u2018Freudian slips.\u2019 Freud\n(1901\u20131975) proposed that slips of the tongue were a way to understand repressed thoughts. According\nto his theories about the subconscious, certain thoughts may be too uncomfortable to be processed by\nthe conscious mind and can be repressed. However, sometimes these unconscious thoughts may surface\nin dreams and slips of the tongue. Even before Freud, Meringer and Mayer (1895) analysed slips of the\ntongue (although not in terms of psychoanalysis).\nSpeech errors can be categorized into a number of subsets in terms of the linguistic units or\nmechanisms involved. Linguistic units involved in speech errors could be phonemes, syllables,\nmorphemes, words or phrases. The mechanisms of the errors can involve the deletion, substitution,\ninsertion, or blending of these units in some way. Fromkin (1971; 1973) argued that the fact that these\nerrors involve some definable linguistic unit established their mental existence at some level in speech\nproduction. We will consider these in more detail in discussing the various stages of speech production.\nSpeech Error Types and Examples\nError Type Error Target\nAnticipation leading list Reading list\nPerseveration black bloxes black boxes\nExchange rat pack pack rat\nSubstitution spencil stencil\nDeletion sippery slippery\nInsertion sakool school\n185  9.2 The Standard Model of Speech Production\nSpeech production falls into three broad areas: conceptualization, formulation and articulation (Levelt,\n1989). In conceptualization, we determine what to say. This is sometimes known as message-level\nprocessing. Then we need to formulate the concepts into linguistic forms. Formulation takes\nconceptual entities as input and connects them with the relevant words associated with them to build a\nsyntactic, morphological, and phonological structure. This structure is phonetically encoded and\narticulated, resulting in speech.\nDuring conceptualization, we develop an intention and select relevant information from the internal\n(memory) or external (stimuli) environment to create an utterance. Very little is known about this level\nas it is pre-verbal. Levelt (1989) divided this stage into microplanning and macroplanning.\nMacroplanning is thought to be the elaboration of a communication goal into subgoals and connecting\nthem with the relevant information. Microplanning assigns the correct shape to these pieces of\ninformation and deciding on the focus of the utterance.\nFormulation is divided into lexicalization and syntactic planning. In lexicalization, we select the\nrelevant word-forms and in syntactic planning we put these together into a sentence. In talking about\nword-forms, we need to consider the idea of lemmas. This is the basic abstract conceptual form which\nis the basis for other derivations. For example, break can be considered a lemma which is the basis for\nother forms such as break, breaks, broke, broken and breaking. Lemma retrieval used a conceptual\nstructure to retrieve a lemma that makes syntactic properties available for encoding (Kempen &\nHoenkamp, 1987). This can specify the parameters such as number, tense, and gender. During word-\nform encoding, the information connected to lemmas is used to access the morphemes and phonemes\nlinked to the word. The reason these two processing levels, lemma retrieval and word-form encoding,\nare assumed to exist comes from speech errors where words exchange within the same syntactic\ncategories. For example, nouns exchange with nouns and verbs with verbs from different phrases.\nBierwisch (1970), Garrett (1975, 1980) and Nooteboom (1967) provide some examples:\n\u2022 \u201c\u2026 I left my briefcase in the cigar\u201d\n\u2022 \u201cWhat we want to do is train its tongue to move the cat\u201d\n\u2022 \u201cWe completely forgot to add the list to the roof\u201d\n\u2022 \u201cAs you reap, Roger, so shall you sow\u201d\nWe see here that not only are the exchange of words within syntactic categories, the function words\nassociated with the exchanges appear to be added after the exchange (as in \u2018its\u2019 before \u2018tongue\u2019 and\n\u2018the\u2019 before \u2018cat\u2019). In contrast to entire words (which exchange across different phrases), segment\nexchanges usually occur within the same phrase and do not make any reference to syntactic categories.\nGarrett (1988) provides an example in \u201cshe is a real rack pat\u201d instead of \u201cshe is a real pack rat.\u201d In\nsuch errors, the segments involved in the error often share phonetic similarities or share the same\nsyllable position (Dell, 1984). This suggests that these segments must be operating within some frame\n187 188 Chapter 9: Speaking\nsuch as syllable structure. To state this in broader terms, word exchanges are assumed to occur during\nlemma retrieval, and segment exchanges occur during word-form encoding.\nPutting these basic elements together, Meyer (2000) introduced the \u2018Standard Model of Word-form\nEncoding\u2019 (see Figure 9.2) as a summation of previously proposed speech production models (Dell,\n1986; Levelt et al., 1999; Shattuck-Huffnagel, 1979, 1983; Fromkin, 1971, 1973; Garrett, 1975, 1980).\nThe model is not complete in itself but a way for understanding the various levels assumed by most\npsycholinguistic models. The model represents levels for morphemes, segments, and phonetic\nrepresentations.\nFigure 9.2 The Standard Model of Speech Production [Image description]\nMorpheme Level\nWe have already seen (in Chapter 3) that morphemes are the smallest units of meaning. A word can be\nmade up on one or more morphemes. Speech errors involving morphemes effect the lemma level or the\nwordform level (Dell, 1986) as in:\n\u2022 \u201chow many pies does it take to make an apple?\u201d (Garrett, 1988)\n\u2022 \u201cso the apple has less trees\u201d (Garrett, 2001)\n\u2022 \u201cI\u2019d hear one if I knew it\u201d (Garrett, 1980)\n\u2022 \u201c\u2026 slicely thinned\u201d (Stemberger, 1985)\nIn the first, we see that the morpheme that indicates the plural number has remained in place while the\nmorpheme for \u2018apple\u2019 and \u2018pie\u2019 exchanged. This is also seen in the last example. This suggests that the\nexchange occurred after the parameters for number were set indicating that lemmas can switch 9.2 The Standard Model of Speech Production 189\nindependent of their morphological and phonological representations (which occur further down in\nspeech production).\nSegment Level\nWhile speech production models differ in their organisation and storage of segments, we will assume\nthay segments have to be retrieved at some level of speech production. Between 60-90% of all speech\nerrors tend to involve segments (Boomer & Laver, 1968; Fromkin, 1971; Nooteboom, 1969; Shattuck-\nHufnagel, 1983). However, 10-30% of all speech errors also involve segment sequences (Stemberger,\n1983; Shattuck-Hufnagel, 1983). Reaction time experiments have also been employed to justify this\nlevel. Roeloffs (1999) asked participants to learn a set of word pairs followed by the first word in the\npair being presented as a prompt to produce the second word. These test blocks were presented as\neither homogeneous or heterogenous phonological forms. In the homogenous blocks there were shared\nonsets or the segments differed only in voicing. In the heterogenous blocks the initial segments\ncontrasted in voicing and place of articulation. He found that there were priming effects in homogenous\nblocks when the targets shared an initial segment but not when all but one feature was shared\nsuggesting that whole phonological segments are represented at some level rather than distinctive\nfeatures.\nPhonetic Level\nThe segmental level we just discussed is based on phonemes. The standard understanding of speech is\nthat there must be a phonetic level that represents the actual articulated speech as opposed to the stored\nrepresentations of sound. We have already discussed this in Chapter 2 and will expand here. For\nexample, in English, there are two realizations of unvoiced stops. One form is unaspirated \/p\/, \/k\/, and\n\/t\/ and the other is aspirated [ph], [kh], and [th]. This can be seen in the words pit [ph\u026at] and lip [l\u026ap]\nwhere syllable-initial stops are aspirated as a rule. The pronunciation of pit as *[p\u026at] doesn\u2019t change the\nmeaning but will sound odd to a native speaker. This shows that \/p\/ has one phonemic value but two\nphonetic values: [p] and [ph]. This can be understood as going from an abstract level to a concrete level\ndeveloping as speech production occurs. Having familiarized ourselves with the basic levels of speech\nproduction, we can now go on to see how they are realized in actual speech production models.\nImage descriptions\nFigure 9.2 The Standard Model of Speech Production\nThe Standard Model of Word-form Encoding as described by Meyer (2000), illustrating five level of\nsummation of conceptualization, lemma, morphemes, phonemes, and phonetic levels, using the\nexample word \u201ctiger\u201d. From top to bottom, the levels are:\n\u2022 Semantic level: the conceptualization of \u201ctiger\u201d with an image of a tiger.\n\u2022 Lemma level: select the lemma of the word \u201ctiger\u201d.\n\u2022 Morpheme level: morphological encoding of the word tiger, t, i, g, e, r. 190 Chapter 9: Speaking\n\u2022 Phoneme level: phonological encoding of each morpheme in the word \u201ctiger\u201d.\n\u2022 Phonetic kevel: syllabification of the phonemes in the word \u201ctiger\u201d.\n[Return to place in text (Figure 9.2)]\nMedia Attributions\n\u2022 Figure 9.2 The Standard Model of Speech Production by Dinesh Ramoo, the author, is\nlicensed under a CC BY 4.0 licence. 9.3 Speech Production Models\nThe Dell Model\nSpeech error analysis has been used as the basis for the model developed by Dell (1986, 1988). Dell\u2019s\nspreading activation model (as seen in Figure 9.3) has features that are informed by the nature of\nspeech errors that respect syllable position constraints. This is based on the observation that when\nsegmental speech errors occur, they usually involve exchanges between onsets, peaks or codas but\nrarely between different syllable positions. Dell (1986) states that word-forms are represented in a\nlexical network composed on nodes that represent morphemes, segments and features. These nodes are\nconnected by weighted bidirectional vertices.\nFigure 9.3 The Dell Model\nAs seen in Figure 9.3, when the morpheme node is activated, it spreads through the lexical network\nwith each node transmitting a proportion of its activation to its direct neighbour(s). The morpheme is\nmapped onto its associated segments with the highest level of activation. The selected segments are\nencoded for particular syllable positions which can then be slotted into a syllable frame. This means\nthat the \/p\/ phoneme that is encoded for syllable onset is stored separately from the \/p\/ phonemes\n191 192 Chapter 9: Speaking\nencoded for syllable coda position. This also accounts for the phonetic level in that instead of having\ntwo separate levels for segments (phonological and phonetic levels), there is only one segmental level.\nIn this level, the onset \/p\/ is stored with its characteristic aspiration as [ph] and the coda \/p\/ is stored in\nits unaspirated form [p]. Although this means that segments need to be stored twice for onset and coda\npositions, it simplified the syllabification process as the segments automatically slot into their\nrespective position. Dell\u2019s model ensures the preservation of syllable constraints in that onset phonemes\ncan only fit into onset syllable slots in the syllable template (the same being true for peaks and codas).\nThe model also has an implicit competition between phonemes that belong to the same syllable\nposition and this explains tongue-twisters such as the following:\n\u2022 \u201cShe sells sea shells by the seashore\u201d \u0283i\u02d0 s\u025blz si\u02d0\u0283\u025blz ba\u026a \u00f0i\u02d0 si\u02d0\u0283\u0254\u02d0\n\u2022 \u201cBetty Botter bought a bit of butter\u201d b\u025bti\u02d0 b\u0252t\u0259 b\u0254\u02d0t \u0259 b\u026at \u0252v b\u028ct\u0259\nIn these examples, speakers are assumed to make errors because of competition between segments that\nshare the same syllable position. As seen in Figure 9.3, Dell (1988) proposes a word-shape header node\nthat contains the CV specifications for the word-form. This node activates the segment nodes one after\nthe other. This is supported by the serial effects seen in implicit priming studies (Meyer, 1990; 1991) as\nwell as some findings on the influence of phonological similarity on semantic substitution errors (Dell\n& Reich, 1981). For example, the model assumes that semantic errors (errors based on shared meaning)\narise in lemma nodes. The word cat shares more segments with a target such as mat ((\/\u00e6\/nu and \/t\/cd)\nthan with sap (only \/\u00e6\/nu). Therefore, the lemma node of mat will have a higher activation level than\nthe one for sap creating the opportunity for a substitution error. In addition, the feedback from\nmorpheme nodes leads to a bias towards producing words rather then nonword error. The model also\ntakes into account the effect of speech rate on error probability (Dell, 1986) and the frequency\ndistribution of anticipation-, perseveration- and transposition- errors (Nooteboom, 1969). The model\naccounts for differences between various error types by having an in-built bias for anticipation.\nActivation spreads through time. Therefore, upcoming words receive activation (at a lower level than\nthe current target). Speech rate also has an influence on errors because higher speech rates may lead to\nnodes not having enough time to reach a specified level of activation (leading to more errors).\nWhile the Dell model has a lot of support for it\u2019s architecture, there have been criticisms. The main\nevidence used for the model, speech errors, have themselves been questioned as a useful piece of\nevidence for informing speech production models (Cutler, 1981). For instance, the listener might\nmisinterpret the units involved in the error and may have a bias towards locating errors at the beginning\nof words (accounting for the large number of word-onset errors). Evidence for the CV header node is\nlimited as segment insertions usually create clusters when the target word also had a cluster and CV\nsimilarities are not found for peaks.\nThe model also has an issue with storage and retrieval as segments need to be stored for each syllable\nposition. For example, the \/l\/ in English needs to be stored as [l] for syllable onset, [\u026b] for coda and [\u1e37]\nwhen it appears as a syllabic consonant in the peak (as in bottle). However, while this may seem\nredundant and inefficient, recent calculations of storage costs based on information theory by Ramoo\nand Olson (2021) suggest that the Dell model may actually be more storage efficient than previously\nthought. They suggest that one of the main inefficiencies of the model are during syllabification across\nword and morpheme boundaries. During the production of connected speech or polymorphic words,\nsegments from one morpheme or word will move to another (Chomsky & Halle, 1968; Selkirk, 1984;\nLevelt, 1989). For example, when we say \u201cwalk away\u201d \/w\u0254k.\u0259.we\u026a\/, we produce [w\u0254.k\u0259.we\u026a] where the 9.3 Speech Production Models 193\n\/k\/ moves from coda to onset in the next syllable. As the Dell model codes segments for syllable\nposition, it may not be possible for such segments to move from coda to onset position during\nresyllabification. These and other limitations have led researchers such as Levelt (1989) and his\ncolleagues (Meyer, 1992; Roelofs, 2000) to propose a new model based on reaction time experiments.\nThe Levelt, Roelofs, and Meyer (LRM) Model\nThe Levelt, Roelofs, and Meyer or LRM model is one of the most popular models for speech\nproduction in psycholinguistics. It is also one of the most comprehensive in that it takes into account all\nstages from conceptualization to articulation (Levelt et al., 1999). The model is based on reaction time\ndata from naming experiments and is a top-down model where information flows from more abstract\nlevels to more concrete stages. The Word-form Encoding by Activation and VERification (WEAVER)\nis the computational implementation of the LRM model developed by Roelof (1992, 1996, 1997a,\n1997b, 1998, 1999). It is a spreading activation model inspired by Dell\u2019s (1986) ideas about word-form\nencoding. It accounts for the syllable frequency effect and ambiguous syllable priming data (although\nthe computational implementation has been more successful in illustrating syllable frequency effects\nrather than priming effects).\nFigure 9.4 The LRM Model\nAs we can see in Figure 9.4, the lemma node is connected to segment nodes. These vertices are\nspecified for serial position and the segments are not coded for syllable position. Indeed, the only\nsyllabic information that is stored in this model are syllable templates that indicate the stress patterns of\neach word (which syllable in the word is stressed and which is not). These syllabic templates are used\nduring speech production to syllabify the segments using the principle of onset-maximization (all\nsegments that can legally go into a syllable onset in a language are put into the onset and the leftover\nsegments go into the coda). This kind of syllabification during production accounts for resyllabification\n(which is a problem for the Dell model). The model also has a mental syllabary which is hypothesized\nto contain the articulatory programs that are used to plan articulation. 194 Chapter 9: Speaking\nThe model is interesting in that syllabification is only relevant at the time of production. Phonemes are\ndefined within the lexicon with regard to their serial position in the word or lemma. This allows for\nresyllabification across morpheme and word boundaries without any difficulties. Roelofs and Meyer\n(1998) investigated whether syllable structures are stored in the mental frame. They employed an\nimplicit priming paradigm where participants produced one word out of a set of words in rapid\nsuccession. The words were either homogenous (all words had the same word onsets) or\nheterogeneous. They found that priming depended on the targets having the same number of syllable\nand stress patterns but not the same syllable structure. This led them to conclude that syllable structure\nwas not a stored component of speech production but computed during speech (Choline et al., 2004).\nCosta and Sebastian-Galles (1998) employed a picture-word interference paradigm to investigate this\nfurther. They asked participants to name a picture while a word was presented after 150 ms. They\nfound that participants were faster to name a picture when they shared the same syllable structure with\nthe word. These results challenge the view that syllable structure is absent as an abstract encoding\nwithin the lexicon. A new model has challenged the LRM model\u2019s assumptions on this with a Lexicon\nwith Syllable Structure (LEWISS) model.\nThe Lexicon with Syllable Structure (LEWISS) Model\nProposed by Romani et al. (2011), the Lexicon with Syllable Structure (LEWISS) model explores the\npossibility of stored syllable structure in phonological encoding. As seen in Figure 9.5 the organisation\nof segments in this model is based on a syllable structure framework (similar to proposals by Selkirk,\n1982; Cairns & Feinstein, 1982). However, unlike the Dell model, the segments are not coded for\nsyllable position. The syllable structural hierarchy is composed of syllable constituent nodes (onset,\npeak and coda) with the vertices having different weights based on their relative positions. This means\nthat the peak (the most important part of a syllable) has a very strongly weighted vertex compared to\nonsets and codas. Within onsets and codas, the core positions are more strongly weighted compared to\nsatellite position. This is based on the fact that there are positional variations in speech errors. For\nexample, onsets and codas are more vulnerable to errors compared to vowels or peaks. Within onsets\nand codas, the satellite positions are more vulnerable compared to core positions. For example, in a\nword like print, the \/r\/ and \/n\/ in onset and coda satellite positions are more likely to be the subjects of\nerrors than the \/p\/ and \/t\/ which are core positions. The main evidence for the LEWISS model comes\nfrom the speech errors of aphasic patients (Romani et al., 2011). It was observed that not only did they\nproduce errors that weighted syllable positions differently, they also preserved the syllable structure of\ntheir targets even when making speech errors. 9.3 Speech Production Models 195\nFigure 9.5 The LEWIS Model\nIn terms of syllabification, the LEWISS model syllabifies at morpheme and word edges instead of\nhaving to syllabify the entire utterance each time it is produced. The evidence from speech errors\nsupports the idea of having syllable position constraints. While Romani et al. (2011) have presented\ndata from Italian, speech error analysis in Spanish also supports this view (Garcia-Albea et al., 1989).\nThe evidence from Spanish is also interesting in that the errors are mostly word-medial rather than\nword-initial as is the case for English (Shattuck-Hufnagel, 1987, 1992). Stemberger (1990)\nhypothesised that structural frames for CV structure encoding may be compatible with phonological\nsystems proposed by Clements and Keyser (1983) as well as Goldsmith (1990). This was supported by\nspeech errors from German and Swedish (Stemberger, 1984). However, such patterns were not\nobserved in English. Costa and Sebastian-Gall\u00e9s (1998) found primed picture-naming was facilitated\nby primes that shared CV structure with the targets. Sevald, Dell and Cole (1995) found similar effects\nin repeated pronunciation tasks in English. Romani et al. (2011) brought these ideas to the fore with\ntheir analysis of speech errors made by Italian aphasic and apraxic patients. The patients did repetition,\nreading, and picture-naming tasks. Both groups of patients produced errors that targeted vulnerable\nsyllable positions such as onset- and coda- satellites consistent with previous findings (Den Ouden,\n2002). They also found that a large proportion of the errors preserved syllable structure even in the\nerrors. This is noted by previous findings as well (Wilshire, 2002). Previous findings by Romani and\nCalabrese (1996) found that Italian patients replaced geminates with heterosyllabic clusters rather than\nhomosyllabic clusters. For example, \/\u02a4i.raf.fa\/ became \/\u02a4i.rar.fa\/ rather than \/\u02a4i.ra.fra\/ preserving the\noriginal syllable structure of the target. While the Dell model\u2019s segments coded for syllable position\ncan also explain such errors, it cannot account for errors that moved from one syllable position to\nanother. More recent computational calculations by Ramoo and Olson (2021) found that the\nresyllabification rates in English and Hindi as well as storage costs predicted by information theory do\nnot discount LEWISS based on storage and computational costs. 196 Chapter 9: Speaking\nLanguage Production Models\nAn interactive H5P element has been excluded from this version of the text. You can view it online here:\nhttps:\/\/opentextbc.ca\/psyclanguage\/?p=1338#h5p-26\nDell Model\n1. Concept Node\n\u25e6 This is the non-verbal concept of the object that is elicited when we see a picture,\nread the word or hear it.\n2. Lemma Node\n\u25e6 An abstract conceptual form of a word that has been mentally selected for\nutterance.\n3. Morpheme Node\n\u25e6 The meaningful unit (or units) of the lemma attached to specific segments.\n4. Syllable Nodes\n\u25e6 Syllable nodes are created using the syllable template. 9.3 Speech Production Models 197\n5. Segment Nodes\n\u25e6 Segment nodes are specified for syllable position. So, [p onset] will be a separate\nsegment from [p coda].\n6. Diacritic Feature node\n\u25e6 This node indicates that the word is singular.\n7. Header node\n\u25e6 This node specifies the CV structure and order of the word.\n8. Syllable template\n\u25e6 A syllable template is used in the syllabification process to indicate which\nsegments can go where.\n9. Segment Category Nodes\n\u25e6 The segment category nodes are specified for syllable position. So, they only\nactivate segments that are for onset, peak or coda syllable positions. Activation will\nbe higher for the appropriate segment. 198 Chapter 9: Speaking\nLRM Model\n1. Conceptual Node\n\u25e6 This is the non-verbal concept of the object that is elicited when we see a picture,\nread the word or hear it.\n2. Lemma Node\n\u25e6 An abstract conceptual form of a word that has been mentally selected for\nutterance.\n3. Morpheme Node\n\u25e6 The meaningful unit (or units) of the lemma attached to specific segments.\n4. Segment Nodes\n\u25e6 Segment nodes are connected to the morpheme node specified for serial position.\n5. Syllable Template 9.3 Speech Production Models 199\n\u25e6 The morpheme is connected to a syllable template that indicates how many syllable\nare contained within the phonological word. It also indicates which syllables are\nstressed and unstressed.\n6. Post-lexical Syllabification\n\u25e6 Post-lexical syllabification uses the syllable template to syllabify the phonemes.\nThis is also the place where phonological rules can be implimented. For example,\nin English, unvoiced stops will be aspirated in output.\n7. Mental Syllabary\n\u25e6 Syllabified representations are used to access a Mental Syllabary of articulatory\nmotor programs.\n8. Output\n\u25e6 The final output.\nLEWISS Model 200 Chapter 9: Speaking\n1. Conceptual Node\n\u25e6 This is the non-verbal concept of the object that is elicited when we see a picture,\nread the word or hear it.\n2. Lemma Node\n\u25e6 An abstract conceptual form of a word that has been mentally selected for\nutterance.\n3. Morpheme Node\n\u25e6 The meaningful unit (or units) of the lemma attached to specific segments.\n4. Syllable Structure Nodes\n\u25e6 The syllable structure nodes indicate the structure of the word\u2019s syllable structure.\nThey also specify syllable stress or tone. In addition, the connections are weighted.\nSo, core positions and peak positions are strongly weighted compared to satellite\npositions.\n5. Segment Nodes\n\u25e6 Segment nodes are connected to the morpheme node. They are also connected to a\nsyllable structure that keeps them in place.\n6. Post-lexical Syllabification\n\u25e6 Post-lexical syllabification syllabify the phonemes at morpheme and word\nboundaries. This is also the place where phonological rules can be implimented.\nFor example, in English, unvoiced stops will be aspirated in output.\n7. Output\n\u25e6 The final output.\nNavigate to the above link to view the interactive version of these models.\nMedia Attributions\n\u2022 Figure 9.3 The Dell Model by Dinesh Ramoo, the author, is licensed under a CC BY 4.0\nlicence.\n\u2022 Figure 9.4 The LRM Model by Dinesh Ramoo, the author, is licensed under a CC BY 4.0\nlicence.\n\u2022 Figure 9.5 The LEWIS Model by Dinesh Ramoo, the author, is licensed under a CC BY 4.0\nlicence. Summary\nIn this chapter, we discussed speech production models and some of the evidence used to support them.\nThe main source of evidence in understanding speech production comes from speech errors. However,\nthis has since been supplemented with evidence from reaction time experiments, computational\nmodelling, and errors made by patients with acquired language disorders. We discussed three major\nspeech production models by Dell (1986; 1988), Levelt, Roelofs, and Meyer (1999) as well as Romani,\nGalluzzi, Bureca, and Olson (2011).\nKey Takeaways\n\u2022 Speech production can be understood as conceptualization, formulation, and execution.\n\u2022 Formulation included syntactic planning and lexicalization.\n\u2022 Lexicalization is the process of retrieving the phonemes associated with a word.\n\u2022 The Dell model proposes phonemes encoded for syllable position and CV header nodes.\n\u2022 The LRM model organizes phonemes according to serial position and has post-lexical\nsyllabification based on the onset-maximization principle.\n\u2022 The LEWISS model encodes abstract syllable structure connected to segments and only\nsyllabifies at morpheme and word edges.\nExercises in Critical Thinking\n1. Be mindful of your own speech errors for a week or two and write them down.\n2. Analyse your speech errors and classify them according to the types of errors you make.\n3. How much do they agree with the evidence presented for the three speech models we discussed in\nthis chapter?\n201 "}