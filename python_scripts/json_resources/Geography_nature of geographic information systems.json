{"text":"Chapter 1\n1 Data and Information\nDavid DiBiase\n1.1. Overview\nWhen I started writing this text in 1997, my office was across the street (and, fortunately, upwind)\nfrom Penn State\u2019s power plant. The energy used to heat and cool my office is still produced there by\nburning coal mined from nearby ridges. Combustion transforms the potential energy stored in the coal\ninto electricity, which solves the problem of an office that would otherwise be too cold or too warm.\nUnfortunately, the solution itself causes another problem, namely emissions of carbon dioxide and other\nmore noxious substances into the atmosphere. Cleaner means of generating electricity exist, of course,\nbut they too involve transforming energy from one form to another. And cleaner methods cost more than\nmost of us are willing or able to pay.\nIt seems to me that a coal-fired power plant is a pretty good analogy for a geographic information\nsystem. For that matter, GIS is comparable to any factory or machine that transforms a raw material into\nsomething more valuable. Data is grist for the GIS mill. GIS is like the machinery that transforms the\ndata into the commodity\u2013information\u2013that is needed to solve problems or create opportunities. And the\nproblems that the manufacturing process itself creates include uncertainties resulting from imperfections\nin the data, intentional or unintentional misuse of the machinery, and ethical issues related to what the\ninformation is used for, and who has access to it.\nThis text explores the nature of geographic information. To study the nature of something is to\ninvestigate its essential characteristics and qualities. To understand the nature of the energy produced in a\ncoal-fired power plant, one should study the properties, morphology, and geographic distribution of coal.\nBy the same reasoning I believe that a good approach to understanding the information produced by GIS\nis to investigate the properties of geographic data and the technologies and institutions that produce it.\nObjectives\nThe goal of Chapter 1 is to situate GIS in a larger enterprise known as Geographic Information Science\nand Technology (GIS&T), and in what the U.S. Department of Labor calls the \u201cgeospatial industry.\u201d In\nparticular, students who successfully complete Chapter 1 should be able to:\n1. Define a geographic information system;\n2. Recognize and name basic database operations from verbal descriptions;\n3. Recognize and name basic approaches to geographic representation from verbal descriptions;\n4. Identify and explain at least three distinguishing properties of geographic data; and\n5. Outline the kinds of questions that GIS can help answer.\n1.2. Checklist\nThe following checklist is for Penn State students who are registered for classes in which this text, and\n2 3 David DiBiase\nassociated quizzes and projects in the ANGEL course management system, have been assigned. You\nmay find it useful to print this page out first so that you can follow along with the directions.\nChapter 1 Checklist (for registered students only)\nChapter 1 Checklist\nStep Activity Access\/Directions\nThis is the second page of Chapter 1. Click on the links\nat the bottom of the page to continue or to return to the\n1 Read Chapter 1 previous page, or to go to the top of the chapter. You\ncan also navigate the text via the links in the GEOG\n482 menu on the left.\nSubmit quizzes as you come across them in the\nchapter. Blue banners denote practice quizzes\nGo to ANGEL > [your course section] > Lessons tab >\n2 that are not graded. Red banners signal graded\nChapter 1 folder > [quiz]\nquizzes. (Note that Chapter 1 does not include\na graded quiz.)\nPerform \u201cTry This\u201d activities as you come\n3 across them in the chapter. \u201cTry This\u201d Instructions are provided for each activity.\nactivities are not graded.\nRead comments and questions posted by Comments and questions may be posted on any page of\n4 fellow students. Add comments and questions the text, or in a Chapter-specific discussion forum in\nof your own, if any. ANGEL.\n1.3. Data\n\u201cAfter more than 30 years, we\u2019re still confronted by the same major challenge that GIS professionals\nhave always faced: You must have good data. And good data are expensive and difficult to create.\u201d\n(Wilson, 2001, p. 54)\nData consist of symbols that represent measurements of phenomena. People create and study\ndata as a means to help understand how natural and social systems work. Such systems can be hard\nto study because they\u2019re made up of many interacting phenomena that are often difficult to observe\ndirectly, and because they tend to change over time. We attempt to make systems and phenomena\neasier to study by measuring their characteristics at certain times. Because it\u2019s not practical to measure\neverything, everywhere, at all times, we measure selectively. How accurately data reflect the phenomena\nthey represent depends on how, when, where, and what aspects of the phenomena were measured. All\nmeasurements, however, contain a certain amount of error.\nMeasurements of the locations and characteristics of phenomena can be represented with several\ndifferent kinds of symbols. For example, pictures of the land surface, including photographs and maps,\nare made up of graphic symbols. Verbal descriptions of property boundaries are recorded on deeds using\nalphanumeric symbols. Locations determined by satellite positioning systems are reported as pairs of\nnumbers called coordinates. As you probably know, all of these different types of data\u2013pictures, words,\nand numbers\u2013can be represented in computers in digital form. Obviously, digital data can be stored,\ntransmitted, and processed much more efficiently than their physical counterparts that are printed on\npaper. These advantages set the stage for the development and widespread adoption of GIS. Nature of Geographic Information 4\n1.4. Information\nInformation is data that has been selected or created in response to a question. For example, the\nlocation of a building or a route is data, until they are needed to dispatch an ambulance in response to\nan emergency. When used to inform those who need to know \u201cwhere is the emergency, and what\u2019s the\nfastest route between here and there?,\u201d the data are transformed into information. The transformation\ninvolves the ability to ask the right kind of question, and the ability to retrieve existing data\u2013or to\ngenerate new data from the old\u2013that help people answer the question. The more complex the question,\nand the more locations involved, the harder it becomes to produce timely information with paper maps\nalone.\nInterestingly, the potential value of data is not necessarily lost when they are used. Data can be\ntransformed into information again and again, provided that the data are kept up to date. Given the\nrapidly increasing accessibility of computers and communications networks in the U.S. and abroad, it\u2019s\nnot surprising that information has become a commodity, and that the ability to produce it has become a\nmajor growth industry.\n1.5. Information Systems\nInformation systems are computer-based tools that help people transform data into information.\nAs you know, many of the problems and opportunities faced by government agencies, businesses, and\nother organizations are so complex, and involve so many locations, that the organizations need assistance\nin creating useful and timely information. That\u2019s what information systems are for.\nAllow me a fanciful example. Suppose that you\u2019ve launched a new business that manufactures solar-\npowered lawn mowers. You\u2019re planning a direct mail campaign to bring this revolutionary new product\nto the attention of prospective buyers. But since it\u2019s a small business, you can\u2019t afford to sponsor coast-\nto-coast television commercials, or to send brochures by mail to more than 100 million U.S. households.\nInstead, you plan to target the most likely customers \u2013 those who are environmentally conscious, have\nhigher than average family incomes, and who live in areas where there is enough water and sunshine to\nsupport lawns and solar power.\nFortunately, lots of data are available to help you define your mailing list. Household incomes are\nroutinely reported to banks and other financial institutions when families apply for mortgages, loans,\nand credit cards. Personal tastes related to issues like the environment are reflected in behaviors such as\nmagazine subscriptions and credit card purchases. Firms like Claritas amass such data, and transform it\ninto information by creating \u201clifestyle segments\u201d \u2013 categories of households that have similar incomes\nand tastes. Your solar lawnmower company can purchase lifestyle segment information by 5-digit ZIP\ncode, or even by ZIP+4 codes, which designate individual households.\nIt\u2019s astonishing how companies like Claritas can create valuable information from the millions upon\nmillions of transactions that are recorded every day. Their products are made possible by the fact that\nthe original data exist in digital form, and because the companies have developed information systems\nthat enable them to transform the data into information that companies like yours value. The fact that\nlifestyle information products are often delivered by geographic areas, such as ZIP codes, speaks to the\nappeal of geographic information systems.\nTRY THIS\nTry out the demo of what Claritas used to call the \u201cYou Are Where You Live\u201d tool. The Nielson 5 David DiBiase\nCompany has acquired Claritas and the tool is now called \u201cMyBestSegments.\u201d Point your browser to\nthe My Best Segments page. Click the button labeled \u201cZIP Code Look-up.\u201d\nEnter your ZIP code then choose a segmentation system. Do the lifestyle segments, listed on the left,\nseem accurate for your community? If you don\u2019t live in the United States, try Penn State\u2019s Zip code,\n16802.\nDoes the market segmentation match your expectations? Registered students are welcome to post\ncomments directly to this page.\n1.6. Databases, Mapping, and GIS\nOne of our objectives in this first chapter is to be able to define a geographic information system. Here\u2019s\na tentative definition: A GIS is a computer-based tool used to help people transform geographic\ndata into geographic information.\nThe definition implies that a GIS is somehow different from other information systems, and that\ngeographic data are different from non-geographic data. Let\u2019s consider the differences next.\n1.7. Database Management Systems\nClaritas and similar companies use database management systems (DBMS) to create the \u201clifestyle\nsegments\u201d that I referred to in the previous section. Basic database concepts are important since GIS\nincorporates much of the functionality of DBMS.\nDigital data are stored in computers as files. Often, data are arrayed in tabular form. For this reason,\ndata files are often called tables. A database is a collection of tables. Businesses and government\nagencies that serve large clienteles, such as telecommunications companies, airlines, credit card firms,\nand banks, rely on extensive databases for their billing, payroll, inventory, and marketing\noperations. Database management systems are information systems that people use to store, update,\nand analyze non-geographic databases.\nOften, data files are tabular in form, composed of rows and columns. Rows, also known as records,\ncorrespond with individual entities, such as customer accounts. Columns correspond with the\nvariousattributes associated with each entity. The attributes stored in the accounts database of a\ntelecommunications company, for example, might include customer names, telephone numbers,\naddresses, current charges for local calls, long distance calls, taxes, etc.\nGeographic data are a special case: records correspond with places, not people or accounts. Columns\nrepresent the attributes of places. The data in the following table, for example, consist of records for\nPennsylvania counties. Columns contain selected attributes of each county, including the county\u2019s ID\ncode, name, and 1980 population. Nature of Geographic Information 6\n1980 Population Data for PA Counties\nFIPS Code County 1980 Pop\n42001 Adams County 78274\n42003 Allegheny County 1336449\n42005 Armstrong County 73478\n42007 Beaver County 186093\n42009 Bedford County 47919\n42011 Berks County 336523\n42013 Blair County 130542\n42015 Bradford County 60967\n42017 Bucks County 541174\n42019 Butler County 152013\n42021 Cambria County 163062\n42023 Cameron County 5913\n42025 Carbon County 56846\n42027 Centre County 124812\nThe contents of one file in a database.\nThe example is a very simple file, but many geographic attribute databases are in fact very large (the\nU.S. is made up of over 3,000 counties, almost 50,000 census tracts, about 43,000 five-digit ZIP code\nareas and many tens of thousands more ZIP+4 code areas). Large databases consist not only of lots\nof data, but also lots of files. Unlike a spreadsheet, which performs calculations only on data that are\npresent in a single document, database management systems allow users to store data in, and retrieve\ndata from, many separate files. For example, suppose an analyst wished to calculate population change\nfor Pennsylvania counties between the 1980 and 1990 censuses. More than likely, 1990 population data\nwould exist in a separate file, like so: 7 David DiBiase\n1990 Population Data\nfor PA Counties\nFIPS Code 1990 Pop\n42001 84921\n42003 1296037\n42005 73872\n42007 187009\n42009 49322\n42011 352353\n42013 131450\n42015 62352\n42017 578715\n42019 167732\n42021 158500\n42023 5745\n42025 58783\n42027 131489\nAnother file in a database. A database management system (DBMS) can relate this file to the prior one\nillustrated above because they share the list of attributes called \u201cFIPS Code.\u201d\nIf two data files have at least one common attribute, a DBMS can combine them in a single new file.\nThe common attribute is called a key. In this example, the key was the county FIPS code (FIPS stands\nfor Federal Information Processing Standard). The DBMS allows users to produce new data as well as\nto retrieve existing data, as suggested by the new \u201c% Change\u201d attribute in the table below. Nature of Geographic Information 8\nPercent Change in Populations for PA Counties\n1980-1990\nFIPS County 1980 1990 % Change\n42001 Adams 78274 84921 8.5\n42003 Allegheny 1336449 1296037 -3\n42005 Armstrong 73478 73872 0.5\n42007 Beaver 186093 187009 0.5\n42009 Bedford 47919 49322 2.9\n42011 Berks 336523 352353 4.7\n42013 Blair 130542 131450 0.7\n42015 Bradford 60967 62352 2.3\n42017 Bucks 541174 578715 6.9\n42019 Butler 152013 167732 10.3\n42021 Cambria 163062 158500 -2.8\n42023 Cameron 5913 5745 -2.8\n42025 Carbon 56846 58783 3.4\n42027 Centre 124812 131489 5.3\nA new file produced from the prior two files as a result of two database operations. One operation\nmerged the contents of the two files without redundancy. A second operation produced a new\nattribute\u2013\u201d% Change\u201d\u2013dividing the difference between \u201c1990 Pop\u201d and \u201c1980 Pop\u201d by \u201c1980 Pop\u201d and\nexpressing the result as a percentage.\nDatabase management systems are valuable because they provide secure means of storing and\nupdating data. Database administrators can protect files so that only authorized users can make changes.\nDBMS provide transaction management functions that allow multiple users to edit the database\nsimultaneously. In addition, DBMS also provide sophisticated means to retrieve data that meet user\nspecified criteria. In other words, they enable users to select data in response to particular questions. A\nquestion that is addressed to a database through a DBMS is called a query.\nDatabase queries include basic set operations, including union, intersection, and difference. The\nproduct of aunion of two or more data files is a single file that includes all records and attributes,\nwithout redundancy. An intersection produces a data file that contains only records present in all files.\nA difference operation produces a data file that eliminates records that appear in both original files. (Try\ndrawing Venn diagrams\u2013intersecting circles that show relationships between two or more entities\u2013to\nillustrate the three operations. Then compare your sketch to the venn diagram example. ) All operations\nthat involve multiple data files rely on the fact that all files contain a common key. The key allows the\ndatabase system to relate the separate files. Databases that contain numerous files that share one or more\nkeys are called relational databases. Database systems that enable users to produce information from\nrelational databases are calledrelational database management systems.\nA common use of database queries is to identify subsets of records that meet criteria established by the 9 David DiBiase\nuser. For example, a credit card company may wish to identify all accounts that are 30 days or more past\ndue. A county tax assessor may need to list all properties not assessed within the past 10 years. Or the\nU.S. Census Bureau may wish to identify all addresses that need to be visited by census takers, because\ncensus questionnaires were not returned by mail. DBMS software vendors have adopted a standardized\nlanguage called SQL (Structured Query Language) to pose such queries.\nPRACTICE QUIZ\n1.8. Mapping Systems\nGIS (geographic information systems) arose out of the need to perform spatial queries on geographic\ndata. A spatial query requires knowledge of locations as well as attributes. For example, an\nenvironmental analyst might want to know which public drinking water sources are located within one\nmile of a known toxic chemical spill. Or, a planner might be called upon to identify property parcels\nlocated in areas that are subject to flooding. To accommodate geographic data and spatial queries,\ndatabase management systems need to be integrated with mapping systems. Until about 1990, most\nmaps were printed from handmade drawings or engravings. Geographic data produced by draftspersons\nconsisted of graphic marks inscribed on paper or film. To this day, most of the lines that appear on\ntopographic maps published by the U.S. Geological Survey were originally engraved by hand. The place\nnames shown on the maps were affixed with tweezers, one word at a time. Needless to say, such maps\nwere expensive to create and to keep up to date. Computerization of the mapmaking process had obvious\nappeal.\nComputer-aided design (CAD) CAD systems were originally developed for engineers, architects,\nand other design professionals who needed more efficient means to create and revise precise drawings of\nmachine parts, construction plans, and the like. In the 1980s, mapmakers began to adopt CAD in place of\ntraditional map drafting. CAD operators encode the locations and extents of roads, streams, boundaries\nand other entities by tracing maps mounted on electronic drafting tables, or by key-entering location\ncoordinates, angles, and distances. Instead of graphic features, CAD data consist of digital features, each\nof which is composed of a set of point locations. Calculations of distances, areas, and volumes can\neasily be automated once features are digitized. Unfortunately, CAD systems typically do not encode\ndata in forms that support spatial queries. In 1988, a geographer named David Cowen illustrated the\nbenefits and shortcomings of CAD for spatial decision making. He pointed out that a CAD system would\nbe useful for depicting the streets, property parcel boundaries, and building footprints of a residential\nsubdevelopment. A CAD operator could point to a particular parcel, and highlight it with a selected\ncolor or pattern. \u201cA typical CAD system\u201d, Cowen observed, \u201ccould not automatically shade each parcel\nbased on values in an assessor\u2019s database containing information regarding ownership, usage, or value,\nhowever.\u201d A CAD system would be of limited use to someone who had to make decisions about land\nuse policy or tax assessment.\nDesktop mapping An evolutionary stage in the development of GIS, desktop mapping systems like\nAtlas*GIS combined some of the capabilities of CAD systems with rudimentary linkages between\nlocation data and attribute data. A desktop mapping system user could produce a map in which\nproperty parcels are automatically colored according to various categories of property values, for\nexample. Furthermore, if property value categories were redefined, the map\u2019s appearance could be\nupdated automatically. Some desktop mapping systems even supported simple queries that allow users to\nretrieve records from a single attribute file. Most real-world decisions require more sophisticated queries\ninvolving multiple data files. That\u2019s where real GIS comes in. Nature of Geographic Information 10\nGeographic information systems (GIS) As stated earlier, information systems assist decision\nmakers by enabling them to transform data into useful information. GIS specializes in helping users\ntransform geographic data into geographic information. David Cowen (1988) defined GIS as a decision\nsupport tool that combines the attribute data handling capabilities of relational database management\nsystems with the spatial data handling capabilities of CAD and desktop mapping systems. In particular,\nGIS enables decision makers to identify locations or routes whose attributes match multiple criteria,\neven though entities and attributes may be encoded in many different data files.\nInnovators in many fields, including engineers, computer scientists, geographers, and others, started\ndeveloping digital mapping and CAD systems in the 1950s and 60s. One of the first challenges they\nfaced was to convert the graphical data stored on paper maps into digital data that could be stored in,\nand processed by, digital computers. Several different approaches to representing locations and extents\nin digital form were developed. The two predominant representation strategies are known as \u201cvector\u201d\nand \u201craster.\u201d\n1.9. Representation Strategies for Mapping\nRecall that data consist of symbols that represent measurements. Digital geographic data are encoded\nas alphanumeric symbols that represent locations and attributes of locations measured at or near Earth\u2019s\nsurface. No geographic data set represents every possible location, of course. The Earth is too big, and\nthe number of unique locations is too great. In much the same way that public opinion is measured\nthrough polls, geographic data are constructed by measuring representative samples of locations. And\njust as serious opinion polls are based on sound principles of statistical sampling, so too do geographic\ndata represent reality by measuring carefully chosen samples of locations. Vector and raster data are, at\nessence, two distinct sampling strategies.\nThe vector approach involves sampling locations at intervals along the length of linear entities (like\nroads), or around the perimeter of areal entities (like property parcels). When they are connected by\nlines, the sampled points form line features and polygon features that approximate the shapes of their\nreal-world counterparts.\nTwo frames (the first and last) of an animation showing the construction of a vector representation of a\nreservoir and highway. 11 David DiBiase\nTRY THIS\nClick the graphic above to download and view the animation file (vector.avi, 1.6 Mb) in a separate\nMicrosoft Media Player window.\nTo view the same animation in QuickTime format (vector.mov, 1.6 Mb), click here. Requires the\nQuickTime plugin, which is available free at apple.com.\nThe aerial photograph above left shows two entities, a reservoir and a highway. The graphic above\nright illustrates how the entities might be represented with vector data. The small squares are nodes:\npoint locations specified by latitude and longitude coordinates. Line segments connect nodes to form\nline features. In this case, the line feature colored red represents the highway. Series of line segments\nthat begin and end at the same node form polygon features. In this case, two polygons (filled with blue)\nrepresent the reservoir.\nThe vector data model is consistent with how surveyors measure locations at intervals as they traverse\na property boundary. Computer-aided drafting (CAD) software used by surveyors, engineers, and others,\nstores data in vector form. CAD operators encode the locations and extents of entities by tracing maps\nmounted on electronic drafting tables, or by key-entering location coordinates, angles, and distances.\nInstead of graphic features, CAD data consist of digital features, each of which is composed of a set of\npoint locations.\nThe vector strategy is well suited to mapping entities with well-defined edges, such as highways\nor pipelines or property parcels. Many of the features shown on paper maps, including contour lines,\ntransportation routes, and political boundaries, can be represented effectively in digital form using the\nvector data model.\nThe raster approach involves sampling attributes at fixed intervals. Each sample represents one cell\nin a checkerboard-shaped grid.\nTwo frames (the first and last) of an animation showing the construction of a raster representation of a\nreservoir and highway.\nTRY THIS\nClick the graphic above to download and view the animation file (raster.avi, 0.8 Mb) in a separate\nMicrosoft Media Player window.\nTo view the same animation in QuickTime format (raster.mov, 0.6 Mb), click here. Requires the\nQuickTime plugin, which is available free at apple.com.\nThe graphic above illustrates a raster representation of the same reservoir and highway as shown in Nature of Geographic Information 12\nthe vector representation. The area covered by the aerial photograph has been divided into a grid. Every\ngrid cell that overlaps one of the two selected entities is encoded with an attribute that associates it with\nthe entity it represents. Actual raster data would not consist of a picture of red and blue grid cells, of\ncourse; they would consist of a list of numbers, one number for each grid cell, each number representing\nan entity. For example, grid cells that represent the highway might be coded with the number \u201c1\u2033 and\ngrid cells representing the reservoir might be coded with the number \u201c2.\u201d\nThe raster strategy is a smart choice for representing phenomena that lack clear-cut boundaries, such\nas terrain elevation, vegetation, and precipitation. Digital airborne imaging systems, which are replacing\nphotographic cameras as primary sources of detailed geographic data, produce raster data by scanning\nthe Earth\u2019s surface pixel by pixel and row by row.\nBoth the vector and raster approaches accomplish the same thing: they allow us to caricature the\nEarth\u2019s surface with a limited number of locations. What distinguishes the two is the sampling strategies\nthey embody. The vector approach is like creating a picture of a landscape with shards of stained glass\ncut to various shapes and sizes. The raster approach, by contrast, is more like creating a mosaic with\ntiles of uniform size. Neither is well suited to all applications, however. Several variations on the vector\nand raster themes are in use for specialized applications, and the development of new object-oriented\napproaches is underway.\nPRACTICE QUIZ\n1.10. Automated Map Analysis\nAs I mentioned earlier, the original motivation for developing computer mapping systems was to\nautomate the map making process. Computerization has not only made map making more efficient, it\nhas also removed some of the technological barriers that used to prevent people from making maps\nthemselves. What used to be an arcane craft practiced by a few specialists has become a \u201ccloud\u201d\napplication available to any networked computer user. When I first started writing this course in 1997,\nmy example was the mapping extension included in Microsoft Excel 97, which made creating a simple\nmap as easy as creating a graph. Ten years later, who hasn\u2019t used Google Maps or MapQuest?\nAs much as computerization has changed the way maps are made, it has had an even greater impact\non how maps can be used. Calculations of distance, direction, and area, for example, are tedious and\nerror-prone operations with paper maps. Given a digital map, such calculations can easily be automated.\nThose who are familiar with CAD systems know this from first-hand experience. Highway engineers,\nfor example, rely on aerial imagery and digital mapping systems to estimate project costs by calculating\nthe volumes of rock that need to be excavated from hillsides and filled into valleys.\nThe ability to automate analytical tasks not only relieves tedium and reduces errors. It also allows us\nto perform tasks that would otherwise seem impractical. Consider, for example, if you were asked to\nplot on a map a 100-meter-wide buffer zone surrounding a protected stream. If all you had to work with\nwas a paper map, a ruler, and a pencil, you might have a lengthy job on your hands. You might draw\nlines scaled to represent 100 meters, perpendicular to the river on both sides, at intervals that vary in\nfrequency with the sinuosity of the stream. Then you might plot a perimeter that connects the end points\nof the perpendicular lines. If your task was to create hundreds of such buffer zones, you might conclude\nthat automation is a necessity, not just a luxury. 13 David DiBiase\nSurrounding a protected stream with a buffer polygon.\nSome tasks can be implemented equally well in either vector- or raster- oriented mapping systems.\nOther tasks are better suited to one representation strategy or another. The calculation of slope, for\nexample, or ofgradient\u2013the direction of maximum slope along a surface\u2013is more efficiently\naccomplished with raster data. The slope of one raster grid cell may be calculated by comparing its\nelevation to the elevations of the eight cells that surround it. Raster data are also preferred for a procedure\ncalled viewshed analysis that predicts which portions of a landscape will be in view, or hidden from\nview, from a particular perspective.\nSome mapping systems provide ways to analyze attribute data as well as locational data. For example,\nthe Excel mapping extension I mentioned above links the geographic data display capabilities of a\nmapping system with the data analysis capabilities of a spreadsheet. As you probably know, spreadsheets\nlike Excel let users perform calculations on individual fields, columns, or entire files. A value changed\nin one field automatically changes values throughout the spreadsheet. Arithmetic, financial, statistical,\nand even certain database functions are supported. But as useful as spreadsheets are, they were not\nengineered to provide secure means of managing and analyzing large databases that consist of many\nrelated files, each of which is the responsibility of a different part of an organization. A spreadsheet is\nnot a DBMS. And by the same token, a mapping system is not a GIS.\n1.11. Geographic Information Systems\nThe preceding discussion leads me to revise my working definition:\nAs I mentioned earlier, a geographer named David Cowen defined GIS as a decision-support tool\nthat combines the capabilities of a relational database management system with the capabilities of\na mapping system (1988). Cowen cited an earlier study by William Carstensen (1986), who sought to\nestablish criteria by which local governments might choose among competing GIS products. Carstensen\nchose site selection as an example of the kind of complex task that many organizations seek to\naccomplish with GIS. Given the necessary database, he advised local governments to expect that a fully\nfunctional GIS should be able to identify property parcels that are:\n\u2022 At least five acres in size; Nature of Geographic Information 14\n\u2022 Vacant or for sale;\n\u2022 Zoned commercial;\n\u2022 Not subject to flooding;\n\u2022 Located not more than one mile from a heavy duty road; and\n\u2022 Situated on terrain whose maximum slope is less than ten percent.\nThe first criterion\u2013identifying parcels five acres or more in size\u2013might require two operations. As\ndescribed earlier, a mapping system ought to be able to calculate automatically the area of a parcel. Once\nthe area is calculated and added as a new attribute into the database, an ordinary database query could\nproduce a list of parcels that satisfy the size criterion. The parcels on the list might also be highlighted\non a map, as in the example below.\nThe cartographic result of a database query identifying all property parcels greater than or equal to\nfive acres in size. (City of Ontario, CA, GIS Department. Used by permission.)\nThe ownership status of individual parcels would be an attribute of a property database maintained by\na local tax assessor\u2019s office. Parcels whose ownership status attribute value matched the criteria \u201cvacant\u201d\nor \u201cfor sale\u201d could be identified through another ordinary database query. 15 David DiBiase\nThe cartographic result of a spatial intersection (or map overlay) operation identifying all property\nparcels zoned for commercial (C-1) development. (City of Ontario, CA, GIS Department. Used by\npermission.)\nCarstensen\u2019s third criterion was to determine which parcels were situated within areas zoned for\ncommercial development. This would be simple if authorized land uses were included as an attribute\nin the community\u2019s property parcel database. This is unlikely to be the case, however, since zoning\nand taxation are the responsibilities of different agencies. Typically, parcels and land use zones exist as\nseparate paper maps. If the maps were prepared at the same scale, and if they accounted for the shape of\nthe Earth in the same manner, then they could be superimposed one over another on a light table. If the\nmaps let enough light through, parcels located within commercial zones could be identified.\nThe GIS approach to a task like this begins by digitizing the paper maps, and by producing\ncorresponding attribute data files. Each digital map and attribute data file is stored in the GIS separately,\nlike separate maplayers. A fully functional GIS would then be used to perform a spatial\nintersection that is analogous to the overlay of the paper maps. Spatial intersection, otherwise known\nas map overlay, is one of the defining capabilities of GIS. Nature of Geographic Information 16\nThe cartographic result of a buffer operation identifying all property parcels located within a specified\ndistance of a specified type of highway. (City of Ontario, CA, GIS Department. Used by permission.)\nAnother of Carstensen\u2019s criteria was to identify parcels located within one mile of a heavy-duty\nhighway. Such a task requires a digital map and associated attributes produced in such a way as to allow\nheavy-duty highways to be differentiated from other geographic entities. Once the necessary database is\nin place, abuffer operation can be used to create a polygon feature whose perimeter surrounds all \u201cheavy\nduty highway\u201d features at the specified distance. A spatial intersection is then performed, isolating the\nparcels within the buffer from those outside the buffer.\nTo produce a final list of parcels that meet all the site selection criteria, the GIS analyst might perform\nanintersection operation that creates a new file containing only those records that are present in all the\nother intermediate results. 17 David DiBiase\nThe cartographic result of the intersection of the above three figures. Only the parcels shown in this\nmap satisfy all of the site selection criteria. (City of Ontario, CA, GIS Department. Used by permission.)\nI created the maps shown above in 1998 using the Geographic Information Web Server of the City\nof Ontario, California. Although it is no longer supported, the City of Ontario was one of the first of its\nkind to provide much of the functionality required to perform a site suitability analysis online. Today,\nmany local governments offer similar Internet map services to current and prospective taxpayers.\nTRY THIS\nFind an online site selection utility similar to the one formerly provided by the City of Ontario.\nRegistered Penn State students can post a comment to this page describing the site\u2019s functionality, and\ncomparing it with the capabilities of the example illustrated above.\n1.12. Geographic Information Science and Technology\nSo far in this chapter I\u2019ve tried to make sense of GIS in relation to several information technologies,\nincluding database management, computer-aided design, and mapping systems. At this point I\u2019d like\nto expand the discussion to consider GIS as one element in a much larger field of study called\n\u201cGeographic Information Science and Technology\u201d (GIS&T). As shown in the following illustration,\nGIS&T encompasses three subfields including:\n\u2022 Geographic Information Science, the multidisciplinary research enterprise that addresses\nthe nature of geographic information and the application of geospatial technologies to basic\nscientific questions;\n\u2022 Geospatial Technology, the specialized set of information technologies that support\nacquisition, management, analysis, and visualization of geo-referenced data, including the\nGlobal Navigation Satellite System (GPS and others), satellite, airborne, and shipboard Nature of Geographic Information 18\nremote sensing systems; and GIS and image analysis software tools; and\n\u2022 Applications of GIS&T, the increasingly diverse uses of geospatial technology in\ngovernment, industry, and academia.This is the subfield in which most GIS professionals\nwork.\nArrows in the diagram below reflect relationships among the three subfields, as well as to numerous\nother fields, including Geography, Landscape Architecture, Computer Science, Statistics, Engineering,\nand many others. Each of these fields has influenced, and some have been influenced by, the\ndevelopment of GIS&T. It is important to note that these fields and subfields do not neatly correspond\nwith professions like GIS analyst, photogrammetrist, or land surveyor. Rather, GIS&T is a nexus of\noverlapping professions that differ in backgrounds, disciplinary allegiances, and regulatory status.\nThe field of Geographic Information Science and Technology (GIS&T) and its relations to other\nfields. Two-way relations that are half-dashed represent asymmetrical contributions between allied\nfields. (\u00a9 2006 Association of American Geographers and University Consortium for Geographic\nInformation Science. Used by permission. All rights reserved.)\nThe illustration above first appeared in the Geographic Information Science and Technology Body\nof Knowledge (DiBiase, DeMers, Johnson, Kemp, Luck, Plewe, and Wentz, 2006), published by the\nUniversity Consortium for Geographic Information Science (UCGIS) and the Association of American\nGeographers (AAG) in 2006. The Body of Knowledge is a community-developed inventory of the\nknowledge and skills that define the GIS&T field. Like the bodies of knowledge developed in Computer\nScience and other fields, the GIS&T BoK represents the GIS&T knowledge domain as a hierarchical\nlist of knowledge areas, units, topics, and educational objectives. The ten knowledge areas and 73 units\nthat make up the first edition are shown in the table below. Twenty-six \u201ccore\u201d units (those in which\nall graduates of a degree or certificate program should be able to demonstrate some level of mastery)\nare shown in bold type. Not shown are the 329 topics that make up the units, or the 1,660 education\nobjectives by which topics are defined. These appear in the full text of the GIS&T BoK. Unfortunately, 19 David DiBiase\nthe full text is not freely available online. An important related work produced by the U.S. Department\nof Labor is, however. We\u2019ll take a look at that shortly.\nKNOWLEDGE AREAS AND UNITS COMPRISING THE 1ST EDITION OF THE GIS&T BOK\n-Knowledge Area AM. Analytical Methods\n-Unit AM1 Academic and analytical origins\n-Unit AM2 Query operations and query languages\n-Unit AM3 Geometric measures\n-Unit AM4 Basic analytical operations\n-Unit AM5 Basic analytical methods\n-Unit AM6 Analysis of surfaces\n-Unit AM7 Spatial statistics\n-Unit AM8 Geostatistics\n-Unit AM9 Spatial regression and econometrics\n-Unit AM10 Data mining\n-Unit AM11 Network analysis\n-Unit AM12 Optimization and location-allocation modeling\n-Knowledge Area CF. Conceptual Foundations\n-Unit CF1 Philosophical foundations\n-Unit CF2 Cognitive and social foundations\n-Unit CF3 Domains of geographic information\n-Unit CF4 Elements of geographic information\n-Unit CF5 Relationships\n-Unit CF6 Imperfections in geographic information\n-Knowledge Area CV. Cartography and Visualization\n-Unit CV1 History and trends\n-Unit CV2 Data considerations\n-Unit CV3 Principles of map design\n-Unit CV4 Graphic representation techniques\n-Unit CV5 Map production\n-Unit CV6 Map use and evaluation\n-Knowledge Area DA. Design Aspects\n-Unit DA1 The scope of GI S&T system design\n-Unit DA2 Project definition\n-Unit DA3 Resource planning\n-Unit DA4 Database design\n-Unit DA5 Analysis design\n-Unit DA6 Application design\n-Unit DA7 System implementation\n-Knowledge Area DM. Data Modeling\n-Unit DM1 Basic storage and retrieval structures\n-Unit DM2 Database management systems\n-Unit DM3 Tessellation data models\n-Unit DM4 Vector and object data models\n-Unit DM5 Modeling 3D, temporal, and uncertain phenomena\n-Knowledge Area DN. Data Manipulation Nature of Geographic Information 20\n-Unit DN1 Representation transformation\n-Unit DN2 Generalization and aggregation\n-Unit DN3 Transaction management of geospatial data\n-Knowledge Area GC. Geocomputation\n-Unit GC1 Emergence of geocomputation\n-Unit GC2 Computational aspects and neurocomputing\n-Unit GC3 Cellular Automata (CA) models\n-Unit GC4 Heuristics\n-Unit GC5 Genetic algorithms (GA)\n-Unit GC6 Agent-based models\n-Unit GC7 Simulation modeling\n-Unit GC8 Uncertainty\n-Unit GC9 Fuzzy sets\n-Knowledge Area GD. Geospatial Data\n\u2013Unit GD1 Earth geometry\n\u2013Unit GD2 Land partitioning systems\n-Unit GD3 Georeferencing systems\n-Unit GD4 Datums\n-Unit GD5 Map projections\n-Unit GD6 Data quality\n-Unit GD7 Land surveying and GPS\n-Unit GD8 Digitizing\n-Unit GD9 Field data collection\n-Unit GD10 Aerial imaging and photogrammetry\n-Unit GD11 Satellite and shipboard remote sensing\n-Unit GD12 Metadata, standards, and infrastructures\n-Knowledge Area GS. GIS&T and Society\n-Unit GS1 Legal aspects\n-Unit GS2 Economic aspects\n-Unit GS3 Use of geospatial information in the public sector\n-Unit GS4 Geospatial information as property\n-Unit GS5 Dissemination of geospatial information\n-Unit GS6 Ethical aspects of geospatial information and technology\n-Unit GS7 Critical GIS\n-Knowledge Area OI. Organizational and Institutional Aspects\n-Unit OI1 Origins of GI S&T\n-Unit O2 Managing the GI system operations and infrastructure\n-Unit OI3 Organizational structures and procedures\n-Unit OI4 GI S&T workforce themes\n-Unit OI5 Institutional and inter-institutional aspects\n-Unit OI6 Coordinating organizations (national and international)\nTen knowledge areas and 73 units comprising the 1st edition of the GIS&T BoK. Core units are\nindicated with bold type. (\u00a9 2006 Association of American Geographers and University Consortium\nfor Geographic Information Science. Used by permission. All rights reserved.)\nNotice that the knowledge area that includes the most core units is GD: Geospatial Data. This\ncourse focuses on the sources and distinctive characteristics of geographic data. This is one part of\nthe knowledge base that most successful geospatial professionals possess. The Department of Labor\u2019s 21 David DiBiase\nGeospatial Technology Competency Model (GTCM) highlights this and other essential elements of the\ngeospatial knowledge base. We\u2019ll consider it next.\n1.13. Geospatial Competencies and Our Curriculum\nA body of knowledge is one way to think about the GIS&T field. Another way is as an industry\nmade up of agencies and firms that produce and consume goods and services, generate sales and\n(sometimes) profits, and employ people. In 2003, the U.S. Department of Labor (DoL) identified\n\u201cgeospatial technology\u201d as one of 14 \u201chigh growth\u201d technology industries, along with biotech, nanotech,\nand others. However, the DoL also observed that the geospatial technology industry was ill-defined, and\npoorly understood by the public.\nSubsequent efforts by the DoL and other organizations helped to clarify the industry\u2019s nature and\nscope. Following a series of \u201croundtable\u201d discussions involving industry thought leaders, the Geospatial\nInformation Technology Association (GITA) and the Association of American Geographers (AAG)\nsubmitted the following \u201cconcensus\u201d definition to DoL in 2006:\nThe geospatial industry acquires, integrates, manages, analyzes, maps, distributes, and uses\ngeographic, temporal, and spatial information and knowledge. The industry includes basic and applied\nresearch, technology development, education, and applications to address the planning, decision making,\nand operational needs of people and organizations of all types.\nIn addition to the proposed industry definition, the GITA and AAG report recommended that DoL\nestablish additional occupations in recognition of geospatial industry workforce activities and needs. At\nthe time, the existing geospatial occupations included only Surveyors, Surveying Technicians, Mapping\nTechnicians, and Cartographers and Photogrammetrists. Late in 2009, with input from the GITA, AAG,\nand other stakeholders, the DoL established six new geospatial occupations: Geospatial Information\nScientists and Technologists, Geographic Information Systems Technicians, Remote Sensing Scientists\nand Technologists, Remote Sensing Technicians, Precision Agriculture Technicians, and Geodetic\nSurveyors.\nTRY THIS\nInvestigate the geospatial occupations at the U.S. Department of Labor\u2019s \u201cO*Net\u201d database. Enter\n\u201cgeospatial\u201d in the search field named \u201cOccupation Quick Search.\u201d Follow links to occupation\ndescriptions. Note the estimates for 2008 employment and employment growth through 2018. Also\nnote that, for some anomalous reason, the keyword \u201cgeospatial\u201d is not associated with the occupation\n\u201cGeodetic Surveyor.\u201d Nature of Geographic Information 22\nMeanwhile, DoL commenced a \u201ccompetency modeling\u201d initiative for high-growth industries in 2005.\nTheir goal was to help educational institutions like ours meet the demand for qualified technology\nworkers by identifying what workers need to know and be able to do. At DoL, a competency is \u201cthe\ncapability to apply or use a set of related knowledge, skills, and abilities required to successfully perform\n\u2018critical work functions\u2019 or tasks in a defined work setting\u201d (Ennis 2008). A competency model is \u201ca\ncollection of competencies that together define successful performance in a particular work setting.\u201d\nWorkforce analysts at DoL began work on a Geospatial Technology Competency Model (GTCM)\nin 2005. Building on their research, a panel of accomplished practitioners and educators produced\na complete draft of the GTCM, which they subsequently revised in response to public comments.\nPublished in June 2010, the GTCM identifies the competencies that characterize successful workers in\nthe geospatial industry. In contrast to GIS&T Body of Knowledge, an academic project meant to define\nthe nature and scope of the field, the GTCM is an industry specification the defines what individual\nworkers and students should aspire to know and learn.\nTRY THIS\nExplore the Geospatial Technology Competency Model (GTCM) at the U.S. Department of Labor\u2019s\nCompetency Model Clearinghouse. Under \u201cIndustry Competency Models,\u201d follow the link \u201cGeospatial\nTechnology.\u201d There, the pyramid (as shown below) is an image map which you can click to reveal the\nvarious competencies. The complete GTCM is also available as a Word doc and PDF file. 23 David DiBiase\nThe GTCM specifies several \u201ctiers\u201d of competencies, progressing from general to occupationally\nspecific. Tiers 1 through 3 (the gray and red layers), called Foundation Competencies, specify general\nworkplace behaviors and knowledge that successful workers in most industries exhibit. Tiers 4 and 5\n(yellow) include the distinctive technical competencies that characterize a given industry and its three\nsectors: Positioning and Data Acquisition, Analysis and Modeling, and Programming and Application\nDevelopment. Above Tier 5 are additional Tiers corresponding to the occupation-specific competencies\nand requirements that are specified in the occupation descriptions published at O*NET Online, and in a\nGeospatial Management Competency Model that is in development as of January, 2012.\nOne way educational institutions and students can use the GTCM is as a guideline for assessing\nhow well curricula align with workforce needs. The Penn State Online GIS program conducted such an\nassessment in 2011. Results appear in the spreadsheet linked below.\nTRY THIS\nOpen the attached Excel spreadsheet to see how our Penn State Online GIS curricula address workforce\nneeds identified in the GTCM.\nThe sheet will open on a cover page. At the bottom of the sheet are tabs that correspond to Tiers 1-5\nof the GTCM. Click the tabs to view the worksheet associated with the Tier you want to see. Nature of Geographic Information 24\nIn each Tier worksheet, rows correspond to the GTCM competencies. Columns correspond to the\nPenn State Online courses included in the assessment. Courses that are required for most students are\nhighlighted light blue. Course authors and instructors were asked to state what students actually do in\nrelation to each of the GTCM competencies. Use the scroll bar at the bottom right edge of the sheet to\nreveal more courses.\nOpen the attached Flash movie to view a video demonstration of how to navigate the spreadsheet.\nBy studying this spreadsheet you\u2019ll gain insight about how individual courses, and how the Penn State\nOnline curriculum as a whole, relates to geospatial workforce needs. If you\u2019re interested in comparing\nours to curricula at other institutions, ask if they\u2019ve conducted a similar assessment. If they haven\u2019t, ask\nwhy not.\nFinally, don\u2019t forget that you can preview much of our online courseware through our Open\nEducational Resouces initiative.\n1.14. Distinguishing Properties of Geographic Data\nThe claim that geographic information science is a distinct field of study implies that spatial data are\nsomehow special data. Goodchild (1992) points out several distinguishing properties of geographic\ninformation. I have paraphrased four such properties below. Understanding them, and their implications\nfor the practice of geographic information science, is a key objective of this course.\n1. Geographic data represent spatial locations and non-spatial attributes measured at certain\ntimes.\n2. Geographic space is continuous.\n3. Geographic space is nearly spherical.\n4. Geographic data tend to be spatially dependent.\nLet\u2019s consider each of these properties next.\n1.15. Locations and Attributes\nGeographic data represent spatial locations and non-spatial attributes measured at certain\ntimes.Goodchild (1992, p. 33) observes that \u201ca spatial database has dual keys, allowing records to\nbe accessed either by attributes or by locations.\u201d Dual keys are not unique to geographic data, but\n\u201cthe spatial key is distinct, as it allows operations to be defined which are not included in standard\nquery languages.\u201d In the intervening years, software developers have created variations on SQL that\nincorporate spatial queries. The dynamic nature of geographic phenomena complicates the issue further,\nhowever. The need to pose spatio-temporal queries challenges geographic information scientists\n(GIScientists) to develop ever more sophisticated ways to represent geographic phenomena, thereby\nenabling analysts to interrogate their data in ever more sophisticated ways.\n1.16. Continuity\nGeographic space is continuous. Although dual keys are not unique to geographic data, one property\nof the spatial key is. \u201cWhat distinguishes spatial data is the fact that the spatial key is based on two 25 David DiBiase\ncontinuous dimensions\u201d (Goodchild, 1992, p.33). \u201cContinuous\u201d refers to the fact that there are no\ngaps in the Earth\u2019s surface. Canyons, crevasses, and even caverns notwithstanding, there is no position\non or near the surface of the Earth that cannot be fixed within some sort of coordinate system grid.\nNor is there any theoretical limit to how exactly a position can be specified. Given the precision of\nmodern positioning technologies, the number of unique point positions that could be used to define a\ngeographic entity is practically infinite. Because it\u2019s not possible to measure, let alone to store, manage,\nand process, an infinite amount of data, all geographic data is selective, generalized, approximate.\nFurthermore, the larger the territory covered by a geographic database, the more generalized the\ndatabase tends to be.\nGeographic data are generalized according to scale. Click on the buttons beneath the map to zoom\nin and out on the town of Gorham. (U.S. Geological Survey). (Note: You will need to have the Adobe\nFlash player installed in order to complete this exercise. If you do not already have the Flash player, you\ncan download it for free from Adobe.)\nFor example, the illustration above shows a town called Gorham depicted on three\ndifferent topographic maps produced by the United States Geological Survey. Gorham occupies a\nsmaller space on the small-scale (1:250,000) map than it does at 1:62,000 or at 1:24,000. But the relative\nsize of the feature isn\u2019t the only thing that changes. Notice that the shape of the feature that represents\nthe town changes also. As does the number of features and the amount of detail shown within the town\nboundary and in the surrounding area. The name for this characteristically parallel decline in map detail\nand map scale is generalization.\nIt is important to realize that generalization occurs not only on printed maps, but in digital databases\nas well. It is possible to represent phenomena with highly detailed features (whether they be made up of\nhigh-resolution raster grid cells or very many point locations) in a single scale-independent database.\nIn practice, however, highly detailed databases are not only extremely expensive to create and maintain,\nbut they also bog down information systems when used in analyses of large areas. For this reason,\ngeographic databases are usually created at several scales, with different levels of detail captured for\ndifferent intended uses.\n1.17. Nearly Spherical\nGeographic space is nearly spherical. The fact that the Earth is nearly, but not quite, a sphere poses\nsome surprisingly complex problems for those who wish to specify locations precisely. Nature of Geographic Information 26\nDifferences in elevation between a geoid model and a reference ellipsoid. Deviations range from a\nhigh of 75 meters (colored red, over New Guinea) to a low of 104 meters (colored purple, in the Indian\nOcean). (National Geodetic Survey, n. d.).\nThe geographic coordinate system of latitude and longitude coordinates provides a means to define\npositions on a sphere. Inaccuracies that are unacceptable for some applications creep in, however,\nwhen we confront the Earth\u2019s \u201cactual\u201d irregular shape, which is called the geoid. Furthermore, the\ncalculations of angles and distance that surveyors and others need to perform routinely are cumbersome\nwith spherical coordinates.\nThat consideration, along with the need to depict the Earth on flat pieces of paper, compels us to\ntransform the globe into a plane, and to specify locations in plane coordinates instead of spherical\ncoordinates. The set of mathematical transformations by which spherical locations are converted to\nlocations on a plane\u2013called map projections\u2013all lead inevitably to one or another form of inaccuracy.\nAll this is trouble enough, but we encounter even more difficulties when we seek to define \u201cvertical\u201d\npositions (elevations) in addition to \u201chorizontal\u201d positions. Perhaps it goes without saying that an\nelevation is the height of a location above some datum, such as mean sea level. Unfortunately, to be\nsuitable for precise positioning, a datum must correspond closely with the Earth\u2019s actual shape. Which\nbrings us back again to the problem of the geoid.\nWe will consider these issues in greater depth in Chapter 2. For now, suffice it to say that geographic\ndata are unique in having to represent phenomena that are distributed on a continuous and nearly\nspherical surface.\n1.18. Spatial Dependency\nGeographic data tend to be spatially dependent. Spatial dependence is \u201cthe propensity for nearby\nlocations to influence each other and to possess similar attributes\u201d (Goodchild, 1992, p.33). In other\nwords, to paraphrase a famous geographer named Waldo Tobler, while everything is related to\neverything else, things that are close together tend to be more related than things that are far apart.\nTerrain elevations, soil types, and surface air temperatures, for instance, are more likely to be similar 27 David DiBiase\nat points two meters apart than at points two kilometers apart. A statistical measure of the similarity of\nattributes of point locations is called spatial autocorrelation.\nGiven that geographic data are expensive to create, spatial dependence turns out to be a very\nuseful property. We can sample attributes at a limited number of locations, then estimate the attributes\nof intermediate locations. The process of estimating unknown values from nearby known values is\ncalledinterpolation. Interpolated values are reliable only to the extent that the spatial dependence of the\nphenomenon can be assumed. If we were unable to assume some degree of spatial dependence, it would\nbe impossible to represent continuous geographic phenomena in digital form.\nPRACTICE QUIZ\n19. Geographic Data and Geographic Questions\nThe ultimate objective of all geospatial data and technologies, after all, is to produce knowledge. Most\nof us are interested in data only to the extent that they can be used to help understand the world around\nus, and to make better decisions. Decision making processes vary a lot from one organization to another.\nIn general, however, the first steps in making a decision are to articulate the questions that need to be\nanswered, and to gather and organize the data needed to answer the questions (Nyerges & Golledge,\n1997).\nGeographic data and information technologies can be very effective in helping to answer certain kinds\nof questions. The expensive, long-term investments required to build and sustain GIS infrastructures\ncan be justified only if the questions that confront an organization can be stated in terms that GIS is\nequipped to answer. As a specialist in the field, you may be expected to advise clients and colleagues on\nthe strengths and weaknesses of GIS as a decision support tool. To follow are examples of the kinds of\nquestions that are amenable to GIS analyses, along with questions that GIS is not so well suited to help\nanswer.\nQUESTIONS CONCERNING INDIVIDUAL GEOGRAPHIC ENTITIES\nThe simplest geographic questions pertain to individual entities. Such questions include:\nQUESTIONS ABOUT SPACE\n\u2022 Where is the entity located?\n\u2022 What is its extent?\nQUESTIONS ABOUT ATTRIBUTES\n\u2022 What are the attributes of the entity located there?\n\u2022 Do its attributes match one or more criteria?\nQUESTIONS ABOUT TIME\n\u2022 When were the entity\u2019s location, extent or attributes measured?\n\u2022 Has the entity\u2019s location, extent, or attributes changed over time? Nature of Geographic Information 28\nSimple questions like these can be answered effectively with a good printed map, of course. GIS\nbecomes increasingly attractive as the number of people asking the questions grows, especially if they\nlack access to the required paper maps.\nQUESTIONS CONCERNING MULTIPLE GEOGRAPHIC ENTITIES\nHarder questions arise when we consider relationships among two or more entities. For instance, we can\nask:\nQUESTIONS ABOUT SPATIAL RELATIONSHIPS\n\u2022 Do the entities contain one another?\n\u2022 Do they overlap?\n\u2022 Are they connected?\n\u2022 Are they situated within a certain distance of one another?\n\u2022 What is the best route from one entity to the others?\n\u2022 Where are entities with similar attributes located?\nQUESTIONS ABOUT ATTRIBUTE RELATIONSHIPS\n\u2022 Do the entities share attributes that match one or more criteria?\n\u2022 Are the attributes of one entity influenced by changes in another entity?\nQUESTIONS ABOUT TEMPORAL RELATIONSHIPS\n\u2022 Have the entities\u2019 locations, extents, or attributes changed over time?\nGeographic data and information technologies are very well suited to answering moderately complex\nquestions like these. GIS is most valuable to large organizations that need to answer such questions\noften.\nQUESTIONS THAT GIS IS NOT PARTICULARLY GOOD AT ANSWERING\nHarder still, however, are explanatory questions\u2013such as why entities are located where they\nare, why they have the attributes they do, and why they have changed as they have. In addition,\norganizations are often concerned with predictive questions\u2013such as what will happen at this location if\nthus-and-so happens atthat location? In general, commercial GIS software packages cannot be expected\nto provide clear-cut answers to explanatory and predictive questions right out of the box. Typically,\nanalysts must turn to specialized statistical packages and simulation routines. Information produced\nby these analytical tools may then be re-introduced into the GIS database, if necessary. Research and\ndevelopment efforts intended to more tightly couple analytical software with GIS software are underway\nwithin the GIScience community. It is important to keep in mind that decision support tools like GIS are\nno substitutes for human experience, insight, and judgment.\nAt the outset of the chapter I suggested that producing information by analyzing data is something like\nproducing energy by burning coal. In both cases, technology is used to realize the potential value of a 29 David DiBiase\nraw material. Also in both cases, the production process yields some undesirable by-products. Similarly,\nin the process of answering certain geographic questions, GIS tends to raise others, such as:\n\u2022 Given the intrinsic imperfections of the data, how reliable are the results of the GIS analysis?\n\u2022 Does the information produced through GIS analysis tend to systematically benefit some\nconstituent groups at the expense of others?\n\u2022 Should the data used to make the decision be made public?\n\u2022 Does the use of GIS affect the organization\u2019s decision-making processes in ways that are\nbeneficial to its management, its employees, and its customers?\nAs is the case in so many endeavors, the answer to a geographic question usually includes more\nquestions.\nTRY THIS\nCan you cite an example of a \u201chard\u201d question that you and your GIS system have been called upon to\naddress? Registered Penn State students can post a comment directly to this page.\n1.20. Summary\nIt\u2019s a truism among specialists in geographic information that the lion\u2019s share of the cost of most GIS\nprojects is associated with the development and maintenance of a suitable database. It seems appropriate,\ntherefore, that our first course in geographic information systems should focus upon the properties of\ngeographic data.\nI began this first chapter by defining data in a generic sense, as sets of symbols that represent\nmeasurements of phenomena. I suggested that data are the raw materials from which information is\nproduced. Information systems, such as database management systems, are technologies that people use\nto transform data into the information needed to answer questions, and to make decisions.\nSpatial data are special data. They represent the locations, extents, and attributes of objects and\nphenomena that make up the Earth\u2019s surface at particular times. Geographic data differ from other kinds\nof data in that they are distributed along a continuous, nearly spherical globe. They also have the unique\nproperty that the closer two entities are located, the more likely they are to share similar attributes.\nGIS is a special kind of information system that combines the capabilities of database management\nsystems with those of mapping systems. GIS is one object of study of the loosely-knit, multidisciplinary\nfield called Geographic Information Science and Technology. GIS is also a profession\u2013one of several\nthat make up the geospatial industry. As Yogi Berra said, \u201cIn theory, there\u2019s no difference between theory\nand practice. In practice there is.\u201d In the chapters and projects that follow, we\u2019ll investigate the nature of\ngeographic information from both conceptual and practical points of view.\nCOMMENTS AND QUESTIONS\nRegistered students are welcome to post comments, questions, and replies to questions about the\ntext. Particularly welcome are anecdotes that relate the chapter text to your personal or professional\nexperience. In addition, there are discussion forums available in the ANGEL course management system\nfor comments and questions about topics that you may not wish to share with the whole world. Nature of Geographic Information 30\nTo post a comment, scroll down to the text box under \u201cPost new comment\u201d and begin typing in the text\nbox, or you can choose to reply to an existing thread. When you are finished typing, click on either the\n\u201cPreview\u201d or \u201cSave\u201d button (Save will actually submit your comment). Once your comment is posted,\nyou will be able to edit or delete it as needed. In addition, you will be able to reply to other posts at any\ntime.\nNote: the first few words of each comment become its \u201ctitle\u201d in the thread.\n1.21. Bibliography\nCarstensen, L. W. (1986). Regional land information systems development using relational databases\nand geographic information systems. Proceedings of the AutoCarto, London, 507-516.\nCity of Ontario, California. (n.d.). Geographic information web server. Retrieved on July 6, 1999\nfrom http:\/\/www.ci.ontario.ca.us\/gis\/index.asp(since retired).\nCowen, D. J. (1988). GIS versus CAD versus DBMS: What are the differences? Photogrammetric\nEngineering and Remote Sensing 54:11, 1551-1555.\nDiBiase, D. and twelve others (2010). The New Geospatial Technology Competency Model: Bringing\nworkforce needs into focus. URISA Journal22:2, 55-72.\nDiBiase, D, M. DeMers, A. Johnson, K. Kemp, A. Luck, B. Plewe, and E. Wentz (2007). Introducing\nthe First Edition of the GIS&T Body of Knowledge. Cartography and Geographic Information\nScience, 34(2), pp. 113-120. U.S. National Report to the International Cartographic Association.\nEnnis, M. R. (2008). Competency models: A review of the literature and the role of the employment\nand training administration (ETA).http:\/\/www.careeronestop.org\/COMPETENCYMODEL\/\ninfo_documents\/OPDRLiteratureReview.pdf.\nGITA and AAG (2006). Defining and communicating geospatial industry workforce demand: Phase I\nreport.\nGoodchild, M. (1992). Geographical information science. International Journal of Geographic\nInformation Systems 6:1, 31-45.\nGoodchild, M. (1995). GIS and geographic research. In J. Pickles (Ed.),Ground truth: the social\nimplications of geographic information systems(pp. of chapter). New York: Guilford.\nNational Decision Systems. A zip code can make your company lots of money! Retrieved on July 6,\n1999 fromhttp:\/\/laguna.natdecsys.com\/lifequiz (since retired).\nNational Geodetic Survey. (1997). Image generated from 15\u2032x15\u2032 geoid undulations covering the\nplanet Earth. Retrieved 1999, fromhttp:\/\/www.ngs.noaa.gov\/GEOID\/geo-index.html (since retired).\nNyerges, T. L. & Golledge, R. G. (n.d.) NCGIA core curriculum in GIS, National Center for\nGeographic Information and Analysis, University of California, Santa Barbara, Unit 007. Retrieved\nNovember 12, 1997, fromhttp:\/\/www.ncgia.ucsb.edu\/giscc\/units\/u007\/u007.html (since retired).\nUnited States Department of the Interior Geological Survey. (1977). [map]. 1:24 000. 7.5 minute\nseries. Washington, D.C.: USDI.\nUnited States Geologic Survey. \u201cBellefonte, PA Quadrangle\u201d (1971). [map]. 1:24 000. 7.5 minute\nseries. Washington, D.C.:USGS.\nUniversity Consortium for Geographic Information Science. Retrieved April 26, 2006,\nfrom http:\/\/www.ucgis.org\nWilson, J. D. (2001). Attention data providers: A billion-dollar application awaits. GEOWorld,\nFebruary, 54.\nWorboys, M. F. (1995). GIS: A computing perspective. London: Taylor and Francis.\n\u2039 20. Summary up Chapter 2: Scales and Transformations \u203a Chapter 2\n31 Scales and Transformations\nDavid DiBiase\n2.1. Overview\nChapter 1 outlined several of the distinguishing properties of geographic data. One is that geographic\ndata are necessarily generalized, and that generalization tends to vary with scale. A second\ndistinguishing property is that the Earth\u2019s complex, nearly-spherical shape complicates efforts to specify\nexact positions on Earth\u2019s surface. This chapter explores implications of these properties by illuminating\nconcepts of scale, Earth geometry, coordinate systems, the \u201chorizontal datums\u201d that define the\nrelationship between coordinate systems and the Earth\u2019s shape, and the various methods for transforming\ncoordinate data between 3D and 2D grids, and from one datum to another.\nCompared to Chapter 1, Chapter 2 may seem long, technical, and abstract, particularly to those for\nwhom these concepts are new. Registered students will notice that we\u2019ve allotted more time to work\nthrough the chapter and associated quizzes. Seven practice quizzes are available in ANGEL to help\nregistered students get a grip on these concepts. Chapter 2 also includes a graded quiz in the same open-\nbook format as the practice quizzes. If you do reasonably well on the practice quizzes, you should do\nwell enough on the graded quiz too.\nObjectives\nStudents who successfully complete Chapter 2 should be able to:\n1. Demonstrate your ability to specify geospatial locations using geographic coordinates;\n2. Convert geographic coordinates between two different formats;\n3. Explain the concept of a horizontal datum;\n4. Calculate the change in a coordinate location due to a change from one horizontal datum to\nanother;\n5. Estimate the magnitude of \u201cdatum shift\u201d associated with the adjustment from NAD 27 to\nNAD 83;\n6. Recognize the kind of transformation that is appropriate to georegister two or more data sets;\n7. Describe the characteristics of the UTM coordinate system, including its basis in the\nTransverse Mercator map projection;\n8. Plot UTM coordinates on a map;\n9. Describe the characteristics of the SPC system, including map projection on which it is\nbased;\n10. Convert geographic coordinates to SPC coordinates;\n11. Interpret distortion diagrams to identify geometric properties of the sphere that are preserved\nby a particular projection; and\n12. Classify projected graticules by projection family.\n32 33 David DiBiase\nComments and Questions\nRegistered students are welcome to post comments, questions, and replies to questions about the\ntext. Particularly welcome are anecdotes that relate the chapter text to your personal or professional\nexperience. In addition, there are discussion forums available in the ANGEL course management system\nfor comments and questions about topics that you may not wish to share with the whole world.\nTo post a comment, scroll down to the text box under \u201cPost new comment\u201d and begin typing in the text\nbox, or you can choose to reply to an existing thread. When you are finished typing, click on either the\n\u201cPreview\u201d or \u201cSave\u201d button (Save will actually submit your comment). Once your comment is posted,\nyou will be able to edit or delete it as needed. In addition, you will be able to reply to other posts at any\ntime.\nNote: the first few words of each comment become its \u201ctitle\u201d in the thread.\n2.2. Checklist\nThe following checklist is for Penn State students who are registered for classes in which this text,\nand associated quizzes and projects in the ANGEL course management system, have been assigned. You\nmay find it useful to print this page out first so that you can follow along with the directions. Nature of Geographic Information 34\nChapter 2 Checklist (for registered students only)\nStep Activity Access\/Directions\nThis is the second page of the Chapter. Click on the links at the bottom\nof the page to continue or to return to the previous page, or to go to the\n1 Read Chapter 2\ntop of the chapter. You can also navigate the text via the links in the\nGEOG 482 menu on the left.\nSubmit eight practice\nquizzesincluding:\n\u2022 Map Scale\n\u2022 Geographic\nCoordinate System\n\u2022 Horizontal Datums\n\u2022 Coordinate\nTransformations\n\u2022 UTM Coordinate\nGo to ANGEL > [your course section] > Lessons tab > Chapter 2 folder\n2 System\n> [quiz]\n\u2022 SPC Coordinate\nSystem\n\u2022 Map Projection\nProperties\n\u2022 Classifying Map\nProjections\nPractice quizzes are not graded\nand may be submitted more\nthan once.\nPerform \u201cTry this\u201d\nactivities Including:\n\u2022 Geographic\ncoordinates practice\napplication\n\u2022 Calculate horizontal\ndatum shift\n3 \u2022 UTM coordinates Instructions are provided for each activity.\npractice application\n\u2022 Explore SPC zone\ncharacteristics\n\u2022 Interactive Album of\nMap Projections\n\u201cTry this\u201d activities are not\ngraded.\nSubmit the Chapter 2 Graded ANGEL > [your course section] > Lessons tab > Chapter 2 folder >\n4\nQuiz Chapter 2 Graded Quiz 35 David DiBiase\nStep Activity Access\/Directions\nRead comments and\nquestionsposted by fellow Comments and questions may be posted on any page of the text, or in a\n5\nstudents. Add comments and Chapter-specific discussion forum in ANGEL.\nquestions of your own, if any.\n2.3. Scale\nYou hear the word \u201cscale\u201d often when you work around people who produce or use geographic\ninformation. If you listen closely, you\u2019ll notice that the term has several different meanings, depending\non the context in which it is used. You\u2019ll hear talk about the scales of geographic phenomena and about\nthe scales at which phenomena are represented on maps and aerial imagery. You may even hear the word\nused as a verb, as in \u201cscaling a map\u201d or \u201cdownscaling.\u201d The goal of this section is to help you learn to tell\nthese different meanings apart, and to be able to use concepts of scale to help make sense of geographic\ndata.\nSpecifically, in this part of Chapter 2 you will learn to:\n1. Calculate map scale using representative fractions.\n2. Describe the general relationship between map scale, detail, and accuracy.\n2.4. Scale as Scope\nOften \u201cscale\u201d is used as a synonym for \u201cscope,\u201d or \u201cextent.\u201d For example, the title of an international\nresearch project called The Large Scale Biosphere-Atmosphere Experiment in Amazonia (1999) uses the\nterm \u201clarge scale\u201d to describe a comprehensive study of environmental systems operating across a large\nregion. This usage is common not only among environmental scientists and activists, but also among\neconomists, politicians, and the press. Those of us who specialize in geographic information usually use\nthe word \u201cscale\u201d differently, however.\n2.5. Map and Photo Scale\nWhen people who work with maps and aerial images use the word \u201cscale,\u201d they usually are talking about\nthe sizes of things that appear on a map or air photo, relative to the actual sizes of those things on the\nground.\nMap scale is the proportion between a distance on a map and a corresponding distance on the\nground:\n(Dm \/ Dg).\nBy convention, the proportion is expressed as a \u201crepresentative fraction\u201d in which map distance (Dm)\nis reduced to 1. The proportion, or ratio, is also typically expressed in the form 1 : Dg rather than 1 \/ Dg.\nThe representative fraction 1:100,000, for example, means that a section of road that measures 1 unit\nin length on a map stands for a section of road on the ground that is 100,000 units long.\nIf we were to change the scale of the map such that the length of the section of road on the map was Nature of Geographic Information 36\nreduced to, say, 0.1 units in length, we would have created a smaller-scale map whose representative\nfraction is 0.1:100,000, or 1:1,000,000. When we talk about large- and small-scale maps and geographic\ndata, then, we are talking about the relative sizes and levels of detail of the features represented in the\ndata. In general, the larger the map scale, the more detail is shown. This tendency is illustrated below.\nGeographic data are generalized according to scale. Click on the buttons beneath the map to zoom in\nand out on the town of Gorham. (Adapted from Thompson, 1988)\nOne of the defining characteristics of topographic maps is that scale is consistent across each map\nand within each map series. This isn\u2019t true for aerial imagery, however, except for images that have\nbeen orthorectified. As discussed in Chapter 6, large scale maps are typically derived from aerial\nimagery. One of the challenges associated with using air photos as sources of map data is that the scale\nof an aerial image varies from place to place as a function of the elevation of the terrain shown in the\nscene. Assuming that the aircraft carrying the camera maintains a constant flying height (which pilots\nof such aircraft try very hard to do), the distance between the camera and the ground varies along each\nflight path. This causes air photo scale to be larger where the terrain is higher and smaller where the\nterrain lower. An \u201corthorectified\u201d image is one in which variations in scale caused by variations in terrain\nelevation (among other effects) have been removed.\nYou can calculate the average scale of an unrectified air photo by solving the equation Sp = f \/ (H-\nhavg), where f is the focal length of the camera, H is the flying height of the aircraft above mean\nsea level, and havg is the average elevation of the terrain. You can also calculate air photo scale at a\nparticular point by solving the equation Sp = f \/ (H-h), where f is the focal length of the camera, H is the\nflying height of the aircraft above mean sea level, and h is the elevation of the terrain at a given point.\nYou\u2019ll have a chance to practice calculating both map scale and air photo scale in a forthcoming practice\nquiz.\n2.6. Graphic Map Scales\nAnother way to express map scale is with a graphic (or \u201cbar\u201d) scale. Unlike representative fractions,\ngraphic scales remain true when maps are shrunk or magnified.\nGraphic scales.\nIf they include a scale at all, most maps include a bar scale like the one shown above left. Some\nalso express map scale as a representative fraction. Either way, the implication is that scale is uniform\nacross the map. In fact, except for maps that show only very small areas, scale varies across every map.\nAs you probably know, this follows from the fact that positions on the nearly-spherical Earth must be\ntransformed to positions on two-dimensional sheets of paper. Systematic transformations of this kind are\ncalled map projections. As we will discuss in greater depth later in this chapter, all map projections\nare accompanied by deformation of features in some or all areas of the map. This deformation causes 37 David DiBiase\nmap scale to vary across the map. Representative fractions may therefore specify map scale along a line\nat which deformation is minimal (nominal scale). Bar scales denote only the nominal or average map\nscale. Variable scales, like the one illustrated above right, show how scale varies, in this case by latitude,\ndue to deformation caused by map projection.\n2.7. Map Scale and Accuracy\nOne of the special characteristics of geographic data is that phenomena shown on maps tend to be\nrepresented differently at different scales. Typically, as scale decreases, so too does the number of\ndifferent features, and the detail with which they are represented. Not only printed maps, but also digital\ngeographic data sets that cover extensive areas tend to be moregeneralized than data sets that cover\nlimited areas.\nAccuracy also tends to vary in proportion with map scale. The United States Geological Survey,\nfor example, guarantees that the mapped positions of 90 percent of well-defined points shown on\nits topographic map series at scales smaller than 1:20,000 will be within 0.02 inches of their actual\npositions on the map (see the National Geospacial Program Standards and Specifications). Notice that\nthis \u201cNational Map Accuracy Standard\u201d is scale-dependent. The allowable error of well-defined points\n(such as control points, road intersections, and such) on 1:250,000 scale topographic maps is thus 1\n\/ 250,000 = 0.02 inches \/ Dg or Dg = 0.02 inches x 250,000 = 5,000 inches or 416.67 feet. Neither\nsmall-scale maps nor the digital data derived from them are reliable sources of detailed geographic\ninformation.\nAreas (in gray) disqualified as potential sites for a low level radioactive waste storage facility depicted\non a small scale map (original 1:1,500,000) mask small suitable areas large enough to contain the\n500-acre facility (Chem-Nuclear Systems, Inc., 1994).\nSometimes the detail lost on small-scale maps causes serious problems. For example, a contractor\nhired to use GIS to find a suitable site for a low level radioactive waste storage facility in Pennsylvania\npresented a series of 1:1,500,000 scale maps at public hearings around the state in the early 1990s. The Nature of Geographic Information 38\nscale was chosen so that disqualified areas of the entire state could be printed on a single 11 x 17 inch\npage. A report accompanying the map included the disclaimer that \u201cit is possible that small areas of\nsufficient size for the LLRW disposal facility site may exist within regions that appear disqualified on\nthe [map]. The detailed information for these small areas is retained within the GIS even though they are\nnot visually illustrated\u2026\u201d (Chem-Nuclear Systems, Inc. 1993, p. 20). Unfortunately for the contractor, alert\ncitizens recognized the shortcomings of the small-scale map, and newspapers published reports accusing\nthe out-of-state company of providing inaccurate documents. Subsequent maps were produced at a scale\nlarge enough to discern 500-acre suitable areas.\n2.8. Scale as a Verb\nThe term \u201cscale\u201d is sometimes used as a verb. To scale a map is to reproduce it at a different size. For\ninstance, if you photographically reduce a 1:100,000-scale map to 50 percent of its original width and\nheight, the result would be one-quarter the area of the original. Obviously the map scale of the reduction\nwould be smaller too: 1\/2 x 1\/100,000 = 1\/200,000.\nBecause of the inaccuracies inherent in all geographic data, particularly in small scale maps,\nscrupulous geographic information specialists avoid enlarging source maps. To do so is to exaggerate\ngeneralizations and errors. The original map used to illustrate areas in Pennsylvania disqualified from\nconsideration for low-level radioactive waste storage shown on an earlier page, for instance, was printed\nwith the statement \u201cBecause of map scale and printing considerations, it is not appropriate to enlarge or\notherwise enhance the features on this map.\u201d\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 2 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about Map Scale.\nYou may take practice quizzes as many times as you wish. They are not scored and do not affect your\ngrade in any way.\n2.9. Geospatial Measurement Scales\nThe word \u201cscale\u201d can also be used as a synonym for a ruler\u2013a measurement scale. Because data\nconsist of symbols that represent measurements of phenomena, it\u2019s important to understand the reference\nsystems used to take the measurements in the first place. In this section we\u2019ll consider a measurement\nscale known as the geographic coordinate system that is used to specify positions on the Earth\u2019s\nroughly spherical surface. In other sections we\u2019ll encounter two-dimensional (plane) coordinate systems,\nas well as the measurement scales used to specify attribute data.\nIn this section of Chapter 2 you will:\n1. Demonstrate your ability to specify geospatial locations using geographic coordinates.\n2. Convert geographic coordinates between two different formats. 39 David DiBiase\n2.10. Coordinate Systems\nA Cartesian coordinate system.\nAs you probably know, locations on the Earth\u2019s surface are measured and represented in terms\nof coordinates. A coordinate is a set of two or more numbers that specifies the position of a point,\nline, or other geometric figure in relation to some reference system. The simplest system of this kind\nis a Cartesian coordinate system (named for the 17th century mathematician and philosopher Ren\u00e9\nDescartes). A Cartesian coordinate system is simply a grid formed by juxtaposing two measurement\nscales, one horizontal (x) and one vertical (y). The point at which both x and y equal zero is called\nthe origin of the coordinate system. In the illustration above, the origin (0,0) is located at the center of\nthe grid. All other positions are specified relative to the origin. The coordinate of upper right-hand corner\nof the grid is (6,3). The lower left-hand corner is (-6,-3). If this is not clear, please ask for clarification!\nCartesian and other two-dimensional (plane) coordinate systems are handy due to their simplicity.\nFor obvious reasons they are not perfectly suited to specifying geospatial positions, however.\nThe geographic coordinate system is designed specifically to define positions on the Earth\u2019s roughly-\nspherical surface. Instead of the two linear measurement scales x and y, the geographic coordinate\nsystems juxtaposes two curved measurement scales. The east-west scale,\ncalled longitude (conventionally designated by the Greek symbol lambda), ranges from +180\u00b0 to -180\u00b0.\nBecause the Earth is round, +180\u00b0 (or 180\u00b0 E) and -180\u00b0 (or 180\u00b0 W) are the same grid line. That grid\nline is roughly the International Date Line, which has diversions that pass around some territories and\nisland groups. Opposite the International Date Line is the prime meridian, the line of longitude defined\nby international treaty as 0\u00b0. The north-south scale, called latitude(designated by the Greek symbol phi),\nranges from +90\u00b0 (or 90\u00b0 N) at the North pole to -90\u00b0 (or 90\u00b0 S) at the South pole. We\u2019ll take a closer\nlook at the geographic coordinate system next.\nThe geographic (or \u201cgeodetic\u201d) coordinate system. Nature of Geographic Information 40\n2.11. Geographic Coordinate System\nThe geographic coordinate system.\nLongitude specifies positions east and west as the angle between theprime meridian and a\nsecond meridian that intersects the point of interest. Longitude ranges from +180 (or 180\u00b0 E) to -180\u00b0\n(or 180\u00b0 W). 180\u00b0 East and West longitude together form the International Date Line.\nLatitude specifies positions north and south in terms of the angle subtended at the center of the Earth\nbetween two imaginary lines, one that intersects the equator and another that intersects the point of\ninterest. Latitude ranges from +90\u00b0 (or 90\u00b0 N) at the North pole to -90\u00b0 (or 90\u00b0 S) at the South pole. A\nline of latitude is also known as a parallel.\nAt higher latitudes, the length of parallels decreases to zero at 90\u00b0 North and South. Lines of longitude\nare not parallel, but converge toward the poles. Thus while a degree of longitude at the equator is equal\nto a distance of about 111 kilometers, that distance decreases to zero at the poles.\nTRY THIS!\nGEOGRAPHIC COORDINATE SYSTEM PRACTICE APPLICATION\nNearly everyone learned latitude and longitude as a kid. But how well do you understand the geographic\ncoordinate system, really? My experience is that while everyone who enters this class has heard of\nlatitude and longitude, only about half can point to the location on a map that is specified by a pair\nof geographic coordinates. The Flash application linked below lets you test your knowledge. The\napplication asks you to click locations on a globe as specified by randomly generated geographic\ncoordinates.\nYou will notice that the application lets you choose between \u201ceasy problems\u201d and \u201chard problems.\u201d\nEasy problems are those in which latitude and longitude coordinates are specified in 30\u00b0 increments.\nSince the resolution of the graticule (the geographic coordinate system grid) used in the application is\nalso 30\u00b0, the solution to every \u201ceasy\u201d problem occurs at the intersection of a parallel and a meridian. The\n\u201ceasy\u201d problems are good warm-ups.\n\u201cHard\u201d problems specify coordinates in 1\u00b0 increments. You have to interpolate positions between grid 41 David DiBiase\nlines. You can consider yourself to have a good working knowledge of the geographic coordinate\nsystem if you can solve at least six \u201chard\u201d problems consecutively and on the first click.\nClick here to download and launch the Geographic Coordinate System practice application (5.7 Mb).\n(If the globe doesn\u2019t appear after the Flash application has loaded, right-click and select \u201cPlay\u201d from the\npop-up menu.)\nNote: You will need to have the Adobe Flash player installed in order to complete this exercise. If you\ndo not already have the Flash player, you can download it for free at the adobe website.\n2.12. Geographic Coordinate Formats\nGeographic coordinates may be expressed in decimal degrees, or in degrees, minutes, and seconds.\nSometimes you need to convert from one form to another. Steve Kiouttis (personal communication,\nSpring 2002), manager of the Pennsylvania Urban Search and Rescue Program, described one such\nsituation on the course Bulletin Board: \u201cI happened to be in the state Emergency Operations Center in\nHarrisburg on Wednesday evening when a call came in from the Air Force Rescue Coordination Center\nin Dover, DE. They had an emergency locator transmitter (ELT) activation and requested the PA Civil\nAir Patrol to investigate. The coordinates given to the watch officer were 39 52.5 n and -75 15.5 w. This\nwas plotted incorrectly (treated as if the coordinates were in decimal degrees 39.525n and -75.155 w)\nand the location appeared to be near Vineland, New Jersey. I realized that it should have been interpreted\nas 39 degrees 52 minutes and 5 seconds n and -75 degrees and 15 minutes and 5 seconds w) and made the\nconversion (as we were taught in Chapter 2) and came up with a location on the grounds of Philadelphia\nInternational Airport, which is where the locator was found, in a parked airliner.\u201d\nHere\u2019s how it works:\nTo convert -89.40062 from decimal degrees to degrees, minutes, seconds: Nature of Geographic Information 42\n1. Subtract the number of whole degrees (89\u00b0) from the total (89.40062\u00b0). (The minus sign is\nused in the decimal degree format only to indicate that the value is a west longitude or a\nsouth latitude.)\n2. Multiply the remainder by 60 minutes (.40062 x 60 = 24.0372).\n3. Subtract the number of whole minutes (24\u2032) from the product.\n4. Multiply the remainder by 60 seconds (.0372 x 60 = 2.232).\n5. The result is 89\u00b0 24\u2032 2.232\u2033 W or S.\nTo convert 43\u00b0 4\u2032 31\u2033 from degrees, minutes, seconds to decimal degrees:\nDD = Degrees + (Minutes\/60) + (Seconds\/3600)\n1. Divide the number of seconds by 60 (31 \u00f7 60 = 0.5166).\n2. Add the quotient of step (1) to the whole number of minutes (4 + 0.5166).\n3. Divide the result of step (2) by 60 (4.5166 \u00f7 60 = 0.0753).\n4. Add the quotient of step (3) to the number of whole number degrees (43 + 0.0753).\n5. The result is 43.0753\u00b0\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 2 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about the Geographic Coordinate System.\nYou may take practice quizzes as many times as you wish. They are not scored and do not affect your\ngrade in any way.\n2.13. Horizontal Datums\nGeographic data represent the locations and attributes of things on the Earth\u2019s surface. Locations\nare measured and encoded in terms of geographic coordinates (i.e., latitude and longitude) or plane\ncoordinates (e.g., UTM). To measure and specify coordinates accurately, one first must define the\ngeometry of the surface itself. To see what I mean, imagine a soccer ball. If you or your kids play\nsoccer you can probably conjure up a vision of a round mosaic of 20 hexagonal (six sided) and 12\npentagonal (five sided) panels (soccer balls come in many different designs, but the 32-panel ball is used\nin most professional matches. Visitsoccerballworld.com for more than you ever wanted to know about\nsoccer balls). Now focus on one point at an intersection of three panels. You could use spherical (e.g.,\ngeographic) coordinates to specify the position of that point. But if you deflate the ball, the position of\nthe point in space changes, and so must its coordinates. The absolute (though not the relative) position\nof a point on a surface, then, depends upon the shape of the surface.\nEvery position is determined in relation to at least one other position. Coordinates, for example, are\ndefined relative to the origin of the coordinate system grid. A land surveyor measures the \u201ccorners\u201d of\na property boundary relative to a previously-surveyed control point. Surveyors and engineers measure\nelevations at construction sites and elsewhere. Elevations are expressed in relation to a vertical datum,\na reference surface such as mean sea level. As you probably know there is also such a thing as\na horizontal datum, although this is harder to explain and to visualize than the vertical case. Horizontal 43 David DiBiase\ndatums define the geometric relationship between a coordinate system grid and the Earth\u2019s\nsurface. Because the Earth\u2019s shape is complex, the relationship is too. The goal of this section is to\nexplain the relationship.\nSpecifically, in this section of Chapter 2 you will learn to:\n1. Explain the concept of a horizontal datum\n2. Calculate the change in a coordinate location due to a change from one horizontal datum to\nanother\n3. Estimate the magnitude of \u201cdatum shift\u201d associated with the adjustment from NAD 27 to\nNAD 83\n2.14. Geoids\nThe Earth\u2019s shape is defined as a surface that closely approximates global mean sea level, but across\nwhich gravity is everywhere equal. The caricature of the geoid shown above is not drawn to scale.\nIrregularities are greatly exaggerated\n(Adapted from Smith, 1988).\nThe accuracy of coordinates that specify geographic locations depends upon how the coordinate Nature of Geographic Information 44\nsystem grid is aligned with the Earth\u2019s surface. Unfortunately for those who need accurate geographic\ndata, defining the shape of the Earth\u2019s surface is a non-trivial problem. So complex is the problem that\nan entire profession, called geodesy, has arisen to deal with it.\nGeodesists define the Earth\u2019s surface as a surface that closely approximates global mean sea level,\nbut across which gravity is everywhere equal. They refer to this shape as the geoid. Geoids are lumpy\nbecause gravity varies from place to place in response to local differences in terrain and variations in the\ndensity of materials in the Earth\u2019s interior. Geoids are also a little squat. Sea level gravity at the poles\nis greater than sea level gravity at the equator, a consequence of Earth\u2019s \u201coblate\u201d shape as well as the\ncentrifugal force associated with its rotation.\nGeodesists at the U.S. National Geodetic Survey describe the geoid as an \u201cequipotential surface\u201d\nbecause the potential energy associated with the Earth\u2019s gravitational pull is equivalent everywhere on\nthe surface. Like fitting a trend line through a cluster of data points, the geoid is a three-dimensional\nstatistical surface that fits as closely as possible gravity measurements taken at millions of locations\naround the world. As additional and more accurate gravity measurements become available, geodesists\nrevise the geoid periodically. Some geoid models are solved only for limited areas; GEOID03, for\ninstance, is calculated only for the continental U.S.\nRecall that horizontal datums define how coordinate system grids align with the Earth\u2019s surface. Long\nbefore geodesists calculated geoids, surveyors used much simpler surrogates called ellipsoids to model\nthe shape of the Earth. 45 David DiBiase\n2.15. Ellipsoids\nEllipsoids approximate the geoid (Adapted from Smith, 1988).\nAn ellipsoid is a three-dimensional geometric figure that resembles a sphere, but whose equatorial\naxis (a is the illustration above) is slightly longer than its polar axis (b). The equatorial axis of the World\nGeodetic System of 1984, for instance, is approximately 22 kilometers longer than the polar axis, a\nproportion that closely resembles the oblate spheroid that is planet Earth. Ellipsoids are commonly\nused as surrogates for geoids so as to simplify the mathematics involved in relating a coordinate\nsystem grid with a model of the Earth\u2019s shape. Ellipsoids are good, but not perfect, approximations\nof geoids. The map below shows differences in elevation between a geoid model called GEOID96 and\nthe WGS84 ellipsoid. The surface of GEOID96 rises up to 75 meters above the WGS84 ellipsoid over\nNew Guinea (where the map is colored red). In the Indian Ocean (where the map is colored purple), the\nsurface of GEOID96 falls about 104 meters below the ellipsoid surface. Nature of Geographic Information 46\nDeviations between an ellipsoid and a geoid (National Geodetic Survey, 1997).\nMany ellipsoids are in use around the world. (Peter Dana has published a list at colorado.edu)\nLocal ellipsoids minimize differences between the geoid and the ellipsoid for individual countries or\ncontinents. The Clarke 1866 ellipsoid, for example, minimizes deviations in North America. TheNorth\nAmerican Datum of 1927 (NAD 27) associates the geographic coordinate grid with the Clarke 1866\nellipsoid. NAD 27 involved an adjustment of the latitude and longitude coordinates of some 25,000\ngeodetic control point locations across the U.S. The nationwide adjustment commenced from an initial\ncontrol point at Meades Ranch, Kansas, and was meant to reconcile discrepancies among the many local\nand regional control surveys that preceded it.\nThe North American Datum of 1983 (NAD 83) involved another nationwide adjustment,\nnecessitated in part by the adoption of a new ellipsoid, called GRS 80. Unlike Clarke 1866, GRS 80 is\na global ellipsoid centered upon the Earth\u2019s center of mass. GRS 80 is essentially equivalent to WGS\n84, the global ellipsoid upon which the Global Positioning System is based. NAD 27 and NAD 83 both\nalign coordinate system grids with ellipsoids. They differ simply in that they refer to different\nellipsoids. Because Clarke 1866 and GRS 80 differ slightly in shape as well as in the positions of their\ncenter points, the adjustment from NAD 27 to NAD 83 involved a shift in the geographic coordinate\ngrid. Because a variety of datums remain in use, geospatial professionals need to understand this shift,\nas well as how to transform data between horizontal datums. 47 David DiBiase\n2.16. Control Points and Datum Shifts\nIn the U.S., high-order horizontal control point locations are marked with permanent metal\n\u201cmonuments\u201d like the one shown above. The physical manifestation of datum is a network of control\npoint measurements (National Geodetic Survey, 2004).\nGeoids, ellipsoids, and even coordinate systems are all abstractions. The fact that \u201chorizontal datum\u201d\nrefers to a relationship between an ellipsoid and a coordinate system, two abstractions, may explain why\nthe concept is so frequently misunderstood. Datums do have physical manifestations, however.\nShown above is one of the approximately two million horizontal and vertical control points that\nhave been established in the U.S. Although control point markers are fixed, the coordinates that specify\ntheir locations are liable to change. The U.S. National Geodetic Survey maintains a database of the\ncoordinate specifications of these control points, including historical locations as well as more recent\nadjustments. One occasion for adjusting control point coordinates is when new horizontal datums are\nadopted. Since every coordinate system grid is aligned with an ellipsoid that approximates the\nEarth\u2019s shape, coordinate grids necessarily shift when one ellipsoid is replaced by another. When\ncoordinate system grids shift, the coordinates associated with fixed control points need to be adjusted.\nHow we account for the Earth\u2019s shape makes a difference in how we specify locations.\nTRY THIS!\nHere\u2019s a chance to calculate how much the coordinates of a control point change in response to an\nadjustment from North American Datum of 1927 (based on the Clarke 1866 ellipsoid) to the North Nature of Geographic Information 48\nAmerican Datum of 1983 (based upon the GRS 80 ellipsoid). You\u2019ll be asked to interpret your results in\nan upcoming practice quiz.\n1. Find the geographic coordinates of a populated place\n1. Start at the USGS\u2019 Geographic Names Information System at theU.S. Board on\nGeographic Names\n2. Follow the links labeled Domestic Names, then Search to search place names\nincluded in the Geographic Names Information System.\n3. At the Query Form, enter the name of your home town (or other named geographic\nfeature) in the Feature Name field, as well as your home State. Choose Populated\nPlace (or other, as appropriate) for theFeature Class.\n\u25aa If your home is somewhere other than the U.S., enter a place name of\ninterest or fantasy destination (e.g., \u201cLas Vegas\u201d ;-).\n4. Click Send Query.\n5. The result should include latitude and longitude coordinates of acentroid that\nrepresents where the name your town (or other feature) would appear on a map.\nYou\u2019ll need those coordinates for the next step.\n2. Find the geographic coordinates of a nearby horizontal control point\n1. Visit the U.S. National Geodetic Survey home page\n2. Follow the link labeled Survey Mark Datasheets\n3. At the NGS Datasheet page, follow the link labeled Datasheets.\n\u25aa You may wish to begin with the \u201cInfo Link\u201d labeled \u201cTell me more about\ndatasheets\u201d\n4. At the NGS Datasheet Retrieval page, follow the link labeled Radial Search.\n(You\u2019re welcome to experiment with another retrieval method if you wish.)\n5. At the NGS Datasheet Point Radius form:\n\u25aa Enter the latitude and longitude coordinates you looked up in step #1.\nPay attention to the input format.\n\u25aa Specify a Search Radius.\n\u25aa Select Any Horz. and\/or Vert. Control from the Data Type Desired\nscrolling field.\n\u25aa Select Any Stability from the Stability Desired scrolling field.\n\u25aa Click Submit.\n6. The result should be a Station List Results form that looks like the contents of the\nwindow pictured below. These are the results of my search on the centroid\ncoordinates for State College PA. Note that I have highlighted the station that is 49 David DiBiase\nboth nearest to the coordinates I entered and a first-order control point (see the \u201c1\u2033\nunder the column labeled \u201cH\u201d?)\n7. Select the station nearest to the coordinates you specified that is also the highest-\norder horizontal control point.\n8. Click Get Datasheets. The system should respond with a station datasheet like this\nexample.\n9. In the example linked above, the CURRENT SURVEY CONTROL of the station\npoint is listed as NAD 83(1992) 40 48 13.83840(N) 077 51 44.25410(W)\nADJUSTED. These are the geographic coordinates of the control point relative to\nthe NAD 83 horizontal datum. In the next step we\u2019ll see how much the control\npoint \u201cmoved\u201d as a result of the adjustment of those coordinates from the earlier\nNAD 27 datum. (The geographic coordinates of the control point are specified to\n100,000th of a second precision, or approximately 0.3 mm of longitude. Keep in\nmind, however, the difference between precision and accuracy; the trailing 0\nsuggests that the accuracy is an order of magnitude less than the precision.)\n3. Calculate the datum shift associated with a conversion from one horizontal datum to\nanother Nature of Geographic Information 50\n1. Return to the U.S. National Geodetic Survey home page\n2. Follow the link labeled geodetic tool kit.\n3. At the NGS Geodetic Tool Kit page, follow the link labeledNADCON (you\u2019ll be\ntaken to an explanatory page, where you\u2019ll need to click NADCON again to\nproceed to the utility).\n4. At the North American Datum Conversion Utility page, read the introductory\nparagraphs, then follow the link labeled Interactively compute a datum shift\nbetween NAD 27 and NAD 83. The link referred to in the previous sentence has\nrecently been removed. Instead click on the here link in the ***Notice\u2026 at the top\nof the page.\n5. At the NADCON computations form, under the heading compute a datum shift\nfor a specific location:\n\u25aa Select direction of conversion: NAD 83 to NAD27\n\u25aa Enter the NAD 83 latitude and longitude coordinates of your control\nstation. Pay attention to format.\n\u25aa Click Compute Datum Shift for a Single Location.\n6. The result should be a NADCON Output report like this example. In the State\nCollege example, the adjustment from NAD 83 to NAD 27 (associated with the\nreplacement of the old Clarke 1866 ellipsoid by the Earth-centered GRS 80\nellipsoid, caused the geographic coordinate system grid to shift nearly 7 meters\nSouth and over 23 meters West. That grid shift is reflected in the adjustment of the\ncoordinates that specify the control point\u2019s location. Note that the point didn\u2019t\nmove, rather, the grid shifted. How much shift occurred at your location?\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 2 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about horizontal datums.\nYou may take practice quizzes as many times as you wish. They are not scored and do not affect your\ngrade in any way.\n2.17. Coordinate Transformations\nGIS specialists often need to transform data from one coordinate system and\/or datum to another. For\nexample, digital data produced by tracing paper maps over a digitizing tablet need to be transformed\nfrom the tablet\u2019s non-georeferenced plane coordinate system into a georeferenced plane or spherical\ncoordinate system that can be georegistered with other digital data \u201clayers.\u201d Raw image data produced\nby scanning the Earth\u2019s surface from space tend to be skewed geometrically as a result of satellite\norbits and other factors; to be useful these too need to be transformed into georeferenced coordinate\nsystems. Even the point data produced by GPS receivers, which are measured as latitude and longitude\ncoordinates based upon the WGS84 datum, often need to be transformed to other coordinate systems\nor datums to match project specifications. This section describes three categories of coordinate 51 David DiBiase\ntransformations: (1) plane coordinate transformations; (2) datum transformations; and (3) map\nprojections.\nStudents who successfully complete this section of Chapter 2 should be able to:\n1. Recognize the kind of transformation that is appropriate to georegister two or more data sets.\n2.18. Plane Coordinate Transformations\nSome coordinate transformations are simple. For example, the transformation from non-georeferenced\nplane coordinates to non-georeferenced polar coordinates shown below involves nothing more than the\nreplacement of one kind of coordinates with another.\nThe same position specified within two non-georeferenced plane coordinate systems: Cartesian (left)\nand polar (right) (Adapted from Iliffe, 2000).\nUnfortunately, most plane coordinate transformation problems are not so simple. The geometries\nof non-georeferenced plane coordinate systems and georeferenced plane coordinate systems tend to\nbe quite different, mainly because georeferenced plane coordinate systems are often projected. As\nyou know, the act of projecting a nearly-spherical surface onto a two-dimensional plane necessarily\ndistorts the geometry of the original spherical surface. Specifically, the scale of a projected map (or\nan unrectified aerial photograph, for that matter) varies from place to place. So long as the geographic\narea of interest is not too large, however, formulae like the ones described here can be effective\nin transforming a non-georeferenced plane coordinate system grid to match a georeferenced plane\ncoordinate system grid with reasonable, and measurable, accuracy. We won\u2019t go into the math of the\ntransformations here, since the formulae are implemented within GIS software. Instead, this section aims\nto familiarize you with how some common transformations work and how they may be used.\nSIMILARITY TRANSFORMATION\nIn the hypothetical illustration below, the spatial arrangement of six control points digitized from a paper\nmap (\u201cbefore\u201d) are shown to differ from the spatial arrangement of the same points that appear in a\ngeoreferenced aerial photograph that referenced to a different plane coordinate system grid (\u201cafter\u201d). If,\nas shown, the arrangement of the two sets of points differs only in scale, rotation, and offset, a relatively\nsimple four-parameter similarity transformation may do the trick. Your GIS software should derive the Nature of Geographic Information 52\nparameters for you by comparing the relative positions of the common points. Note that while only six\ncontrol points are illustrated, ten to twenty control points are recommended (Chrisman 2002).\nSix control point locations before and after a similarity transformation used to correct systematic\ndifferences in scale, rotation, and offset between two plane coordinate systems.\nTRY THIS!\nClick the graphic above to view a Flash animation (transform_sim.swf) in a separate browser window.\nNote: You will need to have the Adobe Flash player installed to complete this activity. If you have not\nalready installed the Flash player, you candownload it for free from Adobe.\nAFFINE TRANSFORMATION\nSometimes a similarity transformation doesn\u2019t do the trick. For example, because paper maps expand\nand contract more along the paper grain than across the grain in response to changes in humidity, the\nscale of a paper map is likely to be slightly greater along one axis than the other. In such cases a six-\nparameter affine transformation may be used to accommodate differences in scale, rotation, and offset\nalong each of the two dimensions of the source and target coordinate systems. This characteristic is\nparticularly useful for transforming image data scanned from polar-orbiting satellites whose orbits trace\nS-shaped paths over the rotating Earth. 53 David DiBiase\nSix control point locations before and after an affine transformation used to correct systematic\ndifferences in scale, rotation, and offset between two plane coordinate systems. Notice that the\narrangement of points before the transformation is skewed as well as offset and rotated.\nTRY THIS!\nClick the graphic above to view a Flash animation (transform_aff.swf) in a separate browser window.\nSECOND-ORDER POLYNOMIAL TRANSFORMATION\nWhen neither similarity nor affine transformations yield acceptable results, you may have to resort\nto a twelve-parameter Second-order polynomial transformation. Their advantage is the potential to\ncorrect data sets that are distorted in several ways at once. A disadvantage is that the stability of\nthe results depend very much upon the quantity and arrangement of control points and the degree of\ndissimilarity of the source and target geometries (Iliffe 2000). Nature of Geographic Information 54\nSix control point locations before and after a second-order polynomial transformation. Notice that the\narrangement of points before the transformation is distorted in multiple ways in comparison with the\ncorrected arrangement.\nTRY THIS!\nClick the graphic above to view a Flash animation (transform_poly.swf) in a separate browser window.\nEven more elaborate plane transformation methods, known collectively asrubber sheeting, optimize\nthe fit of a source data set to the geometry of a target data set as if the source data were mapped onto a\nstretchable sheet.\nROOT MEAN SQUARE ERROR\nGIS software provides a statistical measure of how well a set of transformed control points match the\npositions of the same points in a target data set. Put simply, Root Mean Square (RMS) Error is the\naverage of the distances (also known as residuals) between each pair of control points. What constitutes\nan acceptably low RMS Error depends on the nature of the project and the scale of analysis.\n2.19. Datum Transformations\nPoint locations are specified in terms of (a) their positions relative to some coordinate system grid and\n(b) their heights above or below some reference surface. Obviously the elevation of a stationary point\ndepends upon the size and shape of the reference surface (e.g., mean sea level) upon which the elevation\nmeasurement is based. In the same way, a point\u2019s position in a coordinate system grid depends on the\nsize and shape of the surface upon which the grid is draped. The relationship between a grid and a\nmodel of the Earth\u2019s surface is called a horizontal datum. GIS specialists who are called upon to\nmerge data sets produced at different times and in different parts of the world need to be knowledgeable\nabout datum transformations.\nNAD 27 to NAD 83\nIn the U.S. the two most frequently encountered horizontal datums are the North American Datum of 55 David DiBiase\n1927 (NAD 27) and the North American Datum of 1983 (NAD 83). The advent of the Global Positioning\nSystem necessitated an update of NAD 27 that included (a) adoption of a geocentric ellipsoid, GRS\n80, in place of the Clarke 1866 ellipsoid; and (b) correction of many distortions that had accrued in\nthe older datum. Bearing in mind that the realization of a datum is a network of fixed control point\nlocations that have been specified in relation to the same reference surface, the 1983 adjustment of\nthe North American Datum caused the coordinate values of every control point managed by the\nNational Geodetic Survey (NGS) to change. Obviously the points themselves did not shift on account\nof the datum transformation (although they did move a centimeter or more a year due to plate tectonics).\nRather, the coordinate system grids based upon the datum shifted in relation to the new ellipsoid.\nAnd because local distortions were adjusted at the same time, the magnitude of grid shift varies from\nplace to place. The illustrations below compare the magnitude of the grid shifts associated with the NAD\n83 adjustment at one location and nationwide.\nA corner of the 1:24,000 scale topographic quadrangle map for State College PA showing the\nmagnitude of grid shift associated with the NAD 83 adjustment. The map is based on NAD 27, but was\nreprinted with revisions in 1987, including the statement that coordinate system grid lines shift 24 meters\nwest and 5 meters south if NAD 83 coordinates are used instead of NAD 27. Nature of Geographic Information 56\nMagnitude of grid shift associated with the NAD 83 adjustment for the continental 48 U.S. states.\nShifts range from 10 to 100 meters in the lower 48 (least in upper Midwest states) to over 200 meters in\nAlaska, and over 400 meters in Hawaii (Dewhurst 1990).\nGiven the irregularity of the shift, NGS could not suggest a simple transformation algorithm that\nsurveyors and mappers could use to adjust local data based upon the older datum. Instead NGS created a\nsoftware program called NADCON (Dewhurst 1990, Mulcare 2004) that calculates adjusted coordinates\nfrom user-specified input coordinates by interpolation from a pair of 15\u00b0 correction grids generated by\nNGS from hundreds of thousands of previously-adjusted control points.\nTRY THIS!\nTry out the National Geodetic Survey\u2019s NADCON tool.\nGPS DATA AND WGS 84\nThe U.S. Department of Defense created the Global Positioning System (GPS) over a period of\n16 years at a startup cost of about $10 billion. GPS receivers calculate their positions in terms of\nlatitude, longitude, and height above or below the World Geodetic System of 1984 ellipsoid (WGS 84).\nDeveloped specifically for the Global Position System, WGS 84 is an Earth-centered ellipsoid which,\nunlike the many regional, national, and local ellipsoids still in use, minimizes deviations from the geoid\nworldwide. Depending on where a GIS specialist may be working, or what data he or she may need\nto work with, the need to transform GPS data from WGS 84 to some other datum is likely to arise.\nDatum transformation algorithms are implemented within GIS software as well as in the post-processing\nsoftware provided by GPS vendors for use with their receivers. Some transformation algorithms yield\nmore accurate results than others. The method you choose will depend on what choices are available to\nyou and how much accuracy your application requires.\nUnlike the plane transformations described earlier, datum transformations involve ellipsoids and\nare therefore three-dimensional. The simplest is the three-parameter Molodenski transformation. In\naddition to knowledge of the size and shape of the source and target ellipsoids (specified in terms\nofsemimajor axis, the distance from the ellipsoid\u2019s equator to its center, andflattening ratio, the degree 57 David DiBiase\nto which the ellipsoid is flattened to approximate the Earth\u2019s oblate shape), the offset between the two\nellipsoids needs to be specified along X, Y, and Z axes. The window shown below illustrates ellipsoidal\nand offset parameters for several horizontal datums, all expressed in relation to WGS 84.\nDatum list window in the Waypoint+ software utility (Hildebrand 1997). NAD 27, NAD 83, and WGS\n84 are highlighted. The ellipsoid associated with each datum is named, and its size and shape specified\n(Delta A and Delta (1\/f)x10e4), along with three offset parameters, in meters, relative to WGS 84 (Delta\nx, Delta y, Delta z).\nFor larger study areas more accurate results may be obtained using aseven-parameter\ntransformation that accounts for rotation as well as scaling and offset. Nature of Geographic Information 58\nFinally, surface-fitting transformations like the NADCON grid interpolation described above yield\nthe best results over the largest areas.\nFor routine mapping applications covering relatively small geographic areas (i.e., larger than\n1:25,000), the plane transformations described earlier may yield adequate results when datum\nspecifications are unknown and when a sufficient number of appropriately distributed control points can\nbe identified.\n2.20. Map Projections\nLatitude and longitude coordinates specify positions in a more-or-less spherical grid called\nthe graticule. Plane coordinates like the eastings and northings in the Universal Transverse Mercator\n(UTM) and State Plane Coordinates (SPC) systems denote positions in flattened grids. This is why\ngeoreferenced plane coordinates are referred to as projected and geographic coordinates are\ncalled unprojected. The mathematical equations used to transform latitude and longitude coordinates to\nplane coordinates are called map projections. Inverse projection formulae transform plane coordinates\nto geographic. The simplest kind of projection, illustrated below, transforms the graticule into a\nrectangular grid in which all grid lines are straight, intersect at right angles, and are equally spaced. More\ncomplex projections yield grids in which the lengths, shapes, and spacing of the grid lines vary.\nMap projections are mathematical transformations between geographic coordinates and plane\ncoordinates.\nIf you are a GIS practitioner you have probably faced the need to superimpose unprojected latitude\nand longitude data onto projected data, and vice versa. For instance, you might have needed to merge\ngeographic coordinates measured with a GPS receiver with digital data published by the USGS that\nare encoded as UTM coordinates. Modern GIS software provides sophisticated tools for projecting\nand unprojecting data. To use such tools most effectively you need to understand the projection\ncharacteristics of the data sets you intend to merge. We\u2019ll examine map projections in some detail\nelsewhere in this lesson. Here let\u2019s simply review the characteristics that are included in the \u201cSpatial\nReference Information\u201d section of the metadata documents that (ideally!) accompany the data sets you\nmight wish to incorporate in your GIS. These include:\n\u2022 Projection Name Most common in the GIS realm is the Transverse Mercator, which serves\nas the basis of the global UTM plane coordinate system, the U.K. and proposed U.S. National\nGrids, and many zones in the U.S. State Plane Coordinate system (SPC). Other SPC zones\nare based upon the Lambert Conic Conformal projection, which like many projections is\nnamed for its inventor as well as its projection category (conic) and the geometric properties 59 David DiBiase\nit preserves (conformal). Much map data, particularly in the form of printed paper maps, are\nbased upon \u201clegacy\u201d projections (like the Polyconic in the U.S.) that are no longer widely\nused. A much greater variety of projection types tend to be used in small scale thematic\nmapping than in large scale reference mapping.\n\u2022 Central Meridian Although no land masses are shown, let\u2019s assume that the graticule and\nprojected grid shown above are centered on the intersection of the equator (0 latitude) and\nprime meridian (0\u00b0 longitude). Most map projection formulae include a parameter that allows\nyou to center the projected map upon any longitude.\n\u2022 Latitude of Projection Origin Under certain conditions, most map projection formulae\nallow you to specify different aspects of the grid. Instead of the equatorial aspect illustrated\nabove, you might specify apolar aspect or oblique aspect by varying the latitude of\nprojection origin such that one of the poles, or any latitude between the pole and the equator,\nis centered in the projected map. As you might imagine, the appearance of the grid changes a\nlot when viewed at different aspects.\n\u2022 Scale Factor at Central Meridian This is the ratio of map scale along the central meridian\nand the scale at a standard meridian, where scale distortion is zero. The scale factor at the\ncentral meridian is .9996 in each of the 60 UTM coordinate system zones since each contains\ntwo standard lines 180 kilometers west and east of the central meridian. Scale distortion\nincreases with distance from standard lines in all projected coordinate systems.\n\u2022 Standard Lines Some projections, including the Lambert Conic Conformal, include\nparameters by which you can specify one or twostandard lines along which there is no scale\ndistortion caused by the act of transforming the spherical grid into a flat grid. By the same\nreasoning that two standard lines are placed in each UTM zone to minimize distortion\nthroughout the zone to a maximum of one part in 1000, two standard parallels are placed in\neach SPC zone that is based upon a Lambert projection such that scale distortion is no worse\nthan one part in 10,000 anywhere in the zone.\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 2 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about coordinate transformations.\nYou may take practice quizzes as many times as you wish. They are not scored and do not affect your\ngrade in any way.\n2.21. UTM Coordinate System\nShown below is the southwest corner of a 1:24,000-scale topographic map published by the United\nStates Geological Survey (USGS). Note that the geographic coordinates (40 45\u2032 N latitude, 77\u00b0 52\u2032\n30\u2033 W longitude) of the corner are specified. Also shown, however, are ticks and labels representing\ntwo plane coordinate systems, the Universal Transverse Mercator (UTM) system and the State Plane\nCoordinates (SPC) system. The tick labeled \u201c4515\u2033 represents a UTM grid line (called a \u201cnorthing\u201d) that\nruns parallel to, and 4,515,000 meters north of, the equator. Ticks labeled \u201c258\u2033 and \u201c259\u2033 represent grid\nlines that run perpendicular to the equator and 258,000 meters and 259,000 meters east, respectively, of\nthe origin of the UTM Zone 18 North grid. Unlike longitude lines, UTM \u201ceastings\u201d are straight and do Nature of Geographic Information 60\nnot converge upon the Earth\u2019s poles. All of this begs the question, Why are multiple coordinate system\ngrids shown on the map? Why aren\u2019t geographic coordinates sufficient?\nSouthwest corner of a USGS topographic map showing grid ticks and labels for three different\ncoordinate systems, including the UTM coordinate system. (USGS. \u201cState College quadrangle,\nPennsylvania\u201d)\nYou can think of a plane coordinate system as the juxtaposition of two measurement scales. In other\nwords, if you were to place two rulers at right angles, such that the \u201c0\u2033 marks of the rulers aligned,\nyou\u2019d define a plane coordinate system. The rulers are called \u201caxes.\u201d The absolute location of any point\nin the space in the plane coordinate system is defined in terms of distance measurements along the x\n(east-west) and y (north-south) axes. A position defined by the coordinates (1,1) is located one unit to\nthe right, and one unit up from the origin (0,0). The UTM grid is a widely-used type of geospatial plane\ncoordinate system in which positions are specified as eastings (distances, in meters, east of an origin)\nand northings (distances north of the origin).\nBy contrast, the geographic coordinate system grid of latitudes and longitudes consists of\ntwo curved measurement scales to fit the nearly-spherical shape of the Earth. As you know, geographic\ncoordinates are specified in degrees, minutes, and seconds of arc. Curved grids are inconvenient to\nuse for plotting positions on flat maps. Furthermore, calculating distances, directions and areas\nwith spherical coordinates is cumbersome in comparison with plane coordinates. For these reasons,\ncartographers and military officials in Europe and the U.S. developed the UTM coordinate system. UTM\ngrids are now standard not only on printed topographic maps but also for the geospatial referencing of\nthe digital data that comprise the emerging U.S. \u201cNational Map.\u201d\nIn this section of Chapter 2 you will learn to:\n1. Describe the characteristics of the UTM coordinate system, including its basis in the\nTransverse Mercator map projection; and\n2. Plot UTM coordinates on a map 61 David DiBiase\n2.22. The UTM Grid and Transverse Mercator Projection\nA Mercator projection of the world showing the 60 UTM coordinate system zones, each divided into\nnorth and south halves at the equator. Also shown are two polar coordinate systems used to specify\npositions beyond the northern and southern limits of the UTM system.\nThe Universal Transverse Mercator system is not really universal, but it does cover nearly the entire\nEarth surface. Only polar areas\u2013latitudes higher than 84\u00b0 North and 80\u00b0 South\u2013are excluded. (Polar\ncoordinate systems are used to specify positions beyond these latitudes.) The UTM system divides the\nremainder of the Earth\u2019s surface into 60 zones, each spanning 6\u00b0 of longitude. These are numbered west\nto east from 1 to 60, starting at 180\u00b0 West longitude (roughly coincident with the International Date\nLine).\nThe illustration above depicts UTM zones as if they were uniformly \u201cwide\u201d from the Equator to their\nnorthern and southern limits. In fact, since meridians converge toward the poles on the globe, every\nUTM zone tapers from 666,000 meters in \u201cwidth\u201d at the Equator (where 1\u00b0 of longitude is about 111\nkilometers in length) to only about 70,000 meters at 84\u00b0 North and about 116,000 meters at 80\u00b0 South.\n\u201cTransverse Mercator\u201d refers to the manner in which geographic coordinates are transformed into\nplane coordinates. Such transformations are called map projections. The illustration below shows the\n60 UTM zones as they appear when projected using a Transverse Mercator map projection formula that\nis optimized for the UTM zone highlighted in yellow, Zone 30, which spans 6\u00b0 West to 0\u00b0 East longitude\n(the prime meridian).\nAs you can imagine, you can\u2019t flatten a globe without breaking or tearing it somehow. Similarly, the\nact of mathematically transforming geographic coordinates to plane coordinates necessarily displaces\nmost (but not all) of the transformed coordinates to some extent. Because of this, map scale varies within\nprojected (plane) UTM coordinate system grids. Nature of Geographic Information 62\nThe distortion ellipses plotted in red help us visualize the pattern of scale distortion associated with\na particular projection. Had no distortion occurred in the process of projecting the map shown below, all\nof the ellipses would be the same size, and circular in shape. As you can see, the ellipses centered within\nthe highlighted UTM zone are all the same size and shape. Away from the highlighted zone the ellipses\nsteadily increase in size, although their shapes remain uniformly circular. This pattern indicates that scale\ndistortion is minimal within Zone 30, and that map scale increases away from that zone. Furthermore,\nthe ellipses reveal that the character of distortion associated with this projection is that shapes of features\nas they appear on a globe are preserved while their relative sizes are distorted. Map projections that\npreserve shape by sacrificing the fidelity of sizes are called conformal projections. The plane coordinate\nsystems used most widely in the U.S., UTM and SPC (the State Plane Coordinates system) are both\nbased upon conformal projections.\nThe result of a Transverse Mercator projection of the world centered on UTM Zone 30. Red circles\nreveal the scale distortion introduced during the transformation from geographic to projected plane\ncoordinates. On the globe, all the circles would be the same size.\nThe Transverse Mercator projection illustrated above minimizes distortion within UTM zone 30.\nFifty-nine variations on this projection are used to minimize distortion in the other 59 UTM zones. In\nevery case, distortion is no greater than 1 part in 1,000. This means that a 1,000 meter distance measured\nanywhere within a UTM zone will be no worse than + or \u2013 1 meter off.\nThe animation linked to the illustration below shows a series of 60 Transverse Mercator projections\nthat form the 60 zones of the UTM system. Each zone is based upon a unique Transverse Mercator map\nprojection that minimizes distortion within that zone. Zones are numbered 1 to 60 eastward from the\ninternational date line. The animation begins with Zone 1. 63 David DiBiase\nOne frame of an animation showing a sequence of the 60 Transverse Mercator projections used as the\nbasis of the UTM coordinate system. Highlighted in red is UTM Zone 01, which spans 180\u00b0 W to 174\u00b0\nW. A unique projection is used for every UTM zone, so that deformation within each zone is minimized.\nTRY THIS!\nClick the graphic above to view the animation file (utm.avi, 0.5 Mb) in a separate Microsoft Media\nPlayer window.\nTo view the same animation in QuickTime format (utm.mov, 2.9 Mb),click here. Requires the\nQuickTime plugin, which is available free atapple.com.\nMap projections are mathematical formulae used to transform geographic coordinates into plane\ncoordinates. (Inverse projection formulae transform plane coordinates back into latitudes and\nlongitudes.) \u201cTransverse Mercator\u201d is one of a hypothetically infinite number of such projection\nformulae. A visual analog to the Transverse Mercator projection appears below. Conceptually, the\nTransverse Mercator projection transfers positions on the globe to corresponding positions on a\ncylindrical surface, which is subsequently cut from end to end and flattened. In the illustration, the\ncylinder is tangent to the globe along one line, called the standard line. As shown in the little world\nmap beside the globe and cylinder, scale distortion is minimal along the standard line and increases\nwith distance from it. The animation linked above was produced by rotating the cylinder 59 times at an\nincrement of 6\u00b0. Nature of Geographic Information 64\nThe map above represents a Transverse Mercator projection of the world with a standard meridian\nat 0\u00b0 longitude. (Note that because of the very small size of the map, the graticule is shown at 30\u00b0\nresolution.) The globe wrapped in a cylinder is a conceptual model of how the Transverse Mercator\nprojection formula transfers positions on the globe to positions on a plane (The cylinder can be flattened\nto a plane surface after it is unwrapped from the globe.) The thicker red line on the cylinder and the map\nis the standard line along which scale distortion is zero. As the distortion ellipses on the map indicate,\ndistortion increases with distance from the standard line.\nIn the illustration above there is one standard meridian. Some projection formulae, including the\nTransverse Mercator projection, allow two standard lines. Each of the 60 variations on the Transverse\nMercator projection used as the foundations of the 60 UTM zones employ not one, but two,\nstandard lines. These two standard lines are parallel to, and 180,000 meters east and west of, each\ncentral meridian. This scheme ensures that the maximum error associated with the projection due to\nscale distortion will be 1 part in 1,000 (at the outer edge of the zone at the equator). The error due to\nscale distortion at the central meridian is 1 part in 2,500. Distortion is zero, of course, along the standard\nlines.\nSo what does the term \u201ctransverse\u201d mean? This simply refers to the fact that the cylinder shown above\nhas been rotated 90\u00b0 from the equatorial aspect of the standard Mercator projection, in which a single\nstandard line coincides with 0\u00b0 latitude. 65 David DiBiase\nThe ten UTM zones that span the conterminous U.S. (U.S. Geological Survey, 2004).\nOne disadvantage of the UTM system is that multiple coordinate systems must be used to account\nfor large entities. The lower 48 United States, for instance, spreads across ten UTM zones. The fact\nthat there are many narrow UTM zones can lead to confusion. For example, the city of Philadelphia,\nPennsylvania is east of the city of Pittsburgh. If you compare the Eastings of centroids representing\nthe two cities, however, Philadelphia\u2019s Easting (about 486,000 meters) is less than Pittsburgh\u2019s (about\n586,000 meters). Why? Because although the cities are both located in the U.S. state of Pennsylvania,\nthey are situated in two different UTM zones. As it happens, Philadelphia is closer to the origin of\nits Zone 18 than Pittsburgh is to the origin of its Zone 17. If you were to plot the points representing\nthe two cities on a map, ignoring the fact that the two zones are two distinct coordinate systems,\nPhiladelphia would appear to the west of Pittsburgh. Inexperienced GIS users make this mistake all\nthe time. Fortunately, GIS software is getting sophisticated enough to recognize and merge different\ncoordinate systems automatically.\n2.23. UTM Zone Characteristics\nThe illustration below depicts the area covered by a single UTM coordinate system grid zone. Each\nUTM zone spans 6\u00b0 of longitude, from 84\u00b0 North and 80\u00b0 South. Zones taper from 666,000 meters in\n\u201cwidth\u201d at the Equator (where 1\u00b0 of longitude is about 111 kilometers in length) to only about 70,000\nmeters at 84\u00b0 North and about 116,000 meters at 80\u00b0 South. Polar areas are covered by polar coordinate\nsystems. Each UTM zone is subdivided along the equator into two halves, north and south. Nature of Geographic Information 66\nExtent of one UTM coordinate system grid zone. Note that although latitudes are used to specify the\nextent precisely in relation to the globe, they are geographic, not UTM, coordinates.\nThe illustration below shows how UTM coordinate grids relate to the area of coverage illustrated\nabove. The north and south halves are shown side by side for comparison. Each half is assigned\nits own origin. The north south zone origins are positioned to south and west of the zone. North\nzone origins are positioned on the Equator, 500,000 meters west of the central meridian. Origins are\npositioned so that every coordinate value within every zone is a positive number. This minimizes the\nchance of errors in distance and area calculations. By definition, both origins are located 500,000 meters\nwest of the central meridian of the zone (in other words, the easting of the central meridian is always\n500,000 meters E). These are considered \u201cfalse\u201d origins since they are located outside the zones to which\nthey refer. UTM eastings range from 167,000 meters to 833,000 meters at the equator. These ranges\nnarrow toward the poles. Northings range from 0 meters to nearly 9,400,000 in North zones and from\njust over 1,000,000 meters to 10,000,000 meters in South zones. Note that positions at latitudes higher\nthan 84\u00b0 North and 80\u00b0 South are defined in Polar Stereographic coordinate systems that supplement the\nUTM system. 67 David DiBiase\nUTM coordinate system zone characteristics. Yellow represents areas in which UTM coordinates\nare valid for a given zone. Red lines parallel to the central meridian represent the two standard lines\nemployed in each Transverse Mercator projection. Each square grid cell in the illustration spans 500,000\nmeters on each side.\nTRY THIS!\nUTM COORDINATE SYSTEM PRACTICE APPLICATION\nAre you ready to try your hand at positioning within a UTM coordinate system grid? The Flash\napplication linked below lets you test your knowledge. The application asks you to click locations within\na grid zone as specified by randomly generated UTM coordinates.\nYou will notice that the application lets you choose between easy problems (in which the locations\nof possible solutions are symbolized with dots) or harder problems that require you\nto interpolate solutions. You can consider yourself to have a good working knowledge of the\ngeographic coordinate system if you can solve at least six \u201chard\u201d problems consecutively and on\nthe first click.\nClick here to launch the UTM Coordinate System practice application. If the UTM zone fails to appear\nafter the Flash application loads, right-click the application and select \u201cPlay\u201d from the pop-up menu. Nature of Geographic Information 68\nNote: You will need to have the Adobe Flash player installed in order to complete this exercise. If you\ndo not already have the Flash player, you can download it for free at adobe.com\nSee the Bibliography (last page of the chapter) for further readings about the UTM grid system.\n2.24. National Grids\nThe Transverse Mercator projection provides a basis for existing and proposed national grid systems in\nthe United Kingdom and the United States.\nIn the U.K., topographic maps published by the Ordnance Survey refer to a national grid of 100 km\nsquares, each of which is identified by a two-letter code. Positions within each grid square are specified\nin terms of eastings and northings between 0 and 100,000 meters. The U.K. national grid is a plane\ncoordinate system that is based upon a Transverse Mercator projection whose central meridian is 2 West\nlongitude, with standard meridians 180 km west and east of the central meridian. The grid is typically\nrelated to the Airy 1830 ellipsoid, a relationship known as the National Grid (OSGB36\u00ae) datum. The\ncorresponding UTM zones are 29 (central meridian 9\u00b0 West) and 30 (central meridian 3\u00b0 West). One of\nthe advantages of the U.K. national grid over the global UTM coordinate system is that it eliminates the\nboundary between the two UTM zones.\nA similar system has been proposed for the U.S. by the Federal Geographic Data Committee. The\nproposed \u201cU.S. National Grid\u201d is the same as the Military Grid Reference System (MGRS), a worldwide\ngrid that is very similar to the UTM system. As Phil and Julianna Muehrcke (1998, p.p. 229-230) write\nin the 4th edition of Map Use, \u201cthe military [specifically, the U.S. Department of Defense] aimed to\nminimize confusion when using long numerical [UTM] coordinates\u201d by specifying UTM zones and sub-\nzones with letters instead of numbers. Like the UTM system, the MGRS consists of 60 zones, each 69 David DiBiase\nspanning 6\u00b0 longitude. Each UTM zone is subdivided into 19 MGRS quadrangles of 8\u00b0 latitude and one\n(quadrangle from 72\u00b0 to 84\u00b0 North) of 12\u00b0 latitude. The letters C through X are used to designate the grid\ncell rows from south to north. I and O are omitted to avoid confusion with numbers. Wikipedia offers a\ngood entry on the MGRS here.\nTRY THIS!\nINTERACTIVE DEMO OF U.K. NATIONAL GRID\nAn informative and fun demonstration of the U.K. National Grid is published by the U.K. Ordnance\nSurvey.\nNote: You will need to have the Adobe Flash player installed in order to view this demo. If you do not\nalready have the Flash player, you can download it for free at adobe.com\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 2 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about UTM coordinate system.\nYou may take practice quizzes as many times as you wish. They are not scored and do not affect your\ngrade in any way.\n2.25. State Plane Coordinate System\nShown below is the southwest corner of a 1:24,000-scale topographic map published by the United\nStates Geological Survey (USGS). Note that the geographic coordinates (40 45\u2032 N latitude, 77\u00b0 52\u2032\n30\u2033 W longitude) of the corner are specified. Also shown, however, are ticks and labels representing\ntwo plane coordinate systems, the Universal Transverse Mercator (UTM) system and the State Plane\nCoordinate (SPC) system. The tick labeled \u201c1 970 000 FEET\u201d represents a SPC grid line that runs\nperpendicular to the equator and 1,970,000 feet east of the origin of the Pennsylvania North zone. The\norigin lies far to the west of this map sheet. Other SPC grid lines, called \u201cnorthings\u201d (not shown in the\nillustration), run parallel to the equator and perpendicular to SPC eastings at increments of 10,000 feet.\nUnlike longitude lines, SPC eastings and northings are straight and do not converge upon the Earth\u2019s\npoles. Nature of Geographic Information 70\nSouthwest corner of a USGS topographic map showing grid ticks and labels for three different\ncoordinate systems, including the SPC coordinate system. (USGS. \u201cState College quadrangle,\nPennsylvania\u201d)\nThe SPC grid is a widely-used type of geospatial plane coordinate system in which positions are\nspecified as eastings (distances east of an origin) and northings (distances north of an origin). You can\ntell that the SPC grid referred to in the map illustrated above is the older 1927 version of the SPC grid\nsystem because (a) eastings and northings are specified in feet and (b) grids are based upon the North\nAmerican Datum of 1927 (NAD27). The 124 zones that make up the State Plane Coordinates system of\n1983 are based upon NAD 83, and generally use the metric system to specify eastings and northings.\nState Plane Coordinates are frequently used to georeference large scale (small area) surveying and\nmapping projects because plane coordinates are easier to use than latitudes and longitudes for calculating\ndistances and areas. And because SPC zones extend over relatively smaller areas, less error accrues to\npositions, distances, and areas calculated with State Plane Coordinates than with UTM coordinates.\nIn this section you will learn to:\n1. Describe the characteristics of the SPC system, including map projection on which it is\nbased; and\n2. Convert geographic coordinates to SPC coordinates\n2.26. The SPC Grid and Map Projections\nPlane coordinate systems pretend the world is flat. Obviously, if you flatten the entire globe to a plane\nsurface, the sizes and shapes of the land masses will be distorted, as will distances and directions\nbetween most points. If your area of interest is small enough, however, and if you flatten it cleverly, you\ncan get away with a minimum of distortion. The basic design problem that confronted the geodesists\nwho designed the State Plane Coordinate System, then, was to establish coordinate system zones that\nwere small enough to minimize distortion to an acceptable level, but large enough to be useful. 71 David DiBiase\nThe State Plane Coordinate System of 1983 (SPC) is made up of 124 zones that cover the 50 U.S.\nstates. As shown below, some states are covered with a single zone while others are divided into multiple\nzones. Each zone is based upon a unique map projection that minimizes distortion in that zone to 1 part\nin 10,000 or better. In other words, a distance measurement of 10,000 meters will be at worst one meter\noff (not including instrument error, human error, etc.). The error rate varies across each zone, from zero\nalong the projection\u2019s standard lines to the maximum at points farthest from the standard lines. Errors\nwill accrue at a rate much lower than the maximum at most locations within a given SPC zone. SPC\nzones achieve better accuracy than UTM zones because they cover smaller areas, and so are less\nsusceptible to projection-related distortion.\nThe U.S. State Plane Coordinate system of 1983 consists of 124 zones (Doyle 2004). Each zone is a\ndistinct plane coordinate system. (Alaska and Hawaii not shown).\nMost SPC zones are based on either a Transverse Mercator or Lambert Conic Conformal map\nprojection whose parameters (such as standard line(s) and central meridians) are optimized for each\nparticular zone. \u201cTall\u201d zones like those in New York state, Illinois, and Idaho are based upon unique\nTransverse Mercator projections that minimize distortion by running two standard lines north-south on\neither side of the central meridian of each zone. \u201cWide\u201d zones like those in Pennsylvania, Kansas, and\nCalifornia are based on unique Lambert Conformal Conic projections that run two standard parallels\nwest-east through each zone. (One of Alaska\u2019s zones is based upon an \u201coblique\u201d variant of the Mercator\nprojection. That means that instead of standard lines parallel to a central meridian, as in the transverse\ncase, the Oblique Mercator runs two standard lines that are tilted so as to minimize distortion along the\nAlaskan panhandle.)\nThe two types of map projections share the property of conformality, which means that angles\nplotted in the coordinate system are equal to angles measured on the surface of the Earth. As you\ncan imagine, conformality is a useful property for land surveyors, who make their livings measuring\nangles. (Surveyors measure distances too, but unfortunately there is no map projection that can preserve\ntrue distances everywhere within a plane coordinate system.) Let\u2019s consider these two types of map\nprojections briefly.\nLike most map projections, the Transverse Mercator projection is actually a mathematical\ntransformation. The illustration below may help you understand how the math works. Conceptually,\nthe Transverse Mercator projection transfers positions on the globe to corresponding positions on a\ncylindrical surface, which is subsequently cut from end to end and flattened. In the illustration, the\ncylinder is tangent to (touches) the globe along one line, the standard line (specifically, the standard Nature of Geographic Information 72\nmeridian). As shown in the little world map beside the globe and cylinder, scale distortion is minimal\nalong the standard line and increases with distance from it.\nThe distortion ellipses plotted in red help us visualize the pattern of scale distortion associated with\na generic Transverse Mercator projection. Had no distortion occurred in the process of projecting the\nmap shown below, all of the ellipses would be the same size, and circular in shape. As you can see, the\nellipses plotted along the central meridian are all the same size and circular shape. Away from the central\nmeridian the ellipses steadily increase in size, although their shapes remain uniformly circular. This\npattern reflects the fact that scale distortion increases with distance from the standard line. Furthermore,\nthe ellipses reveal that the character of distortion associated with this projection is that shapes of features\nas they appear on a globe are preserved while their relative sizes are distorted. By preserving true angles,\nconformal projections like the Mercator (including its transverse and oblique variants) also preserve\nshapes.\nConceptual model of a Transverse Mercator map projection (left) and the resulting map (right). The\nthick red lines represent the line of tangency between the globe and the projection surface (the cylinder),\nand the corresponding standard meridian on the map. Red circles on the map reveal that distortion\nintroduced as a result of the map projection increases with distance from the standard line. On the globe,\nall the circles would be the same size.\nSPC zones that trend west to east (including Pennsylvania\u2019s) are based on unique Lambert Conformal\nConic projections. Instead of the cylindrical projection surface used by projections like the Mercator, the\nLambert Conformal Conic and map projections like it employ conical projection surfaces like the one\nshown below. Notice the two lines at which the globe and the cone intersect. Both of these are standard\nlines; specifically, standard parallels. The latitudes of the standard parallels selected for each SPC zones\nminimize scale distortion throughout that zone. 73 David DiBiase\nConceptual model of a Lambert Conformal Conic map projection (left) and the resulting map (right).\nThe two thick red lines marking the intersections of the globe and the projection surface (the cone)\ncorrespond with two standard parallels on the map. Red circles on the map confirm that map scale\nis equal along both standard parallels. Distortion increases with distance from the standard parallels\neverywhere else in the projected map and in the coordinate system on which it is based.\n2.27. SPC Zone Characteristics\nIn consultation with various state agencies, the National Geodetic Survey (NGS) devised the State Plane\nCoordinate System with several design objectives in mind. Chief among these were:\n1. Plane coordinates for ease of use in calculations of distances and areas;\n2. All positive values to minimize calculation errors; and\n3. A maximum error rate of 1 part in 10,000.\nPlane coordinates specify positions in flat grids. Map projections are needed to transform latitude and\nlongitude coordinates to plane coordinates. The designers did two things to minimize the inevitable\ndistortion associated with map projections. First, they divided the U.S. into 124 relatively small zones.\nSecond, they used slightly different map projection formulae for each zone. The curved, dashed red lines\nin the illustration below represent the two standard parallels that pass through each zone. The latitudes\nof the standard lines are one of the parameters of the Lambert Conic Conformal projection that can be\ncustomized to minimize distortion within the zone.\nPositions in any coordinate system are specified relative to an origin. SPC zone origins are defined\nso as to ensure that every easting and northing in every zone are positive numbers. As shown\nin the illustration below, SPC origins are positioned south of the counties included in each zone. The\norigins coincide with the central meridian of the map projection upon which each zone is based. The\neasting and northing values at the origins are not 0, 0. Instead, eastings are defined as positive values\nsufficiently large to ensure that every easting in the zone is also a positive number. The false origin of\nthe Pennsylvania North zone, for instance, is defined as 600,000 meters East, 0 meters North. Origin\neastings vary from zone to zone from 200,000 to 8,000,000 meters East. Nature of Geographic Information 74\nSchematic view of two State Plane Coordinate System zones, showing the counties that make up each\nzone (in yellow), the origins of each zone, and the standard parallels of the map projections upon which\nthe zones are based, along which scale distortion is zero.\nTry This!\nInvestigating your local State Plane Coordinate System grid zone\nIn this activity you will:\n1. Read part of an authoritative manual on State Plane Coordinates;\n2. Look up the designation of your local SPC zone (or a would-be zone if you are from a\ncountry other than the U.S.);\n3. Investigate the parameters of the map projection upon which your local SPC zone is based;\nand\n4. Use a Web-based tool provided by the U.S. National Geodetic Survey to convert geographic\ncoordinates to SPC.\nThe practice quiz at the end of this section will help you assess your fluency with the SPC system. 75 David DiBiase\n1. Read the introduction to the National Geodetic Survey manual State Plane Coordinate System of 1983 by James E. Stem (1990).\nFollow this link to download the manual in Portable Document Format (PDF). Read pages 1-13 (pages\n11-23 of the PDF document). Also see Appendix A, beginning on p. 62 (73), which lists map projections\nand other parameters of each zone.\n2. Look up your local SPC zone.\nHome page of the National Geodetic Survey toolkit\n1. Visit the National Geodetic Survey\u2019s NGS Geodetic Toolkit. Note the various programs that\nNGS supports for the surveying and mapping community.\n2. Use the dropdown menu to navigate to the State Plane Coordinates tool.\n3. At the State Plane Coordinates page, follow the Interactive Conversions link labeled \u201cFind\nZone.\u201d\n4. Look up your local SPC zone (or adopted zone) by county or position. Nature of Geographic Information 76\n5. You might check the result using Rick King\u2019s list or the Stem (1990) manual you downloaded\nearlier.\n3. Look up the map projection and grid origin upon which your local SPC zone is based.\n1. Refer to the Stem (1990) manual you downloaded earlier. In particular, see Appendix A, pp.\n63-72 (73-83). Upon which map projection is your local (or adopted) zone based?\n2. Note that the appendix reports a central meridian and scale factor for each zone that is\nbased upon a Transverse Mercator projection. Standard parallels are listed for zones based\nupon the Lambert Conformal Conic projection. In the Stem (1990) manual, \u201cscale factor\u201d is\nexpressed in terms of maximum measurement error associated with each zone.\n3. Appendix A also lists the SPC coordinates of each zone origin as well as its corresponding\ngeographic coordinates.\n4. Use the NGS Toolkit to convert geographic coordinates to SPC coordinates.\nNational Geodetic Survey State Plane Coordinate toolkit available here.\n1. You\u2019ll need to know the geographic coordinates of a place of interest to complete this part of\nthe activity. To look up the latitude and longitude associated with a U.S. place name, visit\nthe USGS Geographic Names Information System. If you do not reside in the U.S., use\nthe Getty Thesaurus of Geographic Names. Pay attention; be sure to choose the correct\ninstance of the place name. Cities and towns are listed as \u201cPopulated Places\u201d in the 77 David DiBiase\nGeographic Names Information System and as \u201cInhabited Places\u201d in the Getty Thesaurus.\n2. Return to the National Geodetic Survey\u2019s NGS Geodetic Toolkit.\n3. Use the dropdown menu to navigate to the State Plane Coordinates tool.\n4. At the State Plane Coordinates page, follow the Interactive Conversions link labeled\n\u201cLatitude\/Longitude -> SPC\u201d\n5. Specify geographic (a.k.a. \u201cgeodetic\u201d) coordinates in degrees-minutes-seconds format. You\ndo not need to show five places to the right of the decimal, as in the example illustrated\nabove, but you do need to add a decimal point at the end of the DMS input values; the tool\nallows you to input a DMS value that is accurate to fractions of a Second and so is\nprogrammed to expect the decimal point.\n6. A correct result will include a SPC Northing, Easting, zone, convergence (a correction factor\nfor distance calculations that compensates for the tendency of meridians to converge toward\nthe poles), and the scale factor at the specified point.\nPractice Quiz\nRegistered Penn State students should return now to the Chapter 2 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about State Plane Coordinate system.\nYou may take practice quizzes as many times as you wish. They are not scored and do not affect your\ngrade in any way.\n2.28. Map Projections\nLatitude and longitude coordinates specify point locations within a coordinate system grid that is fitted\nto sphere or ellipsoid that approximates the Earth\u2019s shape and size. To display extensive geographic\nareas on a page or computer screen, as well as to calculate distances, areas, and other quantities most\nefficiently, it is necessary to flatten the Earth.\nMap projections are mathematical equations that transform geographic coordinates (conventionally\ndesignated by the Greek symbols lambda for longitude and phi for latitude) into plane coordinates\n(x and y). If all the necessary parameters are known, inverse projection equations can be used to\ntransform projected coordinates back into unprojected geographic coordinates.\nGeoreferenced plane coordinate systems like the Universal Transverse Mercator and State Plane\nCoordinates systems (examined elsewhere in this lesson) are created by first flattening the graticule, Nature of Geographic Information 78\nthen superimposing a rectangular grid over the flattened graticule. The first step, transforming the\ngeographic coordinate system grid from a more-or-less spherical shape to a flat surface, involves systems\nof equations called map projections.\nMany different map projection methods exist. Although only a few are widely used in large scale\nmapping, the projection parameters used vary greatly. Geographic information systems professionals are\nexpected to be knowledgeable enough to select a map projection that is suitable for a particular mapping\nobjective. Such professionals are expected to be able to recognize the type, amount, and distribution\nof geometric distortion associated with different map projections. Perhaps most important, they need to\nknow about the parameters of map projections that must be matched in order to merge geographic data\nfrom different sources. The pages that follow introduce the key concepts. The topic is far too involved to\nmaster in a one section of a single chapter, however. Indeed, Penn State offers an entire one-credit online\ncourse in \u201cMap Projections for Geospatial Professionals\u201d (GEOG 861). If you are, or plan to become, a\nGIS professional, you should own at least one good book on map projections. Several recommendations\nfollow in the bibliography at the end of this lesson. If you care to offer a recommendation of your own,\nplease add it as a comment to the bibliography page.\nStudents who successfully complete this section should be able to:\n1. Interpret distortion diagrams to identify geometric properties of the sphere that are preserved\nby a particular projection.\n2. Classify projected graticules by projection family.\n2.29. Geometric Properties Preserved and Distorted\nMany types of map projections have been devised to suit particular purposes. No projection allows us\nto flatten the globe without distorting it, however. Distortion ellipses help us to visualize what type\nof distortion a map projection has caused, how much distortion occurred, and where it occurred. The\nellipses show how imaginary circles on the globe are deformed as a result of a particular projection. If\nno distortion had occurred in the process of projecting the map shown below, all of the ellipses would be\nthe same size, and circular in shape.\nWhen positions on the graticule are transformed to positions on a projected grid, four types of\ndistortion can occur: distortion of sizes, angles, distances, and directions. Map projections that avoid one\nor more of these types of distortion are said to preserve certain properties of the globe.\nEQUIVALENCE\nSo-called equal-area projections maintain correct proportions in the sizes of areas on the globe\nand corresponding areas on the projected grid (allowing for differences in scale, of course). Notice 79 David DiBiase\nthat the shapes of the ellipses in the Cylindrical Equal Area projection above are distorted, but the\nareas each one occupies are equivalent. Equal-area projections are preferred for small-scale thematic\nmapping, especially when map viewers are expected to compare sizes of area features like countries and\ncontinents.\nCONFORMALITY\nThe distortion ellipses plotted on the conformal projection shown above vary substantially in size,\nbut are all the same circular shape. The consistent shapes indicate that conformal projections (like this\nMercator projection of the world) preserve the fidelity of angle measurements from the globe to the\nplane. In other words, an angle measured by a land surveyor anywhere on the Earth\u2019s surface can\nbe plotted on at its corresponding location on a conformal projection without distortion. This useful\nproperty accounts for the fact that conformal projections are almost always used as the basis for large\nscale surveying and mapping. Among the most widely used conformal projections are the Transverse\nMercator, Lambert Conformal Conic, and Polar Stereographic.\nConformality and equivalence are mutually exclusive properties. Whereas equal-area projections\ndistort shapes while preserving fidelity of sizes, conformal projections distort sizes in the process of\npreserving shapes. Nature of Geographic Information 80\nEQUIDISTANCE\nEquidistant map projections allow distances to be measured accurately along straight lines radiating\nfrom one or two points only. Notice that ellipses plotted on the Cylindrical Equidistant (Plate Carr\u00e9e)\nprojection shown above vary in both shape and size. The north-south axis of every ellipse is the same\nlength, however. This shows that distances are true-to-scale along every meridian; in other words,\nthe property of equidistance is preserved from the two poles. See chapters 11 and 12 of the online\npublication Matching the Map Projection to the Need to see how projections can be customized to\nfacilitate distance measurements and to effectively depict ranges and rings of activity.\nAZIMUTHALITY\nAzimuthal projections preserve directions (azimuths) from one or two points to all other points on\nthe map. See how the ellipses plotted on the gnomonic projection shown above, vary in size and shape,\nbut are all oriented toward the center of the projection? In this example, that\u2019s the one point at which\ndirections measured on the globe are not distorted on the projected graticule. 81 David DiBiase\nCOMPROMISE\nSome map projections preserve none of the properties described above, but instead seek a compromise\nthat minimizes distortion of all kinds. The example shown above is the Polyconic projection, which\nwas used by the U.S. Geological Survey for many years as the basis of its topographic quadrangle map\nseries until it was superceded by the conformal Transverse Mercator. Another example is the Robinson\nprojection, which is often used for small-scale thematic maps of the world.\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 2 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about the geometric properties of map projections.\nYou may take practice quizzes as many times as you wish. They are not scored and do not affect your\ngrade in any way.\n2.30. Classifying Projection Methods\nThe term \u201cprojection\u201d implies that the ball-shaped net of parallels and meridians is transformed by\ncasting its shadow upon some flat, or flattenable, surface. In fact, almost all map projection methods\nare mathematical equations. The analogy of an optical projection onto a flattenable surface is useful,\nhowever, as a means to classify the bewildering variety of projection equations devised over the past two\nthousand years or more. Nature of Geographic Information 82\nThree types of \u201cflattenable\u201d surfaces to which the graticule can be projected: a plane, a cone, and a\ncylinder.\nImagine a model globe that is translucent, and contains a bright light bulb. Imagine the light literally\ncasting shadows of the graticule, and of the shapes of the continents, onto another surface that touches\nthe globe. The National Geographic Society has prepared a set of animations that may help you to\nvisualize the analogy.\nAs you might imagine, the appearance of the projected grid will change quite a lot depending on the\ntype of surface it is projected onto, and how that surface is aligned with the globe. The three surfaces\nshown above\u2013the disk-shaped plane, the cone, and the cylinder\u2013represent categories that account for\nthe majority of projection equations that are encoded in GIS software. All three are shown in their\nnormal aspects. The plane often is centered upon a pole. The cone is typically aligned with the globe\nsuch that its line of contact (tangency) coincides with a parallel in the mid-latitudes. And the cylinder is\nfrequently positioned tangent to the equator (unless it is rotated 90\u00b0, as it is in the Transverse Mercator\nprojection). The following illustrations shows some of the projected graticules produced by projection\nequations in each category.\nFour categories of map projections\nCylindric projection equations yield projected graticules with straight meridians and parallels that\nintersect at right angles. The example shown above is a Cylindrical Equidistant (also called Plate Carr\u00e9e\nor geographic) in its normal equatorial aspect.\nPseudocylindric projections are variants on cylindrics in which meridians are curved. The result of a\nSinusoidal projection is shown above.\nConic projections yield straight meridians that converge toward a single point at the poles, parallels\nthat form concentric arcs. The example shown above is the result of an Albers Conic Equal Area, which\nis frequently used for thematic mapping of mid latitude regions.\nPlanar projections also yield meridians that are straight and convergent, but parallels form concentric\ncircles rather than arcs. Planar projections are also called azimuthal because every planar projection\npreserves the property of azimuthality. The projected graticule shown above is the result of an Azimuthal\nEquidistant projection in its normal polar aspect.\nAppearances can be deceiving. It\u2019s important to remember that the look of a projected graticule\ndepends on several projection parameters, including latitude of projection origin, central meridian, 83 David DiBiase\nstandard line(s), and others. Customized map projections may look entirely different from the archetypes\ndescribed above.\nTRY THIS!\nJohn Snyder and Phil Voxland (1994) published an Album of Map Projections that describes and\nillustrates many more examples in each projection category. Excerpts from that important work are\nincluded in our Interactive Album of Map Projections, which registered students will use to complete\nProject 1. The Interactive Album is available here. The variety of projections available, as well as\nusers\u2019 ability to manipulate projection parameters, is limited to the capabilities of the ArcIMS software\nplatform upon which we developed the Interactive Album.\nFlex Projector is a free, open source software program developed in Java that supports many more\nprojections and variable parameters than the Interactive Album. Bernhard Jenny of the Institute of\nCartography at ETH Zurich created the program with assistance from Tom Patterson of the US National\nPark Service. You can download Flex Projector fromflexprojector.com\nThose who wish to explore map projections in greater depth than is possible in this course might wish\nto visit an informative page published by the International Institute for Geo-Information Science and\nEarth Observation (Netherlands), which is known by the legacy acronym ITC.\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 2 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about Classifying Map Projections.\nYou may take practice quizzes as many times as you wish. They are not scored and do not affect your\ngrade in any way.\n2.31. Summary\nIn this lesson we\u2019ve explored several connotations of the term scale. Scale is synonymous with scope\nwhen it is used to describe the extent of a phenomenon. In this sense, \u201clarge scale\u201d means \u201clarge\narea.\u201d Specialists in geographic information often use the term differently, however. Map scale refers\nto the relative sizes of features on a map and of corresponding objects on the ground. In this context,\n\u201clarge scale\u201d implies \u201csmall area.\u201d Large scale also implies greater detail and greater accuracy, an\nimportant point to keep in mind when using maps as sources for GIS databases. Map scale is defined\nmathematically as the proportion of map distance to ground distance. I hope you are now prepared to\nuse scale equations to calculate map scale.\nScale can also be thought of as a reference system for measurement. Locations on the globe are\nspecified with reference to the geographic coordinate system of latitudes and longitudes. Plane\ncoordinates are often preferred over geographic coordinates because they ease calculations of distance,\narea, and other quantities. Georeferenced plane coordinate systems like UTM and SPC are established\nby first flattening the graticule, then superimposing a plane coordinate grid. The mathematical equations\nused to transform geographic coordinates into plane coordinates are called map projections. Both plane\nand geographic coordinate system grids are related to approximations of the Earth\u2019s size and shape\ncalledellipsoids. Relations between grids and ellipsoids are called horizontal datums.\nHorizontal datum is an elusive concept for many GIS practitioners. It is relatively easy to visualize\na horizontal datum in the context of unprojected geographic coordinates. Simply drape the latitude and Nature of Geographic Information 84\nlongitude grid over an ellipsoid and there\u2019s your horizontal datum. It is harder to think about datum\nin the context of a projected coordinate grid like UTM and SPC, however. Think of it this way: First\ndrape the latitude and longitude grid on an ellipsoid. Then project that grid to a 2-D plane surface. Then,\nsuperimpose a rectangular grid of eastings and northings over the projection, using control points to\ngeoregister the grids. There you have it\u2013a projected coordinate grid based upon a horizontal datum.\nNumerous coordinate systems, datums, and map projections are in use around the world. Because\nwe often need to combine georeferenced data from various sources, GIS professionals need to be able\nto georegister two or more data sets that are based upon different coordinate systems, datums, and\/or\nprojections. Transformations, including coordinate transformations, datum transformations, and map\nprojections, are the mathematical procedures used to bring diverse data into alignment. Characteristics\nof the coordinate systems, datums, and projections considered in this course are outlined in the following\ntables.\nCoordinate systems referenced in this course (many other national and local systems are in use)\nCoordinate systems referenced\nCoordinate\nUnits Extent Projection basis\nsystem\nAngles (expressed as\nGeographic degrees, minutes, seconds Global None\nor decimal degrees).\nNear-global\nUnique Transverse Mercator projection for each of 60\nUTM Distances (meters) (8430\u2032 N,\nzones\n80\u00b0 30\u2032 S)\nDistances (meters in Unique Transverse Mercator or Lambert Conformal\nState Plane\nSPCS 83, feet in SPCS U.S. Conic projection for each of 123 zones (plus Oblique\nCoordinates\n27) Mercator for Alaska panhandle)\nDatums referenced in this course (many other national and local systems are in use)\nDatums referenced\nDatum Horiztonal or vertical Optimized for Reference surface\nNAD 27 Horizontal North America Clarke 1866 ellipsoid\nNAD 83 Horizontal North America GRS 80 ellipsoid\nWGS 84 Horizontal World WGS 84 ellipsoid\nNAVD 88 Vertical North America Sea level measured at coastal tidal stations\nMap projections referenced in this course (many other national and local systems are in use) 85 David DiBiase\nMap projections referenced\nProperties\nProjection name Class Distortion\npreserved\nArea distortion increases with distance from\nMercator Conformal Cylindrical\nstandard parallel (typically equator)\nArea distortion increases with distance from\nTransverse Mercator Conformal Cylindrical\nstandard meridian\nArea distortion increases with distance from one\nLambert Conformal Conic Conformal Conic\nor two standard parallels\nPlate Carr\u00e9e (sometimes called Area and shape distortion increases with distance\nEquidistant Cylindrical\n\u201cGeographic\u201d projection) from standard parallel (typically equator)\nShape distortion increases with distance from one\nAlbers Equal-Area Conic Equivalent Conic\nor two standard parallels\nCompiled from Snyder, 1997\nQUIZ\nRegistered Penn State students should return now to the Chapter 2 folder in ANGEL (via the Resources\nmenu to the left) to take the Chapter 2 graded quiz.\nThis one counts. You may take graded quizzes only once.\nThe purpose of the graded quizzes is to ensure that you have studied the text closely, that you have\nmastered the practice activities, and that you have fulfilled the chapter\u2019s learning objectives. You are free\nto review the chapter during the quiz.\nOnce you have submitted the quiz and posted any questions you may have to either our discussion\nforums or chapter pages, you will have completed Chapter 2.\nCOMMENTS AND QUESTIONS\nRegistered students are welcome to post comments, questions, and replies to questions about the\ntext. Particularly welcome are anecdotes that relate the chapter text to your personal or professional\nexperience. In addition, there are discussion forums available in the ANGEL course management system\nfor comments and questions about topics that you may not wish to share with the whole world.\nTo post a comment, scroll down to the text box under \u201cPost new comment\u201d and begin typing in the text\nbox, or you can choose to reply to an existing thread. When you are finished typing, click on either the\n\u201cPreview\u201d or \u201cSave\u201d button (Save will actually submit your comment). Once your comment is posted,\nyou will be able to edit or delete it as needed. In addition, you will be able to reply to other posts at any\ntime.\nNote: the first few words of each comment become its \u201ctitle\u201d in the thread.\n2.32. Bibliography\n3-D Software (2005). Map projections pages. Retrieved January 8, 2005,\nfrom http:\/\/www.3dsoftware.com\/Cartography\/ Nature of Geographic Information 86\nAmerican Congress on Surveying and Mapping (n. d.). The North American Datum of 1983. A\ncollection of papers describing the planning and implementation of the readjustment of the North\nAmerican horizontal network. Monograph No. 2.\nBurkard, R. K. et al. (1959-2002). Geodesy for the layman. Retrieved October 29, 2003, from\nthe National Imagery and Mapping Agency Web site http:\/\/www.ngs.noaa.gov\/PUBS_LIB\/\nGeodesy4Layman\/toc.htm\nChem-Nuclear Systems, Inc. (1993). Site screening interim report: Stage two \u2014 regional\ndisqualification. Harrisburg PA.\nChrisman, N. (2002). Exploring geographic information systems (2nd ed.). New York: John Wiley &\nSons.\nClarke, K. (1995). Analytical and computer cartography (2nd ed.). Upper Saddle River, NJ: Prentice\nHall.\nDana, P. H. (1998). Coordinate systems overview. The Geographer\u2019s Craft Project. Retrieved June\n25, 2004, from The University of Colorado at Boulder, Department of Geography Web\nsite:http:\/\/www.colorado.edu\/geography\/gcraft\/notes\/coordsys\/coordsys.html\nDana, P. H. (1999). Geodetic datums overview. The Geographer\u2019s Craft Project. Retrieved June\n25, 2004, from The University of Colorado at Bolder, Department of Geography Web\nsite:http:\/\/www.colorado.edu\/geography\/gcraft\/notes\/datum\/datum.html\nDewhurst, W. T. (1990). NADCON: The application of minimum-curvature-derived surfaces in the\ntransformation of positional data from the North American datum of 1927 to the North American\ndatum of 1983. NOAA Technical Memorandum NOS NGS 50. Retrieved January 1, 2005,\nfrom http:\/\/www.ngs.noaa.gov\/PUBS_LIB\/NGS50.pdf\nDoyle, D. (2004, February). NGS geodetic toolkit, Part 7: Computing state plane\ncoordinates. Professional Surveyor Magazine, 24:, 34-36.\nDutch, S. (2003). The Universal Transverse Mercator System. Retrieved January 9, 2008\nfromhttp:\/\/www.uwgb.edu\/DutchS\/FieldMethods\/UTMSystem.htm\nFederal Geographic Data Committee. (December 2001). United States National Grid. Retrieved\nMay 8, 2006, fromhttp:\/\/www.fgdc.gov\/standards\/projects\/FGDC-standards-projects\/usng\/\nfgdc_std_011_2001_usng.pdf\nHildebrand, B. (1997). Waypoint+. Retrieved January 1, 2005, fromhttp:\/\/www.tapr.org\/~kh2z\/\nWaypoint\/\nIliffe, J.C. (2000). Datums and map projections for remote sensing, GIS and surveying. Caithness,\nScotland: Whittles Publishing. Distributed in U.S. by CRC Press.\nLarrimore, C. (2002). NGS Geodetic Toolkit. Retrieved October 26, 2004,\nfrom http:\/\/www.ngs.noaa.gov\/TOOLS\nMuehrcke, P. C. & Muehrcke, J. O. (1992). Map use (3rd ed.). Madison WI: JP Publications.\nMuehrcke, P. C. & Muehrcke, J. O. (1998). Map use (4th ed.). Madison WI: JP Publications.\nMulcare, D. M. (2004). The National Geodetic Survey NADCON Tool.Professional Surveyor\nMagazine, February, pp. 28-33.\nNational Geodetic Survey. (n.d.). North American datum conversion utility. Retrieved April 2004,\nfromhttp:\/\/www.ngs.noaa.gov\/TOOLS\/Nadcon\/Nadcon.html\nNational Geodetic Survey. (1997). Image generated from 15\u2032x15\u2032 geoid undulations covering the\nplanet Earth. Retrieved 1999, fromhttp:\/\/www.ngs.noaa.gov\/GEOID\/geo-index.html (since retired).\nNational Geodetic Survey. (2004). Coast and geodetic survey historical image collection. Retrieved\nJune 25, 2004, fromhttp:\/\/www.photolib.noaa.gov\/cgs\/index.html\nNational Geographic Society (1999). Round earth, flat maps. Retrieved April 18, 2006,\nfromhttp:\/\/www.nationalgeographic.com\/features\/2000\/exploration\/projections\/index.html 87 David DiBiase\nOrdnance Survey (2000). National GPS network information. 7: Transverse mercator map\nprojections. Retrieved August 27, 2004, fromhttp:\/\/www.gps.gov.uk\/guide7.asp\nRobinson, A. et al. (1995). Elements of cartography (5th ed.). New York: John Wiley & Sons.\nRobinson, A. H. & Snyder, J. P. (1997). Matching the map projection to the need. Retrieved January 8,\n2005, from the Cartography and Geographic Information Society and the Pennsylvania State University\nweb site: https:\/\/courseware.e-education.psu.edu\/projection\/\nSlocum, T. A., McMaster, R. B., Kessler, F, C., & Howard, H. H. (2005).Thematic cartography and\nvisualization (2nd ed.). Upper Saddle River, NJ: Prentice Hall.\nSmith, J.R. (1988). Basic geodesy. Rancho Cordova CA: Landmark Enterprises.\nSnyder, J. P. (1987). Map projections: A working manual (U.S. Geological Survey Professional Paper\nNo. 1395). Washington DC: United States Government Printing Office.\nSnyder, J. P. (1987). Map projections: A working manual. (USGS Professional Paper No. 1395).\nWashington DC: U.S. Geological Survey (Electronic versions available athttp:\/\/pubs.er.usgs.gov\/djvu\/\nPP\/PP_1395.pdf)\nSnyder, J. P. & Voxland P. M. (1989). An album of map projections(U.S. Geological Survey\nProfessional Paper No. 1453). Washington DC: United States Government Printing Office.\nSnyder, J. P. & Voxland, P. M. (1994). An album of map projections. (USGS Professional Paper No.\n1453). Washington DC: U.S. Geological Survey. (ordering information published athttp:\/\/erg.usgs.gov\/\nisb\/pubs\/factsheets\/fs08799.html)\nStem, J. E. (1990). State Plane Coordinate System of 1983 (NOAA Manual NOS NGS 5). Rockville,\nMD: National Geodetic Information Center.\nThe Large Scale Biosphere-Atmosphere Experiment in Amazonia (1999, July 1). Retrieved July 12,\n1999, fromhttp:\/\/daacl.ESD.ORNL.Gov\/lba_cptec\/ (since retired).\nUnited States Geological Survey (2001). The universal transverse mercator grid. Fact sheet 077-01.\nRetrieved June 30, 2004, fromhttp:\/\/mac.usgs.gov\/mac\/isb\/pubs\/factsheets\/fs07701.html (since retired).\nUnited States Geological Survey (2003). National mapping program standards. Retrieved October\n29, 2005, fromhttp:\/\/rockyweb.cr.usgs.gov\/nmpstds\/nmas647.html\nUSGS. \u201cState College Quadrangle\u201d [map]. 7.5 minute series. Washington, D.C.: USGS, 1962.\nVan Sickle, J. (2004). Basic GIS coordinates. Boca Raton FL: CRC Press.\nWikipedia. The free encyclopedia. (2006). World geodetic system. Retrieved May 8, 2006,\nfrom http:\/\/en.wikipedia.org\/wiki\/WGS84\nWolf, P. R. & Brinker, R. C. (1994) Elementary Surveying (9th ed.). New York NY: HarperCollins. Chapter 3\n88 Census Data and Thematic Maps\nDavid DiBiase\n3.1. Overview\nIn Chapter 2 we compared the characteristics of geographic and plane coordinate systems that are used\nto measure and specify positions on the Earth\u2019s surface. Coordinate systems, remember, are formed by\njuxtaposing two or more spatial measurement scales. I mentioned, but did not explain, that attribute\ndata also are specified with reference to measurement scales. In this chapter we\u2019ll take a closer look\nat how attributes are measured and represented.\nMaps are both the raw material and the product of GIS. All maps, but especially so-called reference\nmaps made to support a variety of uses, can be defined as sets of symbols that represent the locations and\nattributes of entities measured at certain times. Many maps, however, are subsets of available geographic\ndata that have been selected and organized in response to a particular question. Maps created specifically\nto highlight the distribution of a particular phenomenon or theme are called thematic maps. Thematic\nmaps are among the most common forms of geographic information produced by GIS.\nA flat sheet of paper is an imperfect but useful analog for geographic space. Notwithstanding the\nintricacies of map projections, it is a fairly straightforward matter to plot points that stand for locations\non the globe. Representing the attributes of locations on maps is sometimes not so straightforward,\nhowever. Abstract graphic symbols must be devised that depict, with minimum ambiguity, the quantities\nand qualities that give locations their meaning. Over the past 100 years or so, cartographers have adopted\nand tested conventions concerning symbol color, size, and shape for thematic maps. The effective use\nof graphic symbols is an important component in the transformation of geographic data into useful\ninformation.\nPopulation change in the United States, by county, from 1990 to 2000.\n(Data from 1990 & 2000 decennial censuses).\nConsider the map above, which shows how the distribution of U.S. population changed, by county,\nfrom 1990 to 2000. To gain a sense of how effective this thematic map is in transforming data into\n89 Nature of Geographic Information 90\ninformation, we need only to compare it to a list of population change rates for the more than 3,000\ncounties of the U.S. The thematic map reveals spatial patterns that the data themselves conceal.\nThis chapter explores the characteristics of attribute data used for thematic mapping, especially\nattribute data produced by U.S. Census Bureau. It also considers how the characteristics of attribute data\ninfluence choices about how to present the data on thematic maps.\nObjectives\nStudents who successfully complete Chapter 3 should be able to:\n1. Use metadata and the World Wide Web to assess the content and availability of attribute data\nproduced by the U.S. Census Bureau;\n2. Discriminate between different levels of measurement of attribute data;\n3. Explain the differences between counts, rates, and densities, and identify the types of map\nsymbols that are most appropriate for representing each; and\n4. Use quantile and equal interval classification schemes to divide census attribute data into\ncategories suitable for choroplethic mapping.\nComments and Questions\nRegistered students are welcome to post comments, questions, and replies to questions about the\ntext. Particularly welcome are anecdotes that relate the chapter text to your personal or professional\nexperience. In addition, there are discussion forums available in the ANGEL course management system\nfor comments and questions about topics that you may not wish to share with the whole world.\nTo post a comment, scroll down to the text box under \u201cPost new comment\u201d and begin typing in the text\nbox, or you can choose to reply to an existing thread. When you are finished typing, click on either the\n\u201cPreview\u201d or \u201cSave\u201d button (Save will actually submit your comment). Once your comment is posted,\nyou will be able to edit or delete it as needed. In addition, you will be able to reply to other posts at any\ntime.\nNote: the first few words of each comment become its \u201ctitle\u201d in the thread.\n3.2. Checklist\nThe following checklist is for Penn State students who are registered for classes in which this text,\nand associated quizzes and projects in the ANGEL course management system, have been assigned. You\nmay find it useful to print this page out first so that you can follow along with the directions. 91 David DiBiase\nChapter 3 Checklist (for registered students only)\nStep Activity Access\/Directions\nThis is the second page of the Chapter. Click on the links at the bottom\nof the page to continue or to return to the previous page, or to go to the\n1 Read Chapter 3\ntop of the chapter. You can also navigate the text via the links in the\nGEOG 482 menu on the left.\nSubmit five practice\nquizzesincluding:\n\u2022 Census Attribute\nData\n\u2022 Recognizing Levels\nof Measurement\n\u2022 Levels and\nGo to ANGEL > [your course section] > Lessons tab > Chapter 3 folder\n2 Operations\n> [quiz]\n\u2022 Thematic Map Types\n\u2022 Data Classification\nfor Thematic\nMapping\nPractice quizzes are not graded\nand may be submitted more\nthan once.\nPerform \u201cTry this\u201d\nactivitiesincluding:\n\u2022 Acquiring U.S.\nCensus data\n3 Instructions are provided for each activity.\n\u2022 Acquiring world\ndemographic data\n\u201cTry this\u201d activities are not\ngraded.\nSubmit theChapter 3 Graded ANGEL > [your course section] > Lessons tab > Chapter 3 folder >\n4\nQuiz Chapter 3 Graded Quiz\nRead comments and\nquestionsposted by fellow Comments and questions may be posted on any page of the text, or in a\n5\nstudents. Add comments and Chapter-specific discussion forum in ANGEL.\nquestions of your own, if any.\n3.3. Census Attribute Data\nA thematic map is a graphic display that shows the geographic distribution of a particular attribute,\nor relationships among a few selected attributes. Some of the richest sources of attribute data are\nnational censuses. In the United States, a periodic count of the entire population is required by the U.S.\nConstitution. Article 1, Section 2, ratified in 1787, states that Representatives and direct taxes shall\nbe apportioned among the several states which may be included within this union, according to their Nature of Geographic Information 92\nrespective numbers \u2026 The actual Enumeration shall be made [every] ten years, in such manner as [the\nCongress] shall by law direct.\u201d The U.S. Census Bureau is the government agency charged with carrying\nout the decennial census.\nA portion of the Constitution of the United States of America.\nThe results of the U.S. decennial census determine states\u2019 portions of the 435 total seats in the\nU.S. House of Representatives. The map below shows states that lost and gained seats as a result of\nthe reapportionmentthat followed the 2000 census. Congressional voting district boundaries must be\nredrawn within the states that gained and lost seats, a process called redistricting. Constitutional rules\nand legal precedents require that voting districts contain equal populations (within about 1 percent). In\naddition, districts must be drawn so as to provide equal opportunities for representation of racial and\nethnic groups that have been discriminated against in the past.\nReapportionment of the U.S. House of Representatives as a result of the 2000 census.\nBesides reapportionment and redistricting, U.S. census counts also affect the flow of billions of dollars\nof federal expenditures, including contracts and federal aid, to states and municipalities. In 1995, for\nexample, some $70 billion of Medicaid funds were distributed according to a formula that compared\nstate and national per capita income. $18 billion worth of highway planning and construction funds\nwere allotted to states according to their shares of urban and rural population. And $6 billion of Aid\nto Families with Dependent Children was distributed to help children of poor families do better in\nschool. The two thematic maps below illustrate the strong relationship between population counts and\nthe distribution of federal tax dollars. 93 David DiBiase\nPopulation and federal expenditures, by state, 1995. (Cartography by Thad Lenker. Data from U.S.\nCensus Bureau, Federal Expenditures by State, http:\/\/www.census.gov\/prod\/2\/gov\/fes95rv.pdf)\nThe Census Bureau\u2019s mandate is to provide the population data needed to support governmental\noperations including reapportionment, redistricting, and allocation of federal expenditures. Its mission,\nto be \u201cthe preeminent collector and provider of timely, relevant, and quality data about the people and\neconomy of the United States\u201d, is broader, however. To fulfill this mission, the Census Bureau needs to\ncount more than just numbers of people, and it does.\nTRY THIS!\nThe Redistricting Game\n3.4. Enumerations versus Samples\nSixteen U.S. Marshals and 650 assistants conducted the first U.S. census in 1791. They counted some 3.9\nmillion individuals, although as then-Secretary of State Thomas Jefferson reported to President George\nWashington, the official number understated the actual population by at least 2.5 percent (Roberts,\n1994). By 1960, when the U.S. population had reached 179 million, it was no longer practical to have a\ncensus taker visit every household. The Census Bureau then began to distribute questionnaires by mail.\nOf the 116 million households to which questionnaires were sent in 2000, 72 percent responded by mail.\nA mostly-temporary staff of over 800,000 was needed to visit the remaining households, and to produce\nthe final count of 281,421,906. Using statistically reliable estimates produced from exhaustive follow-up\nsurveys, the Bureau\u2019s permanent staff determined that the final count was accurate to within 1.6 percent\nof the actual number (although the count was less accurate for young and minority residences than it was\nfor older and white residents). It was the largest and most accurate census to that time. (Interestingly,\nCongress insists that the original enumeration or \u201chead count\u201d be used as the official population count, Nature of Geographic Information 94\neven though the estimate calculated from samples by Census Bureau statisticians is demonstrably more\naccurate.)\nAs of this writing, the decennial census of 2010 is still underway. Like 2000, the mail-in response\nrate was 72 percent. The official 2010 census count, by state, must be delivered to the U.S. Congress by\nDecember 31, 2010.\nIn 1791, census takers asked relatively few questions. They wanted to know the numbers of free\npersons, slaves, and free males over age 16, as well as the sex and race of each individual. (You can view\nreplicas of historical census survey forms here) As the U.S. population has grown, and as its economy\nand government have expanded, the amount and variety of data collected has expanded accordingly. In\nthe 2000 census, all 116 million U.S. households were asked six population questions (names, telephone\nnumbers, sex, age and date of birth, Hispanic origin, and race), and one housing question (whether the\nresidence is owned or rented). In addition, a statistical sample of one in six households received a \u201clong\nform\u201d that asked 46 more questions, including detailed housing characteristics, expenses, citizenship,\nmilitary service, health problems, employment status, place of work, commuting, and income. From the\nsampled data the Census Bureau produced estimated data on all these variables for the entire population.\nIn the parlance of the Census Bureau, data associated with questions asked of all households are\ncalled 100% data and data estimated from samples are called sample data. Both types of data are\navailable aggregated by various enumeration areas, including census block, block group, tract, place,\ncounty, and state (see the illustration below). Through 2000, the Census Bureau distributes the 100%\ndata in a package called the \u201cSummary File 1\u2033 (SF1) and the sample data as \u201cSummary File 3\u2033\n(SF3). In 2005 the Bureau launched a new project called American Community Survey that surveys\na representative sample of households on an ongoing basis. Every month one household out of every\n480 in each county or equivalent area receives a survey similar to the old \u201clong form.\u201d Annual or semi-\nannual estimates produced from American Community Survey samples replaced the SF3 data product in\n2010.\nTo protect respondents\u2019 confidentiality, as well as to make the data most useful to legislators, the\nCensus Bureau aggregates the data it collects from household surveys to several different types of\ngeographic areas. SF1 data, for instance, are reported at the block or tract level. There were about 8.5\nmillion census blocks in 2000. By definition, census blocks are bounded on all sides by streets, streams,\nor political boundaries. Census tracts are larger areas that have between 2,500 and 8,000 residents.\nWhen first delineated, tracts were relatively homogeneous with respect to population characteristics,\neconomic status, and living conditions. A typical census tract consists of about five or six sub-areas\ncalled block groups. As the name implies, block groups are composed of several census blocks.\nAmerican Community Survey estimates, like the SF3 data that preceded them, are reported at the block\ngroup level or higher. 95 David DiBiase\nRelationships among the various census geographies. (U.S. Census Bureau, American FactFinder,\n2005,http:\/\/factfinder.census.gov\/jsp\/saff\/SAFFInfo.jsp?_pageId=gn7_maps An updated source for the\ndiagram can be found athttp:\/\/factfinder2.census.gov\/faces\/nav\/jsf\/pages\/using_factfinder5.xhtml).\nTRY THIS!\nAcquiring U.S. Census Data via the World Wide Web\nThe purpose of this practice activity is to guide you through the process of finding and acquiring\n2000 census data from the U.S. Census Bureau data via the Web. Your objective is to look up the total\npopulation of each county in your home state (or an adopted state of the U.S.). On January 29, 2013, a\nredesigned version of the American FactFinder web pages was revealed. Some necessary changes to the\nsteps below are highlighed in green text.\n1. Go to the U.S. Census Bureau site.\n2. At the Census Bureau home page, hover your mouse cursor over theData tab and\nselect American FactFinder. American FactFinder is the Census Bureau\u2019s primary medium\nfor distributing census data to the public.\n3. Click the ADVANCED SEARCH button, and take note of the three steps featured on the\npage you are taken to. That\u2019s what we are about in this exercise.\n4. Click the Topics search option box. In the Select Topics overlay window expand\nthe People list. Next expand the Basic Count\/Estimatelist. Then choose Population Total.\nNote that a Population Total entry is placed in the Your Selections box in the upper left, and\nit disappears from the Basic Count\/Estimate list.\nClose the Select Topics window.\n5. The list of datasets in the resulting Search Results window is for the entire United States. We\nwant to narrow the search to county-level data for your home or adopted state.\nClick the Geographies search options box. In the Select Geographiesoverlay window that\nopens, under Select a geographic type:, clickCounty \u2013 050.\nNext select the entry for your state from the Select a state list, and then from the Select one\nor more geographic areas\u2026. list select All counties within <your state> . Nature of Geographic Information 96\nLast click ADD TO YOUR SELECTIONS. This will place your All Counties\u2026 choice in\nthe Your Selections box.\nClose the Select Geographies window.\n6. The list of datasets in the Search Results window now pertains to the counties in your state.\nTake a few moments to review the datasets that are listed. Note that there are SF1, SF2, ACS\n(American Community Survey), etc., datasets, and that if you page through the list far\nenough you will see that data from past years is listed. We are going to focus our effort on\nthe2010 SF1 100% Data.\n7. Given that our goal is to find the population of the counties in your home state, can you\ndetermine which dataset we should look at?\nThere is a TOTAL POPULATION entry. Find it, and make certain you have located the\n2010 SF1 100% Data dataset. (You can use the Narrow your search: slot above the dataset\nlist to help narrow the search.)\nCheck the box for it, and then click View.\nIn the new Results window that opens you should be able to find the population of the\ncounties your chosen state.\nNote the row of Actions:, which includes Print and Download buttons.I encourage you to\nexperiment some with the American FactFinder site. Start slow, and just click the BACK TO\nADVANCED SEARCH button, un-check the TOTAL POPULATION dataset and choose a\ndifferent dataset to investigate. Registered students will need to answer a couple of quiz\nquestions based on using this site.\nPay attention to what is in the Your Selections window. You can easily remove entries by\nclicking the blue circle with the white X.On a search page you might try typing \u201cQT\u201d or\n\u201cGCT\u201d in the topic or table name slot. QT stands for Quick Tables which are preformatted\ntables that show several related themes for one or more geographic areas. GCT stands\nfor Geographic Comparison Tables which are the most convenient way to compare data\ncollected for all the counties, places, or congressional districts in a state, or all the census\ntracts in a county.\n{C}\n{C}\n{C}\n{C}\n{C}\n1. Go to the U.S. Census Bureau site at http:\/\/www.census.gov.\n2. At the Census Bureau home page, hover your mouse cursor over theData tab and\nselect American FactFinder. American FactFinder is the Census Bureau\u2019s primary medium\nfor distributing census data to the public.\n3. Click the SEARCH button, and take note of the three steps featured in the yellow rectangle.\nThat\u2019s what we are about in this exercise.\n4. Click the Topics search option box. In the Select Topics overlay window expand\nthe People list. Next expand the Basic Count\/Estimatelist. Then choose Population Total.\nNote that a Population Total entry is placed in the Your Selections box in the upper left, and\nit disappears from the Basic Count\/Estimate list. 97 David DiBiase\nClose the Select Topics window.\n5. The list of datasets in the resulting Search Results window is for the entire United States. We\nwant to narrow the search to county-level data for your home or adopted state.\nClick the Geographies search options box. In the Select Geographiesoverlay window that\nopens, under Geography Filter Options, clickCounty. This will yield a list of All counties\nwithin <your state> underGeography Results.\nCheck the box next to the entry for your state, and then click Add. This will place your All\nCounties\u2026 choice in the Your Selections box.\nClose the Select Geographies window.\n6. The list of datasets in the Search Results window now pertains to the counties in your state.\nTake a few moments to review the datasets that are listed. Note that there are SF1, SF2, ACS\n(American Community Survey), etc., datasets, and that if you page through the list far\nenough you will see that data from past years is listed. We are going to focus our effort on\nthe2010 SF1 100% Data.\n7. Given that our goal is to find the population of the counties in your home state, can you\ndetermine which dataset we should look at?\nThere is a TOTAL POPULATION entry, probably on page 2. Find it, and make certain you\nhave located the 2010 SF1 100% Data dataset.\nCheck the box for it and click View.\nIn the new Results window that opens you should be able to find the population of the\ncounties your chosen state.\nNote the row of Actions:, which includes Print and Download buttons.\nI encourage you to experiment some with the American FactFinder site. Start slow, and just click\nthe BACK TO SEARCH button, un-check the TOTOL POPULATION dataset and choose a different\ndataset to investigate. Registered students will need to answer a couple of quiz questions based on using\nthis site.\nPay attention to what is in the Your Selections window. You can easily remove entries by clicking the\nred circle with the white X.\nOn the SEARCH page, with nothing in the Your Selections box, you might try typing \u201cQT\u201d or\n\u201cGCT\u201d in the Search for: slot. QT stands forQuick Tables which are preformatted tables that show\nseveral related themes for one or more geographic areas. GCT stands for Geographic Comparison\nTables which are the most convenient way to compare data collected for all the counties, places, or\ncongressional districts in a state, or all the census tracts in a county.\n3.5. American Community Survey\nBeginning in 2010, the American Community Survey (ACS) replaced the \u201clong form\u201d that was used to\ncollect sample data in past decennial censuses. Instead of sampling one in six households every ten years\n(about 18 million households in 2000), the ACS samples 2-3 million households every year. The goal of\nthe ACS is to enable Census Bureau statisticians to produce more timely estimates of the demographic,\neconomic, social, housing, and financial characteristics of the U.S. population. You can view a sample\nACS questionnaire by entering the keywords \u201cAmerican Community Survey questionnaire\u201d into your\nfavorite Internet search engine. Nature of Geographic Information 98\nAcquiring and Understanding American Community Survey (ACS) DataThe purpose of this\npractice activity is to guide your exploration of ACS data and methodology. In the end you should be\nable to identify the types of geographical areas for which ACS data are available; to explain why 1-year\nand 3-year estimates are available for some areas and not for others; and to describe how the statistical\nreliability of ACS estimates vary among 1-year, 3-year and 5-year estimates.\n1. Return to the U.S. Census Bureau site athttp:\/\/www.census.gov.\n2. With your mouse cursor, hover over the People tab and under Related Content follow the link\ntoAmerican Community Survey. This takes you to the main American Community Survey\npage. (You can also find a link to American Community Survey by following the Subjects A\nto Z link in the upper right.)\n3. Begin by clicking the Guidance for Data Users tab and looking through the information\navailable there.\nPay particular attention to the When to use\u2026 section and the descriptions of the various\nestimates (1-, 3- and 5-year).\nYou will also find a section on Comparing ACS Datato other census data, a section\non Handbooks for Data Users, and an E-Tutorial. (Some of the tutorial is not up to date\nrelative to the new web pages, but you might benefit from Lesson3: Understanding the\nAmerican Community Survey.)\n4. Next, look at the content under the Data & Documentation tab.\nIn the Data Releases section you will find release dates for the various datasets.\nIn the Documentation section there are links to documentation associated with current and\npast surveys, and within that section, under Accuracy of the Data, links to documents\ndescribing the methodology used and the accuracy of the data estimates.\nYou can download ACS data to make maps and analyses using your own GIS or statistical\nsoftware. Find download links and pertinent information in the sections titled Downloadable\nTry\nData via FTP, andSummary File.\nThis!\nThere is also a section pertaining to Public Use Microdata Sample (PUMS). PUMS data are\nedited, however, to protect the confidentiality of individuals and households.\n5. In the remaining steps you will make a map or two, to reinforce the geographies covered by the\nACS. You will map data from your home (or adopted) state.\nYou need to go to the American FactFinder. If you are still on the American Community\nSurvey page, click the Data & Documentation tab, then follow the link to the American\nFactFinder website. You should land on the SEARCH page with American Community\nSurvey in the Your Selections window, and a list of Search Results that are ACS-based.\n(If you were not already on the American Community Survey page, go to the MAIN American\nFactFinder site (http:\/\/factfinder2.census.gov), click the Topics search box, then expand\nthe Program list and chooseAmerican Community Survey. Close the Select Topics overlay\nwindow.)\n6. Click the Geographies search options box (on the left) to reveal the Select\nGeographies overlay window. Under Select a geographic type click County \u2013 050. Next\nfrom the Select a state list, choose your state. Then from the Select one or more geographic\nareas\u2026 list, choose All Counties within <your state>. Then click ADD TO YOUR\nSELECTIONS. This will add the All Counties\u2026 entry to the Your Selections list. Close\nthe Select Geographies overlay window.\nIf the Search Results window shows a list of datasets for 2005, advance the page, the list will\nrefresh so that page 1 shows datasets for the most recent years.\n7. In the Search Results window note that there are many datasets that have 1-, 3- and 5-year\nestimates entries. Decide upon a 1-Year dataset to look at and check the box for it. Then\nclick View. On the newResults page that you land on be sure that the Create a Map choice is\nblue \u2013 not grayed out. If it is grayed out click the BACK TO ADVANCED SEARCH button\nand make sure only one dataset box is checked, or make a different choice, then 99 David DiBiase\nclick View again.\nClick on Create a Map. The data values in the table will turn blue and you will be prompted to\n\u201cClick on a data value in the table.\u201d Clicking a single data value from any row will allow you\nto map the data in that row for all of the counties for which it is available. Click on a blue data\nvalue of your choice \u2013 remember which row you choose. Click on the SHOW MAPbutton in\nthe small popup window that appears.\nAre all of the counties in the state symbolized as having data? Why not?\n8. Now click the BACK TO ADVANCED SEARCHbutton. Un-check the box for the 1-year\ndataset and check the box for the 3-year estimate of the same category. Proceed as above to\nmap the data. After the map is refreshed note how many counties now exhibit data.\nTake a look at the 5-year estimates for the same dataset if you wish.\nRegistered Penn State students should return now to the Chapter 3 folder in ANGEL (via the\nPractice Resources menu to the left) to take a self-assessment quiz about Census Attribute Data. You may take\nQuiz practice quizzes as many times as you wish. They are not scored and do not affect your grade in any\nway.\n3.6. International Data\nThe International Data Base is published on the Web by the Census Bureau\u2019s International Programs\nCenter. It combines demographic data compiled from censuses and surveys of some 227 countries and\nareas of the world, along with estimates produced by Census Bureau demographers. Data variables\ninclude population by age and sex; vital rates, infant mortality, and life tables; fertility and child\nsurvivorship; migration; marital status; family planning; ethnicity, religion, and language; literacy; and\nlabor force, employment, and income. Census and survey data are available by country for selected\nyears from 1950; projected data are available through 2050. The International Data Base allows you to\ndownload attribute data in formats appropriate for thematic mapping.\nTRY THIS!\nAcquiring World Demographic Data via the World Wide Web\nThe purpose of this practice activity is to guide you through the process of finding and acquiring\ndemographic data for the countries of the world from the U.S. Census Bureau data via the Web. Your\nobjective is to retrieve population change rates for a country of your choice over two or more years.\n1. Return to the U.S. Census Bureau site.\n2. Hover over or click the People tab and choose International Data Base.\n3. Choose the data theme you are interested in from the Select Reportpick list. The choices\nhave to do with births and mortality, population change including such things as migration,\npopulation by age group, etc.\n4. Tables are available by Country or by Region.\nFrom the Select Country(ies) selection box you can specify that you want data for a single\ncountry, or for a collection of multiple countries, for as many Year(s) as you want to select.\nSee the instructions beneath the Submit button on how to select multiple entries from the Nature of Geographic Information 100\nselection boxes.\nFrom the Select Region(s) selection box you can choose from pre-selected groupings of\ncountries.\n5. Choose a single country under Country Search and two or more years. Then\nclick SUBMIT. You will see a summary table of data for your selected country and years.\n6. Experiment with the choices in the Select Region(s) selection box and the Aggregation\nOptions choice list.\n7. For your information: to download an Excel (.xls) or text file (.csv) version of the data, find\nthe respective link on the Results page: \u201cExcel\u201d or \u201cCSV\u201d\nDownload links may not appear when the search has been broad.\n3.7. Counts, Rates, and Densities\nThe raw data collected during decennial censuses are counts\u2013whole numbers that represent people\nand housing units. The Census Bureau aggregates counts to geographic areas such as counties, tracts,\nblock groups and blocks, and reports the aggregate totals. In other cases summary measures, such\nas averages and medians, are reported. Counts can be used to ensure that redistricting plans comply\nwith the constitutional requirement that each district contain equal population. Districts are drawn\nlarger in sparsely populated areas, and smaller where population is concentrated. Counts, averages,\nand medians cannot be used to determine that districts are drawn so that minority groups have an\nequal probability of representation, however. For this, pairs of counts must be converted\ninto rates or densities. A rate, such as Hispanic population as a percentage of total population, is\nproduced by dividing one count by another. A density, such as persons per square kilometer, is a count\ndivided by the area of the geographic unit to which the count was aggregated. In this chapter we\u2019ll\nconsider how the differences between counts, rates, and densities influence the ways in which the data\nmay be processed in geographic information systems and displayed on thematic maps.\n3.8. Attribute Measurement Scales\nChapter 2 focused upon measurement scales for spatial data, including map scale (expressed as a\nrepresentative fraction), coordinate grids, and map projections (methods for transforming three\ndimensional to two dimensional measurement scales). You may know that the meter, the length standard\nestablished for the international metric system, was originally defined as one-ten-millionth of the\ndistance from the equator to the North Pole. In virtually every country except the United States,\nthe metric system has benefited science and commerce by replacing fractions with decimals, and by\nintroducing an Earth-based standard of measurement.\nStandardized scales are needed to measure non-spatial attributes as well as spatial features. Unlike\npositions and distances, however, attributes of locations on the Earth\u2019s surface are often not amenable\nto absolute measurement. In a 1946 article in Science, a psychologist named S. S. Stevens outlined a\nsystem of four levels of measurement meant to enable social scientists to systematically measure and\nanalyze phenomena that cannot simply be counted. (In 1997, geographer Nicholas Chrisman pointed out\nthat a total of nine levels of measurement are needed to account for the variety of geographic data.) The\nlevels are important to specialists in geographic information because they provide guidance about the 101 David DiBiase\nproper use of different statistical, analytical, and cartographic operations. In the following we consider\nexamples of Stevens\u2019 original four levels of measurement: nominal, ordinal, interval, and ratio.\n3.9. Nominal Level\nData produced by assigning observations into unranked categories are said to be nominal level\nmeasurements. Nominal categories can be differentiated and grouped into categories, but cannot\nlogically be ranked from high to low (unless they are associated with preferences or other exogenous\nvalue systems). For example, one can classify the land cover at a certain location as woods, scrub,\norchard, vineyard, or mangrove. One cannot say, however, that a location classified as \u201cwoods\u201d is twice\nas vegetated as another location classified \u201cscrub.\u201d The phenomenon \u201cvegetation\u201d is a set of categories,\nnot range of numerical values, and the categories are not ranked. That is, \u201cwoods\u201d is in no way greater\nthan \u201cmangrove,\u201d unless the measurement is supplemented by a preference or priority.\nAttribute data measured at the nominal level: Selected vegetation categories depicted on USGS\ntopographic maps. (Steger, 1986).\nAlthough census data originate as counts, much of what is counted is individuals\u2019 membership in\nnominal categories. Race, ethnicity, marital status, mode of transportation to work (car, bus, subway,\nrailroad\u2026), type of heating fuel (gas, fuel oil, coal, electricity\u2026), all are measured as numbers of\nobservations assigned to unranked categories. For example, the map below, which appears in the Census\nBureau\u2019s first atlas of the 2000 census, highlights the minority groups with the largest percentage of\npopulation in each U.S. state. Colors were chosen to differentiate the groups, but not to imply any\nquantitative ordering.\n(Brewer & Suchan, 2001). Nature of Geographic Information 102\n3.10. Ordinal Level\nLike the nominal level of measurement, ordinal scaling assigns observations to discrete categories.\nOrdinal categories are ranked, however. It was stated in the preceding page that nominal categories\nsuch as \u201cwoods\u201d and \u201cmangrove\u201d do not take precedence over one another, unless an extrinsic set of\npriorities is imposed upon them. In fact, the act of prioritizing nominal categories transforms nominal\nlevel measurements to the ordinal level.\nAttribute data measured at the ordinal level: Ranked categories of boundaries depicted on USGS\ntopographic maps.\nExamples of ordinal data often seen on reference maps include political boundaries that are classified\nhierarchically (national, state, county, etc.) and transportation routes (primary highway, secondary\nhighway, light-duty road, unimproved road). Ordinal data measured by the Census Bureau include how\nwell individuals speak English (very well, well, not well, not at all), and level of educational attainment.\nSocial surveys of preferences and perceptions are also usually scaled ordinally.\nIndividual observations measured at the ordinal level typically should not be added, subtracted,\nmultiplied, or divided. For example, suppose two 640-acre grid cells within your county are being\nevaluated as potential sites for a hazardous waste dump. Say the two areas are evaluated on three\nsuitability criteria, each ranked on a 0 to 3 ordinal scale, such that 0 = unsuitable, 1 = marginally\nunsuitable, 2 = marginally suitable, and 3 = suitable. Now say Area A is ranked 0, 3, and 3 on the three\ncriteria, while Area B is ranked 2, 2, and 2. If the Siting Commission was to simply add the three criteria,\nthe two areas would seem equally suitable (0 + 3 + 3 = 6 = 2 + 2 + 2), even though a ranking of 0 on one\ncriteria ought to disqualify Area A.\n3.11. Interval and Ratio Levels\nInterval and ratio are the two highest levels of measurement in Stevens\u2019 original system. Unlike\nnominal- and ordinal-level data, which are qualitative in nature, interval- and ratio-level data are\nquantitative. Examples of interval level data include temperature and year. Examples of ratio level data\ninclude distance and area (e.g., acreage). The scales are similar in so far as units of measurement are\narbitrary (Celsius versus Fahrenheit, Gregorian versus Islamic calendar, English versus metric units).\nThe scales differ in that the zero point is arbitrary on interval scales, but not on ratio scales. For instance,\nzero degrees Fahrenheit and zero degrees Celsius are different temperatures, and neither indicates the\nabsence of temperature. Zero meters and zero feet mean exactly the same thing, however. An implication\nof this difference is that a quantity of 20 measured at the ratio scale is twice the value of 10, a relation\nthat does not hold true for quantities measured at the interval level (20 degrees is not twice as warm as\n10 degrees).\nBecause interval and ratio level data represent positions along continuous number lines, rather\nthan members of discrete categories, they are also amenable to analysis using inferential statistical\ntechniques. Correlation and regression, for example, are commonly used to evaluate relationships\nbetween two or more data variables. Such techniques enable analysts to infer not only the form of a\nrelationship between two quantitative data sets, but also the strength of the relationship. 103 David DiBiase\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 3 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about Recognizing Levels of Measurement. You may\ntake practice quizzes as many times as you wish. They are not scored and do not affect your grade in any\nway.\n3.12. Levels and Operations\nOne reason that it\u2019s important to recognize levels of measurement is that different measurement scales\nare amenable to different analytical operations (Chrisman 2002). Some of the most common operations\ninclude:\n\u2022 Group: Categories of nominal and ordinal data can be grouped into fewer categories. For\ninstance, grouping can be used to reduce the number of land use\/land cover classes from, say,\nfour (residential, commercial, industrial, parks) to one (urban).\n\u2022 Isolate: One or more categories of nominal, ordinal, interval, orratio data can be selected,\nand others set aside. As a hypothetical example, consider a range of georeferenced soil\nmoisture readings taken over a farm field. A subrange of readings that are amenable to a\nparticular fertilizer or pesticide might be isolated so that application is limited to the\nappropriate areas of the field.\n\u2022 Cross tab: Two or more sets of nominal or ordinal categories can be associated one to\nanother in pairs, triplets, etc. Chrisman (2002) points to the multicharacter codes used in the\nNational Wetland Inventory as an example of a cross tab. Each position in the NWI code\nrepresents a particular attribute. Each unique code, therefore, represents a cross tabulation of\nthe possible combinations of attributes.\n\u2022 Difference: The difference of two interval level observations (such as two calendar years)\nresults in one ratio level observation (such as one age).\n\u2022 Other arithmetic operations: Two or more compatible sets of ratioor interval level data\ncan be added, subtracted, multiplied, or divided. For example, the per capita (average)\nincome of a census tract can be calculated by dividing the sum of the income of every\nindividual in a census tract (a ratio level variable), by the sum of persons residing in the tract\n(a second ratio level variable).\n\u2022 Classification: Interval and ratio data are frequently sorted into ordinal level categories for\nthematic mapping.\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 3 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about Levels and Operations. You may take practice\nquizzes as many times as you wish. They are not scored and do not affect your grade in any way. Nature of Geographic Information 104\n3.13. Thematic Mapping\nUnlike reference maps, thematic maps are usually made with a single purpose in mind. Typically, that\npurpose has to do with revealing the spatial distribution of one or two attribute data sets.\nIn this section we will consider distinctions among three types of ratio level data, counts, rates,\nand densities. We will also explore several different types of thematic maps, and consider which type of\nmap is conventionally used to represent the different types of data. We will focus on what is perhaps the\nmost prevalent type of thematic map, thechoropleth map. Choropleth maps tend to display ratio level\ndata which have been transformed into ordinal level classes. Finally, you will learn two common data\nclassification procedures, quantiles and equal intervals.\n3.14. Graphic Variables\nMaps use graphic symbols to represent the locations and attributes of phenomena distributed across the\nEarth\u2019s surface. Variations in symbolsize, color lightness, color hue, and shape can be used to represent\nquantitative and qualitative variations in attribute data. By convention, each of these \u201cgraphic variables\u201d\nis used to represent a particular type of attribute data.\n3.15. Counts, Rates, and Densities\nRatio level data predominate on thematic maps. Ratio data are of several different kinds, including\ncounts, rates, and densities. As stated earlier,counts (such as total population) are whole numbers\nrepresenting discrete entities, like people. Rates and densities are produced from pairs of counts. A rate,\nsuch as percent population change, is produced by dividing one count (for example, population in year\n2) by another (population in year 1). A density, such as persons per square kilometer, is a count divided\nby the area of the geographic unit to which the count was aggregated (e.g., total population divided by\nnumber of square kilometers). It is conventional to use different types of thematic maps to depict each\ntype of ratio-level data.\n3.16. Mapping Counts\nThe simplest thematic mapping technique for count data is to show one symbol for every individual\ncounted. If the location of every individual is known, this method often works fine. If not, the solution\nis not as simple as it seems. Unfortunately, individual locations are often unknown, or they may be\nconfidential. Software like ESRI\u2019s ArcMap, for example, is happy to overlook this shortcoming. Its \u201cDot\nDensity\u201d option causes point symbols to be positioned randomly within the geographic areas in which\nthe counts were conducted. The size of dots, and number of individuals represented by each dot, are also\noptional. Random dot placement may be acceptable if the scale of the map is small, so that the areas in\nwhich the dots are placed are small. Often, however, this is not the case. 105 David DiBiase\nA \u201cdot density\u201d map that depicts count data. Cartography by Geoff Hatchard.\nAn alternative for mapping counts that lack individual locations is to use a single symbol, a circle,\nsquare, or some other shape, to represent the total count for each area. ArcMap calls the result of this\napproach aProportional Symbol map. In the map shown below, the size of each symbol varies in direct\nproportion to the data value it represents. In other words, the area of a symbol used to represent the\nvalue \u201c1,000,000\u2033 is exactly twice as great as a symbol that represents \u201c500,000.\u201d To compensate for the\nfact that map readers typically underestimate symbol size, some cartographers recommend that symbol\nsizes be adjusted. ArcMap calls this option \u201cFlannery Compensation\u201d after James Flannery, a research\ncartographer who conducted psychophysical studies of map symbol perception in the 1950s, 60s, and\n70s. A variant on the Proportional Symbol approach is the Graduated Symbol map type, in which\ndifferent symbol sizes represent categories of data values rather than unique values. In both of these map\ntypes, symbols are usually placed at the mean locations, or centroids, of the areas they represent. Nature of Geographic Information 106\nA \u201cproportional circle\u201d map that depicts count data. Cartography by Geoff Hatchard.\n3.17. Mapping Rates and Densities\nA rate is a proportion between two counts, such as Hispanic population as a percentage of total\npopulation. One way to display the proportional relationship between two counts is with what ArcMap\ncalls its Pie Chartoption. Like the Proportional Symbol map, the Pie Chart map plots a single symbol at\nthe centroid of each geographic area by default, though users can opt to place pie symbols such that they\nwon\u2019t overlap each other (This option can result in symbols being placed far away from the centroid of a\ngeographic area.) Each pie symbol varies in size in proportion to the data value it represents. In addition,\nhowever, the Pie Chart symbol is divided into pieces that represent proportions of a whole. 107 David DiBiase\nA \u201cpie chart \u201d map that depicts rate data. Cartography by Geoff Hatchard.\nSome perceptual experiments have suggested that human beings are more adept at judging the relative\nlengths of bars than they are at estimating the relative sizes of pie pieces (although it helps to have the\nbars aligned along a common horizontal base line). You can judge for yourself by comparing the effect\nof ArcMap\u2019s Bar\/Column Chart option.\nA \u201cbar\/column chart\u201d map that depicts rate data. Cartography by Geoff Hatchard.\nLike rates, densities are produced by dividing one count by another, but the divisor of a density is Nature of Geographic Information 108\nthe magnitude of a geographic area. Both rates and densities hold true for entire areas, but not for any\nparticular point location. For this reason it is conventional not to use point symbols to symbolize\nrate and density data on thematic maps. Instead, cartography textbooks recommend a technique that\nArcMap calls \u201cGraduated Colors.\u201d Maps produced by this method, properly calledchoropleth maps, fill\ngeographic areas with colors that represent attribute data values.\nA \u201cgraduated color\u201d (choropleth) map that depicts density data. Cartography by Geoff Hatchard.\nBecause our ability to discriminate among colors is limited, attribute data values at the ratio or interval\nlevel are usually sorted into four to eight ordinal level categories. ArcMap calls these categories classes.\nUsers can adjust the number of classes, the class break values that separate the classes, and the colors\nused to symbolize the classes. Users may choose a group of predefined colors, known as a color ramp,\nor they may specify their own custom colors. Color ramps are sequences of colors that vary from light to\ndark, where the darkest color is used to represent the highest value range. Most textbook cartographers\nwould approve of this, since they have long argued that it is the lightness and darkness of colors, not\ndifferent color hues, that most logically represent quantitative data.\nLogically or not, people prefer colorful maps. For this reason some might be tempted to choose\nArcMap\u2019s Unique Values option to map rates, densities, or even counts. This option assigns a unique\ncolor to each data value. Colors vary in hue as well as lightness. This symbolization strategy is designed\nfor use with a small number of nominal level data categories. As illustrated in the map below, the use of\nan unlimited set of color hues to symbolize unique data values leads to a confusing thematic map. 109 David DiBiase\nA \u201cunique values\u201d map that depicts density data. Note that the legend, which in the original shows\none category for each state, is trimmed off. Cartography by Geoff Hatchard.\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 3 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about Thematic Map Types. You may take practice\nquizzes as many times as you wish. They are not scored and do not affect your grade in any way.\n3.18. Data Classification\nYou\u2019ve read several times already in this text that geographic data is always generalized. As you recall\nfrom Chapter 1, generalization is inevitable due to the limitations of human visual acuity, the limits of\ndisplay resolution, and especially by limits imposed by the costs of collecting and processing detailed\ndata. What we have not previously considered is that generalization is not only necessary, it is sometimes\nbeneficial.\nGeneralization helps make sense of complex data. Consider a simple example. The graph below\nshows the percent population change for Pennsylvania\u2019s 67 counties over a five-year period. Categories\nalong the x axis of the graph represent each of the 49 unique percentage values (some of the counties\nhad exactly the same rate). Categories along the y axis are the numbers of counties associated with each\nrate. As you can see, it\u2019s difficult to discern a pattern in these data. Nature of Geographic Information 110\nUnclassified population change rates for 67 Pennsylvania counties.\nThe following graph shows exactly the same data set, only grouped into 7 classes. It\u2019s much easier to\ndiscern patterns and outliers in the classified data than in the unclassified data. Notice that the mass of\npopulation change rates are distributed around 0 to 5 percent, and that there are two counties (x and y\ncounties) whose rates are exceptionally high. This information is obscured in the unclassified data.\nClassified population change rates for 67 Pennsylvania counties.\nData classification is a means of generalizing thematic maps. Many different data classification\nschemes exist. If a classification scheme is chosen and applied skillfully, it can help reveal patterns and\nanomalies that otherwise might be obscured. By the same token, a poorly-chosen classification scheme\nmay hide meaningful patterns. The appearance of a thematic map, and sometimes conclusions drawn\nfrom it, may vary substantially depending on data classification scheme used. 111 David DiBiase\n3.19. Two Classification Schemes\nMany different systematic classification schemes have been developed. Some produce \u201coptimal\u201d classes\nfor unique data sets, maximizing the difference between classes and minimizing differences within\nclasses.Since optimizing schemes produce unique solutions, however, they are not the best choice\nwhen several maps need to be compared. For this, data classification schemes that treat every data set\nalike are preferred.\nPortion of the ArcMap classification dialog box highlighting the schemes supported in ArcMap 8.2.\nTwo commonly used schemes are quantiles and equal intervals(\u201cquartiles,\u201d \u201cquintiles,\u201d and\n\u201cpercentiles\u201d are instances of quantile classifications that group data into four, five, and 100 classes\nrespectively) .The following two graphs illustrate the differences.\nCounty population change rates divided into five quantile categories.\nThe graph above groups the Pennsylvania county population change data into five classes, each of\nwhich contains the same number of counties (in this case, approximately 20 percent of the total in each).\nThe quantilesscheme accomplishes this by varying the width, or range, of each class. Nature of Geographic Information 112\nCounty population change rates divided into five equal interval categories.\nIn the second graph, the width or range of each class is equivalent (8.5 percentage points).\nConsequently, the number of counties in each equal interval class varies.\nThe five quantile classes mapped. 113 David DiBiase\nThe five equal interval classes mapped.\nAs you can see, the effect of the two different classification schemes on the appearance of the two\nchoropleth maps above is dramatic. The quantiles scheme is often preferred because it prevents the\nclumping of observations into a few categories shown in the equal intervals map. Conversely, the equal\ninterval map reveals two outlier counties which are obscured in the quantiles map. A good point to take\nfrom this little experiment is that it is often useful to compare the maps produced by several different\nmap classifications. Patterns that persist through changes in classification scheme are likely to be more\nconclusive evidence than patterns that shift.\n3.20. Calculating Quantile Classes\nThe objective of this section is to ensure that you understand how mapping programs like ArcMap\nclassify data for choropleth maps. First we will step through the classification of the Pennsylvania county\npopulation change data. Then you will be asked to classify another data set yourself.\nStep 1: Sort the data.\nAttribute data retrieved from sources like the Census Bureau\u2019s Web site are likely to be sorted\nalphabetically by geographic area. To classify the data set, you need to resort the data from the highest\nattribute data value to the lowest.\nStep 2: Define the number of classes.\nThere are no absolute rules on this. Since our ability to differentiate colors is limited, the more classes\nyou make, the harder they may be to tell apart. In general, four to eight classes are used for choropleth\nmapping. Use an odd number of classes if you wish to visualize departures from a central class that\ncontains a median (or zero) value. Nature of Geographic Information 114\nStep 3: Determine class breaks by dividing the number of observations by the number of classes.\nFor example, 67 counties divided by 5 classes yields 13.4 counties per class. Obviously, in cases like this\nthe number of counties in each class has to vary a little. Make sure that counties having the same value\nare assigned to the same class, even if that class ends up with more members than other classes.\nStep 4: Assign color symbols to differentiate the categories.\nThe illustration below shows three iterations of a data table. The first (on the left) is sorted alphabetically\nby county name. The middle table is sorted by percent population change, in descending order. The third\ntable breaks the re-sorted counties into five quintile categories. Normally you would classify the data\nand symbolize the map using GIS software, of course. The illustration includes the colors that were used\nto symbolize the corresponding choropleth map on the preceding page. If you\u2019d like to try sorting the\ndata table illustrated below, follow this link to open the spreadsheet file.\nData classification for choropleth mapping\nBreaking a data table into five quintile categories for choropleth mapping.\nPractice Quiz\nRegistered Penn State students should return now to the Chapter 3 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about Data Classification for Thematic Mapping. You\nmay take practice quizzes as many times as you wish. They are not scored and do not affect your grade\nin any way.\n3.21. Summary\nNational censuses, such as the decennial census of the U.S., are among the richest sources of attribute\ndata. Attribute data are heterogeneous. They range in character from qualitative to quantitative; from\nunranked categories to values that can be positioned along a continuous number line. Social scientists\nhave developed a variety of different measurement scales to accommodate the variety of phenomena\nmeasured in censuses and other social surveys. The level of measurement used to define a particular data\nset influences analysts\u2019 choices about which analytical and cartographic procedures should be used to\ntransform the data into geographic information.\nThematic maps help transform attribute data by revealing patterns obscured in lists of numbers.\nDifferent types of thematic maps are used to represent different types of data. Count data, for instance,\nare conventionally portrayed with symbols that are distinct from the statistical areas they represent,\nbecause counts are independent of the sizes of those areas. Rates and densities, on the other hand, are\noften portrayed as choropleth maps, in which the statistical areas themselves serve as symbols whose\ncolor lightness vary with the attribute data they represent. Attribute data shown on choropleth maps are\nusually classified. Classification schemes that facilitate comparison of map series, such as the quantiles\nand equal intervals schemes demonstrated in this lesson, are most common.\nThe U.S. Census Bureau\u2019s mandate requires it to produce and maintain spatial data as well as attribute\ndata. In Chapter 4 we will study the characteristics of those data, which are part of a nationwide\ngeospatial database called \u201cTIGER.\u201d 115 David DiBiase\nQUIZ\nRegistered Penn State students should return now to the Chapter 3 folder in ANGEL (via the Resources\nmenu to the left) to access the graded quiz for this chapter. This one counts. You may take graded\nquizzes only once.\nThe purpose of the quiz is to ensure that you have studied the text closely, that you have mastered the\npractice activities, and that you have fulfilled the chapter\u2019s learning objectives. This quiz consists of ten\nproblems. You are free to review the chapter during the quiz.\nOnce you have submitted the quiz and posted any questions you may have to either our discussion\nforums or chapter pages, you will have completed Chapter 3.\nCOMMENTS AND QUESTIONS\nRegistered students are welcome to post comments, questions, and replies to questions about the\ntext. Particularly welcome are anecdotes that relate the chapter text to your personal or professional\nexperience. In addition, there are discussion forums available in the ANGEL course management system\nfor comments and questions about topics that you may not wish to share with the whole world.\nTo post a comment, scroll down to the text box under \u201cPost new comment\u201d and begin typing in the text\nbox, or you can choose to reply to an existing thread. When you are finished typing, click on either the\n\u201cPreview\u201d or \u201cSave\u201d button (Save will actually submit your comment). Once your comment is posted,\nyou will be able to edit or delete it as needed. In addition, you will be able to reply to other posts at any\ntime.\nNote: the first few words of each comment become its \u201ctitle\u201d in the thread.\n3.22. Bibliography\nBrewer, C. & Suchan, T., (2001). Mapping census 2000: The geography of U. S. diversity. U. S. Census\nBureau, Census Special Reports, Series CENSR\/01-1. Washington, D. C.: U.S. Government Printing\nOffice.\nChrisman, N. (1997). Exploring geographic information systems. New York: John Wiley & Sons, Inc.\nChrisman, N. (2002). Exploring geographic information systems. (2nd ed.). New York: John Wiley &\nSons, Inc.\nMicrosoft Corporation. (2006). MapPoint 2006. Retrieved April 27, 2006,\nfrom http:\/\/www.microsoft.com\/mappoint\/default.mspx\nMonmonier, M. (1995). Drawing the line: Tales of maps and cartocontroversy. New York: Henry Holt\nand Company.\nOregon State University. Information Services. (n. d.). Government information sharing project.\nRetrieved July 19, 1999, fromhttp:\/\/govinfo.kerr.orst.edu (since retired).\nPennsylvania State University. University Libraries. Social Science Library. Census Extractor and\nLocator Sites. Retrieved July, 19, 1999, from http:\/\/www.libraries.psu.edu\/crsweb\/docs\/\nextract.htm (since retired).\nRoberts, S. (1994). Who we are: A portrait of America based on the latest U.S. census. New York:\nTimes Books.\nSpeer, G. (1998). The metric system. Retrieved July 19, 1999, fromhttp:\/\/www.essex1.com\/\npeople\/ speer\/metric.html (since retired).\nSteger, T. D. (1986). Topographic maps. Washington D.C.: U.S. Government Printing Office. Nature of Geographic Information 116\nStevens, S.S. (1946). On the theory of scales of measurement. Science, 103, 677-680.1\nU.S. Census Bureau (n. d.). Retrieved July 19, 1999, fromhttp:\/\/www.census.gov\nU.S. Census Bureau (1996). Federal expenditures by state for fiscal year 1995. Retrieved May 9,\n2006, fromwww.census.gov\/prod\/2\/gov\/fes95rv.pdf\nU.S. Census Bureau (2005). American FactFinder Retrieved July, 19, 1999,\nfrom http:\/\/factfinder.census.gov\nU.S. Census Bureau (n. d.). American FactFinder Retrieved August 2, 2012,\nfrom http:\/\/factfinder2.census.gov\/faces\/nav\/jsf\/pages\/using_factfinder5.xhtml\nU.S. Census Bureau (2008). A Compass for understanding and using American Community Survey\ndata: What general users need to know.U.S. Government Printing Office, Washington DC, 2008. Chapter 4\n117 TIGER, Topology and Geocoding\nDavid DiBiase\n4.1. Overview\nIn the Chapter 3 we studied the population data produced by the U.S. Census Bureau, and some of the\nways those data can be visualized with thematic maps.\nIn addition to producing data about the U.S. population and economy, the Census Bureau is a leading\nproducer of digital map data. The Census Bureau\u2019s Geography Division created its \u201cTopologically\nIntegrated Geographic Encoding and Referencing\u201d (TIGER) spatial database with help from the U.S.\nGeological Survey. In preparation for the 2010 census, the Bureau conducted a database redesign project\nthat combined TIGER with a Master Address File (MAF) database. MAF\/TIGER enables the Bureau\nto associate census data, which it collects by household address, with the right census areas and voting\ndistricts. This is an example of a process called address-matching or geocoding.\nThe MAF\/TIGER database embodies the vector approach to spatial representation. It uses point, line,\nand polygon features to represent streets, water bodies, railroads, administrative boundaries, and select\nlandmarks. In addition to the \u201cabsolute\u201d locations of these features, which are encoded with latitude and\nlongitude coordinates, MAF\/TIGER encodes their \u201crelative\u201d locations\u2013a property called topology.\nMAF\/TIGER also includes attributes of these vector features including names, administrative codes,\nand, for many streets, address ranges and ZIP Codes. Vector feature sets are extracted from the MAF\/\nTIGER database to produce reference maps for census takers and thematic maps for census data users.\nSuch extracts are called TIGER\/Line Shapefiles.\nCharacteristics of TIGER\/Line Shapefiles that make them useful to the Census Bureau also make\nthem valuable to other government agencies and businesses. Because they are not protected by\ncopyright, TIGER\/Line data have been widely adapted for many commercial uses. TIGER has been\ndescribed as \u201cthe first truly useful nationwide general-purpose spatial data set\u201d (Cooke 1997, p. 47).\nSome say that it jump-started a now-thriving geospatial data industry in the U.S.\nObjectives\nThe objective of this chapter is to familiarize you with MAF\/TIGER and two important concepts it\nexemplifies: topology and geocoding. Specifically, students who successfully complete Chapter 4 should\nbe able to:\n1. Explain how geographic entities are represented within MAF\/TIGER;\n2. Explain how geometric primitives in MAF\/TIGER are represented in TIGER\/Line Shapefile\nextracts;\n3. Define topology and explain why and how it is encoded in TIGER;\n4. Perform address geocoding; and\n5. Describe how TIGER\/Line files and similar products can be used for other applications,\nincluding routing and allocation.\n118 119 David DiBiase\nComments and Questions\nRegistered students are welcome to post comments, questions, and replies to questions about the\ntext. Particularly welcome are anecdotes that relate the chapter text to your personal or professional\nexperience. In addition, there are discussion forums available in the ANGEL course management system\nfor comments and questions about topics that you may not wish to share with the whole world.\nTo post a comment, scroll down to the text box under \u201cPost new comment\u201d and begin typing in the text\nbox, or you can choose to reply to an existing thread. When you are finished typing, click on either the\n\u201cPreview\u201d or \u201cSave\u201d button (Save will actually submit your comment). Once your comment is posted,\nyou will be able to edit or delete it as needed. In addition, you will be able to reply to other posts at any\ntime.\nNote: the first few words of each comment become its \u201ctitle\u201d in the thread.\nConcept Map\nYou may be interested in seeing the concept map used to guide development of Chapters 3 and 4.\n4.2. Checklist\nThe following checklist is for Penn State students who are registered for classes in which this text,\nand associated quizzes and projects in the ANGEL course management system, have been assigned. You\nmay find it useful to print this page out first so that you can follow along with the directions. Nature of Geographic Information 120\nChapter 4 Checklist (for registered students only)\nStep Activity Access\/Directions\nThis is the second page of the Chapter. Click on the links at the bottom\nof the page to continue or to return to the previous page, or to go to the\n1 Read Chapter 4\ntop of the chapter. You can also navigate the text via the links in the\nGEOG 482 menu on the left.\nSubmit four practice\nquizzesincluding:\n\u2022 MAF and TIGER\n\u2022 Shapefiles\nGo to ANGEL > [your course section] > Lessons tab > Chapter 4 folder\n2 \u2022 Topology\n> [quiz]\n\u2022 Geocoding\nPractice quizzes are not graded\nand may be submitted more\nthan once.\nPerform \u201cTry this\u201d\nactivitiesincluding:\n\u2022 Explore availability\nof TIGER\/Line\nShapefile\ngeographies and\nfeatures\n\u2022 Download and view\na TIGER\/Line\nShapefile\n\u2022 Geocode your\naddress using a\n3 Instructions are provided for each activity.\nTIGER\/Line\nShapefile\n\u2022 Compare the\ngeocoding\nperformance of\nonline routing\nservices\n\u2022 Explore resources\nabout the Traveling\nSalesman Problem\n\u201cTry this\u201d activities are not\ngraded.\nSubmit theChapter 4 Graded ANGEL > [your course section] > Lessons tab > Chapter 4 folder >\n4\nQuiz Chapter 4 Graded Quiz. See the Calendar tab in ANGEL for due dates. 121 David DiBiase\nStep Activity Access\/Directions\nReadcomments and\nquestionsposted by fellow Comments and questions may be posted on any page of the text, or in a\n5\nstudents. Add comments and Chapter-specific discussion forum in ANGEL.\nquestions of your own, if any.\n4.3. MAF\/TIGER\nMAF\/TIGER is the Census Bureau\u2019s geographic database system. Several factors prompted the U.S.\nCensus Bureau to create MAF\/TIGER: the need to conduct the census by mail, the need to produce\nwayfinding aids for census field workers, and its mission to produce map and data products for census\ndata users.\nCONDUCTING THE CENSUS BY MAIL\nAs the population of the U.S. increased it became impractical to have census takers visit every household\nin person. Since 1970, the Census Bureau has mailed questionnaires to most households with\ninstructions that completed forms should be returned by mail. Most but certainly not all of these\nquestionnaires are dutifully mailed\u2014about 72 percent of all questionnaires in 2010. At that rate the\nCensus Bureau estimates that some $1.6 billion was saved by reducing the need for field workers to visit\nnon-responding households. Nature of Geographic Information 122\n2010 Census questionnaire. For a question-by-question tour, go here.\nTo manage its mail delivery and return operations, the Census Bureau relies upon a Master Address\nFile (MAF). MAF is a complete inventory of housing units and many business locations in the U.S.,\nPuerto Rico, and associated island areas. MAF was originally built from the U.S. Postal Service\u2019s\nDelivery Sequence File of all residential addresses. The MAF is updated through both corrections from 123 David DiBiase\nfield operations and a Local Update of Census Address (LUCA) program by which tribal, state, and local\ngovernment liaisons review and suggest updates to local address records. \u201cMAF\/TIGER\u201d refers to the\ncoupling of the Master Address File with the TIGER spatial database, which together enable the\nCensus Bureau to efficiently associate address-referenced census and survey data received by mail with\ngeographic locations on the ground and tabulation areas of concern to Congress and many governmental\nagencies and businesses.\nIt\u2019s not as simple as it sounds. Postal addresses do not specify geographic locations precisely enough\nto fulfill the Census Bureau\u2019s constitutional mandate. An address is not a position in a grid coordinate\nsystem\u2013it is only one in a series of ill-defined positions along a route. The location of an address is often\nambiguous because street names are not unique, numbering schemes are inconsistent, and because routes\nhave two sides, left and right. Location matters, as you recall, because census data must be accurately\ngeoreferenced to be useful for reapportionment, redistricting, and allocation of federal funds. Thus\nthe Census Bureau had to find a way to assign address referenced data automatically to particular census\nblocks, block groups, tracts, voting districts, and so on. That\u2019s what the \u201cGeographic Encoding and\nReferencing\u201d in the TIGER acronym refers to.\nMAPS FOR CENSUS FIELD WORKERS\nA second motivation that led to MAF\/TIGER was the need to help census takers find their way\naround. Millions of households fail to return questionnaires by mail, after all. Census takers (called\n\u201cenumerators\u201d at the Bureau) visit non-responding households in person. Census enumerators need\nmaps showing streets and select landmarks to help locate households. Census supervisors need maps\nto assign census takers to particular territories. Field notes collected by field workers are an important\nsource of updates and corrections to the MAF\/TIGER database.\nPrior to 1990, the Bureau relied on local sources for its maps. For example, 137 maps of different\nscales, quality, and age were used to cover the 30-square-mile St. Louis area during the 1960 census.\nThe need for maps of consistent scale and quality forced the Bureau to become a map maker as well as a\nmap user. Using the MAF\/TIGER system, Census Bureau geographers created over 17 million maps for\na variety of purposes in preparation for the 2010 Census.\nDATA PRODUCTS\nThe Census Bureau\u2019s mission is not only to collect data, but also to make data products available\nto its constituents. In addition to the attribute data considered in Chapter 3, the Bureau disseminates\na variety of geographic data products, including wall maps, atlases, and one of the earliest on-line\nmapping services, the TIGER Mapping Service. You can explore theBureau\u2019s maps and cartographic\ndata products here. Nature of Geographic Information 124\nLaunched in 1995, the TIGER Mapping Service was one of the earliest Internet map services.\nRegistered students will use its successor, American Factfinder, in Project 2.\nMAF\/TIGER DATABASE REDESIGN\nThe Census Bureau conducted a major redesign of the MAF\/TIGER database in the years leading up\nto the 2010 decennial census. What were separate, homegrown database systems (MAF and TIGER)\nare now unified in the industry-standard Oracle relational database management system. Benefits of\nthis \u201ccommercial off-the-shelf\u201d (COTS) database software include concurrent multi-user access, greater\nuser familiarity, and better integration with Web development tools. As Galdi (2005) explains in his\nwhite paper \u201cSpatial Data Storage and Topology in the Redesigned MAF\/TIGER System,\u201d the redesign\n\u201cmirrors a common trend in the Information Technology (IT) and Geographic Information System (GIS)\nindustries: the integration of spatial and non-spatial data into a single enterprise data set\u201d (p. 2).\nConcurrent with the MAF\/TIGER redesign, the Census Bureau also updated the distribution format\nof its TIGER\/Line map data extracts. Consistent with the Bureau\u2019s COTS strategy, it adopted the defacto\nstandard Esri \u201cShapefile\u201d format. The following pages consider characteristics of the spatial data stored\nin MAF\/TIGER and in TIGER\/Line Shapefile extracts.\nPODCAST\nHear more about how the Census Bureau\u2019s Geography Division uses MAF\/TIGER and related tools to\ncreate maps for the 2010 Census.\n4.4. Vector Extracts from MAF\/TIGER\nThe Census Bureau began to develop a digital geographic database of 144 metropolitan areas in the\n1960s. By 1990, the early efforts had evolved into TIGER: a seamless digital geographic database that 125 David DiBiase\ncovered the whole of the United States and its territories. As discussed in the previous page, MAF\/\nTIGER succeeded TIGER in the lead-up to the 2010 Census.\nTIGER\/Line Shapefiles are digital map data products extracted from the MAF\/TIGER database.\nThey are freely available from the Census Bureau, and are suitable for use by individuals, businesses\nand other agencies that don\u2019t have direct access to MAF\/TIGER.\nThis section outlines the geographic entities represented in the MAF\/TIGER database, describes how\na particular implementation of the vector data model is used to represent those entities, and considers the\naccuracy of digital features in relation to their counterparts on the ground. The following page considers\ncharacteristics of the \u201cShapefile\u201d data format used to distribute digital extracts from MAF\/TIGER.\nGEOGRAPHIES REPRESENTED IN TIGER AND SHAPEFILE EXTRACTS\nThe MAF\/TIGER database is selective. Only those geographic entities needed to fulfill the Census\nBureau\u2019s operational mission are included. Entities that don\u2019t help the Census Bureau conduct its\noperations by mail, or help field workers navigate a neighborhood, are omitted. Terrain elevation\ndata, for instance, are not included in MAF\/TIGER. A comprehensive list of the \u201cfeature classes\u201d and\n\u201csuperclasses\u201d included in MAF\/TIGER and Shapefiles can be found in Appendix F of theTIGER\/Line\nShapefiles Technical Documentation. Examples of superclasses include:\n\u2022 Potential living quarters (e.g., sites of shelters, retirement homes, prisons, dormitories)\n\u2022 Road\/path features (e.g., primary roads, secondary roads, local neighborhood roads)\n\u2022 Hydrographic features (e.g., stream\/river, lake\/pond, ocean\/sea)\n\u2022 Miscellaneous linear features (e.g., pipeline, powerline, fence line)\n\u2022 Tabulation areas (e.g., county or equivalent, tract, block group, block Nature of Geographic Information 126\nExcerpt from TIGER\/Line Technical Documentation\nFEATURE FEATURE CLASS\nMTFCC SUPERCLASS POINT LINEAR AREAL\nCLASS DESCRIPTION\nGenerally a paved non-arterial\nstreet, road, or byway that\nusually has a single lane of\nLocal traffic in each direction. Roads in\nNeighborhood this feature class may be\nRoad\/Path\n$1400 Road, Rural N Y N privately or publicly maintained.\nFeatures\nRoad, City Scenic park roads would be\nStreet included in this feature class, as\nwould (depending on the region\nof the country) some unpaved\nroads.\nAn unpaved dirt trail where a\nfour-wheel drive vehicle is\nrequired. These vehicular trails\nVehicular Road\/Path are found almost exclusively in\n$1500 N Y N\nTrail (4WD) Features very rural areas. Minor, unpaved\nroads usable by ordinary cars\nand trucks belong in the $1400\ncategory.\nA road that allows controlled\naccess from adjacent roads onto\nRoad\/Path a limited access highway, often\n$1630 Ramp N Y N\nFeatures in the form of a cloverleaf\ninterchange. These roads are\nunaddressable.\nExcerpt from TIGER\/Line Technical Documentation (Census Bureau 2012) showing some of the feature\nclasses included in the \u201cRoad\/Path Features\u201d superclass.\nNote also that neither the MAF\/TIGER database nor TIGER\/Line Shapefiles include the\npopulation data collected through questionnaires and by census takers. MAF\/TIGER merely\nprovides the geographic framework within which address-referenced census data are tabulated.\nTRY THIS!\nEXPLORING AVAILABLE TIGER\/LINE SHAPEFILES\nIn this Try This (One of 3 dealing with TIGER\/Line Shapefiles) you are going to explore which TIGER\/\nLine Shapefiles are available for download at various geographies and what information those files\ncontain. We will be exploring the 2009 and 2010 versions of the TIGER\/Line Shapefile data sets.\nVersions from other years are available. Feel free to investigate those, too.\n\u2022 Follow this link to get to the TIGER Products page of the Census Bureau web site, then\nfollow the TIGER\/Line Shapefiles link found under Which product should I use? to get to\nthe Geography page.\n\u2022 Link to the 2010 TIGER\/Line Shapefiles via the 2010 tab link. 127 David DiBiase\n\u2022 Select Download, and then from the expanded list choose Web Interface.\n\u2022 Expand the pick list under Select a layer type. Spend some time choosing different entries\nfrom the layer pick list and then using theSubmit button to navigate through the sub layers\ntaking note of when you are offered access to a Download button. Take note of a couple of\nthings. (1) Some of the pick lists make a selection available that allows you to download a\nshapefile dataset for the entire country. (2) For some of the choices you must navigate to the\nCounty level before the Download button is available\nAs stated above we want you to get a sense of the sorts of data that are available for the various\ngeographies \u2014 from the county to the national level. Perusing the various layers as I had you doing\nabove makes it difficult to make an overall assessment of what data there is at a given geographic scale.\nFortunately for our purposes the Census has provided a convenient table to help us in this regard.\n\u2022 You should still be on the 2010 TIGER\/Line Shapefiles | Select a layer type page.\nClick on the Documentation link in the upper right portion of the page. This will take you\nback to the Geography page.\n\u2022 Select the 2010 tab again.\n\u2022 Select File Availability.\nStudy the table that appears.\n\u2022 Note that there are columns titled State- and County-based Files,Nation-based Files,\nand American Indian Area-based Files.\n\u2022 Compare which geographies (the Layer column) are available in theNation-Based\nFiles category to those available in the State-Based Files category.\nWhat files are available for a state that are not available for the whole nation? Can you think\nof reasons why these are not available as a single national file? Post a comment below to\ndiscuss with your fellow students.\n\u2022 Now, compare the State-Based Files category to the County-Based Files category. What files\navailable at the state level are also available at the county-level? Once again, share your\nthoughts with your peers.\nGEOMETRIC PRIMITIVES\nLike other implementations of the vector data model, MAF\/TIGER represents geographic entities using\ngeometric primitives including nodes (point features), edges (linear features), and faces (area features).\nThese are defined and illustrated below.\n\u2022 Nodes (labeled \u201cN\u201d in the illustration below) are \u201c0-dimensional,\u201d consisting only of a single\npair of latitude and longitude coordinates.\n\u25e6 Nodes N21-23 are isolated nodes. That is, they are not end points of edges.\n\u2022 Edges (labeled \u201cE\u201d in the illustration below) are 1-dimensional linear primitives used to\nrepresent streets, railroads, pipelines, and rivers.\n\u25e6 The end points of an edge are called connecting nodes.\n\u25e6 Each edge is assigned a direction, denoted by the arrowheads. The directionality of Nature of Geographic Information 128\nthe edge allows the designation of a Start Node and an End Node. The Start Node\nof edge E12 below is N9, and the End Node is N6.\n\u25e6 An edge may have intermediate points called vertices that define its shape.\n\u2022 Faces (labeled \u201cF\u201d in the illustration below) are the 2-dimensional geometric primitives used\nto represent entities like blocks, counties, and voting districts. A face is a polygon bounded\nby edges.\n\u25e6 The directionality of an edge also allows left and right faces to be designated.\nFace F1 is on the left of edge E12 and face F2 is to the right.\nGeometric primitives of the Topologically Integrated Geographic Encoding and Referencing (TIGER)\ndatabase. The figure shows what might be two adjacent Census blocks, with the bottom block bounded\non the south by a river. The remaining edges might correspond to streets, and the isolated nodes might\nbe landmarks such as a school, a church and a zoo.\nGEOMETRIC ACCURACY\nUntil recently the geometric accuracy of the vector features encoded in TIGER were notoriously poor\n(see illustration below). How poor?Through 2003, the TIGER\/Line metadata stated that\nCoordinates in the TIGER\/Line files have six implied decimal places, but the positional accuracy of these\ncoordinates is not as great as the six decimal places suggest. The positional accuracy varies with the source\nmaterials used, but generally the information is no better than the established National Map Accuracy standards\nfor 1:100,000-scale maps from the U.S. Geological Survey (Census Bureau 2003)\nTRY THIS!\nHaving performed scale calculations in Chapter 2 you should be able to calculate the magnitude of error 129 David DiBiase\n(ground distance) associated with 1:100,000-scale topographic maps. Recall that the allowed error for USGS\ntopographic maps at scales of 1:20,000 or smaller is 1\/50 inch (see the nationalmap standards pdf)\nDiscrepancy between pre-modernization TIGER\/Line file streets (red) and actual geometry of street\nnetwork shown in an orthorectified aerial image (U.S. Census Bureau n.d).\nACCURACY IMPROVEMENT\nStarting in 2002, in preparation for the 2010 census, the Census Bureau commissioned a six-year, $200\nmillion MAF\/TIGER Accuracy Improvement Project (MTAIP). One objective of the effort was to\nuse GPS to capture accurate geographic coordinates for every household in the MAF. Another\nobjective was to improve the accuracy of TIGER\u2019s road\/path features. The project aimed to adjust\nthe geometry of street networks to align within 7.6 meters of street intersections observed in orthoimages\nor measured using GPS. The corrected streets are necessary not just for mapping, but for accurate\ngeocoding. Because streets often form the boundaries of census areas, it is essential that accurate\nhousehold locations are associated with accurate street networks.\nMTAIP integrated over 2,000 source files submitted by state, tribal, county, and local governments.\nContractors used survey-grade GPS to evaluate the accuracy of a random sample of street centerline\nintersections of the integrated source files. The evaluation confirmed that most but not all features in\nthe spatial database equal or exceed the 7.6 meter target. Uniform accuracy wasn\u2019t possible due to\nthe diversity of local source materials used, though this accuracy is the standard in the \u201cAll Lines\u201d\nShapefile extracts. The geometric accuracy of particular feature classes included in particular shapefiles\nare documented in the metadata associated with that shapefile extract.\nMTAIP was completed in 2008. In conjunction with the continuous American Community Survey and\nother census operations, corrections and updates are now ongoing. TIGER\/Line Shapefile updates are\nnow released annually. Nature of Geographic Information 130\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 4 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about MAF and TIGER.\nYou may take practice quizzes as many times as you wish. They are not scored and do not affect your\ngrade in any way.\n4.5. Shapefiles\nSince 2007, TIGER\/Line extracts from the MAF\/TIGER database have been distributed in shapefile\nformat. Esri introduced shapefiles in the early 1990s as the native digital vector data format of its\nArcView software product. The shapefile format is proprietary, but open; its technical specifications are\npublished and can be implemented and used freely. Largely as a result of ArcView\u2019s popularity, shapefile\nhas become a de facto standard for creation and interchange of vector geospatial data. The Census\nBureau\u2019s adoption of Shapefile as a distribution format is therefore consistent with its overall strategy of\nconformance with mainstream information technology practices.\nELEMENTS OF A SHAPEFILE DATA SET\nThe first thing GIS pros need to know about shapefiles is that every shapefile data set includes a\nminimum of three files. One of the three required files stores the geometry of the digital features as sets\nof vector coordinates. A second required file holds an index that, much like the index in a book, allows\nquicker access to the spatial features and therefore speeds processing of a given operation involving a\nsubset of features. The third required file stores attribute data in dBASE\u00a9 format, one of the earliest and\nmost widely-used digital database management system formats. All of the files that make up a Shapefile\ndata set have the same root or prefix name, followed by a three-letter suffix or file extension. The list\nbelow shows the names of the three required files making up a shapefile data set named \u201ccounties.\u201d Take\nnote of the file extensions.\n\u2022 counties.shp: The main shape file, containing vector coordinate data\n\u2022 counties.shx: The index file\n\u2022 counties.dbf: The dBASE table\nEsri lists twelve additional optional files, and practitioners are able to include still others. Two of the\nmost important optional files are the \u201c.prj\u201d file, which includes the coordinate system definition, and\n\u201c.xml\u201d, which stores metadata. (Why do you suppose that something as essential as a coordinate system\ndefinition is considered \u201coptional\u201d?)\nTRY THIS!\nDOWNLOADING AND VIEWING A TIGER\/LINE SHAPEFILE\nIn this Try This! (the second of 3 dealing with TIGER\/Line Shapefiles), you will download a TIGER\/\nLine Shapefile dataset, investigate the file structure of a typical Esri shapefile, and view it in GIS\nsoftware.\nYou can use a free software application called Global Mapper (originally known as dlgv32 Pro) to 131 David DiBiase\ninvestigate TIGER\/Line shapefiles. Originally developed by the staff of the USGS Mapping Division at\nRolla, Missouri as a data viewer for USGS data, Global Mapper has since been commercialized, but is\navailable in a free trial version. The instructions below will guide you through the process of installing\nthe software and opening the TIGER\/Line data.\n1. Downloading TIGER\/Line Shapefiles: You are going to use the 2010 TIGER\/Line\nShapefiles.\n\u25e6 Return to the 2010 TIGER\/Line Shapefiles download page.\n\u25e6 From the Select a layer type pick list, under Features, choose All Lines and\nclick submit. (You are welcome to download and investigate any TIGER\/Line\nShapefile(s), but we will use an All Linesdataset in the geocoding Try This later in\nthe chapter, so your downloading one here will make you more familiar with the\ncontent.)\n\u25e6 From the All Lines pick list select a state or territory and clickSubmit.\n\u25e6 Select a County from the next pick list that appears and clickDownload.\n\u25e6 Save the file to your computer.\nThe file you download should have a name liketl_2010_42027_edges.zip. The root\nname of this file,tl_2010_42027_edges in this example, will also be the name of the\nshapefile dataset. The 42027 is a federal code that represents Pennsylvania (state\n42) and Centre County (county 027). The five-digit code in your file name will\ndepend on which state and county you selected.\n\u25e6 The data are compressed in a .zip archive. Extract the data to a new named folder in\na known location. (Within the file hierarchy that is extracted there may be a second\n.zip file that needs to be uncompressed.)\n2. Investigating the shapefile data set:\n\u25e6 Navigate to within the folder in which you stored your uncompressed TIGER\/Line\nShapefile dataset.\n\u25e6 Notice the multiple files which make up the shapefile dataset, including:\n\u25aa tl_2010_42027_edges.shp, containing the vector coordinate data\n\u25aa tl_2010_42027_edges.shp.xml, containing metadata\n\u25aa tl_2010_42027_edges.shx, the index file\n\u25aa tl_2010_42027_edges.dbf, the dBASE file\n\u25aa tl_2010_42027_edges.prj, containing the projection\/spatial reference\n\u25e6 All of the files work in concert to store the necessary components of the\nEsri shapefile data set. You may be familiar with some of the individual files types.\nThe contents of three of them can be easily viewed. Let\u2019s open those three. You can\ndouble click on the file and then select \u201cfrom a list of installed programs,\u201d or you\nmay need to run the suggested application and open the file from within it. Let me\nknow if you need help, or help each other in the ANGEL Chapter 4 Discussion Nature of Geographic Information 132\nForum or in the Comments area below.\n\u25aa Open the .dbf file using Microsoft Excel.\nNote the typical row-column structure of a flat-file database. Can you\nfind the four columns, or fields, that hold the address range information?\nLook for LFROMADD, etc. The field name LFROMADD is shorthand\nfor Left From Address. The 10-character length of the field name points\nup one of the constraints of the dBASE format\u2013field names are limited to\n10 characters.\n\u25aa Open the .xml file using your web browser.\nYou should see the metadata information bracketed by tagscontained\nwithin directional brackets < >. XML stands for Extensible Markup\nLanguage, and is a common set of rules for encoding documents. Can\nyou locate the portion of the document having to do with horizontal\nspatial accuracy? (Spatial accuracy metadata is available when you\u2019ve\nchosen the All Lines file as your candidate shapefile.)\n\u25aa Open the .prj file using Notepad, or any vanilla text editor.\nThere are five pieces of information in this file, separated by commas.\nWhat are they? They should reinforce some of what you learned in\nChapter 2 regarding what defines a geographic coordinate system.\n\u25aa The .shp and .shx files are proprietary and specific to the functionality of\nthe shapefile data set.\n\u25e6 Discuss what you find with your classmates in comments below.\n\u25e6 Note that one should not alter the contents of any of these files with any application\nother than a GIS program that is designed for that task.\n3. Viewing the shapefile dataset in Global Mapper:\n\u25e6 Download and install the Global Mapper software:\n1. Navigate to the Blue Marble Global Mapper site.\n2. Download the trial version of the software\n3. Double-click on the setup file you downloaded to install the program\n4. Launch the Global Mapper program\n\u25e6 After opening the Global Mapper software, choose Open Data File(s)... under\nthe File menu, or click the \u201cOpen Your Own Data Files\u201d button in the center of the\nwindow. Navigate to the extracted shapefile dataset you downloaded above and\nopen it. (Remember, your complete shapefile data set will have a name similar\ntotl_2010_42027_edges. It will show up in the Open dialog with a .shp extension.)\n\u25e6 You should be able to see all of the line features (the edges, from the MAF\/TIGER\ndatabase) contained in your county. If you are using the newest version of Global\nMapper you should be able to discern roads from rivers\/streams from\nadministrative boundaries, etc. In older versions of the application the default view\nshowed all line features in a single color and line weight, so the user needed to use 133 David DiBiase\nthe symbolization tools to make the different classes of features distinguishable.\nWhat do you think has to be understood by the mapping application to allow it to\nautomatically symbolize features differently? Post your thoughts below.\nSHAPEFILE PRIMITIVES\nA single shapefile data set can contain one of three types of spatial data primitives, or features \u2013 points,\nlines or polygons (areas). The technical specification defines these as follows:\n\u2022 Points: A point consists of a pair of double-precision coordinates in the order X,Y.\n\u2022 Lines: More specifically a polyline, is an ordered set of points, or vertices, that consists of\none or more parts. A part is a connected sequence of two or more points. Parts may or may\nnot be connected to one another. Parts may or may not intersect one another.\n\u2022 Polygons: A polygon consists of one or more rings. A ring is a connected sequence of four\nor more points, or vertices, that form a closed, non-self-intersecting loop.\n\u2022 Other: M (measured; route data) and Z (3D; vertical datum) versions of point, polyline and\npolygon Shapefile data sets can be created, but are not included in the TIGER\/Line Shapefile\nextracts.\nThree Shapefile data sets that could be extracted from the MAF\/TIGER data depicted on the preceding\npage\nAt left in the illustration above, a polygon Shapefile data set holds the Census blocks in which the\nedges from the MAF\/TIGER database have been combined to form two distinct polygons, P1 and P2.\nThe diagram shows the two polygons separated to emphasize the fact that what is the single E12 edge\nin the MAF\/TIGER database (see the diagram on page 4) is now present in each of the Census block\npolygon features.\nIn the middle of the illustration, a polyline Shapefile data set holds seven line features (L1-7) that\ncorrespond to the seven edges in the MAF\/TIGER database. The directionality of the line features that\nrepresent streets corresponds to address range attributes in the associated dBASE\u00a9 table. Vertices define Nature of Geographic Information 134\nthe shape of a polygon or a line, and the Start and End Nodes from the MAF\/TIGER database are now\nFirst and Last Vertices.\nFinally, at right in the illustration above, a point Shapefile data set holds the three isolated nodes\nfrom the MAF\/TIGER database.\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 4 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about Shapefiles.\nYou may take practice quizzes as many times as you wish. They are not scored and do not affect your\ngrade in any way.\n4.6. Topology\nTopology is different than topography. (You\u2019d be surprised how often these terms get mixed up.) In\nChapter 2 you read about the various ways that absolute positions of features can be specified in a\ncoordinate system, and how those coordinates can be projected or otherwise transformed. Topology\nrefers to the relative positions of spatial features. Topological relations among features\u2014such as\ncontainment, connectivity, and adjacency\u2014don\u2019t change when a dataset is transformed. For example,\nif an isolated node (representing a household) is located inside a face (representing a congressional\ndistrict) in the MAF\/TIGER database, you can count on it remaining inside that face no matter how you\nmight project, rubber-sheet, or otherwise transform the data. Topology is vitally important to the Census\nBureau, whose constitutional mandate is to accurately associate population counts and characteristics\nwith political districts and other geographic areas.\nAs David Galdi (2005) explains in his white paper \u201cSpatial Data Storage and Topology in the\nRedesigned MAF\/TIGER System,\u201d the \u201cTI\u201d in TIGER stands for \u201cTopologically Integrated.\u201d This\nmeans that the various features represented in the MAF\/TIGER database\u2014such as streets,\nwaterways, boundaries, and landmarks (but not elevation!)\u2014are not encoded on separate\n\u201clayers.\u201d Instead, features are made up of a small set of geometric primitives\u2014including 0-dimensional\nnodes and vertices, 1-dimensional edges, and 2-dimensional faces\u2014without redundancy. That means\nthat where a waterway coincides with a boundary, for instance, MAF\/TIGER represents them both\nwith one set of edges, nodes and vertices. The attributes associated with the geometric primitives allow\ndatabase operators to retrieve feature sets efficiently with simple spatial queries. The separate feature-\nspecific TIGER\/Line Shapefiles published at the county level (such as point landmarks, hydrography,\nCensus block boundaries, and, the \u201cAll Lines\u201d file you are using in the multi-part \u201cTry This\u201d) were\nextracted from the MAF\/TIGER database in that way. Notice, however, that when you examine a\nhydrography shapefile and a boundary shapefile, you will see redundant line segments where the features\ncoincide. That fact confirms that TIGER\/Line Shapefiles, unlike the MAF\/TIGER database itself, are\nnot topologically integrated. Desktop computers are now powerful enough to calculate topology\n\u201con the fly\u201dfrom shapefiles or other non-topological data sets. However, the large batch processes\nperformed by the Census Bureau still benefit from the MAF\/TIGER database\u2019s persistent topology.\nMAF\/TIGER\u2019s topological data structure also benefits the Census Bureau by allowing it to automate\nerror-checking processes. By definition, features in the TIGER\/Line files conform to a set of topological\nrules (Galdi 2005):\n1. Every edge must be bounded by two nodes (start and end nodes).. 135 David DiBiase\n2. Every edge has a left and right face.\n3. Every face has a closed boundary consisting of an alternating sequence of nodes and edges.\n4. There is an alternating closed sequence of edges and faces around every node.\n5. Edges do not intersect each other, except at nodes.\nCompliance with these topological rules is an aspect of data quality calledlogical consistency. In\naddition, the boundaries of geographic areas that are related hierarchically\u2014such as blocks, block\ngroups, tracts, and counties\u2014are represented with common, non-redundant edges. Features that do\nnot conform to the topological rules can be identified automatically, and corrected by the Census\ngeographers who edit the database. Given that the MAF\/TIGER database covers the entire U.S. and\nits territories, and includes many millions of primitives, the ability to identify errors in the database\nefficiently is crucial.\nSo how does topology help the Census Bureau assure the accuracy of population data needed for\nreapportionment and redistricting? To do so, the Bureau must aggregate counts and characteristics\nto various geographic areas, including blocks, tracts, and voting districts. This involves a process\ncalled \u201caddress matching\u201d or \u201caddress geocoding\u201d in which data collected by household is assigned a\ntopologically-correct geographic location. The following pages explain how that works.\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 4 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about Topology.\nYou may take practice quizzes as many times as you wish. They are not scored and do not affect your\ngrade in any way.\n4.7. Geocoding\nGeocoding is the process used to convert location codes, such as street addresses or postal codes,\ninto geographic (or other) coordinates. The terms \u201caddress geocoding\u201d and \u201caddress mapping\u201d refer\nto the same process. Geocoding address-referenced population data is one of the Census Bureau\u2019s key\nresponsibilities. However, as you know, it\u2019s also a very popular capability of online mapping and routing\nservices. In addition, geocoding is an essential element of a suite of techniques that are becoming known\nas \u201cbusiness intelligence.\u201d We\u2019ll look at applications like these later in this chapter, but first let\u2019s consider\nhow the Census Bureau performs address geocoding.\nADDRESS GEOCODING AT THE U.S. CENSUS\nPrior to the MAF\/TIGER modernization project that led up to the decennial census of 2010, the TIGER\ndatabase did not include a complete set of point locations for U.S. households. Lacking point locations,\nTIGER was designed to support address geocoding by approximation. As illustrated below, the pre-\nmodernization TIGER database includedaddress range attributes for the edges that represent streets.\nAddress range attributes were also included in the TIGER\/Line files extracted from TIGER. Coupled\nwith the Start and End nodes bounding each edge, address ranges enable users to estimate locations of\nhousehold addresses. Nature of Geographic Information 136\nHow address range attributes were encoded in TIGER\/Line files (U.S. Census Bureau 1997). Address\nranges in contemporary TIGER\/Line Shapefiles are similar, except that \u201cFrom\u201d (FR) and \u201cTo\u201d nodes are\nnow called \u201cStart\u201d and \u201cEnd\u201d. Also, changes have been made to field (column) names in the attribute\ntables. Compare the names of the address range fields that you looked at in the second Try This exercise\nto those above.\nHere\u2019s how it works. The diagram above highlights an edge that represents a one-block segment of\nOak Avenue. The edge is bounded by two nodes, labeled \u201cStart\u201d and \u201cEnd.\u201d A corresponding record\nin an attribute table includes the unique ID number (0007654320) that identifies the edge, along with\nstarting and ending addresses for the left (FRADDL, TOADDL) and right (FRADDR, TOADDR) sides\nof Oak Avenue. Note also that the address ranges include potential addresses, not just existing ones. This\nis to make sure that the ranges will remain valid as new buildings are constructed along the street.\nA common geocoding error occurs when Start and End designations are assigned to the wrong\nconnecting nodes. You may have read in Galdi\u2019s (2005) white paper \u201cSpatial Data Storage and\nTopology in the Redesigned MAF\/TIGER System,\u201d that in MAF\/TIGER, \u201can arbitrary direction is\nassigned to each edge, allowing designation of one of the nodes as the Start Node, and the other as the\nEnd Node\u201d (p. 3). If an edge\u2019s \u201cdirection\u201d happens not to correspond with its associated address ranges,\na household location may be placed on the wrong side of a street.\nAlthough many local governments in the U.S. have developed their own GIS \u201cland bases\u201d with greater\ngeometric accuracy than pre-modernization TIGER\/Line files, similar address geocoding errors still\noccur. Kathryn Robertson, a GIS Technician with the City of Independence, Missouri (and a student in\nthe Fall 2000 offering of this course) pointed out how important it is that Start (or \u201cFrom\u201d) nodes and\nEnd (or \u201cTo\u201d) nodes correspond with the low and high addresses in address ranges. \u201cI learned this the\nhard way,\u201d she wrote, \u201cgeocoding all 5,768 segments for the city of Independence and getting some 137 David DiBiase\nsegments backward. When address matching was done, the locations were not correct. Therefore, I had\nto go back and look at the direction of my segments. I had a rule of thumb, all east-west streets were to\nstart from west and go east; all north-south streets were to start from the south and go north\u201d (personal\ncommunication).\nAlthough this may have been a sensible strategy for the City of Independence, can you imagine a\nsituation in which Kathryn\u2019s rule-of-thumb might not work for another municipality? If so, and if you\u2019re\na registered student, please add a comment to this page.\nAFTER MAF\/TIGER MODERNIZATION\nIf TIGER had included accurate coordinate locations for every household, and correspondingly accurate\nstreets and administrative boundaries, geocoding census data would be simple and less error-prone.\nMany local governments digitize locations of individual housing units when they build GIS land bases\nfor property tax assessment, E-911 dispatch and other purposes. The MAF\/TIGER modernization project\nbegun in 2002 aimed to accomplish this for the entire nationwide TIGER database in time for the\n2010 census. The illustration below shows the intended result of the modernization project, including\nproperly aligned streets, shorelines, and individual household locations, shown here in relation to an\northorectified aerial image.\nIntended accuracy and completeness of modernized TIGER data in relation to the real world. TIGER Nature of Geographic Information 138\nstreets (yellow), shorelines (blue), and housing unit locations (red) are superimposed over an\northorectified aerial image. (U.S. Census Bureau n.d.). National coverage of housing unit locations and\ngeometrically-accurate streets and other features were not available in 2000 or before.\nThe modernized MAF\/TIGER database described by Galdi (2005) is now in use, including precise\ngeographic locations of over 100 million household units. However, because household locations are\nconsidered confidential, users of TIGER\/Line Shapefiles extracted from the MAF\/TIGER database still\nmust rely upon address geocoding using address ranges.\nLEVERAGING TIGER\/LINE DATA FOR PRIVATE ENTERPRISE\nLaunched in 1996, MapQuest was one of the earliest online mapping, geocoding and routing services.\nMapQuest combined the capabilities of two companies: a cartographic design firm with long experience\nin producing road atlases, \u201cTripTiks\u201d for the American Automobile Association, and other map products,\nand a start-up company that specialized in custom geocoding applications for business. Initially,\nMapQuest relied in part on TIGER\/Line street data extracted from the pre-modernization TIGER\ndatabase. MapQuest and other commercial firms were able to build their businesses on TIGER data\nbecause of the U.S. government\u2019s wise decision not to restrict its reuse. It\u2019s been said that this decision\ntriggered the rapid growth of the U.S. geospatial industry.\nLater on in this chapter we\u2019ll visit MapQuest and some of its more recent competitors. Next, however,\nyou\u2019ll have a chance to see how geocoding is performed using a TIGER\/Line data in a GIS.\n4.8. Geocoding with TIGER\/Line Shapefiles\nTRY THIS!\nGEOCODING IN A GIS\nPart 3 of 3 in the TIGER\/Line Shapefile Try This! series is not interactive but instead illustrates how the\naddress ranges encoded in TIGER\/Line Shapefiles can be used to pinpoint (more or less!) the geographic\nlocations of street addresses in the U.S.\nThe process of geocoding a location within a GIS begins with a line dataset (shapefile) with the\nnecessary address range attributes. The following image is an example of the attribute table of a TIGER\/\nLine shapefile. 139 David DiBiase\nVisible in this image are just a few rows, which represent a handful of road segments and their\ncorresponding address ranges. This shapefile contains over 29,000 road segments in total. Note the\nnames of some of the attributes:\n\u2022 FULLNAME \u2013 The street name of the road segment\n\u2022 LFROMADD \u2013 The address number at the beginning of the road segment on the left side of\nthe street\n\u2022 LTOADD \u2013 The address number at the end of the road segment on the left side of the street\n\u2022 RFROMADD \u2013 The address number at the beginning of the road segment on the right side of\nthe street\n\u2022 RTOADD \u2013 The address number at the end of the road segment on the right side of the street\n\u2022 ZIPL \u2013 The zip code area that is present to the left side of the road segment\n\u2022 ZIPR \u2013 The zip code area that is present to the right side of the street\nNext, the GIS software needs to know which of these attributes contains each piece of the necessary\naddress range information. Some shapefiles use different names for their attributes, so the GIS can\u2019t\nalways know which attribute contains the Right-Side-From-Address information, for example. In\nArcGIS, for example, something called a Locator is configured that maps the attributes in the shapefile\nto the corresponding piece of necessary address information. The image below illustrates what this\nmapping looks like: Nature of Geographic Information 140 141 David DiBiase\nNote the items with an asterisk (*). These are the minimum required attributes that need to be\npresent in the shapfile for the geocoding to work. The items in the \u201cAlias Name\u201d column correspond to\nattributes in the shapefile.\nWe are now ready to find a location by searching for a street address! Let\u2019s geocode the location for\n\u201c1971 Fairwood Lane, 16803\u2033.\nWhen an address is specified, the GIS queries the attribute table to find rows with a matching street\nname in the correct zipcode. Also, the particular segment of the street that contains the address number\nis identified. The below image shows the corresponding selection in the attribute table:\nThe image below shows the corresponding road segment highlighted on a map. The To and From\naddress values for the road segment have been added so you can see the range of addresses. Nature of Geographic Information 142\nFinally, the GIS interpolates where along the road segment the value of 1971 occurs and places it on\nthe appropriate side of the street based on the even\/odd values indicated in the attribute table. The image\nbelow shows the final result of the geocoding process: 143 David DiBiase\nThe accuracy of a geocoded location is dependent on a number of factors, including the quality of\nthe line work in a shapefile, the accuracy of the address range attributes of each road segment, and the\ninterpolation performed by the software. As you may see in the following section, different geocoding\nservices may provide different location results due to the particular data and procedures used.\n4.9. Geocoding Online\nNo doubt you\u2019re familiar with one or more popular online mapping services. How well do they do at\ngeocoding the location of a postal address? You can try it out for yourself at several Web-based mapping\nservices, including MapQuest.com, Microsoft\u2019s Bing Maps, and Tele Atlas\/TomTom\u2019s Geocode.com.\nTele Atlas, for example, is a leading manufacturer of digital street data for vehicle navigation systems. To\naccommodate the routing tasks that navigation systems are called upon to serve, the streets are encoded\nas vector features whose attributes include address ranges. (In order to submit an address for geocoding\nat Geocode.com you have to set up a trial account through their EZ-Locate Interactive web tool or\ndownload the EZ-Locate software). Nature of Geographic Information 144\nSubmitting an address to Tele Atlas\u2019 Geocode.com service for geocoding. \u00a9 2013 TomTom North\nAmerica, Inc. All rights reserved.\nShown above is the form by which you can geocode an address to a location in a Tele Atlas street\ndatabase. The result is shown below. 145 David DiBiase\nTele Atlas\u2019 Geocode.com service estimates the location of the address relative to the address range\nattributes encoded in its database. \u00a9 2013 TomTom North America, Inc. All rights reserved.\nLet\u2019s compare the geocoding capabilities of MapQuest.com to locate the address on an actual map. Nature of Geographic Information 146\nAddress geocoded by MapQuest.com. \u00a9 2013 MapQuest.com, Inc. All rights reserved.\nThe MapQuest.com map from 2013 estimates the address is close to its actual location. Below is a\nsimilar MapQuest product created back in 1998, when this course was first being developed. On the\nolder map the same address is plotted on the opposite side of the street. What do you suppose is wrong\nwith the address range attribute in that case?\nOn the map from 1998, also note the shapes of the streets. The street shapes in the 2011 map have\nbeen improved. The 1998 product seems to have been generated from the 1990 version of the TIGER\/\nLine files, which may have been all that was available for this relatively remote part of the country. Now\nMapQuest licenses street data from a business partner called NAVTEQ. 147 David DiBiase\nSame address geocoded by MapQuest.com in 1998. \u00a9 1998 MapQuest.com, Inc. (formerly\nGeoSystems Global Corp.) All rights reserved.\nThe point of this section is to show that geocoding with address ranges involves a process of\nestimation. The Census Bureau\u2019s TIGER\/Line Shapefiles, like the commercial street databases produced\nby Tele Atlas, Navigation Technologies, and other private firms, represent streets as vector line\nsegments. The vector segments are associated with address range attributes, one for the left side of the\nstreet, one for the right side. The geocoding process takes a street address as input, finds the line segment\nthat represents the specified street, checks the address ranges to determine the correct side of the street,\nthen estimates a location at the appropriate point between the minimum and maximum address for that\nsegment and assignes an estimated latitude\/longitude coordinate to that location. For example, if the\nminimum address is 401, and the maximum is 421, a geocoding algorithm would locate address 411 at\nthe midpoint of the street segment.\nTRY THIS!\nTry one of these geocoding services for your address. Then compare the experience, and the result,\nwith Google Maps, launched in 2005. Apply what we\u2019ve discussed in this chapter to try to explain\ninaccuracies in your results, if any. Registered students can log in and post comments directly to this\npage.\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 4 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about Geocoding.\nYou may take practice quizzes as many times as you wish. They are not scored and do not affect your\ngrade in any way. Nature of Geographic Information 148\n4.10. Applications beyond the Census Bureau\nTwo characteristics of MAF\/TIGER data, address range attributes and explicit topology, make them, and\nderivative products, valuable in many contexts. Consequently, firms like NAVTEQ and Tele Atlas (now\nowned by TomTom) have emerged to provide data with similar characteristics as MAF\/TIGER, but\nwhich are more up-to-date, more detailed and include additional feature classes. The purpose of the next\nsection is to sketch some of the applications of data similar to MAF\/TIGER data beyond the Census\nBureau.\nTRY THIS!\nA February 2006 article by Peter Valdes-Dapena in CNNMoney.comdescribes the work of two\nNAVTEQ employees. See the link above or search on \u201cwhere those driving directions really come from\u201d\n4.11. Geocoding Your Customers\nGeocoded addresses allow governments and businesses to map where their constituents and customers\nlive and work. Federal, state, and local government agencies know where their constituents live by\nvirtue of censuses, as well as applications for licenses and registrations. Banks, credit card companies,\nand telecommunications firms are also rich in address-referenced customer data, including purchasing\nbehaviors. Private businesses and services must be more resourceful.\nSome retail operations, for example, request addresses or ZIP Codes from customers, or capture\naddress data from checks. Discount and purchasing club cards allow retailers to directly match\npurchasing behaviors with addresses. Customer addresses can also be harvested from automobile license\nplates. Business owners pay to record license plate numbers of cars parked in their parking lots or in their\ncompetitors. Addresses of registered owners can be purchased from organizations that acquire motor\nvehicle records from state departments of transportation.\nBusinesses with access to address-referenced customer data, vector street data attributed with address\nranges, and GIS software and expertise, can define and analyze the trade areas within which most of\ntheir customers live and work. Companies can also focus direct mail advertising campaigns on their\nown trade areas, or their competitors\u2019. Furthermore, GIS can be used to analyze the socio-economic\ncharacteristics of the population within trade areas, enabling businesses to make sure that the products\nand services they offer meet the needs and preferences of target populations.\nPoliticians use the same tools to target appearances and campaign promotions.\nTRY THIS!\nCheck out the geocoding system maintained by the Federal Financial Institution\u2019s Examination Council.\nThe FFIEC Geocoding system lets users enter a street address and get a census demographic report or\na street map (Using Tele Atlas data). The system is intended for use by financial institutions that are\ncovered by the Home Mortgage Disclosure Act (HMDA) and Community Reinvestment Act (CRA) to\nmeet their reporting obligation.\n4.12. Delivering Products and Services\nOperations such as mail and package delivery, food and beverage distribution, and emergency medical 149 David DiBiase\nservices need to know not only where their customers are located, but how to deliver products and\nservices to those locations as efficiently as possible. Geographic data products like TIGER\/Line\nShapefiles are valuable to analysts responsible for prescribing the most efficient delivery routes. The\nlarger and more complex the service areas of such organizations, the more incentive they have to\nautomate their routing procedures.\nIn its simplest form, routing involves finding the shortest path through a network from an origin\nto a destination. Although shortest path algorithms were originally implemented in raster frameworks,\ntransportation networks are now typically represented with vector feature data, like TIGER\/Line\nShapefiles. Street segments are represented as digital line segments each formed by two points, a \u201cstart\u201d\nnode and an \u201cend\u201d node. If the nodes are specified within geographic or plane coordinate systems, the\ndistance between them can be calculated readily. Routing procedures sum the lengths of every plausible\nsequence of line segments that begins and ends at the specified locations. The sequence of segments\nassociated with the smallest sum represents the shortest route.\nTo compare various possible sequences of segments, the data must indicate which line segment\nfollows immediately after another line segment. In other words, the procedure needs to know about the\nconnectivity of features. As discussed earlier, connectivity is an example of a topological relationship.\nIf topology is not encoded in the data product, it can be calculated by the GIS software in which the\nprocedure is coded.\nInput form for an early version of the MapQuest routing utility. \u00a9 1998 MapQuest.com, Inc. All rights\nreserved.\nSeveral online travel planning services, including MapQuest.com and Google Maps, provide routing\ncapabilities. Both take origin and destination addresses as input, and produce optimal routes as output.\nThese services are based on vector feature databases in which street segments are attributed with address\nranges, as well as with other data that describe the type and conditions of the roads they represent. Nature of Geographic Information 150\nAn early interface to MapQuest\u2019s routing options. Different algorithms are required to calculate\nshortest and fastest routes. Specific attributes must be encoded in the database to provide the options\nto avoid limited access highways, toll roads, and ferry lanes. \u00a9 1998 MapQuest.com, Inc. All rights\nreserved.\nThe shortest route is not always the best. In the context of emergency medical services, for example,\nthe fastest route is preferred, even if it entails longer distances than others. To determine fastest routes,\nadditional attribute data must be encoded, such as speed limits, traffic volumes, one way streets, and\nother characteristics.\nMapQuest routing solution. \u00a9 1998 MapQuest.com, Inc. All rights reserved.\nThen there are routing problems that involve multiple destinations\u2013a complex special case of routing\ncalled the traveling salesman problem. School bus dispatchers, mail and package delivery service 151 David DiBiase\nmanagers, and food and beverage distributors all seek to minimize the transportation costs involved in\nservicing multiple, dispersed destinations. As the number of destinations and the costs of travel increase,\nthe high cost of purchasing up-to-date, properly attributed network data becomes easier to justify.\nTRY THIS\nThe Georgia Institute of Technology publishes an extensive collection of resources about the Traveling\nSalesman Problem.\n4.13. Delineating Service Areas\nThe need to redraw voting district boundaries every ten years was one of the motivations that led\nthe Census Bureau to create its MAF\/TIGER database. Like voting districts, many other kinds of\nservice area boundaries need to be revised periodically. School districts are a good example. The\nstate of Massachusetts, for instance, has adopted school districting laws that are similar in effect to\nthe constitutional criteria used to guide congressional redistricting. The Framingham (Massachusetts)\nSchool District\u2019s Racial Balance Policy once stated that \u201ceach elementary and middle school shall enroll\na student body that is racially balanced. \u2026 each student body shall include a percentage of minority\nstudent, which reflects the system-wide percentage of minority students, plus or minus ten percent. \u2026\nThe racial balance required by this policy shall be established by redrawing school enrollment areas\u201d\n(Framingham Public Schools 1998). And bus routes must be redrawn as enrollment area boundaries\nchange.\nThe Charlotte-Mecklenberg (North Carolina) public school district also used racial balance as a\ndistricting criterion (although its policy was subsequently challenged in court). Charlotte-Mecklenberg\nconsists of 133 schools, attended by over 100,000 students, about one third of whom ride a bus to school\nevery day. District managers are responsible for routing 3,600 bus routes, traveling a total of 82,000\ndaily miles. A staff of eight routinely uses GIS to manage these tasks. GIS could not be used unless up-\nto-date, appropriately attributed, and topologically encoded data were available.\nAnother example of service area analysis is provided by the City of Beaverton, Oregon. In 1997,\nBeaverton officials realized that 25 percent of the volume of solid waste that was hauled away to land\nfills consisted of yard waste, such as grass clippings and leaves. Beaverton decided to establish a yard\nwaste recycling program, but it knew that the program would not be successful if residents found it\ninconvenient to participate. A GIS procedure called allocation was used to partition Beaverton\u2019s street\nnetwork into service areas that minimized the drive time from residents\u2019 homes to recycling facilities.\nAllocation procedures require vector-format data that includes the features, attributes, and topology\nnecessary to calculate travel times from all residences to the nearest facility. Nature of Geographic Information 152\nTrade areas defined by 3 miles travel distance (blue) and 8 minutes travel time (yellow). (Francica\nn.d.). Used by permission.\nNaturally, private businesses concerned with delivering products and services are keenly interested\nin service area delineation. The screen capture above shows two trade areas surrounding a retail store\nlocation (\u201cSeattle Downtown\u201d) in a network database.\nFormer student Saskia Cohick (Winter 2006), who was then GIS Director for Tioga County,\nPennsylvania, contributed another service area problem: \u201cThis is a topic that local governments are\nstarting to deal with \u2026 To become Phase 2 wireless capable (that is, capable of finding a cell phone\nlocation from a 911 call center within 200 feet of the actual location), county call centers must have\na layer called ESZs (Emergency Service Zones). This layer will tell the dispatcher who to send to\nthe emergency (police, fire, medical, etc). The larger problem is to reach agreement between four fire\ncompanies (for example) as to where they do or do not respond.\u201d\n4.14. Summary\nTo fulfill its mission of being the preeminent producer of attribute data about the population and\neconomy of the United States, the U.S. Census Bureau also became an innovative producer of digital\ngeographic data. The Bureau designed its MAF\/TIGER database to support automatic geocoding of\naddress-referenced census data, as well as automatic data quality control procedures. The key\ncharacteristics of TIGER\/Line Shapefiles, including use of vector features to represent geographic\nentities, and address range attributes to enable address geocoding, are now common features of\nproprietary geographic databases used for trade area analysis, districting, routing, and allocation.\nQUIZ\nRegistered Penn State students should return now to the Chapter 4 folder in ANGEL (via the Resources 153 David DiBiase\nmenu to the left) to access the graded quiz for this chapter. This one counts. You may take graded\nquizzes only once.\nThe purpose of the quiz is to ensure that you have studied the text closely, that you have mastered the\npractice activities, and that you have fulfilled the chapter\u2019s learning objectives. You are free to review\nthe chapter during the quiz. Once you\u2019ve submitted the quiz you will have completed Chapter 4.\nCOMMENTS AND QUESTIONS\nRegistered students are welcome to post comments, questions, and replies to questions about the\ntext. Particularly welcome are anecdotes that relate the chapter text to your personal or professional\nexperience. In addition, there are discussion forums available in the ANGEL course management system\nfor comments and questions about topics that you may not wish to share with the whole world.\nTo post a comment, scroll down to the text box under \u201cPost new comment\u201d and begin typing in the text\nbox, or you can choose to reply to an existing thread. When you are finished typing, click on either the\n\u201cPreview\u201d or \u201cSave\u201d button (Save will actually submit your comment). Once your comment is posted,\nyou will be able to edit or delete it as needed. In addition, you will be able to reply to other posts at any\ntime.\nNote: the first few words of each comment become its \u201ctitle\u201d in the thread.\n4.15. Bibliography\nCharlotte-Mecklenberg Public Schools (n. d.). Retrieved July 19, 1999 from http:\/\/www.cms.k12.nc.us\nCooke, D. F. (1997). Topology and TIGER: The Census Bureau\u2019s Contribution. In T. W. Foresman\n(Ed.), The history of geographic information systems: Perspectives from the pioneers. (pp. 47 \u2013 57).\nUpper Saddle River, NJ: Prentice Hall.\nDangermond, J. (1982). A Classification of Software Components Commonly Used in Geographic\nInformation Systems. In Proceedings of the U.S.\u2014Australia Workshop on the Design and\nImplementation of Computer-Based Geographic Information Systems, Honolulu, HI, pp. 0-91. In\nDemers, M.N. (1997) Fundamentals of Geographic Information Systems. John Wiley & Sons, Inc.\nDiscreet Research (n.d.). Retrieved July 19, 1999 fromhttp:\/\/www.dresearch.com\nESRI (1998) Shapefile Technical Description, An ESRI White paper. Environmental Systems\nResearch Institute, Inc. Retrieved October 4, 2010, from http:\/\/www.esri.com\/library\/whitepapers\/pdfs\/\nshapefile.pdf\nFederal Geographic Data Committee (April 2006). Retrieved July 19, 1999 from http:\/\/www.fgdc.gov\nFramingham Public Schools (1998). Racial balance policy: Assignment of students to schools.\nRetrieved July 19, 1999 fromwww.framingham.k12.ma.us\/update\/0198rbp.html (since retired).\nFrancica, J. (n.d.). Geodezix Consulting. Retrieved July 19, 1999 fromwww.geodezix.com (since\nretired).\nGaldi, D. (2005). Spatial Data Storage and Topology in the Redesigned MAF\/TIGER System.\nRetrieved 19 October 2010 fromhttp:\/\/www.census.gov\/geo\/mtep_obj2\/topo_and_data_stor.html (since\nretired).\nMapQuest (n.d. a). Retrieved July 19, 1998 fromhttp:\/\/www.mapquest.com\nMapQuest (n.d. b). Retrieved January 15, 2013 fromhttp:\/\/www.mapquest.com\nMarx, R. M. (Ed.). (1990). The Census Bureau\u2019s TIGER system. [Special issue]. Cartography and\nGeographic Information Systems 17:1. Nature of Geographic Information 154\nNavigation Technologies Inc. (2006). Welcome to NavTech. Retrieved July 19, 1999\nfrom http:\/\/www.navtech.com\nRammage, S. and P. Woodsford (2002). The Benefits of Topoplogy in the Database. Retrieved\nOctober 6, 2010 fromhttp:\/\/spatialnews.geocomm.com\/features\/laserscan2\/\nTeleAtlas (2006). Welcome to TeleAtlas. Retrieved May 3, 2006 fromhttp:\/\/www.teleatlas.com\/Pub\/\nHome (since retired).\nTheobald, D. M. (2001). Understanding Topology and Shapefiles.ArcUser April-June 2001. Retrieved\nOctober 5, 2010 fromhttp:\/\/www.esri.com\/news\/arcuser\/0401\/topo.html\nU.S. Census Bureau (1997). TIGER\/Line Files (1997 Technical Documentation). Retrieved January 2,\n1999 fromhttp:\/\/www.census.gov\/geo\/tiger\/TIGER97C.pdf (since retired).\nU.S. Census Bureau (2003). TIGER\/Line Files, 2003 (metadata). Retrieved February 3, 2008\nfromhttp:\/\/www.census.gov\/geo\/www\/tlmetadata\/tl2003meta.txt\nU.S. Census Bureau (n. d.). 21st Century MAF\/TIGER Enhancements. Retrieved February 3, 2008\nfromhttp:\/\/www.census.gov\/geo\/mod\/overview.pdf (since retired).\nU.S. Census Bureau (2004). MAF\/TIGER Redesign Project Overview. Retrieved October 19, 2010\nfromhttp:\/\/www.census.gov\/geo\/mtep_obj2\/obj2_issuepaper12_2004.pdf(since retired).\nU.S. Census Bureau (2005). Geography division map gallery. Retrieved July 19, 1999\nfrom http:\/\/www.census.gov\/geo\/www\/mapGallery\/\nU.S. Census Bureau (2012). TIGER\/Line Shapefiles Technical Documentation. Retrieved June, 2013\nfrom of thehttp:\/\/www.census.gov\/geo\/maps-data\/data\/pdfs\/tiger\/tgrshp2012\/\nTGRSHP2012_TechDoc.pdf Chapter 5\n155 Land Surveying and GPS\nDavid DiBiase\n5.1. Overview\nAs you recall from Chapter 1, geographic data represent spatial locations and non-spatial attributes\nmeasured at certain times. We defined \u201cfeature\u201d as a set of positions that specifies the location and extent\nof an entity. Positions, then, are a fundamental element of geographic data. Like the letters that make up\nthese words, positions are the building blocks from which features are constructed. A property boundary,\nfor example, is made up of a set of positions connected by line segments.\nIn theory, a single position is a \u201c0-dimensional\u201d feature: an infinitesimally small point from which\n1-dimensional, 2-dimensional, and 3-dimensional features (lines, areas, and volumes) are formed. In\npractice, positions occupy 2- or 3-dimensional areas as a result of the limited resolution of measurement\ntechnologies and the limited precision of location coordinates. Resolution and precision are two aspects\nof data quality. This chapter explores the technologies and procedures used to produce positional data,\nand the factors that determine its quality.\nObjectives\nStudents who successfully complete Chapter 5 should be able to:\n1. Identify and define the key aspects of data quality, including resolution, precision, and\naccuracy;\n2. List and explain the procedures land surveyors use to produce positional data, including\ntraversing, triangulation, and trilateration;\n3. Calculate plane coordinates by open traverse;\n4. Calculate elevations by leveling;\n5. Explain how radio signals broadcast by Global Positioning System satellites are used to\ncalculate positions on the surface of the Earth;\n6. State the kinds and magnitude of error associated with uncorrected GPS positioning; and\n7. Identify and explain methods used to improve the accuracy of GPS positioning.\nComments and Questions\nRegistered students are welcome to post comments, questions, and replies to questions about the\ntext. Particularly welcome are anecdotes that relate the chapter text to your personal or professional\nexperience. In addition, there are discussion forums available in the ANGEL course management system\nfor comments and questions about topics that you may not wish to share with the whole world.\nTo post a comment, scroll down to the text box under \u201cPost new comment\u201d and begin typing in the text\n156 157 David DiBiase\nbox, or you can choose to reply to an existing thread. When you are finished typing, click on either the\n\u201cPreview\u201d or \u201cSave\u201d button (Save will actually submit your comment). Once your comment is posted,\nyou will be able to edit or delete it as needed. In addition, you will be able to reply to other posts at any\ntime.\nNote: the first few words of each comment become its \u201ctitle\u201d in the thread.\n5.2. Checklist\nThe following checklist is for Penn State students who are registered for classes in which this text,\nand associated quizzes and projects in the ANGEL course management system, have been assigned. You\nmay find it useful to print this page out first so that you can follow along with the directions. Nature of Geographic Information 158\nChapter 5 Checklist (for registered students only)\nStep Activity Access\/Directions\nThis is the second page of the Chapter. Click on the links at the bottom\nof the page to continue or to return to the previous page, or to go to the\n1 Read Chapter 5\ntop of the chapter. You can also navigate the text via the links in the\nGEOG 482 menu on the left.\nSubmit five practice\nquizzesincluding:\n\u2022 Horizontal Positions\n\u2022 Vertical Positions\n\u2022 GPS Components Go to ANGEL > [your course section] > Lessons tab > Chapter 5 folder\n2\n> [quiz]\n\u2022 GPS Error Sources\n\u2022 GPS Error Correction\nPractice quizzes are not graded\nand may be submitted more\nthan once.\nPerform \u201cTry this\u201d\nactivitiesincluding:\n\u2022 Use trilateration to\ndetermine the\nposition of a point in\na control network\n\u2022 Investigate the status\nof the GPS satellite\nconstellation\n\u2022 Visualize the\npositions and orbits\nof GPS satellites\n3 Instructions are provided for each activity.\n\u2022 Take the Trimble\nGPS Tutorial\n\u2022 Download and\nexplore the Trimble\nGPS Planning\nsoftware\n\u2022 Perform differential\ncorrection of GPS\ncoordinates\n\u201cTry this\u201d activities are not\ngraded.\nSubmit theChapter 5 Graded ANGEL > [your course section] > Lessons tab > Chapter 5 folder >\n4\nQuiz Chapter 5 Graded Quiz. See the Calendar tab in ANGEL for due dates. 159 David DiBiase\nStep Activity Access\/Directions\nRead comments and\nquestionsposted by fellow Comments and questions may be posted on any page of the text, or in a\n5\nstudents. Add comments and Chapter-specific discussion forum in ANGEL.\nquestions of your own, if any.\n5.3. Geospatial Data Quality\nQuality is a characteristic of comparable things that allows us to decide that one thing is better than\nanother. In the context of geographic data, the ultimate standard of quality is the degree to which a data\nset is fit for use in a particular application. That standard is called validity. The standard varies from one\napplication to another. In general, however, the key criteria are how much error is present in a data set,\nand how much error is acceptable.\nSome degree of error is always present in all three components of geographic data: features, attributes,\nand time. Perfect data would fully describe the location, extent, and characteristics of phenomena exactly\nas they occur at every moment. Like the proverbial 1:1 scale map, however, perfect data would be too\nlarge, and too detailed to be of any practical use. Not to mention impossibly expensive to create in the\nfirst place!\n5.4. Error and Uncertainty\nPositions are the products of measurements. All measurements contain some degree of error. Errors are\nintroduced in the original act of measuring locations on the Earth surface. Errors are also introduced\nwhen second- and third-generation data is produced, say, by scanning or digitizing a paper map.\nIn general, there are three sources of error in measurement: human beings, the environment in which\nthey work, and the measurement instruments they use.\nHuman errors include mistakes, such as reading an instrument incorrectly, and judgments. Judgment\nbecomes a factor when the phenomenon that is being measured is not directly observable (like an\naquifer), or has ambiguous boundaries (like a soil unit).\nEnvironmental characteristics, such as variations in temperature, gravity, and magnetic declination,\nalso result in measurement errors.\nInstrument errors follow from the fact that space is continuous. There is no limit to how precisely a\nposition can be specified. Measurements, however, can be only so precise. No matter what instrument,\nthere is always a limit to how small a difference is detectable. That limit is calledresolution.\nThe diagram below shows the same position (the point in the center of the bullseye) measured by two\ninstruments. The two grid patterns represent the smallest objects that can be detected by the instruments.\nThe pattern at left represents a higher-resolution instrument. Nature of Geographic Information 160\nResolution.\nThe resolution of an instrument affects the precision of measurements taken with it. In the illustration\nbelow, the measurement at left, which was taken with the higher-resolution instrument, is more precise\nthan the measurement at right. In digital form, the more precise measurement would be represented with\nadditional decimal places. For example, a position specified with the UTM coordinates 500,000. meters\nEast and 5,000,000. meters North is actually an area 1 meter square. A more precise specification would\nbe 500,000.001 meters East and 5,000,000.001 meters North, which locates the position within an area\n1 millimeter square. You can think of the area as a zone of uncertainty within which, somewhere, the\ntheoretically infinitesimal point location exists.Uncertainty is inherent in geospatial data.\nThe precision of a single measurement.\nPrecision takes on a slightly different meaning when it is used to refer to a number of repeated\nmeasurements. In the illustration below, there is less variance among the nine measurements at left than\nthere is among the nine measurements at right. The set of measurements at left is said to be more precise. 161 David DiBiase\nThe precision of multiple measurements.\nHopefully you have noticed that resolution and precision are independent from accuracy. As shown\nbelow, accuracy simply means how closely a measurement corresponds to an actual value.\nAccuracy.\nI mentioned the U.S. Geological Survey\u2019s National Map Accuracy Standard in Chapter 2. In regard\nto topographic maps, the Standard warrants that 90 percent of well-defined points tested will be within\na certain tolerance of their actual positions. Another way to specify the accuracy of an entire spatial\ndatabase is to calculate the average difference between many measured positions and actual positions.\nThe statistic is called the root mean square error (RMSE) of a data set.\n5.5. Systematic vs. Random Errors\nThe diagram below illustrates the distinction between systematic andrandom errors. Systematic errors\ntend to be consistent in magnitude and\/or direction. If the magnitude and direction of the error is known,\naccuracy can be improved by additive or proportional corrections.Additive correction involves adding\nor subtracting a constant adjustment factor to each measurement; proportional correction involves\nmultiplying the measurement(s) by a constant. Nature of Geographic Information 162\nUnlike systematic errors, random errors vary in magnitude and direction. It is possible to calculate the\naverage of a set of measured positions, however, and that average is likely to be more accurate than most\nof the measurements.\nSystematic and random errors.\nIn the sections that follow we compare the accuracy and sources of error of two important positioning\ntechnologies: land surveying and the Global Positioning System.\n5.6. Survey Control\nGeographic positions are specified relative to a fixed reference. Positions on the globe, for instance, may\nbe specified in terms of angles relative to the center of the Earth, the equator, and the prime meridian.\nPositions in plane coordinate grids are specified as distances from the origin of the coordinate system.\nElevations are expressed as distances above or below a vertical datum such as mean sea level, or an\nellipsoid such as GRS 80 or WGS 84, or a geoid.\nLand surveyors measure horizontal positions in geographic or plane coordinate systems relative\nto previously surveyed positions called control points. In the U.S., the National Geodetic Survey\n(NGS) maintains aNational Spatial Reference System (NSRS) that consists of approximately 300,000\nhorizontal and 600,000 vertical control stations (Doyle,1994). Coordinates associated with horizontal\ncontrol points are referenced to NAD 83; elevations are relative to NAVD 88. In a Chapter 2 activity you\nmay have retrieved one of the datasheets that NGS maintains for every NSRS control point, along with\nmore than a million other points submitted by professional surveyors. 163 David DiBiase\nBenchmark used to mark a vertical control point. (Thompson, 1988).\nIn 1988 NGS established four orders of control point accuracy, which are outlined in the table\nbelow. The minimum accuracy for each order is expressed in relation to the horizontal distance\nseparating two control points of the same order. For example, if you start at a control point of order AA\nand measure a 500 km distance, the length of the line should be accurate to within 3 mm base error, plus\nor minus 5 mm line length error (500,000,000 mm \u00d7 0.01 parts per million).\nFour orders of control point accuracy\nMaximum base Maximum Line-length\nOrder Survey activities error(95% dependent error(95%\nconfidence limit) confidence limit)\nGlobal-regional dynamics; deformation\nAA 3 mm 1:100,000,000 (0.01 ppm)\nmeasurements\n1:10,000,000\nA NSRS primary networks 5 mm\n(0.1 ppm)\nNSRS secondary networks; high-precision 1:1,000,000\nB 8 mm\nengineering surveys (1 ppm)\n1st: 1.0 cm 1st: 1:100,000\nNSRS terrestrial; dependent control surveys for\n2nd-I: 2.0 cm 2nd-I: 1:50,000\nC mapping, land information, property, and\n2nd-II: 3.0 cm 2nd-II: 1:20,000\nengineering requirements\n3rd: 5.0 cm 3rd: 1:10,000\nControl network accuracy standards used for U.S. National Spatial Reference System (Federal Geodetic\nControl Committee, 1988).\nDoyle (1994) points out that horizontal and vertical reference systems coincide by less than ten\npercent. This is because\n\u2026.horizontal stations were often located on high mountains or hilltops to decrease the need to construct\nobservation towers usually required to provide line-of-sight for triangulation, traverse and trilateration\nmeasurements. Vertical control points however, were established by the technique of spirit leveling which is Nature of Geographic Information 164\nmore suited to being conducted along gradual slopes such as roads and railways that seldom scale mountain\ntops. (Doyle, 2002, p. 1)\nYou might wonder how a control network gets started. If positions are measured relative to other\npositions, what is the first position measured relative to? The answer is: the stars. Before reliable\ntimepieces were available, astronomers were able to determine longitude only by careful observation\nof recurring celestial events, such as eclipses of the moons of Jupiter. Nowadays geodesists produce\nextremely precise positional data by analyzing radio waves emitted by distant stars. Once a control\nnetwork is established, however, surveyors produce positions using instruments that measure angles\nand distances between locations on the Earth\u2019s surface.\n6.7. Measuring Angles\nAngles can be measured with a magnetic compass, of course. Unfortunately, the Earth\u2019s magnetic field\ndoes not yield the most reliable measurements. The magnetic poles are not aligned with the planet\u2019s axis\nof rotation (an effect called magnetic declination), and they tend to change location over time. Local\nmagnetic anomalies caused by magnetized rocks in the Earth\u2019s crust and other geomagnetic fields make\nmatters worse.\nFor these reasons land surveyors rely on transits (or their more modern equivalents,\ncalled theodolites) to measure angles. A transit consists of a telescope for siting distant target objects,\ntwo measurement wheels that work like protractors for reading horizontal and vertical angles, and bubble\nlevels to ensure that the angles are true. A theodolite is essentially the same instrument, except that some\nmechanical parts are replaced with electronics.\nTransit. (Raisz, 1948). Used by permission.\nSurveyors express angles in several ways. When specifying directions, as is done in the preparation 165 David DiBiase\nof a property survey, angles may be specified as bearings or azimuths. A bearing is an angle less than\n90\u00b0 within a quadrant defined by the cardinal directions. An azimuth is an angle between 0\u00b0 and 360\u00b0\nmeasured clockwise from North. \u201cSouth 45\u00b0 East\u201d and \u201c135\u00b0\u201d are the same direction expressed as a\nbearing and as an azimuth. An interior angle, by contrast, is an angle measured between two lines of\nsight, or between two legs of a traverse (described later in this chapter).\nAzimuths and bearings.\nIn the U.S., professional organizations like the American Congress on Surveying and Mapping,\nthe American Land Title Association, the National Society of Professional Surveyors, and others,\nrecommend minimum accuracy standards for angle and distance measurements. For example, as Steve\nHenderson (personal communication, Fall 2000, updated July 2010) points out, the Alabama Society of\nProfessional Land Surveyors recommends that errors in angle measurements in \u201ccommercial\/high risk\u201d\nsurveys be no greater than 15 seconds times the square root of the number of angles measured.\nTo achieve this level of accuracy, surveyors must overcome errors caused by faulty instrument\ncalibration; wind, temperature, and soft ground; and human errors, including misplacing the instrument\nand misreading the measurement wheels. In practice, surveyors produce accurate data by taking repeated\nmeasurements and averaging the results.\n8. Measuring Distances\nTo measure distances, land surveyors once used 100-foot long metal tapes that are graduated in\nhundredths of a foot. (This is the technique I learned as a student in a surveying class at the University\nof Wisconsin in the early 1980s. The picture shown below is slightly earlier.) Distances along slopes\nare measured in short horizontal segments. Skilled surveyors can achieve accuracies of up to one part\nin 10,000 (1 centimeter error for every 100 meters distance). Sources of error include flaws in the tape\nitself, such as kinks; variations in tape length due to extremes in temperature; and human errors such as\ninconsistent pull, allowing the tape to stray from the horizontal plane, and incorrect readings. Nature of Geographic Information 166\nSurveying team measuring a baseline distance with a metal (Invar) tape. (Hodgson, 1916).\nSince the 1980s, electronic distance measurement (EDM) devices have allowed surveyors to\nmeasure distances more accurately and more efficiently than they can with tapes. To measure the\nhorizontal distance between two points, one surveyor uses an EDM instrument to shoot an energy wave\ntoward a reflector held by the second surveyor. The EDM records the elapsed time between the wave\u2019s\nemission and its return from the reflector. It then calculates distance as a function of the elapsed time.\nTypical short-range EDMs can be used to measure distances as great as 5 kilometers at accuracies up to\none part in 20,000, twice as accurate as taping. 167 David DiBiase\nTotal station.\nInstruments called total stations combine electronic distance measurement and the angle measuring\ncapabilities of theodolites in one unit. Next we consider how these instruments are used to measure\nhorizontal positions in relation to established control networks.\n5.9. Horizontal Positions\nSurveyors have developed distinct methods, based on separate control networks, for measuring\nhorizontal and vertical positions. In this context, a horizontal position is the location of a point relative\nto two axes: the equator and the prime meridian on the globe, or x and y axes in a plane coordinate\nsystem. Control points tie coordinate systems to actual locations on the ground; they are the physical\nmanifestations of horizontal datums. In the following pages we review two techniques that surveyors\nuse to create and extend control networks (triangulation and trilateration) and two other techniques\nused to measure positions relative to control points (open and closed traverses).\n5.10. Traverse\nSurveyors typically measure positions in series. Starting at control points, they measure angles and\ndistances to new locations, and use trigonometry to calculate positions in a plane coordinate system. Nature of Geographic Information 168\nMeasuring a series of positions in this way is known as \u201crunning a traverse.\u201d A traverse that begins and\nends at different locations is called an open traverse.\nAn open traverse. (Adapted from Robinson, et al., 1995)\nFor example, say the UTM coordinates of point A in the illustration above are 500,000.00 E and\n5,000,000.00 N. The distance between points A and P, measured with a steel tape or an EDM, is 2,828.40\nmeters. The azimuth of the line AP, measured with a transit or theodolite, is 45\u00ba. Using these two\nmeasurements, the UTM coordinates of point P can be calculated as follows:\nXP = 500,000.00 + (2,828.40 \u00d7 sin 45) = 501,999.98\nYP = 5,000,000.00 + (2,828.40 \u00d7 cos 45\u00b0) = 5,001,999.98\nA traverse that begins and ends at the same point, or at two different but known points, is called\na closed traverse. Measurement errors in a closed traverse can be quantified by summing the interior\nangles of the polygon formed by the traverse. The accuracy of a single angle measurement cannot be\nknown, but since the sum of the interior angles of a polygon is always (n-2) \u00d7 180, it\u2019s possible to\nevaluate the traverse as a whole, and to distribute the accumulated errors among all the interior angles.\nErrors produced in an open traverse, one that does not end where it started, cannot be assessed\nor corrected. The only way to assess the accuracy of an open traverse is to measure distances and\nangles repeatedly, forward and backward, and to average the results of calculations. Because repeated\nmeasurements are costly, other surveying techniques that enable surveyors to calculate and account for\nmeasurement error are preferred over open traverses for most applications.\n5.11. Triangulation\nClosed traverses yield adequate accuracy for property boundary surveys, provided that an established\ncontrol point is nearby. Surveyors conductcontrol surveys to extend and densify horizontal control\nnetworks. Before survey-grade satellite positioning was available, the most common technique for\nconducting control surveys was triangulation. 169 David DiBiase\nThe purpose of a control survey is to establish new horizontal control points (B, C, and D) based upon\nan existing control point (A).\nUsing a total station equipped with an electronic distance measurement device, the control survey\nteam commences by measuring the azimuthalpha, and the baseline distance AB. These two\nmeasurements enable the survey team to calculate position B as in an open traverse. Before geodetic-\ngrade GPS became available, the accuracy of the calculated position B may have been evaluated by\nastronomical observation. Nature of Geographic Information 170\nEstablishing a second control point (B) in a triangulation network.\nThe surveyors next measure the interior angles CAB, ABC, and BCA at point A, B, and C. Knowing\nthe interior angles and the baseline length, the trigonometric \u201claw of sines\u201d can then be used to calculate\nthe lengths of any other side. Knowing these dimensions, surveyors can fix the position of point C.\nEstablishing the position of point C by triangulation. 171 David DiBiase\nHaving measured three interior angles and the length of one side of triangle ABC, the control survey\nteam can calculate the length of side BC. This calculated length then serves as a baseline for triangle\nBDC. Triangulation is thus used to extend control networks, point by point and triangle by triangle.\nExtending the triangulation network.\n5.12. Trilateration\nTrilateration is an alternative to triangulation that relies upon distance measurements only. Electronic\ndistance measurement technologies make trilateration a cost-effective positioning technique for control\nsurveys. Not only is it used by land surveyors, trilateration is also used to determine location\ncoordinates with Global Positioning System satellites and receivers. Nature of Geographic Information 172\nTrilateration is used to extend control networks by establishing new control points (B, C, and D) based\nupon existing control points (A).\nTrilateration networks commence the same way as triangulation nets. If only one existing control\npoint is available, a second point (B) is established by open traverse. Using a total station equipped\nwith an electronic distance measurement device, the survey team measures the azimuth \u03b1 and baseline\ndistance AB. The total station operator may set up her instrument over point A, while her assistant\nholds a reflector mounted on a shoulder-high pole as steadily as he can over point B. Depending on\nthe requirements of the control survey, the accuracy of the calculated position B may be confirmed by\nastronomical observation. 173 David DiBiase\nEstablishing a second control point (B) in a trilateration network.\nNext, the survey team uses the electronic distance measurement feature of the total station to measure\nthe distances AC and BC. Both forward and backward measurements are taken. After the measurements\nare reduced from slope distances to horizontal distances, the law of cosines can be employed to calculate\ninterior angles, and the coordinates of position C can be fixed. The accuracy of the fix is then checked\nby plotting triangle ABC and evaluating the error of closure. Nature of Geographic Information 174\nMeasuring the distances AC and BC.\nNext, the trilateration network is extended by measuring the distances CD and BD, and fixing point D\nin a plane coordinate system.\nFixing control point D by trilateration. 175 David DiBiase\nTRY THIS!\nUSE TRILATERATION TO DETERMINE A CONTROL POINT LOCATION\nTrilateration is a technique land surveyors use to calculate an undetermined position in a plane\ncoordinate system by measuring distances from two known positions. As you will see later in this\nchapter, trilateration is also the technique that GPS receivers use to calculate their positions on the\nEarth\u2019s surface, relative to the positions of three or more satellite transmitters. The purpose of this\nexercise is to make sure you understand how trilateration works. (Estimated time to complete: 5\nminutes.)\nNote: You will need to have the Adobe Flash player installed in order to complete this exercise. If you\ndo not already have the Flash player, you can download it for free from Adobe.\n1. Display a coordinate system grid: In this exercise, you will interact with a coordinate\nsystem grid. First, display the coordinate system grid in a separate window so that you can\ninteract with it while you read these instructions. Arrange the coordinate system grid window\nand this window so that you can easily view both. You may need to make this window more\nnarrow. Two control points, A and B, are plotted in the coordinate system grid. A survey\ncrew has measured distances from the control points to another point, point C, whose\ncoordinates are unknown. Your job is to fix the position of point C. You will find point C at\nthe intersection of two circles centered on control points A and B, where the radii of the two\ncircles equals the measured distances from the control points to point C.\n2. Plot the distance from control point A to point C: On the coordinate system grid, click on\ncontrol point A to display the data entry form. (You\u2019ll need to click on the actual point, not\nthe \u201cA\u201d.) The form consists of a text field in which you can type in a distance, and a button\nthat plots a circle centered on point A. The radius of the circle will be the distance you\nspecify. According to the surveyors\u2019 measurements, the distance between control point A and\npoint C is 9400 feet. Enter that distance now and click Plot to plot the circle. [View result of\nStep 2]\n3. Plot the distance from control point B to point C: The measured distance from point B to\npoint C is 7000 feet. Click on point B (on the actual point, not the \u201cB\u201d), enter that distance\nand plot a circle. [View result of Step 3]\n4. Plot point C: Now click within the coordinate grid to reveal the position of point C. You\nmay have to hunt for it, but you should know where to look based on the intersection of the\ncircles. [View result of Step 4]\n5. Extend the control network further: Now continue extending the control network by\nplotting a fourth point, point D, in the coordinate system grid. First plot new circles at points\nA and C. The measured distance from point A to point D is 9600 feet. The measured distance\nfrom point C to point D is 8000 feet. (You may wish to set the radius of the circle centered\nupon point B to 0.) Finally, click in the coordinate system grid to plot point D. [View result of\nStep 5]\nOnce you have finished viewing the grid, close the popup window. Nature of Geographic Information 176\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 5 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about Horizontal Positions. You may take practice\nquizzes as many times as you wish. They are not scored and do not affect your grade in any way.\n5.13. Vertical Positions\nA vertical position is the height of a point relative to some reference surface, such as mean sea level,\na geoid, or an ellipsoid. The roughly 600,000 vertical control points in the U.S. National Spatial\nReference System (NSRS) are referenced to the North American Vertical Datum of 1988 (NAVD 88).\nSurveyors created the National Geodetic Vertical Datum of 1929 (NGVD 29, the predecessor to NAVD\n88), by calculating the average height of the sea at all stages of the tide at 26 tidal stations over 19 years.\nThen they extended the control network inland using a surveying technique called leveling. Leveling is\nstill a cost-effective way to produce elevation data with sub-meter accuracy.\nA leveling crew at work in 1916. (Hodgson, 1916).\nThe illustration above shows a leveling crew at work. The fellow under the umbrella is peering\nthrough the telescope of a leveling instrument. Before taking any measurements, the surveyor made sure\nthat the telescope was positioned midway between a known elevation point and the target point. Once\nthe instrument was properly leveled, he focused the telescope crosshairs on a height marking on the rod\nheld by the fellow on the right side of the picture. The chap down on one knee is noting in a field book\nthe height measurement called out by the telescope operator. 177 David DiBiase\nA level used for determining elevations.\nLeveling is still a cost-effective way to produce elevation data with sub-meter accuracy. A modern\nleveling instrument is shown in the photograph above. The diagram below illustrates the technique called\ndifferential leveling. Nature of Geographic Information 178\nDifferential leveling. (Adapted from Wolf & Brinker, 1994)\nThe diagram above illustrates differential leveling. A leveling instrument is positioned midway\nbetween a point at which the ground elevation is known (point A) and a point whose elevation is to be\nmeasured (B). The height of the instrument above the datum elevation is HI. The surveyor first reads\na backsight measurement (BS) off of a leveling rod held by his trusty assistant over the benchmark at\nA. The height of the instrument can be calculated as the sum of the known elevation at the benchmark\n(ZA) and the backsight height (BS). The assistant then moves the rod to point B. The surveyor rotates\nthe telescope 180\u00b0, then reads a foresight (FS) off the rod at B. The elevation at B (ZB) can then be\ncalculated as the difference between the height of the instrument (HI) and the foresight height (FS).\nFormer student Henry Whitbeck (personal communication, Fall 2000) points out that surveyors also\nuse total stations to measure vertical angles and distances between fixed points (prisms mounted upon\ntripods at fixed heights), then calculate elevations by trigonometric leveling.\nHEIGHTS\nSurveyors use the term height as a synonym for elevation. There are several different ways to measure\nheights. A properly-oriented level defines a line parallel to the geoid surface at that point (Van Sickle,\n2001).An elevation above the geoid is called an orthometric height.However, GPS receivers cannot\nproduce orthometric heights directly. Instead, GPS produces heights relative to the WGS 84\nellipsoid.Elevations produced with GPS are therefore called ellipsoidal (or geodetic) heights.\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 5 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about Vertical Positions. You may take practice quizzes\nas many times as you wish. They are not scored and do not affect your grade in any way. 179 David DiBiase\n5.14. Global Positioning System\nPositioning signals broadcast from three Global Positioning System satellites are received at a location\non Earth. (U.S. Federal Aviation Administration, 2007b)\nThe Global Positioning System (GPS) employs trilateration to calculate the coordinates of\npositions at or near the Earth\u2019s surface.Trilateration refers to the trigonometric law by which the\ninterior angles of a triangle can be determined if the lengths of all three triangle sides are known. GPS\nextends this principle to three dimensions.\nA GPS receiver can fix its latitude and longitude by calculating its distance from three or more Earth-\norbiting satellites, whose positions in space and time are known. If four or more satellites are within\nthe receiver\u2019s \u201chorizon,\u201d the receiver can also calculate its elevation, and even its velocity. The U.S.\nDepartment of Defense created the Global Positioning System as an aid to navigation. Since it was\ndeclared fully operational in 1994, GPS positioning has been used for everything from tracking delivery\nvehicles, to tracking the minute movements of the tectonic plates that make up the Earth\u2019s crust, to\ntracking the movements of human beings. In addition to the so-called user segment made up of the GPS\nreceivers and people who use them to measure positions, the system consists of two other components:\na space segment and a control segment. It took about $10 billion to build over 16 years.\nRussia maintains a similar positioning satellite system called GLONASS. Member nations of the\nEuropean Union are in the process of deploying a comparable system of their own, called Galileo. The\nfirst experimental GIOVE-A satellite began transmitting Galileo signals in January 2006. The goal of\nthe Galileo project is a constellation of 30 navigation satellites by 2020. If the engineers and politicians\nsucceed in making Galileo, GLONASS, and the U.S. Global Positioning System interoperable, as\ncurrently seems likely, the result will be a Global Navigation Satellite System (GNSS) that provides\nmore than twice the signal-in-space resource that is available with GPS alone. The Chinese began work\non their own system, called Beidou, in 2000. At the end of 2011 they had ten satellites in orbit, serving\njust China, with the goal being a global system of 35 satellites by 2020.\nIn this section you will learn to:\n1. Explain how radio signals broadcast by Global Positioning System satellites are used to\ncalculate positions on the surface of the Earth; and\n2. Describe the functions of the space, control, and user segments of the Global Positioning\nSystem.\n5.15. Space Segment\nThe space segment of the Global Positioning System currently consists of approximately 30 active and\nspare NAVSTAR satellites (new satellites are launched periodically, and old ones are decommissioned).\n\u201cNAVSTAR\u201d stands for \u201cNAVigation System with Timing And Ranging.\u201d Each satellite circles the Nature of Geographic Information 180\nEarth every 12 hours in sidereal time along one of six orbital \u201cplanes\u201d at an altitude of 20,200 km\n(about 12,500 miles). The satellites broadcast signals used by GPS receivers on the ground to measure\npositions. The satellites are arrayed such that at least four are \u201cin view\u201d everywhere on or near the Earth\u2019s\nsurface at all times, with typically up to eight and potentially 12 \u201cin view\u201d at any given time.\nThe constellation of GPS satellites. Illustration \u00a9 Smithsonian Institution, 1988. Used by Permission.\nTRY THIS!\nThe U.S. Coast Guard\u2019s Navigation Center publishes status reports on the GPS satellite constellation. Its\nreport of August 17, 2010, for example, listed 31 satellites, five to six in each of the six orbits planes (A-\nF), and one scheduled outage, on August 19, 2010. You can look up the current status of the constellation\nhere. 181 David DiBiase\nArtist\u2019s rendition of a NAVSTAR satellite (NAVSTAR GPS Joint Program Office, n.d.).\nTRY THIS!\nScientific programmers at the U.S. National Aeronautics and Space Administration (NASA) have\ncreated an interactive, three-dimensional model of the Earth and the orbits of the more than 500 man-\nmade satellites that surround it. The model is a Java applet called J-Track 3D Satellite Tracking. Your\nbrowser must have Java enabled to view the applet. Instructions at the site describe how you can zoom\nin and out, and drag to rotate the model. To view orbits of particular satellites, choose Select from the\nSatellite menu. The Block IIA and R series are the most current generation of NAVSTAR satellites.\n5.16. Control Segment\nThe control segment of the Global Positioning System is a network of ground stations that monitors the\nshape and velocity of the satellites\u2019 orbits. The accuracy of GPS data depends on knowing the positions\nof the satellites at all times. The orbits of the satellites are sometimes disturbed by the interplay of the\ngravitational forces of the Earth and Moon.\nThe control segment of the Global Positioning System (U.S. Federal Aviation Administration, 2007b).\nMonitor Stations are very precise GPS receivers installed at known locations. They record\ndiscrepancies between known and calculated positions caused by slight variations in satellite orbits. Data\ndescribing the orbits are produced at the Master Control Station at Colorado Springs, uploaded to the\nsatellites, and finally broadcast as part of the GPS positioning signal. GPS receivers use this satellite\nNavigation Message data to adjust the positions they measure.\nIf necessary, the Master Control Center can modify satellite orbits by commands transmitted via the\ncontrol segment\u2019s ground antennas.\n5.17. User Segment\nThe U.S. Federal Aviation Administration (FAA) estimated in 2006 that some 500,000 GPS receivers\nare in use for many applications, including surveying, transportation, precision farming, geophysics, and\nrecreation, not to mention military navigation. This was before in-car GPS navigation gadgets emerged\nas one of the most popular consumer electronic gifts during the 2007 holiday season in North America.\nBasic consumer-grade GPS receivers, like the rather old-fashioned one shown below, consist of a Nature of Geographic Information 182\nradio receiver and internal antenna, a digital clock, some sort of graphic and push-button user interface, a\ncomputer chip to perform calculations, memory to store waypoints, jacks to connect an external antenna\nor download data to a computer, and flashlight batteries for power. The radio receiver in the unit shown\nbelow includes 12 channels to receive signal from multiple satellites simultaneously.\nRecreation-grade GPS receiver, circa 1998.\nNAVSTAR Block II satellites broadcast at two frequencies, 1575.42 MHz (L1) and 1227.6 MHz (L2).\n(For sake of comparison, FM radio stations broadcast in the band of 88 to 108 MHz.) Only L1 was\nintended for civilian use. Single-frequency receivers produce horizontal coordinates at an accuracy of\nabout three to seven meters (or about 10 to 20 feet) at a cost of about $100. Some units allow users to\nimprove accuracy by filtering out errors identified by nearby stationary receivers, a post-process called\n\u201cdifferential correction.\u201d $300-500 single-frequency units that can also receive corrected L1 signals\nfrom the U.S. Federal Aviation Administration\u2019s Wide Area Augmentation System (WAAS) network of\nground stations and satellites can perform differential correction in \u201creal-time.\u201d Differentially-corrected\ncoordinates produced by single-frequency receivers can be as accurate as one to three meters (about 3 to\n10 feet).\nThe signal broadcast at the L2 frequency is encrypted for military use only. Clever GPS receiver\nmakers soon figured out, however, how to make dual-frequency models that can measure slight\ndifferences in arrival times of the two signals (these are called \u201ccarrier phase differential\u201d receivers).\nSuch differences can be used to exploit the L2 frequency to improve accuracy without decoding the\nencrypted military signal. Survey-grade carrier-phase receivers able to perform real-time kinematic 183 David DiBiase\n(RTK) differential correction, can produce horizontal coordinates at sub-meter accuracy at a cost of\n$1000 to $2000. No wonder GPS has replaced electro-optical instruments for many land surveying tasks.\nMeanwhile, a new generation of NAVSTAR satellites (the Block IIR-M series) will add a civilian\nsignal at the L2 frequency that will enable substantially improved GPS positioning.\n5.18. Satellite Ranging\nGPS receivers calculate distances to satellites as a function of the amount of time it takes for satellites\u2019\nsignals to reach the ground. To make such a calculation, the receiver must be able to tell precisely when\nthe signal was transmitted, and when it was received. The satellites are equipped with extremely accurate\natomic clocks, so the timing of transmissions is always known. Receivers contain cheaper clocks, which\ntend to be sources of measurement error. The signals broadcast by satellites, called \u201cpseudo-random\ncodes,\u201d are accompanied by the broadcast ephemeris data that describes the shapes of satellite orbits.\nGPS receivers calculate distance as a function of the difference in time of broadcast and reception of\na GPS signal. (Adapted from Hurn, 1989).\nThe GPS constellation is configured so that a minimum of four satellites is always \u201cin view\u201d\neverywhere on Earth. If only one satellite signal was available to a receiver, the set of possible positions\nwould include the entire range sphere surrounding the satellite. Nature of Geographic Information 184\nSet of possible positions of a GPS receiver relative to a single GPS satellite. (Adapted from Hurn,\n1993).\nIf two satellites are available, a receiver can tell that its position is somewhere along a circle formed\nby the intersection of two spherical ranges.\nSet of possible positions of a GPS receiver relative to two GPS satellites. (Adapted from Hurn, 1993).\nIf distances from three satellites are known, the receiver\u2019s position must be one of two points\nat the intersection of three spherical ranges. GPS receivers are usually smart enough to choose the\nlocation nearest to the Earth\u2019s surface. At a minimum, three satellites are required for a two-dimensional\n(horizontal) fix. Four ranges are needed for a three-dimensional fix (horizontal and vertical). 185 David DiBiase\nSet of possible positions of a GPS receiver relative to three GPS satellites. (Adapted from Hurn,\n1993).\nSatellite ranging is similar in concept to the plane surveying methodtrilateration, by which horizontal\npositions are calculated as a function of distances from known locations. The GPS satellite constellation\nis in effect an orbiting control network.\nTRY THIS!\nTrimble has a tutorial \u201cdesigned to give you a good basic understanding of the principles behind GPS\nwithout loading you down with too much technical detail\u201d. Check it out at http:\/\/www.trimble.com\/\ngps_tutorial\/. Click \u201cWhy GPS?\u201d to get started.\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 5 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about GPS Components. You may take practice quizzes\nas many times as you wish. They are not scored and do not affect your grade in any way.\n5.19. GPS Error Sources\nA thought experiment (Wormley, 2004): Attach your GPS receiver to a tripod. Turn it on and record\nits position every ten minutes for 24 hours. Next day, plot the 144 coordinates your receiver calculated.\nWhat do you suppose the plot would look like?\nDo you imagine a cloud of points scattered around the actual location? That\u2019s a reasonable Nature of Geographic Information 186\nexpectation. Now, imagine drawing a circle or ellipse that encompasses about 95 percent of the points.\nWhat would the radius of that circle or ellipse be? (In other words, what is your receiver\u2019s positioning\nerror?)\nThe answer depends in part on your receiver. If you used a hundred-dollar receiver, the radius of the\ncircle you drew might be as much as ten meters to capture 95 percent of the points. If you used a WAAS-\nenabled, single frequency receiver that cost a few hundred dollars, your error ellipse might shrink to one\nto three meters or so. But if you had spent a few thousand dollars on a dual frequency, survey-grade\nreceiver, your error circle radius might be as small as a centimeter or less. In general, GPS users get what\nthey pay for.\nAs the market for GPS positioning grows, receivers are becoming cheaper. Still, there are lots of\nmapping applications for which it\u2019s not practical to use a survey-grade unit. For example, if your\nassignment was to GPS 1,000 manholes for your municipality, you probably wouldn\u2019t want to set up\nand calibrate a survey-grade receiver 1,000 times. How, then, can you minimize errors associated with\nmapping-grade receivers? A sensible start is to understand the sources of GPS error.\nIn this section you will learn to:\n1. State the kinds and magnitude of error and uncertainty associated with uncorrected GPS\npositioning; and\n2. Use a PDOP chart to determine the optimal times for GPS positioning at a given location and\ndate.\nNote: My primary source for the material in this section is Jan Van Sickle\u2019s text GPS for Land Surveyors,\n2nd Ed. If you want a readable and much more detailed treatment of this material, I recommend Jan\u2019s\nbook. See the bibliography at the end of this chapter for more information about this and other resources.\n5.20. User Equivalent Range Errors\n\u201cUERE\u201d is the umbrella term for all of the error sources below, which are presented in descending order\nof their contributions to the total error budget.\n1. Satellite clock: GPS receivers calculate their distances from satellites as a function of the\ndifference in time between when a signal is transmitted by a satellite and when it is received\non the ground. The atomic clocks on board NAVSTAR satellites are extremely accurate. They\ndo tend to stray up to one millisecond of standard GPS time (which is calibrated to, but not\nidentical to, Coordinated Universal Time). The monitoring stations that make up the GPS\n\u201cControl Segment\u201d calculate the amount of clock drift associated with each satellite. GPS\nreceivers that are able to make use of the clock correction data that accompanies GPS signals\ncan reduce clock error significantly.\n2. Upper atmosphere (ionosphere): Space is nearly a vacuum, but the atmosphere isn\u2019t. GPS\nsignals are delayed and deflected as they pass through the ionosphere, the outermost layers of\nthe atmosphere that extend from approximately 50 to 1,000 km above the Earth\u2019s surface.\nSignals transmitted by satellites close to the horizon take a longer route through the\nionosphere than signals from satellites overhead, and are thus subject to greater interference.\nThe ionosphere\u2019s density varies by latitude, by season, and by time of day, in response to the\nSun\u2019s ultraviolet radiation, solar storms and maximums, and the stratification of the\nionosphere itself. The GPS Control Segment is able to model ionospheric biases, however. 187 David DiBiase\nMonitoring stations transmit corrections to the NAVSTAR satellites, which then broadcast\nthe corrections along with the GPS signal. Such corrections eliminate only about three-\nquarters of the bias, however, leaving the ionosphere the second largest contributor to the\nGPS error budget.\n3. Receiver clock: GPS receivers are equipped with quartz crystal clocks that are less stable\nthan the atomic clocks used in NAVSTAR satellites. Receiver clock error can be eliminated,\nhowever, by comparing times of arrival of signals from two satellites (whose transmission\ntimes are known exactly).\n4. Satellite orbit: GPS receivers calculate coordinates relative to the known locations of\nsatellites in space. Knowing where satellites are at any given moment involves knowing the\nshapes of their orbits as well as their velocities. The gravitational attractions of the Earth,\nSun, and Moon all complicate the shapes of satellite orbits. The GPS Control Segment\nmonitors satellite locations at all times, calculates orbit eccentricities, and compiles these\ndeviations in documents called ephemerides. An ephemeris is compiled for each satellite and\nbroadcast with the satellite signal. GPS receivers that are able to process ephemerides can\ncompensate for some orbital errors.\n5. Lower atmosphere: (troposphere, tropopause, and stratosphere) The three lower layers of\natmosphere encapsulate the Earth from surface to an altitude of about 50 km. The lower\natmosphere delays GPS signals, adding slightly to the calculated distances between satellites\nand receivers. Signals from satellites close to the horizon are delayed the most, since they\npass through more atmosphere than signals from satellites overhead.\n6. Multipath: Ideally, GPS signals travel from satellites through the atmosphere directly to GPS\nreceivers. In reality, GPS receivers must discriminate between signals received directly from\nsatellites and other signals that have been reflected from surrounding objects, such as\nbuildings, trees, and even the ground. Some, but not all, reflected signals are identified\nautomatically and rejected. Antennas are designed to minimize interference from signals\nreflected from below, but signals reflected from above are more difficult to eliminate. One\ntechnique for minimizing multipath errors is to track only those satellites that are at least 15\u00b0\nabove the horizon, a threshold called the \u201cmask angle.\u201d\nDouglas Welsh (personal communication, Winter 2001), an Oil and Gas Inspector Supervisor with\nPennsylvania\u2019s Department of Environmental Protection, wrote about the challenges associated with\nGPS positioning in our neck of the woods: \u201c\u2026in many parts of Pennsylvania the horizon is the limiting\nfactor. In a city with tall buildings and the deep valleys of some parts of Pennsylvania it is hard to find\na time of day when the constellation will have four satellites in view for any amount of time. In the\nforests with tall hardwoods, multipath is so prevalent that I would doubt the accuracy of any spot unless\na reading was taken multiple times.\u201d Van Sickle (2005) points out, however, that GPS modernization\nefforts and the GNSS may well ameliorate such gaps.\nHave you had similar experiences with GPS? If so, please post a comment to this page .\n5.21. Dilution of Precision\nThe arrangement of satellites in the sky also affects the accuracy of GPS positioning. The ideal\narrangement (of the minimum four satellites) is one satellite directly overhead, three others equally Nature of Geographic Information 188\nspaced near the horizon (above the mask angle). Imagine a vast umbrella that encompasses most of the\nsky, where the satellites form the tip and the ends of the umbrella spines.\nGPS coordinates calculated when satellites are clustered close together in the sky suffer from dilution\nof precision (DOP), a factor that multiplies the uncertainty associated with User Equivalent Range\nErrors (UERE \u2013 errors associated with satellite and receiver clocks, the atmosphere, satellite orbits,\nand the environmental conditions that lead to multipath errors). The DOP associated with an ideal\narrangement of the satellite constellation equals approximately 1, which does not magnify UERE.\nAccording to Van Sickle (2001), the lowest DOP encountered in practice is about 2, which doubles the\nuncertainty associated with UERE.\nGPS receivers report several components of DOP, including Horizontal Dilution of Precision (HDOP)\nand Vertical Dilution of Precision (VDOP). The combination of these two components of the three-\ndimensional position is called PDOP \u2013 position dilution of precision. A key element of GPS mission\nplanning is to identify the time of day when PDOP is minimized. Since satellite orbits are known, PDOP\ncan be predicted for a given time and location. Various software products allow you to determine when\nconditions are best for GPS work.\nMGIS student Jason Setzer (Winter 2006) offers the following illustrative anecdote:\nI have had a chance to use GPS survey technology for gathering ground control data in my region and the\nbiggest challenge is often the PDOP (position dilution of precision) issue. The problem in my mountainous\narea is the way the terrain really occludes the receiver from accessing enough satellite signals.\nDuring one survey in Colorado Springs I encountered a pretty extreme example of this. Geographically,\nColorado Springs is nestled right against the Rocky Mountain front ranges, with 14,000 foot Pike\u2019s Peak just\nwest of the city. My GPS unit was easily able to \u2018see\u2019 five, six or even seven satellites while I was on the eastern\nhalf of the city. However, the further west I traveled, I began to see progressively less of the constellation, to\nthe point where my receiver was only able to find one or two satellites. If a 180 degree horizon-to-horizon view\nof the sky is ideal, then in certain places I could see maybe 110 degrees.\nThere was no real work around, other than patience. I was able to adjust my survey points enough to maximize\nmy view of the sky. From there it was just a matter of time\u2026 Each GPS bird has an orbit time of around twelve\nhours, so in a couple of instances I had to wait up to two hours at a particular location for enough of them to\nbecome visible. My GPS unit automatically calculates PDOP and displays the number of available satellites. So\nthe PDOP value was never as low as I would have liked, but it did drop enough to finally be within acceptable\nlimits. Next time I might send a vendor out for such a project!\nTRY THIS!\nTrimble, a leading manufacturer of GPS receivers, offers GPS mission planning software for free\ndownloads. This activity will introduce you to the capabilities of the software, and will prepare you to\nanswer questions about GPS mission planning later.\n(The mission planning software is a Windows application (.exe). Mac users, as well as Windows users,\nsee beneath the numbered steps.)\n1. Visit the Trimble website\n2. Download the Trimble planning software, install it on your computer (note where it is\ninstalling its Common Files), and launch the application.\n3. Install an almanac: In the Almanac menu, move your cursor to Importand in the submenu,\nchoose Almanac | navigate to the folder where the Common Files were installed | 189 David DiBiase\nselect almanac.alm and click the Openbutton | click OK.\n(If your Windows operating system is installed on your C-drive, then the path name to the\nalmanac.alm file probably looks like this, with or without the \u201c(x86)\u201d:\nC:Program Files (x86)Common FilesTrimblePlanning)\n4. Choose File | Station\u2026 Choose a location at which you might wish to plan a GPS mission.\n5. Choose Satellite | Information to explore the characteristics of active GPS, GLONASS, and\nWAAS satellites.\n6. Choose Graphs | DOP | DOP \u2013 position to see how combined HDOP and VDOP vary\nthroughout a selected 24-hour period at your selected location. Can you determine the best\nand worst times of day for GPS work?\nWhile Trimble still makes available for free the planning software that you used above, they are not\nincluding access to an up to date almanac (information about currently available satellites). You may\nhave noticed that the almanac you loaded was from 2010.\nHowever, if you go here you will find an interactive interface that gives you access to a more current\nversion of the same functionality as the planning app used above.\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 5 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about GPS Error Sources. You may take practice quizzes\nas many times as you wish. They are not scored and do not affect your grade in any way.\n5.22. GPS Error Correction\nA variety of factors, including the clocks in satellites and receivers, the atmosphere, satellite orbits,\nand reflective surfaces near the receiver, degrade the quality of GPS coordinates. The arrangement of\nsatellites in the sky can make matters worse (a condition called dilution of precision). A variety of\ntechniques have been developed to filter out positioning errors. Random errors can be partially overcome\nby simply averaging repeated fixes at the same location, although this is often not a very efficient\nsolution. Systematic errors can be compensated for by modeling the phenomenon that causes the error\nand predicting the amount of offset. Some errors, like multipath errors caused when GPS signals are\nreflected from roads, buildings, and trees, vary in magnitude and direction from place to place. Other\nfactors, including clocks, the atmosphere, and orbit eccentricities, tend to produce similar errors over\nlarge areas of the Earth\u2019s surface at the same time. Errors of this kind can be corrected using a collection\nof techniques called differential correction.\nIn this section you will learn to:\n1. Explain the concept of differential correction and other methods used to improve the\naccuracy of GPS positioning; and\n2. Perform differential correction using data and services of the U.S. National Geodetic Survey. Nature of Geographic Information 190\n5.23. Differential Correction\nDifferential correction is a class of techniques for improving the accuracy of GPS positioning by\ncomparing measurements taken by two or more receivers. Here\u2019s how it works:\nThe locations of two GPS receivers\u2013one stationary, one mobile\u2013are illustrated below. The stationary\nreceiver (or \u201cbase station\u201d) continuously records its fixed position over a control point. The difference\nbetween the base station\u2019s actual location and its calculated location is a measure of the positioning error\naffecting that receiver at that location at each given moment. In this example, the base station is located\nabout 25 kilometers from the mobile receiver (or \u201crover\u201d). The operator of the mobile receiver moves\nfrom place to place. The operator might be recording addresses for an E-911 database, or trees damaged\nby gypsy moth infestations, or street lights maintained by a public works department\nA GPS base station is fixed over a control point, while about 25 km away, a mobile GPS receiver is\nused to measure a series of positions.\nThe illustration below shows positions calculated at the same instant (3:01 pm) by the base station\n(left) and the mobile receiver (right). 191 David DiBiase\nActual and calculated positions of a base station and mobile receiver.\nThe base station calculates the correction needed to eliminate the error in the position calculated at\nthat moment from GPS signals. The correction is later applied to the position calculated by the mobile\nreceiver at the same instant. The corrected position is not perfectly accurate because the kinds and\nmagnitudes of errors affecting the two receivers are not identical, and because of the low frequency of\nthe GPS timing code.\nError correction calculated at the base station is applied to the position calculated by the mobile\nreceiver. Nature of Geographic Information 192\nGPS base station used for differential correction. Notice that the antenna is located directly above a\ncontrol point monument.\n5.24. Real-Time Differential Correction\nFor differential correction to work, fixes recorded by the mobile receiver must be synchronized with\nfixes recorded by the base station (or stations). You can provide your own base station, or use correction\nsignals produced from reference stations maintained by the U.S. Federal Aviation Administration,\nthe U.S. Coast Guard, or other public agencies or private subscription services. Given the necessary\nequipment and available signals, synchronization can take place immediately (\u201creal-time\u201d) or after the\nfact (\u201cpost-processing\u201d). First let\u2019s consider real-time differential. 193 David DiBiase\nWAAS-enabled receivers are an inexpensive example of real-time differential correction. \u201cWAAS\u201d\nstands for Wide Area Augmentation System, a collection of about 25 base stations set up to improve\nGPS positioning at U.S. airport runways to the point that GPS can be used to help land airplanes (U.S.\nFederal Aviation Administration, 2007c). WAAS base stations transmit their measurements to a master\nstation, where corrections are calculated and then uplinked to two geosynchronous satellites (19 are\nplanned). The WAAS satellite then broadcasts differentially-corrected signals at the same frequency as\nGPS signals. WAAS signals compensate for positioning errors measured at WAAS base stations, as well\nas clock error corrections and regional estimates of upper-atmosphere errors (Yeazel, 2003). WAAS-\nenabled receivers devote one or two channels to WAAS signals, and are able to process the WAAS\ncorrections. The WAAS network was designed to provide approximately 7-meter accuracy uniformly\nthroughout its U.S. service area.\nDGPS: The U.S. Coast Guard has developed a similar system, called theDifferential Global\nPositioning Service. The DGPS network includes some 80 broadcast sites, each of which includes a\nsurvey-grade base station and a \u201cradiobeacon\u201d transmitter that broadcasts correction signals at 285-325\nkHz (just below the AM radio band). DGPS-capable GPS receivers include a connection to a radio\nreceiver that can tune in to one or more selected \u201cbeacons.\u201d Designed for navigation at sea near U.S.\ncoasts, DGPS provides accuracies no worse than 10 meters. Stephanie Brown (personal communication,\nFall 2003) reported that where she works in Georgia, \u201cwith a good satellite constellation overhead,\n[DGPS accuracy] is typically 4.5 to 8 feet.\u201d\nSurvey-grade real-time differential correction can be achieved using a technique called real-time\nkinematic (RTK) GPS. According to surveyor Laverne Hanley (personal communication, Fall 2000),\n\u201creal-time kinematic requires a radio frequency link between a base station and the rover. I have\nachieved better than centimeter accuracy this way, although the instrumentation is touchy and requires\ngreat skill on the part of the operator. Several times I found that I had great GPS geometry, but had lost\nmy link to the base station. The opposite has also happened, where I wanted to record positions and had\na radio link back to the base station, but the GPS geometry was bad.\u201d\n5.25. Post-Processed Differential Correction\nKinematic positioning can deliver accuracies of 1 part in 100,000 to 1 part in 750,000 with relatively\nbrief observations of only one to two minutes each. For applications that require accuracies of 1 part in\n1,000,000 or higher, including control surveys and measurements of movements of the Earth\u2019s tectonic\nplates, static positioning is required (Van Sickle, 2001). In static GPS positioning, two or more receivers\nmeasure their positions from fixed locations over periods of 30 minutes to two hours. The receivers may\nbe positioned up to 300 km apart. Onlydual frequency, carrier phase differential receivers capable of\nmeasuring the differences in time of arrival of the civilian GPS signal (L1) and the encrypted military\nsignal (L2) are suitable for such high-accuracy static positioning.\nCORS and OPUS: The U.S. National Geodetic Survey (NGS) maintains an Online Positioning User\nService (OPUS) that enables surveyors to differentially-correct static GPS measurements acquired with\na single dual frequency carrier phase differential receiver after they return from the field. Users upload\nmeasurements in a standard Receiver INdependent EXchange format (RINEX) to NGS computers,\nwhich perform differential corrections by referring to three selected base stations selected from a\nnetwork of continuously operating reference stations. NGS oversees two CORS networks; one\nconsisting of its 600 base stations of its own, another a cooperative of public and private agencies that\nagree to share their base station data and to maintain base stations to NGS specifications. Nature of Geographic Information 194\nThe Continuously Operating Reference Station network (CORS) (Snay, 2005)\nThe map above shows distribution of the combined national and cooperative CORS networks. Notice\nthat station symbols are colored to denote the sampling rate at which base station data are stored. After\n30 days, all stations are required to store base station data only in 30 second increments. This policy\nlimits the utility of OPUS corrections to static positioning (although the accuracy of longer kinematic\nobservations can also be improved). Mindful of the fact that the demand for static GPS is steadily\ndeclining, NGS\u2019 future plans include streaming CORS base station data for real-time use in kinematic\npositioning.\nTRY THIS!\nThis optional activity (contributed by Chris Piburn of CompassData Inc.) will guide you through the\nprocess of differentially-correcting static GPS measurements using the NGS\u2019 Online Positioning User\nService (OPUS), which refers to the Continuously Operating Reference Station network (CORS).\nThe context is a CompassData project that involved a carrier phase differential GPS survey in a remote\nstudy area in Alaska. The objective was to survey a set of nine ground control points (GCPs) that would\nlater be used to orthorectify a client\u2019s satellite imagery. So remote is this area that no NGS control point\nwas available at the time the project was carried out. The alternative was to establish a base station for\nthe project and to fix its position precisely with reference to CORS stations in operation elsewhere in\nAlaska.\nThe project team flew by helicopter to a hilltop located centrally within the study area. With some\ndifficulty they hammered an 18 inch #5 rebar into the rocky soil to serve as a control monument.\nAfter setting up a GPS base station receiver over the rebar, they flew off to begin data collection with\ntheir rover receiver. Thanks to favorable weather, Chris and his team collected the nine required photo-\nidentifiable GCPs on the first day. The centrally-located base station allowed the team to minimize\ndistances between the base and the rover, which meant they could minimize the time required to fix each 195 David DiBiase\nGCP. At the end of the day, the team had produced five hours of GPS data at the base station and nine\nfifteen-minute occupations at the GCPs\nAs you might expect, the raw GPS data were not sufficiently accurate to meet project requirements.\n(The various sources of random and systematic errors that contribute to the uncertainty of GPS data\nare considered elsewhere in this chapter.) In particular, the monument hammered into the hilltop was\nunsuitable for use as a control point because the uncertainty associated with its position was too great.\nThe project team\u2019s first step in removing positioning errors was to post-process the data using baseline\nprocessing software, which adjusts computed baseline distances (between the base station and the nine\nGCPs) by comparing the phase of the GPS carrier wave as it arrived simultaneously at both the base\nstation and the rover. The next step was to fix the position of the base station precisely in relation to\nCORS stations operating elsewhere in Alaska.\nThe following steps will guide you through the process of submitting the five hours of dual frequency\nbase station data to the U.S. National Geodetic Survey\u2019s Online Positioning User Service (OPUS), and\ninterpreting the results. (For information about OPUS, go here)\n1. Download the GPS data file. The compressed RINEX format file is approximately 6 Mb in size\nand will take about 1 minute to download via high speed DSL or cable, or about 15 minutes via 56 Kbps\nmodem. If you can\u2019t download this file, contact me right away so we can help you resolve the problem.\n\u2022 WILD282u.zip (5.8 Mb)\nGPS receivers produce data in their manufacturers\u2019 proprietary formats. NGS requires that the GPS data\nbe converted to the \u201cReceiver INdependent EXchange\u201d format (RINEX) for compatibility with OPUS.\nMost software packages that come with the GPS units themselves have a built in utility to convert\ntheir GPS data to RINEX format. NGS itself uses free conversion software provided by a non-profit,\ngovernment-sponsored consortium called UNAVCO.\n2. Examine the RINEX file.\n\u2022 Extract the RINEX file \u201cWILD282u.05O\u201d from its ZIP archive.\n\u2022 Open \u201cWILD282u.05O\u201d with Microsoft Notepad or WordPad. (WordPad does a better job of\npreserving columns of text in this case. Set the word wrap to off.) Or, use another text editor.\n(In any open text editor window, in the File > Open dialog, make sure \u201cFiles of type:\u201d is set\nto \u201cAll files\u201d so that the target file is listed.)\nThe RINEX Observation file contains all the information about the signals that CompassData\u2019s base\nstation receiver tracked during the Alaska survey. Explaining all the contents of the file is well beyond\nthe scope of this activity. For now, note the lines that disclose the antenna type, approximate position of\nthe antenna, and antenna height. You\u2019ll report these parameters to OPUS in the next step.\n3. Submit GPS data to OPUS\n\u2022 Point your browser to the OPUS home page and enter the information needed in order to\n\u201cUpload your data file.\u201d\n\u2022 (OPUS step 1) Click the Browse button to call up a File Upload window. Navigate to and\nupload the RINEX file you downloaded earlier. To streamline your submission, choose the\ncompressed archive \u201cWILD282u.zip\u201d.\n\u2022 (OPUS step 2) Select the antenna type. Refer to the line labeled \u201cANT # \/ TYPE\u201d in the\nRINEX file you opened in your text editor. You should find the antenna type Nature of Geographic Information 196\n\u201cTPSHIPER_PLUS\u201d. Choose this type from the pull-down list.\n\u2022 (OPUS step 3) Enter the height of the antenna above the monument. Refer to the line labeled\n\u201cANTENNA: DELTA H\/E\/N\u201d in the RINEX file you opened in your text editor. The first\nvalue on that line, \u201c1.0854\u2033, is H, in meters. (See the OPUS website for more information\nabout antenna height.)\n\u2022 (OPUS step 4) Enter the email address to which you wish your results to be returned.\n\u2022 (OPUS step 5) Options. OPUS allows users to specify a State Plane Coordinate system zone,\nto select or exclude particular CORS reference stations, to request standard or extended\noutput, and to establish a user profile for use with future jobs. For this activity, no changes to\nthe default settings are needed.\n\u2022 (OPUS step 6) Click the \u201cUpload to STATIC\u201d button to submit the data for differential\ncorrection in relation to three CORS reference stations. Depending on how many requests are\nin NGS\u2019 queue, results may be returned in minutes or hours. When this activity was tested,\nthe queue included only one request (see window below, which appears after requests\nsuccessfully submitted) and results were returned in just a few minutes, but in the past it has\ntaken up to 10 minutes.\nUpload results report, Online Positioning User Service, U.S. National Geodetic Survey. 197 David DiBiase\nWhen you receive your OPUS solution by return email, you will want to discover the magnitude of\ndifferential correction that OPUS calculated. To do this you\u2019ll need to determine (a) the uncorrected\nposition originally calculated by the base station, (b) the corrected position calculated by OPUS, and\n(c) the mark-to-mark distance between the original and corrected positions. In addition to the original\nRINEX file you downloaded earlier, you\u2019ll need the OPUS solution and two free software utilities\nprovided by NGS. Links to these utilities are listed below.\n4. Determine the position of the base station receiver prior to differential correction.\n\u2022 Refer to the RINEX file \u201cWILD282u.05O\u201d you opened in your text editor. The ninth line of\nthe RINEX file lists the position of the base station receiver in Earth-Centered Earth-Fixed X,\nY, Z coordinates. This is a three-dimensional Cartesian coordinate system whose origin is the\nEarth\u2019s center of mass (like the NAD 83 datum).-2389892.2740 -1608765.8567\n5672855.7386 APPROX POSITION XYZ\nNGS provides a conversion utility to transform these X, Y, Z values to more familiar latitude\nand longitude coordinates and ellipsoidal heights.\n\u2022 Go to NGS\u2019 XYZ to GEODETIC conversion.\n\u2022 Enter the X, Y, Z coordinates found in the RINEX file. Your result should be:\n\u25e6 Latitude = 63\u00b013\u201953.74280\u2033 N\n\u25e6 Longitude = 146\u00b003\u201912.12710\u2033 W\n\u25e6 Height = 1349.2248 m\n5. Determine the corrected position of the base station receiver. The OPUS solution you receive by\nemail reports corrected coordinates in Earth-Centered Earth-Fixed X, Y, Z, as geographic coordinates,\nand as UTM and State Plane coordinates. Look for the latitude and longitude coordinates and ellipsoidal\nheight that are specified relative to the NAD 83 datum. They should be very close to:\n\u2022 Latitude = 63\u00b013\u201953.73892\u2033 N\n\u2022 Longitude = 146\u00b003\u201911.98942\u2033 W\n\u2022 Height = 1348.756 m\n6. Calculate the difference between the original and corrected base station positions. NGS provides\nanother software utility to calculate the three-dimensional distance between two positions. Unlike the\nprevious XYZ to GEODETIC converter, however, the \u201cinvers3d.exe\u201d is a program you download to\nyour computer.\n\u2022 Download \u201cinvers3d.exe\u201d\n\u2022 Double-click on the file name to run the program, and choose thegeodetic\ncoordinates option.\n\u2022 Paying close attention to the required formats, enter the uncorrected latitude, longitude, and\nellipsoidal heights you calculated in step 4 above.\n\u2022 Next, choose the geodetic coordinates option again, enter the corrected coordinates and\nheight you calculated in step 5. Nature of Geographic Information 198\n\u2022 Among the results, look for the calculated \u201cmark-to-mark distance.\u201d This is the magnitude of\nthe OPUS correction.\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 5 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about GPS Error Correction. You may take practice\nquizzes as many times as you wish. They are not scored and do not affect your grade in any way.\n5.26. Summary\nPositions are a fundamental element of geographic data. Sets of positions form features, as the letters on\nthis page form words. Positions are produced by acts of measurement, which are susceptible to human,\nenvironmental, and instrument errors. Measurement errors cannot be eliminated, but systematic errors\ncan be estimated, and compensated for.\nLand surveyors use specialized instruments to measure angles and distances, from which they\ncalculate horizontal and vertical positions. The Global Positioning System (and to a potentially greater\nextent, the emerging Global Navigation Satellite System) enables both surveyors and ordinary citizens\nto determine positions by measuring distances to three or more Earth-orbiting satellites. As you\u2019ve read\nin this chapter (and may known from personal experience), GPS technology now rivals electro-optical\npositioning devices (i.e., \u201ctotal stations\u201d that combine optical angle measurement and electronic distance\nmeasurement instruments) in both cost and performance. This raises the question, \u201cIf survey-grade\nGPS receivers can produce point data with sub-centimeter accuracy, why are electro-optical positioning\ndevices still so widely used?\u201d In November 2005 I posed this question to two experts\u2013Jan Van Sickle and\nBill Toothill\u2013whose work I had used as references while preparing this chapter. I also enjoyed a fruitful\ndiscussion with an experienced student named Sean Haile (Fall 2005). Here\u2019s what they had to say:\nJan Van Sickle, author of GPS for Land Surveyors and Basic GIS Coordinates, wrote:\nIn general it may be said that the cost of a good total station (EDM and theodolite combination) is similar to the\ncost of a good \u2018survey grade\u2019 GPS receiver. While a new GPS receiver may cost a bit more, there are certainly\ndeals to be had for good used receivers. However, in many cases a RTK system that could offer production\nsimilar to an EDM requires two GPS receivers and there, obviously, the cost equation does not stand up. In\nsuch a case the EDM is less expensive.\nStill, that is not the whole story. In some circumstances, such as large topographic surveys, the production\nof RTK GPS beats the EDM regardless of the cost differential of the equipment. Remember, you need line of\nsight with the EDM. Of course, if a topo survey gets too large, it is more cost effective to do the work with\nphotogrammetry. And if it gets really large, it is most cost effective to use satellite imagery and remote sensing\ntechnology.\nNow, lets talk about accuracy. It is important to keep in mind that GPS is not able to provide orthometric\nheights (elevations) without a geoid model. Geoid models are improving all the time, but are far from perfect.\nThe EDM on the other hand has no such difficulty. With proper procedures it should be able to provide\northometric heights with very good relative accuracy over a local area. But, it is important to remember that\nrelative accuracy over a local area with line of sight being necessary for good production (EDM) is applicable\nto some circumstances, but not others. As the area grows larger, as line of sight is at a premium, and a more\nabsolute accuracy is required the advantage of GPS increases.\nIt must also be mentioned that the idea that GPS can provide cm level accuracy must always be discussed in\nthe context of the question, \u2018relative to what control and on what datum?\u2019\nIn relative terms, over a local area, using good procedures, it is certainly possible to say that an EDM can 199 David DiBiase\nproduce results superior to GPS in orthometric heights (levels) with some consistency. It is my opinion that this\nidea is the reason that it is rare for a surveyor to do detailed construction staking with GPS, i.e. curb and gutter,\nsewer, water, etc. On the other hand, it is common for surveyors to stake out property corners with GPS on a\ndevelopment site, and other features where the vertical aspect is not critical. It is not that GPS cannot provide\nvery accurate heights, it is just that it takes more time and effort to do so with that technology when compared\nwith EDM in this particular area (vertical component).\nIt is certainly true that GPS is not well suited for all surveying applications. However, there is no surveying\ntechnology that is well suited for all surveying applications. On the other hand, it is my opinion that one would\nbe hard pressed to make the case that any surveying technology is obsolete. In other words, each system has\nstrengths and weaknesses and that applies to GPS as well.\nBill Toothill, professor in the Department of GeoEnvironmental Sciences and Engineering at Wilkes\nUniversity, wrote:\nGPS is just as accurate at short range and more accurate at longer distances than electro-optical equipment. The\ncost of GPS is dropping and may not be much more than a high end electro-optical instrument. GPS is well\nsuited for all surveying applications, even though for a small parcel (less than an acre) traditional instruments\nlike a total station may prove faster. This depends on the availability of local reference sites (control) and the\ncoordinate system reference requirements of the survey.\nMost survey grade GPS units (dual frequency) can achieve centimeter level accuracies with fairly short\noccupation times. In the case of RTK this can be as little as five seconds with proper communication to\na broadcasting \u2018base\u2019. Sub-centimeter accuracies is another story. To achieve sub-centimeter, which most\nsurveyors don\u2019t need, requires much longer occupation times which is not conducive for \u2018production\u2019 work\nin a business environment. Most sub-centimeter applications are used for research, most of which are in the\ngeologic deformation category. I have been using dual frequency GPS for the last eight years in Yellowstone\nNational Park studying the deformation of the Yellowstone Caldera. To achieve sub-centimeter results we need\nat least 4-6 hours of occupation time at each point along a transect.\nSean Haile,a U.S. Park Service employee at Zion National Park whose responsibilities include GIS and\nGPS work, takes issue with some of these statements, as well as with some of the chapter material. While\na student in this class in Fall 2005, Sean wrote:\nA comparison of available products from [one manufacturer] shows that traditional technologies can achieve\naccuracy of 3mm. Under ideal conditions, the most advanced GPS equipment can only get down to 5mm\naccuracy, with real world results probably being closer to 10mm. It is true that GPS is often the faster and easier\nto use technology in the field when compared to electro-optical solutions, and with comparable accuracy levels\nhas displaced traditional methods. If the surveyor needs to be accurate to the mm, however, electro-optical\ntools are more accurate than GPS.\nThere is no way, none, that you can buy a sub-centimeter unit anywhere for $1000-2000. Yes, the prices\nare falling, but it has only been recently (last three years) that you could even buy a single channel sub-meter\naccuracy GPS unit for under $10,000. The units you mention in the chapter for $1000-2000, they would be\n\u2018sell your next of kin\u2019 expensive during that same time period. I am not in the business of measuring tectonic\nplates, but I deal with survey and mapping grade differential correction GPS units daily, so I can speak from\nexperience on that one.\nAnd Bill\u2019s response that GPS is well suited for all survey applications? Well I sincerely beg to differ. GPS is\npoorly suited for surveying where there is limited view of the horizon. You could wait forever and never get the\nrequired number of SVs. Even with mission planning. Obstructions such as high canopy cover, tall buildings,\nbig rock walls\u2026 all these things can result in high multi-path errors, which can ruin data from the best GPS\nunits. None of these things affect EDM. Yes, you can overcome poor GPS collection conditions (to an extent)\nby offsetting your point from a location where signal is good, but when you do that, you are taking the exact Nature of Geographic Information 200\nmeasurements (distance, angle) that you would be doing with an EDM except with an instrument that is not\nsuited to that application!\nThe Global Navigation Satellite System (GNSS) may eventually overcome some of the limitations of\nGPS positioning. Still, these experts seem to agree that both GPS and electro-optical surveying methods\nare here to stay.\nQUIZ\nRegistered Penn State students should return now to the Chapter 5 folder in ANGEL (via the Resources\nmenu to the left) to access the graded quiz for this chapter. This one counts. You may take graded\nquizzes only once.\nThe purpose of the quiz is to ensure that you have studied the text closely, that you have mastered\nthe practice activities, and that you have fulfilled the chapter\u2019s learning objectives. You are welcome to\nreview the chapter during the quiz.\nOnce you have submitted the quiz and posted any questions you may have to either our discussion\nforums or chapter pages, you will have completed Chapter 5.\nCOMMENTS AND QUESTIONS\nRegistered students are welcome to post comments, questions, and replies to questions about the\ntext. Particularly welcome are anecdotes that relate the chapter text to your personal or professional\nexperience. In addition, there are discussion forums available in the ANGEL course management system\nfor comments and questions about topics that you may not wish to share with the whole world.\nTo post a comment, scroll down to the text box under \u201cPost new comment\u201d and begin typing in the text\nbox, or you can choose to reply to an existing thread. When you are finished typing, click on either the\n\u201cPreview\u201d or \u201cSave\u201d button (Save will actually submit your comment). Once your comment is posted,\nyou will be able to edit or delete it as needed. In addition, you will be able to reply to other posts at any\ntime.\nNote: the first few words of each comment become its \u201ctitle\u201d in the thread.\n5.27. Bibliography\nBrinker, R. C. & Wolf, P. R. (1984). Elementary surveying (7th ed.). New York: Harper and Row.\nDana, P. H. (1998). Global positioning system overview. The geographer\u2019s craft project. Retrieved\nAugust 2, 1999, from http:\/\/www.colorado.edu\/geography\/gcraft\/notes\/gps\/gps_f.html\nDoyle, D. R. (1994). Development of the National Spatial Reference System. Retrieved Feburary 10,\n2008, fromhttp:\/\/www.ngs.noaa.gov\/PUBS_LIB\/develop_NSRS.html\nFederal Geodetic Control Committee (1988). Geometric geodetic accuracy standards and\nspecifications for using GPS relative positioning techniques. Retrieved February 10, 2008,\nfromhttp:\/\/www.ngs.noaa.gov\/FGCS\/tech_pub\/GeomGeod.pdf Retrieved September 14, 2013,\nfromhttp:\/\/docs.lib.noaa.gov\/noaa_documents\/NOS\/NGS\/Geom_Geod_Accu_Standards.pdf\nHall, G. W. (1996). USCG differential GPS navigation service. Retrieved November 9, 2005,\nfromhttp:\/\/www.navcen.uscg.gov\/pdf\/dgps\/dgpsdoc.pdf\nHodgson, C. V. Measuring base with invar tape. Tape underway. Base line and astro party, ca.\n1916. NOAA Historical Photo Collection (2004). Retrieved on April 20, 2006,\nfrom http:\/\/www.photolib.noaa.gov\/. 201 David DiBiase\nHurn, J. (1989). GPS: A guide to the next utility. Sunnyvale CA: Trimble Navigation Ltd.\nHurn, J. (1993). Differential GPS Explained. Sunnyvale CA: Trimble Navigation Ltd.\nMonmonier, M. (1995). Boundary litigation and the map as evidence. InDrawing the Line: Tales of\nMaps and Cartocontroversy. New York: Henry Holt.\nNational Geodetic Survey (n. d.). Retrieved November 4, 2009, fromhttp:\/\/www.ngs.noaa.gov\nNational Geodetic Survey (n.d.). National Geodetic Survey \u2013 CORS, Continuously Operating\nReference Station. Retrieved August 15, 2012, from http:\/\/www.ngs.noaa.gov\/CORS\/\nNAVSTAR GPS Joint Program Office. Retrieved October 21, 2000, fromhttp:\/\/gps.losangeles.af.mil\/\nNorse, E. T. (2004). Tracking new signals from space \u2013 GPS modernization and Trimble R-Track\nTechnology. Retrieved November 9, 2005, from http:\/\/www.trimble.com\/\nsurvey_wp_gpssys.asp?Nav=Collection-27596 Retrieved September 14, 2013,\nfromhttp:\/\/www.geosystems.co.nz\/drupal\/files\/u1\/images\/construction\/R-\nTrack_technology_and_GPS_Modernization.pdf\nRaisz, E. (1948). McGraw-Hill series in geography: General cartography(2nd ed.). York, PA: The\nMaple Press Company.\nRobinson, A. et al. (1995). Elements of cartography (5th ed.). New York: John Wiley & Sons.\nSmithsonian National Air and Space Museum (1998). GPS: A new constellation. Retrieved August 2,\n1999, fromhttp:\/\/www.nasm.si.edu\/gps\/\nSnay, R. (2005, September 13). CORS users forum\u2013towards real-time positioning. Power point\npresentation presented at the 2005 CORS Users Forum, Long Beach, CA. Presentation retrieved October\n26, 2005, fromhttp:\/\/www.ngs.noaa.gov\/CORS\/Presentations\/CORSForum2005\/\nRichard_Snay_Forum2005.pdf\nThompson, M. M. (1988). Maps for America, cartographic products of the U.S. Geological Survey\nand others (3d ed.). Reston, Va.: U.S. Geological Survey.\nU.S. Coast Guard Navigation Center (n .d.). DGPS general information. Retrieved February 10, 2008,\nfrom http:\/\/www.navcen.uscg.gov\/?pageName=dgpsMainwww.navcen.uscg.gov\/\nU.S. Federal Aviation Administration (2007a). Frequently asked questions. Retrieved February 10,\n2008, fromhttp:\/\/www.faa.gov\/about\/office_org\/headquarters_offices\/ato\/service_units\/techops\/\nnavservices\/gnss\/faq\/gps\/\nU.S. Federal Aviation Administration (2007b). Global Positioning System: How it works. Retrieved\nFebruary 10, 2008, fromhttp:\/\/www.faa.gov\/about\/office_org\/headquarters_offices\/ato\/service_units\/\ntechops\/navservices\/gnss\/gps\/howitworks\/\nU.S. Federal Aviation Administration. (2007c). Wide Area Augmentation System. Retrieved Feburary\n10, 2008, fromhttp:\/\/www.faa.gov\/about\/office_org\/headquarters_offices\/ato\/service_units\/techops\/\nnavservices\/gnss\/gps\/howitworks\/\nVan Sickle, J. (2001). GPS for land surveyors. New York: Taylor and Francis.\nVan Sickle, J. (2004). Basic GIS coordinates. Boca Raton: CRC Press.\nWolf, P. R. & Brinker, R. C. (1994). Elementary surveying (9th ed.). NY, NY: HarperCollins College\nPublisher.\nWormley, S. (2006). GPS errors and estimating your receiver\u2019s accuracy. Retrieved April 20, 2006,\nfrom http:\/\/www.edu-observatory.org\/gps\/gps_accuracy.html\nYeazel, J. (2006). WAAS and its relation to enabled hand-held GPS receivers. Retrieved October 12,\n2005, fromhttp:\/\/gpsinformation.net\/exe\/waas.html Chapter 6\n202 National Spatial Data Infrastructure I\nDavid DiBiase\n6.1. Overview\nChapters 6 and 7 consider the origins and characteristics of the framework data themes that make\nup the United States\u2019 proposed National Spatial Data Infrastructure (NSDI). The seven themes include\ngeodetic control, orthoimagery, elevation, transportation, hydrography, government units (administrative\nboundaries), and cadastral (property boundaries). Most framework data, like the printed topographic\nmaps that preceded them, are derived directly or indirectly from aerial imagery. Chapter 6\nintroduces the field of photogrammetry, which is concerned with the production of geographic data from\naerial imagery. The chapter begins by considering the nature and status of the U.S. NSDI in comparison\nwith other national mapping programs. It considers the origins and characteristics of the geodetic control\nand orthoimagery themes. The remaining five themes are the subject of Chapter 7.\nObjectives\nStudents who successfully complete Chapter 6 should be able to:\n1. Explain how the distribution of authority for mapping and land title registration among\nvarious levels of government affects the availability of framework data;\n2. Describe how topographic data are compiled from aerial imagery;\n3. Explain the difference between a vertical aerial photograph and an orthoimage;\n4. List and describe characteristics and status of the USGS National Map; and\n5. Discuss the relationship between the National Map and the NSDI framework.\nComments and Questions\nRegistered students are welcome to post comments, questions, and replies to questions about the\ntext. Particularly welcome are anecdotes that relate the chapter text to your personal or professional\nexperience. In addition, there are discussion forums available in the ANGEL course management system\nfor comments and questions about topics that you may not wish to share with the whole world.\nTo post a comment, scroll down to the text box under \u201cPost new comment\u201d and begin typing in the text\nbox, or you can choose to reply to an existing thread. When you are finished typing, click on either the\n\u201cPreview\u201d or \u201cSave\u201d button (Save will actually submit your comment). Once your comment is posted,\nyou will be able to edit or delete it as needed. In addition, you will be able to reply to other posts at any\ntime.\nNote: the first few words of each comment become its \u201ctitle\u201d in the thread.\n203 Nature of Geographic Information 204\n6.2. Checklist\nThe following checklist is for Penn State students who are registered for classes in which this text, and\nassociated quizzes and projects in the ANGEL course management system, have been assigned. You\nmay find it useful to print this page out first so that you can follow along with the directions. 205 David DiBiase\nChapter 6 Checklist (for registered students only)\nStep Activity Access\/Directions\nThis is the second page of the Chapter. Click on the links at the bottom\nof the page to continue or to return to the previous page, or to go to the\n1 Read Chapter 6\ntop of the chapter. You can also navigate the text via the links in the\nGEOG 482 menu on the left.\nSubmit two practice\nquizzes including:\n\u2022 National Spatial Data\nLegacies\nGo to ANGEL > [your course section] > Lessons tab > Chapter 6 folder\n2\n\u2022 Photogrammetry > [quiz]\nPractice quizzes are not graded\nand may be submitted more\nthan once.\nPerform \u201cTry this\u201d\nactivities including:\n\u2022 Compare data\ncopyright policies of\nthe U.S. and Britain\n\u2022 Search for USGS\ntopographic maps\nand aerial imagery\n\u2022 View and explore a\n3 digitally scanned Instructions are provided for each activity.\ntopographic map\n\u2022 View and explore a\ndigital orthophoto\n\u2022 Assess the\navailability of digital\northophotos for your\narea\n\u201cTry this\u201d activities are not\ngraded.\nSubmit the Chapter 6 Graded ANGEL > [your course section] > Lessons tab > Chapter 6 folder >\n4\nQuiz Chapter 6 Graded Quiz. See the Calendar tab in ANGEL for due dates.\nRead comments and\nquestionsposted by fellow Comments and questions may be posted on any page of the text, or in a\n5\nstudents. Add comments and Chapter-specific discussion forum in ANGEL.\nquestions of your own, if any. Nature of Geographic Information 206\n6.3. National Geographic Information Strategies\nIn 1998 Ian Masser published a comparative study of the national geographic information strategies of\nfour developed countries: Britain (England and Wales), the Netherlands, Australia, and the U.S. Masser\nbuilt upon earlier work which found that countries with relatively low levels of digital data availability\nand GIS diffusion also tended to be countries where there had been a fragmentation of data sources in the\nabsence of central or local government coordination\u201d (p. ix). Comparing his four case studies in relation\nto the seven framework themes identified for the U.S. NSDI, Masser found considerable differences in\ndata availability, pricing, and intellectual property protections. Differences in availability of core data,\nhe found, are explained by the ways in which responsibilities for mapping and for land titles registration\nare distributed among national, state, and local governments in each country.\nThe following table summarizes those distributions of responsibilities.\nDistributions of Responsibilities\nBritain (England &\nNetherlands Australia United States\nWales)\nLand titles registration, Land titles registration, Some small-scale\nCentral Small-scale mapping,\nsmall- and large-scale small- and large-scale mapping,\ngovernment statistical data\nmapping, statistical data mapping, statistical data statistical data\nLand titles Some land titles\nState\/\nregistration, small- registration and small-\nTerritorial Not applicable Not applicable\nand large-scale and large-scale\ngovernment\nmapping mapping\nLand titles\nLocal large-scale mapping, Some large-scale\nNone registration,\ngovernment population registers mapping\nlarge-scale mapping\nDistribution of responsibilities among different levels of government (Masser, 1998).\nMasser\u2019s analysis helps to explain what geospatial professionals in the U.S. have known all along \u2014\nthat the coverage of framework data in the U.S. is incomplete or fragmented because thousands of\nlocal governments are responsible for large-scale mapping and land titles registration, and because\nthese activities tend to be poorly coordinated. In contrast, core data coverage is more or less complete\nin Australia, the Netherlands, and Britain, where central and state governments have authority over\nlarge-scale mapping and land-titles registration.\nOther differences among the four countries relate to fees charged by governments to use the\ngeographic and statistical data they produce, as well as the copyright protections they assert over the\ndata. U.S. federal government agencies, Masser notes, differ from their counterparts by charging\nno more than the cost of reproducing their data in forms suitable for delivery to customers. State\nand local government policies in the U.S. vary considerably, however. Longstanding debates persist in\nthe U.S. about the viability and ethics of recouping costs associated with public data.\nThe U.S. also differs starkly from Britain and Australia in regards to copyright protection. Most data\npublished by the U.S. Geological Survey or U.S. Census Bureau resides in the public domain and may\nbe used without restriction. U.K. Ordnance Survey data, by contrast, is protected by Crown copyright,\nand is available for use by others for fees and under the terms of restrictive licensing agreements. One 207 David DiBiase\nconsequence of the federal government\u2019s decision to release its geospatial data to the public\ndomain, some have argued, was the early emergence of a vigorous geospatial industry in the U.S.\nTRY THIS!\nTo learn more about the Crown copyright policy of the Great Britain\u2019s Ordnance Survey, search the\nInternet for \u201cordnance survey crown copyright.\u201d\nThe USGS policy is explained here (or search on \u201cacknowledging usgs as information source\u201d)\n6.4. Legacy Data: USGS Topographic Maps\nSince the eighteenth century, the preparation of a detailed basic reference map has been recognized by the\ngovernments of most countries as fundamental for the delimitation of their territory, for underpinning their\nnational defense and for management of their resources (Parry, 1987).\nSpecialists in geographic information recognize two broad functional classes of maps, reference maps\nand thematic maps. As you recall from Chapter 3, a thematic map is usually made with one particular\npurpose in mind. Often, the intent is to make a point about the spatial pattern of a single\nphenomenon. Reference maps, on the other hand, are designed to serve many different purposes. Like\na reference book, such as a dictionary, encyclopedia, or gazetteer, reference maps help people look up\nfacts. Common uses of reference maps include locating place names and features, estimating distances,\ndirections, and areas, and determining preferred routes from starting points to a destination. Reference\nmaps are also used as base maps upon which additional geographic data can be compiled. Because\nreference maps serve various uses, they typically include a greater number and variety of symbols and\nnames than thematic maps. The portion of the United States Geological Survey (USGS) topographic\nmap shown below is a good example. Nature of Geographic Information 208\nA typical reference map. A portion of a USGS topographic quadrangle map (USGS, 1971)\nThe term topography derives from the Greek topographein, \u201cto describe a place.\u201d Topographic maps\nshow, and name, many of the visible characteristics of the landscape, as well as political and\nadministrative boundaries. Topographic map series provide base maps of uniform scale, content, and\naccuracy (more or less) for entire territories. Many national governments include agencies responsible\nfor developing and maintaining topographic map series for a variety of uses, from natural resource\nmanagement to national defense. Affluent countries, countries with especially valuable natural\nresources, and countries with large or unusually active militaries, tend to be mapped more completely\nthan others.\nThe systematic mapping of the entire U.S. began in 1879, when the U.S. Geological Survey (USGS)\nwas established. Over the next century USGS and its partners created topographic map series at several\nscales, including 1:250,000, 1:100,000, 1:63,360, and 1:24,000. The diagram below illustrates the\nrelative extents of the different map series. Since much of today\u2019s digital map data was digitized from\nthese topographic maps, one of the challenges of creating continuous digital coverage of the entire U.S.\nis to seam together all of these separate map sheets. 209 David DiBiase\nRelative extents of the several USGS quadrangle map series. (Thompson, 1988).\nMap sheets in the 1:24,000-scale series are known as quadrangles or simply quads. A quadrangle is a\nfour-sided polygon. Although each 1:24,000 quad covers 7.5 minutes longitude by 7.5 minutes latitude,\ntheir shapes and area coverage vary. The area covered by the 7.5-minute maps varies from 49 to 71\nsquare miles (126 to 183 square kilometers), because the length of a degree of longitude varies with\nlatitude. Nature of Geographic Information 210\nTopographer compiling topographic map using a plane table and alidade (NOAA, 2007).\nThrough the 1940s, topographers in the field compiled by hand the data depicted on\ntopographic maps. Anson (2002) recalls being outfitted with a 14 inch x 14 inch tracing table and\ntripod, plus an alidade [a 12 inch telescope mounted on a brass ruler], a 13 foot folding stadia rod,\na machete, and a canteen\u2026 (p. 1). Teams of topographers sketched streams, shorelines, and other\nwater features; roads, structures, and other features of the built environment; elevation contours, and\nmany other features. To ensure geometric accuracy, their sketches were based upon geodetic control\nprovided by land surveyors, as well as positions and spot elevations they surveyed themselves using\nalidades and rods. Depending on the terrain, a single 7.5-minute quad sheet might take weeks or\nmonths to compile. In the 1950s, however, photogrammetric methodsinvolving stereoplotters that\npermitted topographers to make accurate stereoscopic measurements directly from overlapping pairs of\naerial photographs provided a viable and more efficient alternative to field mapping. We\u2019ll consider\nphotogrammetry in greater detail later on in this chapter.\nBy 1992 the series of over 53,000 separate quadrangle maps covering the lower 48 states, Hawaii, and\nU.S. territories at 1:24,000 scale was completed, at an estimated total cost of $2 billion. However, by\nthe end of the century the average age of 7.5-minute quadrangles was over 20 years, and federal budget\nappropriations limited revisions to only 1,500 quads a year (Moore, 2000). As landscape change has\nexceeded revisions in many areas of the U.S., the USGS topographic map series has become legacy data\noutdated in terms of format as well as content. 211 David DiBiase\nTRY THIS!\nSearch the Internet on \u201cUSGS topographic maps\u201d to investigate the history and characteristics of USGS\ntopographic maps in greater depth. View preview images, look up publication and revision dates, and\norder topographic maps at \u201cUSGS Store.\u201d\n6.5. Accuracy Standards\nErrors and uncertainty are inherent in geographic data. Despite the best efforts of the USGS\nMapping Division and its contractors, topographic maps include features that are out of place, features\nthat are named or symbolized incorrectly, and features that are out of date.\nAs discussed in Chapter 2, the locational accuracy of spatial features encoded in USGS topographic\nmaps and data are guaranteed to conform to National Map Accuracy Standards. The standard for\ntopographic maps state that horizontal positions of 90 percent of the well-defined points tested will occur\nwithin 0.02 inches (map distance) of their actual positions. Similarly, the vertical positions of 90 percent\nof well-defined points tested are to be true to within one-half of the contour interval. Both standards,\nremember, are scale-dependent.\nObjective standards do not exist for the accuracy of attributes associated with geographic features.\nAttribute errors certainly do occur, however. A chronicler of the national mapping program (Thompson,\n1988, p. 106) recalls a worried user who complained to USGS that \u201cMy faith in map accuracy received\na jolt when I noted that on the map the borough water reservoir is shown as a sewage treatment plant.\u201d\nThe passage of time is perhaps the most troublesome source of errors on topographic maps. As\nmentioned in the previous page, the average age of USGS topographic maps is over 20 years.\nGeographic data quickly lose value (except for historical analyses) unless they are continually revised.\nThe sequence of map fragments below shows how frequently revisions were required between 1949 and\n1973 for the quad that covers Key Largo, Florida. Revisions are based primarily on geographic data\nproduced by aerial photography.\nGeographic data quickly lose value if they are not kept up to date. (Thompson, 1988). Select each\nof the years to view the revised map. Note: You need to have the Adobe Flash player installed in order\nto see and interact with this illustration. You can download Flash Player free athttp:\/\/www.adobe.com\/\nflash.\nTRY THIS!\nInvestigate standards for data quality and other characteristics of U.S. national map data here or by\nsearching the Internet for \u201cusgs national map accuracy standards\u201d\n6.6. Scanned Topographic Maps\nMany digital data products have been derived from the USGS topographic map series. The simplest of\nsuch products are Digital Raster Graphics(DRGs). DRGs are scanned raster images of USGS 1:24,000\ntopographic maps. DRGs are useful as backdrops over which other digital data may be superimposed.\nFor example, the accuracy of a vector file containing lines that represent lakes, rivers, and streams could\nbe checked for completeness and accuracy by plotting it over a DRG. Nature of Geographic Information 212\nPortion of a Digital Raster Graphic (DRG) for Bushkill, PA\nDRGs are created by scanning paper maps at 250 pixels per inch resolution. Since at 1:24,000 1 inch\non the map represents 2,000 feet on the ground, each DRG pixel corresponds to an area about 8 feet (2.4\nmeters) on a side. Each pixel is associated with a single attribute: a number from 0 to 12. The numbers\nstand for the 13 standard DRG colors.\nMagnified portion of a Digital Raster Graphic (DRG) for Bushkill, PA\nLike the paper maps from which they are scanned, DRGs comply withNational Map Accuracy 213 David DiBiase\nStandards. A subset of the more than 50,000 DRGs that cover the lower 48 states have been sampled and\ntested for completeness and positional accuracy.\nDRGs conform to the Universal Transverse Mercator projection used in the local UTM zone. The\nscanned images are transformed to the UTM projection by matching the positions of 16 control points.\nLike topographic quadrangle maps, all DRGs within one UTM zone can be fit together to form a mosaic\nafter the map \u201ccollars\u201d are removed.\nTo investigate DRGs in greater depth, visit the USGS Topomaps website or search the Internet on\n\u201cUSGS Digital Raster Graphics\u201d\nTRY THIS!\nEXPLORE A DRG WITH GLOBAL MAPPER (DLGV32 PRO)\nYou can use a free software application called Global Mapper (also known as dlgv32 Pro) to\ninvestigate the characteristics of a USGS Digital Raster Graphic. Originally developed by the staff of\nthe USGS Mapping Division at Rolla, Missouri as a data viewer for USGS data, Global Mapper has\nsince been commercialized, but is available in a free trial version. The instructions below will guide you\nthrough the process of installing the software and opening the DRG data. Penn State students will later\nbe asked questions that will require you to explore the data for answers.\nNote: Global Mapper is a Windows application and will not run under the Macintosh operating system.\nThe questions asked of Penn State students that involve the use of Global Mapper are not graded.\nGLOBAL MAPPER (DLGV32 PRO) INSTALLATION INSTRUCTIONS\nSkip this step if you already downloaded and installed Global Mapper or dlgv32 Pro.\n1. Navigate to globalmapper.com or search the Internet for \u201cGlobal Mapper\u201d or \u201cdlgv32 Pro\u201d\n2. Download the trial version of the software.\n3. Double-click on the setup file you downloaded to install the program.\n4. Launch Global Mapper or dlgv32 Pro.\nDOWNLOADING AND EXPLORING DRG DATA IN GLOBAL MAPPER\n1. First, create a directory called \u201cUSGS Data\u201d on your hard disk, where you can file your\ncourse materials if you haven\u2019t done so already.\n2. Download the DRG.zip data archive. The ZIP archive is 2.7 Mb in size and will take\napproximately 35 seconds to download via high speed DSL or cable, or about 9 minutes and\n35 seconds minutes via 56 Kbps modem. Registered Penn State students who cannot\ndownload the file should contact their assigned teaching assistant for help.\n3. Now decompress the archive into a directory on your hard disk.\n\u25e6 Open the ZIP archive you downloaded.\n\u25e6 Extract all files in the ZIP archive into a known subdirectory.\nThe result will be five files that make up one Digital Raster Graphic. Nature of Geographic Information 214\n1. Open your DRG in Global Mapper\n\u25e6 Choose File > Open Data File(s)\u2026, then navigate to the subdirectory into which\nyou extracted the DRG files.\n\u25e6 Open the file \u2018bushkill_pa.tif\u2019\nThe DRG data correspond with the 7.5 minute quadrangle for Bushkill, PA.\n1. Notice that as you glide the magnifying glass cursor over the DRG, the UTM (NAD 27)\nand geographic coordinates of the cursor\u2019s position change in the lower right-hand corner of\nthe window. This tells you that the DRG is in fact georeferenced.\n2. Experiment with Global Mapper\u2019s tools. Use the Zoom and Pan tools to magnify and scroll\nacross the DRG. The Full View button (the one with the house icon) refreshes the initial full\nview of the data set.\n3. The Measure tool (ruler icon) allows you to not only measure distance as the crow flies, but\nalso to see the area enclosed by a series of line segments drawn by repeated mouse clicks.\nNote again the location information that is given to you near the bottom of the application\nwindow.\nCertain tools, e.g., the 3D Path Profile\/Line of Sight tool are not functional in the free (unregistered)\nversion of Global Mapper.\n1. To view an excerpt from the DRG metadata, navigate to Tools > Control Center, then click\nthe Metadata button.\n6.7. Federal Geographic Data Committee\nEven before the USGS completed its nationwide 7.5-minute quadrangle series, the U.S. federal\ngovernment had begun to rethink and reorganize its national mapping program. In 1990 the U.S. Office\nof Management and Budget issued Circular A-16, which established the Federal Geographic Data\nCommittee (FGDC) as the interagency coordinating body responsible for facilitating cooperation among\nfederal agencies whose missions include producing and using geospatial data. FGDC is chaired by the\nDepartment of Interior, and is administered by USGS.\nIn 1994 President Bill Clinton\u2019s Executive Order 12906 charged the FGDC with coordinating the\nefforts of government agencies and private sector firms leading to a National Spatial Data\nInfrastructure (NSDI). The Order defined NSDI as \u201cthe technology, policies, standards and human\nresources necessary to acquire, process, store, distribute, and improve utilization of geospatial data\u201d\n(White House, 1994). It called upon FGDC to establish a National Geospatial Data Clearinghouse,\nordered federal agencies to make their geospatial data products available to the public through the\nClearinghouse, and required them to document data in a standard format that facilitates Internet search.\nAgencies were required to produce and distribute data in compliance with standards established by\nFGDC. (The Departments of Defense and Energy were exempt from the order, as was the Central\nIntelligence Agency.)\nFinally, the Order charged FGDC with preparing an implementation plan for a National Digital\nGeospatial Data Framework, the \u201cdata backbone of the NSDI\u201d (FGDC, 1997, p. v). The seven core data\nthemes that comprise the NSDI Framework are listed below, along with the government agencies that 215 David DiBiase\nhave lead responsibility for creating and maintaining each theme. Later on in this chapter, and in the one\nthat follows, we\u2019ll investigate the framework themes one by one.\nNSDI Framework\nDepartment of Commerce, National Oceanographic and Atmospheric\nGeodetic Control\nAdministration, National Geodetic Survey\nOrthoimagery Department of Interior, U.S. Geological Survey\nElevation Department of Interior, U.S. Geological Survey\nTransportation Department of Transportation\nHydrography Department of Interior, U.S. Geological Survey\nAdministrative units\nDepartment of Commerce, U.S. Census Bureau\n(boundaries)\nCadastral Department of Interior, Bureau of Land Management\nSeven data themes that comprise the NSDI Framework and the government agencies responsible for\neach.\n6.8. USGS National Map\nExecutive Order 12906 decreed that a designee of the Secretary of the Department of Interior would\nchair the Federal Geographic Data Committee. The USGS, an agency of the Department of Interior,\nhas lead responsibility for three of the seven NSDI framework themes\u2013orthoimagery, elevation, and\nhydrography, and secondary responsibility for several others. In 2001, USGS announced its vision of a\nNational Map that \u201caligns with the goals of, and is one of several USGS activities that contribute to,\nthe National Spatial Data Infrastructure\u201d (USGS, 2001, p. 31). A 2002 report of the National Research\nCouncil identified the National Map as the most important initiative of USGS\u2019 Geography Discipline\nat the USGS (NRC, 2002). Recognizing its unifying role across its science disciplines, USGS moved\nmanagement responsibility for the National Map from Geography to the USGS Geospatial Information\nOffice in 2004. (One reason that the term \u201cgeospatial\u201d is used at USGS and elsewhere is to avoid\nassociation of GIS with a particular discipline, i.e. Geography.)\nIn 2001, USGS envisioned the National Map as the Nation\u2019s topographic map for the 21st Century\n(USGS, 2001, p.1). Improvements over the original topographic map series were to include: Nature of Geographic Information 216\nCharacteristics of the National Map\nContent will be updated on the basis of changes in the landscape instead of the cyclical\nCurrentness inspection and revisions cycles now in use [for printed topographic map series]. The ultimate\ngoal is that new content be incorporated with seven days of a change in the landscape.\nFeatures will be represented in their entirety and not interrupted by arbitrary edges, such as\nSeamlessness\n7.5-minute map boundaries.\nConsistent Types of features, such as \u201croad\u201d and \u201clake\/pond,\u201d will be identified in the same way\nclassification throughout the Nation.\nData resolution, or pixel size, may vary among imagery of urban, rural, and wilderness areas.\nVariable\nThe resolution of elevation data may be finer for flood plain, coastal, and other areas of low\nresolution\nrelief than for areas of high relief.\nData content will include all mappable features (as defined by the applicable content standards\nCompleteness\nfor each data theme and source).\nConsistency Content will be delineated geographically (that is, in its true ground position within the\nand applicable accuracy limit) to ensure logical consistency between related features. For example,\nintegration \u2026 streams and rivers [should] consistently flow downhill\u2026\nVariable The minimum positional accuracy will be that of the current primary topographic map series for\npositional an area. Actual positional accuracy will be reported in conformance with the Federal\naccuracy Geographic Data Committee\u2019s Geospatial Positioning Accuracy Standard.\nSpatial\nTools will be provided to integrate data that are mapping using different datums and referenced\nreference\nto different coordinates systems, and to reproject data to meet user requirements.\nsystems\nStandardized \u2026will conform to appropriate Federal Geographic Data Committee, other national, and\/or\ncontent international standards.\nAt a minimum, metadata will meet Federal Geographic Data Committee standards to document\nMetadata\n\u2026 [data] lineage, positional and attribute accuracy, completeness, and consistency.\nCharacteristics of the National Map (USGS, 2001, p. 11-13.)\nAs of 2008, USGS\u2019 ambitious vision has not yet been fully realized.Insofar as it depends upon\ncooperation by many federal, state and local government agencies, the vision may never be fully\nachieved. Still, elements of a National Map do exist, including national data themes, data access and\ndissemination technologies such as the Geospatial One Stop portal and the National Map viewer, and\nthe U.S. National Atlas. A new Center of Excellence for Geospatial Information Science (CEGIS)\nhas been established under the USGS Geospatial Information Office to undertake the basic GIScience\nresearch needed to devise and implement advanced tools that will make the National Map more valuable\nto end users.\nThe data themes included in the National Map are shown in the following table, in comparison to\nthe NSDI framework themes outlined earlier in this chapter. As you see, the National Map themes\nalign with five of the seven framework themes, but do not include geodetic control and cadastral data.\nAlso, the National Map adds land cover and geographic names, which are not included among the\nNSDI framework themes. Given USGS\u2019 leadership role in FGDC, why do the National Map themes\ndeviate from the NSDI framework? According to the Committee on Research Priorities for the USGS\nCenter of Excellence for Geospatial Science, \u201cthese themes were selected because USGS is authorized 217 David DiBiase\nto provide them if no other sources are available, and [because] they typically comprise the information\nportrayed on USGS topographic maps (NRC, 2007, p. 31).\nData Themes\nNational Map Themes NSDI Framework Themes\nGeodetic Control No Yes\nOrthoimagery Yes Yes\nLand Cover Yes No\nElevation Yes Yes\nTransportation Yes Yes\nHydrography Yes Yes\nBoundaries Yes Yes\nStructures Yes No\nCadastral No Yes\nGeographic Names Yes No\nComparison of data themes included in the National Map and NSDI framework.\nThe following sections of this chapter, and the one that follows, will describe the derivation,\ncharacteristics, and status of the seven NSDI themes in relation to the National Map. Chapter 8,\nRemotely Sensed Image Data, will include a description of the National Land Cover Data program that\nprovides the land cover theme of the National Map. Registered students used the USGS Geographic\nInformation Names Information System for a project assignment.\n6.9. Theme: Geodetic Control\nIn the U.S. the National Geodetic Survey (NGS) maintains a national geodetic control network called\nthe National Spatial Reference System (NSRS). The NSRS includes approximately 300,000 horizontal\nand 600,000 vertical control points (Doyle, 1994). High-accuracy control networks are needed for\nmapping projects that span large areas; to design and maintain interstate transportation corridors\nincluding highways, pipelines, and transmission lines; and to monitor tectonic movements of the Earth\u2019s\ncrust and sea level changes, among other applications (FGDC, 1998a).\nSome control points are more accurate than others, depending on the methods surveyors used to\nestablish them. The Chapter 5 page titled \u201cSurvey Control\u201d outlines the accuracy classification adopted\nin 1988 for control points in the NSRS. As geodetic-grade GPS technology has become affordable for\nsurveyors, expectations for control network accuracy have increased. In 1998, the FGDC\u2019s Federal\nGeodetic Control Subcommittee published a set of Geospatial Positioning Accuracy Standards. One\nof these is the Standards for Geodetic Networks (FGDC, 1998a). The table below presents the latest\naccuracy classification for horizontal coordinates and heights (ellipsoidal and orthometric). For example,\nthe theoretically infinitesimal location of a horizontal control point classified as \u201c1-Millimeter\u201d must\nhave a 95% likelihood of falling within a 1 mm \u201cradius of uncertainty\u201d (FGDC, 1998b, 1-5). Nature of Geographic Information 218\nAccuracy Classifications\nAccuracy Classification Radius of Uncertainty (95% confidence)\n1-Millimeter 0.001 meters\n2-Millimeter 0.002 meters\n5-Millimeter 0.005 meters\n1-Centimeter 0.010 meters\n2-Centimeter 0.020 meters\n5-Centimeter 0.050 meters\n1-Decimeter 0.100 meters\n2-Decimeter 0.200 meters\n5-Decimeter 0.500 meters\n1-Meter 1.000 meters\n2-Meter 2.000 meters\n5-Meter 5.000 meters\n10-Meter 10.000 meters\nAccuracy classification for geodetic control networks (FGDC, 1998).\nIf in Chapter 2 you retrieved a NGS datasheet for a control point, you probably found that the accuracy\nof your point was reported in terms of the 1988 classification. If yours was a \u201cfirst order\u201d (C) control\npoint, its accuracy classification is 1 centimeter. NGS does plan to upgrade the NSRS, however. Its\n10-year strategic plan states that \u201cthe geodetic latitude, longitude and height of points used in defining\nNSRS should have an absolute accuracy of 1 millimeter at any time\u201d (NGS, 2007, 8).\nTHINK ABOUT IT\nWhy does the 1998 standard refer to absolute accuracies while the 1988 standard (outlined in Chapter\n5) is defined in terms of maximum error relative to distance between two survey points? What changed\nbetween 1988 and 1998 in regard to how control points are established?\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 6 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about National Spatial Data Legacies. You may take\npractice quizzes as many times as you wish. They are not scored and do not affect your grade in any\nway. 219 David DiBiase\n6.10. Theme: Orthoimagery\nThe Federal Geographic Data Committee (FGDC, 1997, p. 18) definesorthoimage as \u201ca georeferenced\nimage prepared from an aerial photograph or other remotely sensed data \u2026 [that] has the same\nmetric properties as a map and has a uniform scale.\u201d Unlike orthoimages, the scale of ordinary aerial\nimages varies across the image, due to the changing elevation of the terrain surface (among other\nthings). The process of creating an orthoimage from an ordinary aerial image is\ncalled orthorectification. Photogrammetrists are the professionals who specialize in creating\northorectified aerial imagery, and in compiling geometrically-accurate vector data from aerial images.\nSo, to appreciate the requirements of the orthoimagery theme of the NSDI framework, we first need to\ninvestigate the field of photogrammetry.\n6.11. Photogrammetry\nPhotogrammetry is a profession concerned with producing precise measurements of objects from\nphotographs and photoimagery. One of the objects measured most often by photogrammetrists is the\nsurface of the Earth. Since the mid-20th century, aerial images have been the primary source of data used\nby USGS and similar agencies to create and revise topographic maps. Before then, topographic maps\nwere compiled in the field using magnetic compasses, tapes, plane tables (a drawing board mounted on\na tripod, equipped with an leveling telescope like a transit), and even barometers to estimate elevation\nfrom changes in air pressure. Although field surveys continue to be important for establishing horizontal\nand vertical control, photogrammetry has greatly improved the efficiency and quality of topographic\nmapping.\nA straight line between the center of a lens and the center of a visible scene is called an optical\naxis. A vertical aerial photograph is a picture of the Earth\u2019s surface taken from above with a camera\noriented such that its optical axis is vertical. In other words, when a vertical aerial photograph is exposed\nto the light reflected from the Earth\u2019s surface, the sheet of photographic film (or an digital imaging\nsurface) is parallel to the ground. In contrast, an image you might create by snapping a picture of the\nground below while traveling in an airplane is called an oblique aerial photograph, because the camera\u2019s\noptical axis forms an oblique angle with the ground. Nature of Geographic Information 220\nA vertical aerial photograph (National Aerial Photography Program, June 28, 1994).\nThe nominal scale of a vertical air photo is equivalent to f \/ H, where f is the focal length of the\ncamera (the distance between the camera lens and the film \u2014 usually six inches), and H is the flying\nheight of the aircraft above the ground. It is possible to produce a vertical air photo such that scale is\nconsistent throughout the image. This is only possible, however, if the terrain in the scene is absolutely\nflat. In rare cases where that condition is met, topographic maps can be compiled directly from vertical\naerial photographs. Most often however, air photos of variable terrain need to be transformed, or\nrectified, before they can be used as a source for mapping.\nGovernment agencies at all levels need up-to-date aerial imagery. Early efforts to sponsor complete\nand recurring coverage of the U.S. included the National Aerial Photography Program, which replaced\nan earlier National High Altitude Photography program in 1987. NAPP was a consortium of federal\ngovernment agencies that aimed to jointly sponsor vertical aerial photography of the entire lower\n48 states every seven years or so at an altitude of 20,000 feet, suitable for producing topographic\nmaps at scales as large as 1:5,000. More recently NAPP has been eclipsed by another consortium\ncalled the National Agricultural Imagery Program. According to student Anne O\u2019Connor (personal\ncommunication, Spring 2004), who represented the Census Bureau in the consortium\nA large portion of the country is flown yearly in the NAIP program due to USDA compliance needs. One\nproblem is that it is leaf on, therefore in areas of dense foliage, some features are obscured. NAIP imagery\nis produced using partnership funds from USDA, USGS, FEMA, BLM, USFS and individual states. Other\npartnerships (between agencies or an agency and state) are also developed depending upon agency and local\nneeds.\nAerial photography missions involve capturing sequences of overlapping images along many parallel\nflight paths. In the portion of the air photo mosaic shown below, note that the photographs overlap one\nanother end to end, and side to side. This overlap is necessary for stereoscopic viewing, which is the\nkey to rectifying photographs of variable terrain. It takes about 10 overlapping aerial photographs taken\nalong two adjacent north-south flightpaths to provide stereo coverage for a 7.5-minute quadrangle. 221 David DiBiase\nPortion of a mosaic of overlapping vertical aerial photographs. (United States Department of\nAgriculture, Commodity Stabilization Service, n.d.).\nTRY THIS!\nUse the USGS\u2019 EarthExplorer (http:\/\/earthexplorer.usgs.gov\/) to identify the vertical aerial photograph\nthat shows the \u201cpopulated place\u201d in which you live. How old is the photo? (EarthExplorer is part of a\nUSGS data distribution system.)\nNote: The Digital Orthophoto backdrop that EarthExplorer allows you to view is not the same as the\nNAPP photos the system allows you to identify and order. By the end of this lesson, you should know\nthe difference! If you don\u2019t, use the Chapter 6 Discussion Forum to ask.\n6.12. Perspective and Planimetry\nTo understand why topographic maps can\u2019t be traced directly off of most vertical aerial photographs,\nyou first need to appreciate the difference between perspective and planimetry. In a perspective view, all\nlight rays reflected from the Earth\u2019s surface pass through a single point at the center of the camera lens.\nA planimetric (plan) view, by contrast, looks as though every position on the ground is being viewed\nfrom directly above. Scale varies in perspective views. In plan views, scale is everywhere consistent\n(if we overlook variations in small-scale maps due to map projections). Topographic maps are said to\nbe planimetrically correct. So are orthoimages. Vertical aerial photographs are not, unless they happen\nto be taken over flat terrain.\nAs discussed above, the scale of an aerial photograph is partly a function of flying height. Thus,\nvariations in elevation cause variations in scale on aerial photographs. Specifically, the higher the\nelevation of an object, the farther the object will be displaced from its actual position away from the\nprincipal point of the photograph (the point on the ground surface that is directly below the camera\nlens). Conversely, the lower the elevation of an object, the more it will be displaced toward the principal Nature of Geographic Information 222\npoint. This effect, called relief displacement, is illustrated in the diagram below. Note that the effect\nincreases with distance from the principal point.\nRelief displacement is scale variation on aerial photographs caused by variations in terrain elevation.\nAt the top of the diagram above, light rays reflected from the surface converge upon a single point at\nthe center of the camera lens. The smaller trapezoid below the lens represents a sheet of photographic\nfilm. (The film actually is located behind the lens, but since the geometry of the incident light is\nsymmetrical, we can minimize the height of the diagram by showing a mirror image of the film below\nthe lens.) Notice the four triangular fiducial marks along the edges of the film. The marks point to\nthe principal point of the photograph, which corresponds with the location on the ground directly below\nthe camera lens at the moment of exposure. Scale distortion is zero at the principal point. Other\nfeatures shown in the photo may be displaced toward or away from the principal point, depending on\nthe elevation of the terrain surface. The larger trapezoid represents the average elevation of the terrain\nsurface within a scene. On the left side of the diagram, a point on the land surface at a higher than\naverage elevation is displaced outwards, away from the principal point and its actual location. On the\nright side, another location at less than average elevation is displaced towards the principal point. As\nterrain elevation increases, flying height decreases and photo scale increases. As terrain elevation\ndecreases, flying height increases and photo scale decreases.\nCompare the map and photograph below. Both show the same gas pipeline, which passes through hilly\nterrain. Note the deformation of the pipeline route in the photo relative to the shape of the route on the\ntopographic map. The deformation in the photo is caused by relief displacement. The photo would\nnot serve well on its own as a source for topographic mapping. 223 David DiBiase\nThe pipeline clearing appears crooked in the photograph because of relief displacement.\nStill confused? Think of it this way: where the terrain elevation is high, the ground is closer to the\naerial camera, and the photo scale is a little larger than where the terrain elevation is lower. Although the\naltitude of the camera is constant, the effect of the undulating terrain is to zoom in and out. The effect\nof continuously-varying scale is to distort the geometry of the aerial photo. This effect is called relief\ndisplacement.\nDistorted perspective views can be transformed into plan views through a process called rectification.\nIn a Discussion Forum posting during the Summer 2001 offering of this class, student Joel Hamilton\nrecounted one very awkward way to rectify aerial photographs:\n\u201cBack in the mid 80\u2032s I saw a very large map being created from a multitude of aerial photos being fitted\ntogether. A problem that arose was that roads did not connect from one photo to the next at the outer edges of\nthe map. No computers were used to create this map. So using a little water to wet the photos on the outside of\nthe map, the photos were streched to correct for the distortions. Starting from the center of the map the mosaic\nmap was created. A very messy process.\u201d\nNowadays, digital aerial photographs can be rectified in an analogous (but much less messy) way, using\nspecialized photogrammetric software that shifts image pixels toward or away from the principal point of\neach photo in proportion to two variables: the elevation of the point of the Earth\u2019s surface at the location\nthat corresponds to each pixel, and each pixel\u2019s distance from the principal point of the photo.\nAnother even simpler way to rectify perspective images is to view pairs of images stereoscopically.\n6.13. Stereoscopy\nIf you have normal or corrected vision in both eyes, your view of the world is stereoscopic. Viewing\nyour environment simultaneously from two slightly different perspectives enables you to estimate very\naccurately which objects in your visual field are nearer, and which are farther away. You know this\nability as depth perception. Nature of Geographic Information 224\nWhen you fix your gaze upon an object, the intersection of your two optical axes at the object form\nwhat is called a parallactic angle. On average, people can detect changes as small as 3 seconds in the\nparallactic angle, an angular resolution that compares well to transits and theodolites. The keenness of\nhuman depth perception is what makes photogrammetric measurements possible.\nYour perception of a three-dimensional environment is produced from two separate two-dimensional\nimages. The images produced by your eyes are analogous to two aerial images taken one after another\nalong a flight path. Objects that appear in the area of overlap between two aerial images are seen from\ntwo different perspectives. A pair of overlapping vertical aerial images is called a stereopair. When a\nstereopair is viewed such that each eye sees only one image, it is possible to envision a three-dimensional\nimage of the area of overlap.\nIn the following page you\u2019ll find a couple of examples of how stereoscopy is used to create\nplanimetrically-correct views of the Earth\u2019s surface. If you have anaglyph stereo (red\/blue) glasses,\nyou\u2019ll be able to see stereo yourself. First, let\u2019s practice viewing anaglyph stereo images.\nTRY THIS!\nOne way to see in stereo is with an instrument called a stereoscope (see examples at James Madison\nUniversity\u2019s Spatial Information Clearinghouse). Another way that works on computer screens and\ndoesn\u2019t require expensive equipment is called anaglyph stereo (anaglyph comes from a Greek word that\nmeans, \u201cto carve in relief\u201d). The anaglyph method involves special glasses in which the left and right\neyes are covered by blue and red filters. CPGIS\/MGIS registered through the World Campus received\nanaglyph glasses along with your welcome letters. Penn State students registered at University Park or\nother campuses should contact their instructor to determine if glasses are available.\nThe anaglyph image shown below consists of a superimposed stereopair in which the left image is\nshown in red, and the right image is shown in green and blue. The filters in the glasses ensure the each\neye sees only one image. Can you make out the three-dimensional image of the U-shaped valley formed\nby glaciers in the French Alps? 225 David DiBiase\nAnaglyph stereopair by Pierre Gidon showing a scene in the French Alps (the image is used by\npermission of the author). Requires red\/blue glasses.\nHow about this one: a panorama of the surface of Mars imaged during the Pathfinder mission, July\n1997? Nature of Geographic Information 226\n(NASA, 1997). Image processing and mosaic by Tim Parker.\nTo find other stereo images on the World Wide Web, search on \u201canaglyph.\u201d\n6.14. Rectification by Stereoscopy\nAerial images need to be transformed from perspective views into plan views before they can be used to\ntrace the features that appear on topographic maps, or to digitize vector features in digital data sets. One\nway to accomplish the transformation is through stereoscopic viewing.\nBelow are portions of a vertical aerial photograph and a topographic map that show the same area,\na synclinal ridge called \u201cLittle Mountain\u201d on the Susquehanna River in central Pennsylvania. A linear\nclearing, cut for a power line, appears on both (highlighted in yellow on the map). The clearing appears\ncrooked on the photograph due to relief displacement. Yet we know that an aerial image like this one\nwas used to compile the topographic map. The air photo had to have been rectified to be used as a\nsource for topographic mapping. 227 David DiBiase\nThe deformation of the powerline clearing shown in the air photo is caused by relief displacement.\n(USGS. \u201cHarrisburg East Quadrangle, Pennsylvania\u201d)\nBelow are portions of two aerial photographs showing Little Mountain. The two photos were taken\nfrom successive flight paths. The two perspectives can be used to create a stereopair.\nA stereopair: two air photos of the same area taken from different points of view. Nature of Geographic Information 228\nNext, the stereopair is superimposed in an anaglyph image. Using your red\/blue glasses, you should\nbe able to see a three-dimensional image of Little Mountain in which the power line appears straight, as\nit would if you were able to see it in person. Notice that the height of Little Mountain is exaggerated due\nto the fact that the distance between the principal points of the two photos is not exactly proportional to\nthe distance between your eyes.\nAn anaglyph (red\/blue) stereo image that fuses the stereopair shown in the above figure. When viewed\nwith a red filter over the left eye and a cyan (blue) filter over the right eye, a sterescopic image is formed.\nNotice that the powerline clearing, which appears crooked in both air photos, appears straight in the\nstereoscopic image. (USGS. \u201cHarrisburg East Quadrangle, Pennsylvania\u201d)\nLet\u2019s try that again. We need to make sure that you can visualize how stereoscopic viewing transforms\noverlapping aerial photographs from perspective views into planimetric views. The aerial photograph\nand topographic map portions below show the same features, a power line clearing crossing the\nSinnemahoning Creek in Central Pennsylvania. The power line appears to bend as it descends to the\ncreek because of relief displacement. 229 David DiBiase\nThe deformation of the powerline clearing shown in the air photo is caused by relief displacement.\n(USGS. \u201cKeating Quadrangle, Pennsylvania\u201d).\nTwo aerial photographs of the same area taken from different perspectives constitute a stereo pair.\nA stereopair, two air photos of the same area taken from different points of view.\nBy viewing the two photographs stereoscopically, we can transform them from two-dimensional Nature of Geographic Information 230\nperspective views to a single three-dimensional view in which the geometric distortions caused by relief\ndisplacement have been removed.\nDeformation caused by relief displacement is rectified when the air photos are viewed in stereo.\n(USGS. \u201cKeating Quadrangle, Pennsylvania\u201d).\nPhotogrammetrists use instruments called stereoplotters to trace, orcompile, the data shown on\ntopographic maps from stereoscopic images like the ones you\u2019ve seen here. The operator pictured\nbelow is viewing a stereoscopic model similar to the one you see when you view the anaglyph stereo\nimages with red\/blue glasses. A stereopair is superimposed on the right-hand screen of the operator\u2019s\nworkstation. The left-hand screen shows dialog boxes and command windows through which she\ncontrols the stereoplotter software. Instead of red\/blue glasses, the operator is wearing glasses with\npolarized lens filters that allow her to visualize a three-dimensional image of the terrain. She handles a\n3-D mouse that allows her to place a cursor on the terrain image within inches of its actual horizontal\nand vertical position. 231 David DiBiase\nMerri MacKay (graduate of the Penn State Certificate Program in GIS, and employee of BAE Systems\nADR), uses an analytic stereoplotter to digitize vertical and horizontal positions from a stereoscopic\nmodel. Photo circa 1998, used with permission of Ms. MacKay and ADR, Inc. When she encountered\nher picture as a student in the class in 2004, Merri wrote \u201cI\u2019ve got short hair and four grandkids now\u2026\u201d\n6.15. Orthorectification\nAn orthoimage (or orthophoto) is a single aerial image in which distortions caused by relief\ndisplacement have been removed. The scale of an orthoimage is uniform. Like a planimetrically correct\nmap, orthoimages depict scenes as though every point were viewed simultaneously from directly above.\nIn other words, as if every optical axis were orthogonal to the ground surface. Notice how the power\nline clearing has been straightened in the orthophoto on the right below. Nature of Geographic Information 232\nComparison of a vertical aerial photograph (left) and an orthophoto.\nRelief displacement is caused by differences in elevation. If the elevation of the terrain surface is\nknown throughout a scene, the geometric distortion it causes can be rectified. Since photogrammetry\ncan be used to measure vertical as well as horizontal positions, it can be used to create a collection of\nvertical positions called a terrain model. Automated procedures for transforming vertical aerial photos\ninto orthophotos require digital terrain models.\nSince the early 1990s, orthophotos have been commonly used as sources for editing and revising of\ndigital vector data.\n6.16. Metadata\nThrough the remainder of this Chapter and the next we\u2019ll investigate the particular data products that\ncomprise the framework themes of the U.S. National Spatial Data Infrastructure (NSDI). The format\nI\u2019ll use to discuss these data products reflects the Federal Geographic Data Committee\u2019sMetadata\nstandard (FGDC, 1998c). Metadata is data about data. It is used to document the content, quality,\nformat, ownership, and lineage of individual data sets. As the FGDC likes to point out, the most familiar\nexample of metadata is the \u201cNutrition Facts\u201d panel printed on food and drink labels in the U.S. Metadata\nalso provides the keywords needed to search for available data in specialized clearinghouses and in the\nWorld Wide Web.\nSome of the key headings included in the FGDC metadata standard include:\n1. Identification Information: Who created the data, a brief description of its content, form,\nand purpose; its status, spatial extent, and use restrictions;\n2. Data Quality Information: Accuracy and completeness of attributes, horizontal and vertical\npositions, sources, and procedures used to create the data; 233 David DiBiase\n3. Spatial Reference Information: Projection and\/or coordinate system; datum and ellipsoid;\n4. Entity and Attribute Information: Feature and attribute categories used; and\n5. Distribution Information: Availability, and how to acquire the data.\nFGDC\u2019s Content Standard for Digital Geospatial Metadata is published here. Geospatial\nprofessionals understand the value of metadata, know how to find it, and how to interpret it.\n6.17. Digital Orthophoto Quadrangle (DOQ)\nIDENTIFICATION\nDigital Orthophoto Quads (DOQs) are raster images of rectified aerial photographs. They are widely\nused as sources for editing and revising vector topographic data. For example, the vector roads data\nmaintained by businesses like NAVTEQ and Tele Atlas, as well as local and state government agencies,\ncan be plotted over DOQs then edited to reflect changes shown in the orthoimage.\nMost DOQs are produced by electronically scanning, then rectifying, black-and-white vertical aerial\nphotographs. DOQ may also be produced from natural-color or near-infrared false-color photos,\nhowever, and from digital imagery. The variations in photo scale caused by relief displacement in the\noriginal images are removed by warping the image to compensate for the terrain elevations within the\nscene. Like USGS topographic maps, scale is uniform across each DOQ.\nMost DOQs covers 3.75\u2032 of longitude by 3.75\u2032 of latitude. A set of four DOQs corresponds to each\n7.5\u2032 quadrangle. (For this reason, DOQs are sometimes called DOQQs\u2013Digital Orthophoto Quarter\nQuadrangles.) For its National Map, USGS has edge-matched DOQs into seamless data layers, by year\nof acquisition. Nature of Geographic Information 234\nPortion of a USGS Digital Orthophoto Quad (DOQ) for Bushkill, PA.\nDATA QUALITY\nLike other USGS data products, DOQs conform to National Map Accuracy Standards. Since the scale\nof the series is 1:12,000, the standards warrant that 90 percent of well-defined points appear within 33.3\nfeet (10.1 meters) of their actual positions. One of the main sources of error is the rectification process,\nduring which the image is warped such that each of a minimum of 3 control points matches its known\nlocation.\nSPATIAL REFERENCE INFORMATION\nAll DOQs are cast on the Universal Transverse Mercator projection used in the local UTM zone.\nHorizontal positions are specified relative to the North American Datum of 1983, which is based on the\nGRS 80 ellipsoid.\nENTITIES AND ATTRIBUTES\nThe fundamental geometric element of a DOQ is the picture element (pixel). Each pixel in a DOQ\ncorresponds to one square meter on the ground. Pixels in black-and-white DOQs are associated with\na single attribute: a number from 0 to 255, where 0 stands for black, 255 stands for white, and the\nnumbers in between represent levels of gray. 235 David DiBiase\nDOQs exceed the scanned topographic maps shown in Digital Raster Graphics (DRGs) in both pixel\nresolution and attribute resolution. DOQs are therefore much larger files than DRGs. Even though an\nindividual DOQ file covers only one-quarter of the area of a topographic quadrangle (3.75 minutes\nsquare), it requires up to 55 Mb of digital storage. Because they cover only 25 percent of the area of\ntopographic quadrangles, DOQs are also known as Digital Orthophoto Quarter Quadrangles (DOQQs).\nDISTRIBUTION\nUSGS DOQ files are in the public domain, and can be used for any purpose without restriction. They\nare available for free download from the USGS, or from various state and regional data clearinghouses\nas well as from the geoCOMMUNITY site. Digital orthoimagery data at 1-foot and 1-meter spatial\nresolution, collected from multiple sources, are available for user-specified areas from the National Map\nViewer site, and even higer resolution imagery (HRO) for certain areas is available through the USGS\nSeamless Data Warehouse site.\nTo investigate DOQ data in greater depth, including links to a complete sample metadata\ndocument, visit Birthplace of the DOQ. You\u2019re also welcome to post a comment to this page to describe\nyour source of DOQ data, and how you use it. FGDC\u2019s Content Standard for Digital Orthoimagery is\npublished here.\nTRY THIS!\nEXPLORE DOQS WITH GLOBAL MAPPER (DLGV32 PRO)\nNow it\u2019s time to use Global Mapper (dlgv32 Pro) again, this time to investigate the characteristics of a\nset of USGS Digital Orthophoto (Quarter) Quadrangles. The instructions below assume that you have\nalready installed the Global Mapper \/ dlgv32 Pro software on your computer. (If you haven\u2019t, return\nto installation instructions presented earlier in Chapter 6).\nNote: Global Mapper is a Windows application and will not run under the Macintosh operating\nsystem. The questions asked of Penn State students that involve the use of Global Mapper are not graded.\n1. First download one or more DOQ data archives. Each compressed DOQ is over 37 Mb in\nsize and will take about 8 minutes to download via high speed DSL or cable, or over two\nhours via 56 Kbps modem.\n\u25e6 DOQ_nw.zip\n\u25e6 DOQ_ne.zip\n\u25e6 DOQ_se.zip\n\u25e6 DOQ_sw.zip\n2. Next decompress each archive into a directory on your hard disk.\n\u25e6 Open an archive (e.g., \u201cDOQ_nw.zip\u201d).\n\u25e6 Create a subdirectory called \u201cDOQ\u201d within the directory you are using for class\nwork.\n\u25e6 Extract all files in the ZIP archive into your new subdirectory. Nature of Geographic Information 236\nIf you download and extract all four ZIP archives, the end result will be four DOQs that\ncorrespond with the Bushkill, PA quadrangle.\n3. Launch Global Mapper (dlgv32 Pro).\n4. Open a Digital Orthophoto (Quarter) Quadrangle by choosing File > Open Data File(s)\u2026,\nthen navigate to the subdirectory into which you extracted the DOQ data, then open the file\n\u2018bushkill_pa_nw.tif\u2018.\n5. The trial version of Global Mapper allows you to open and view up to four files at once. Note\nthat you can turn layers on and off, and even adjust their transparency at Tools > Control\nCenter. You might find it interesting to open and compare the DOQ and DRG layers.\n6. Use the Zoom and Pan tools to magnify and scroll across the DOQ. The \u201cFull View\u201d button\n(house icon) refreshes the initial full view of the dataset.\n7. To view an excerpt of the DOQ metadata, navigate to Tools > Control Center, then click the\nMetadata button.\nTRY THIS!\nASSESS THE AVAILABILITY OF DIGITAL ORTHOIMAGERY VIA THE USGS NATIONAL MAP VIEWER\nThe National Map Viewer is an Internet Map Server application that provides a browsable map interface\nto the digital data layers that make up the National Map. The orthoimagery available through this\ninterface has been gathered from several sources in addition to the USGS DOQ collection describe\nabove.\n1. On the National Map home page, expand the Products and Services list and follow the link\nto National Map Viewers page. This page lists recommended browsers and lets you know\nthat you need the Flash Player in order to use the interface. You are apt to have the Flash\nPlayer already installed. Go ahead and follow the Click here to open viewer link. This will\nopen the viewer in a new browser tab or window. After the application loads, maximize your\nbrowser window.The Help link in the upper right of the interface gives you access to a\nwealth of information about the viewable data as well as user guides.Basic map navigation\ntools are found on a bar at the top of the map display area, along with a vertical scale change\nbar.\n2. With the Overlays tab selected, on the left, and the Content sub-tab selected, check the box\nfor the Imagery list and expand it. Check both boxes\nfor 1_foot and 1_meter_imagery_outlines to see the areal extent of both categories depicted\non the map. Take note of the distribution of the two resolutions. You might speculate on the\nreasons behind the coverage extents of the 1_foot imagery.\n3. You can view the actual 1_meter_imagery, too, by checking the box for it. Go ahead and\ninvestigate that.\n4. Open the Help window, under the Orthoimagery entry, and read about the sources drawn\nfrom to create the bank of orthoimagery available. 237 David DiBiase\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 6 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about Photogrammetry. You may take practice quizzes\nas many times as you wish. They are not scored and do not affect your grade in any way.\n6.18. Summary\nMany local, state and federal government agencies produce and rely upon geographic data to support\ntheir day-to-day operations. The National Spatial Data Infrastructure (NSDI) is meant to foster\ncooperation among agencies to reduce costs and increase the quality and availability of public data\nin the U.S. The key components of NSDI include standards, metadata, data, a clearinghouse for data\ndissemination, and partnerships. The seven framework data themes have been described as \u201cthe data\nbackbone of the NSDI\u201d (FGDC, 1997, p. v). This chapter and the next review the origins, characteristics\nand status of the framework themes. In comparison with some other developed countries, framework\ndata are fragmentary in the U.S., largely because mapping activities at various levels of government\nremain inadequately coordinated.\nChapter 6 considers two of the seven framework themes: geodetic control and orthoimagery. It\ndiscusses the impact of high-accuracy satellite positioning on accuracy standards for the National\nSpatial Reference System\u2013the U.S.\u2019 horizontal and vertical control networks. The chapter stresses the\nfact that much framework data is derived, directly or indirectly, from aerial imagery. Geospatial\nprofessionals understand how photogrammetrists compile planimetrically-correct vector data by\nstereoscopic analysis of aerial imagery. They also understand how orthoimages are produced and used\nto help keep vector data current, among other uses.\nThe most ambitious attempt to implement a nationwide collection of framework data is the\nUSGS\u2019 National Map. Composed of some of the digital data products described in this chapter and\nthose that follow, the proposed National Map is to include high resolution (1 m) digital orthoimagery,\nvariable resolution (10-30 m) digital elevation data, vector transportation, hydrography, and boundaries,\nmedium resolution (30 m) land characterization data derived from satellite imagery, and geographic\nnames. These data are to be seamless (unlike the more than 50,000 sheets that comprise the 7.5-minute\ntopographic quadrangle series) and continuously updated. Meanwhile, in 2005, USGS announced that\ntwo of its three National Mapping Centers (in Reston, Virginia and Rolla, Missouri) would be closed,\nand over 300 jobs eliminated. Although funding for the Rolla center was subsequently restored by\nCongress, it remains to be seen whether USGS will be sufficiently resourced to fulfill its quest for a\nNational Map.\nQUIZ\nRegistered Penn State students should return now to the Chapter 6 folder in ANGEL (via the Resources\nmenu to the left) to access the graded quiz for this chapter. This one counts. You may take graded\nquizzes only once.\nThe purpose of the quiz is to ensure that you have studied the text closely, that you have mastered\nthe practice activities, and that you have fulfilled the chapter\u2019s learning objectives. You are welcome to\nreview the chapter during the quiz.\nOnce you have submitted the quiz and posted any questions you may have to either our discussion\nforums or chapter pages, you will have completed Chapter 6. Nature of Geographic Information 238\nCOMMENTS AND QUESTIONS\nRegistered students are welcome to post comments, questions, and replies to questions about the\ntext. Particularly welcome are anecdotes that relate the chapter text to your personal or professional\nexperience. In addition, there are discussion forums available in the ANGEL course management system\nfor comments and questions about topics that you may not wish to share with the whole world.\nTo post a comment, scroll down to the text box under \u201cPost new comment\u201d and begin typing in the text\nbox, or you can choose to reply to an existing thread. When you are finished typing, click on either the\n\u201cPreview\u201d or \u201cSave\u201d button (Save will actually submit your comment). Once your comment is posted,\nyou will be able to edit or delete it as needed. In addition, you will be able to reply to other posts at any\ntime.\nNote: the first few words of each comment become its \u201ctitle\u201d in the thread.\n6.19. Bibliography\nAnson, A. (2002) Topographic mapping with plane table and alidade in the 1940s. [CD-ROM]\nProfessional Surveyors Publishing Co.\nDoyle, David R. 1994 Development of the national spatial reference system. Retrieved 9 November\n2007 from http:\/\/www.ngs.noaa.gov\/PUBS_LIB\/develop_NSRS.html\nFederal Geodetic Control Committee (1988). Geometric geodetic accuracy standards and\nspecifications for using GPS relative positioning techniques. Retrieved March 27, 2013,\nfromhttp:\/\/docs.lib.noaa.gov\/noaa_documents\/NOS\/NGS\/Geom_Geod_Accu_Standards.pdf\nFederal Geographic Data Committee (1998a). Geospatial positing accuracy standards part 2:\nstandards for geodetic networks. Retrieved February 11, 2008, fromhttp:\/\/www.fgdc.gov\/standards\/\nstandards_publications\/\nFederal Geographic Data Committee (1998b). Geospatial positing accuracy standards part 1: reporting\nmethodology. Retrieved February 11, 2008, from http:\/\/www.fgdc.gov\/standards\/\nstandards_publications\/\nFederal Geographic Data Committee (1998c). Content standard for digital geospatial metadata.\nRetrieved February 19, 2008, from http:\/\/www.fgdc.gov\/standards\/standards_publications\/\nGidon, P. (2006). Alpes_stereo. Retrieved May 10, 2006, fromhttp:\/\/perso.infonie.fr\/alpes_stereo\/\ni_index.htm (Expired link.)\nMasser, I. (1998). Governments and geographic information. London: Taylor & Francis.\nMoore, Larry (2000) The U.S. Geological Survey\u2019s revision program for 7.5-Minute topographic\nmaps. Retrieved December 14, 2007 from http:\/\/pubs.usgs.gov\/of\/2000\/of00-325\/moore.html\nNational Aeronautic and Space Administration (1997). Mars pathfinder. Retrieved June 7, 2006,\nfromhttp:\/\/mars.jpl.nasa.gov\/MPF\/index0.html\nNational Geodetic Survey (2007). The National Geodetic Survey 10 year plan; mission, vision and\nstrategy 2007-2017. Retrieved February 19, 2008 from www.ngs.noaa.gov\/INFO\/ngs_tenyearplan.pdf\nNational Oceanic and Atmospheric Administration (2007) NOAA history. Retrieved February 18,\n2008, from http:\/\/www.history.noaa.gov\/\nNational Research Council (2002). Research opportunities in geography at the U.S. Geological\nSurvey.Washington DC: National Academies Press.\nNational Research Council (2007). A research agenda for geographic information science at the\nUnited States Geological Survey. Washington DC: National Academies Press. 239 David DiBiase\nOffice of Management and Budget (1990) Circular A-16, revised. Retrieved February 19, 2008,\nfromhttp:\/\/www.whitehouse.gov\/omb\/circulars_a016_rev\nParry, R.B. (1987). The state of world mapping. In R. Parry & C. Perkins (Eds.), World mapping\ntoday. Butterworth-Heinemann.\nRobinson, A. et al. (1995). Elements of cartography (5th ed.). New York: John Wiley & Sons.\nThompson, M. M. (1988). Maps for America, cartographic products of the U.S. geological survey and\nothers (3d ed.). Reston, Va.: U.S. Geological Survey.\nUnited States Geological Survey (2001). The National Map: topographic mapping for the 21st\ncentury.Final Report, November 30. Retrieved 11 January 2008 fromhttp:\/\/nationalmap.gov\/report\/\nnational_map_report_final.pdf\nWhite House (1994) Executive order 12906: coordinating geographic data access. Retrieved February\n19, 2008, from http:\/\/www.fgdc.gov\/policyandplanning\/executive_order Chapter 7\n240 National Spatial Data Infrastructure II\nDavid DiBiase\n7.1. Overview\nChapters 6 and 7 consider the origins and characteristics of the framework data themes that make\nup the United States\u2019 proposed National Spatial Data Infrastructure (NSDI). Chapter 6 discussed the\ngeodetic control and orthoimagery themes. This chapter describes the origins, characteristics and\ncurrent status of the elevation, transportation, hydrography, governmental units and cadastral\nthemes.\nObjectives\nStudents who successfully complete Chapter 7 should be able to:\n1. Given a regular or irregular array of spot elevations, construct a triangulated irregular\nnetwork, interpolate contour intervals and draw contour lines;\n2. Compare vector and raster representations of terrain elevation;\n3. Acquire and view digital elevation data from the National Elevation Dataset;\n4. Calculate an interpolated spot elevation based on neighboring elevations;\n5. Contrast the characteristics of three global elevation data products;\n6. Describe the characteristics and current status of the NSDI hydrography, transportation, and\ngovernmental units themes as implemented in USGS\u2019 National Map; and\n7. Interpret the size and relative location of a land parcel designated in terms of the U.S. Public\nLand Survey System.\nComments and Questions\nRegistered students are welcome to post comments, questions, and replies to questions about the\ntext. Particularly welcome are anecdotes that relate the chapter text to your personal or professional\nexperience. In addition, there are discussion forums available in the ANGEL course management system\nfor comments and questions about topics that you may not wish to share with the whole world.\nTo post a comment, scroll down to the text box under \u201cPost new comment\u201d and begin typing in the text\nbox, or you can choose to reply to an existing thread. When you are finished typing, click on either the\n\u201cPreview\u201d or \u201cSave\u201d button (Save will actually submit your comment). Once your comment is posted,\nyou will be able to edit or delete it as needed. In addition, you will be able to reply to other posts at any\ntime.\nNote: the first few words of each comment become its \u201ctitle\u201d in the thread.\n241 Nature of Geographic Information 242\n7.2. Checklist\nThe following checklist is for Penn State students who are registered for classes in which this text, and\nassociated quizzes and projects in the ANGEL course management system, have been assigned. You\nmay find it useful to print this page out first so that you can follow along with the directions.\nChapter 7 Checklist (for registered students only)\nStep Activity Access\/Directions\nThis is the second page of the Chapter. Click on the links at the bottom\nof the page to continue or to return to the previous page, or to go to the\n1 Read Chapter 7\ntop of the chapter. You can also navigate the text via the links in the\nGEOG 482 menu on the left.\nSubmit 3 practice\nquizzesincluding:\n\u2022 Contouring\n\u2022 DLGs and DEMs Go to ANGEL > [your course section] > Lessons tab > Chapter 7 folder\n2\n> [quiz]\n\u2022 Interpolation\nPractice quizzes are not graded\nand may be submitted more\nthan once.\nPerform \u201cTry this\u201d\nactivitiesincluding:\n\u2022 Draw a contour map\n\u2022 Explore Digital Line\nGraph hypsography\n\u2022 Explore a Digital\n3 Elevation Model Instructions are provided for each activity.\n\u2022 Download and view\nan extract from the\nNational Elevation\nDataset\n\u201cTry this\u201d activities are not\ngraded.\nSubmit theChapter 7 Graded ANGEL > [your course section] > Lessons tab > Chapter 7 folder >\n4\nQuiz Chapter 7 Graded Quiz. See the Calendar tab in ANGEL for due dates.\nReadcomments and\nquestionsposted by fellow Comments and questions may be posted on any page of the text, or in a\n5\nstudents. Add comments and Chapter-specific discussion forum in ANGEL.\nquestions of your own, if any. 243 David DiBiase\n7.3. Theme: Elevation\nThe NSDI Framework Introduction and Guide (FGDC, 1997, p. 19) points out that \u201celevation data are\nused in many different applications.\u201d Civilian applications include flood plain delineation, road planning\nand construction, drainage, runoff, and soil loss calculations, and cell tower placement, among many\nothers. Elevation data are also used to depict the terrain surface by a variety of means, from contours to\nrelief shading and three-dimensional perspective views.\nThe NSDI Framework calls for an \u201celevation matrix\u201d for land surfaces. That is, the terrain is to be\nrepresented as a grid of elevation values. The spacing (or resolution) of the elevation grid may vary\nbetween areas of high and low relief (i.e., hilly and flat). Specifically, the Framework Introduction states\nthat\nElevation values will be collected at a post-spacing of 2 arc-seconds (approximately 47.4 meters at\n40\u00b0 latitude) or finer. In areas of low relief, a spacing of 1\/2 arc-second (approximately 11.8 meters at\n40\u00b0 latitude) or finer will be sought (FGDC, 1997, p. 18).\nThe elevation theme also includes bathymetry\u2013depths below water surfaces\u2013for coastal zones and\ninland water bodies. Specifically,\nFor depths, the framework consists of soundings and a gridded bottom model. Water depth is\ndetermined relative to a specific vertical reference surface, usually derived from tidal observations. In\nthe future, this vertical reference may be based on a global model of the geoid or the ellipsoid, which is\nthe reference for expressing height measurements in the Global Positioning System (Ibid).\nUSGS has lead responsibility for the elevation theme. Elevation is also a key component of USGS\u2019\nNational Map. The next several pages consider how heights and depths are created, how they are\nrepresented in digital geographic data, and how they may be depicted cartographically.\n7.4. Vector and Raster Approaches\nThe terms raster and vector were introduced back in Chapter 1 to denote two fundamentally different\nstrategies for representing geographic phenomena. Both strategies involve simplifying the infinite\ncomplexity of the Earth\u2019s surface. As it relates to elevation data, the raster approach involves measuring\nelevation at a sample of locations. The vector approach, on the other hand, involves measuring the\nlocations of a sample of elevations. I hope that this distinction will be clear to you by the end of this\nchapter.\nVector and raster representations of the same terrain surface. Nature of Geographic Information 244\nThe illustration above compares how elevation data are represented in vector and raster data. On the\nleft are elevation contours, a vector representation that is familiar with anyone who has used a USGS\ntopographic map. The technical term for an elevation contour isisarithm, from the Greek words for\n\u201csame\u201d and \u201cnumber.\u201d The termsisoline, isogram, and isopleth all mean more or less the same thing.\n(See any cartography text for the distinctions.)\nAs you will see later in this chapter, when you explore Digital Line Graph hypsography data using\nGlobal Mapper or dlgv 32 Pro, elevations in vector data are encoded as attributes of line features. The\ndistribution of elevation points across the quadrangle is therefore irregular. Raster elevation data, by\ncontrast, consist of grids of points at which elevation is encoded at regular intervals. Raster elevation\ndata are what\u2019s called for by the NSDI Framework and the USGS National Map. Digital contours can\nnow be rendered easily from raster data. However, much of the raster elevation data used in the National\nMap was produced from digital vector contours and hydrography (streams and shorelines). For this\nreason we\u2019ll consider the vector approach to terrain representation first.\n7.5. Contours\nContour lines trace the elevation of the terrain surface at regularly-spaced intervals (Raisz, 1948. \u00a9\nMcGraw-Hill, Inc. Used by permission).\nDrawing contour lines is a way to represent a terrain surface with a sample of elevations. Instead\nof measuring and depicting elevation at every point, you measure only along lines at which a series\nof imaginary horizontal planes slice through the terrain surface. The more imaginary planes, the more\ncontours, and the more detail is captured. 245 David DiBiase\nContour lines representing the same terrain as in the first figure, but in plan view. (Raisz, 1948. \u00a9\nMcGraw-Hill, Inc. Used by permission).\nUntil photogrammetric methods came of age in the 1950s, topographers in the field sketched contours\non the USGS 15-minute topographic quadrangle series. Since then, contours shown on most of the\n7.5-minute quads were compiled from stereoscopic images of the terrain, as described in Chapter 6.\nToday computer programs draw contours automatically from the spot elevations that photogrammetrists\ncompile stereoscopically.\nAlthough it is uncommon to draw terrain elevation contours by hand these days, it is still worthwhile\nto know how. In the next few pages you\u2019ll have a chance to practice the technique, which is analogous\nto the way computers do it.\n7.6. Contouring By Hand\nThis page will walk you through a methodical approach to rendering contour lines from an array of spot\nelevations (Rabenhorst and McDermott, 1989). To get the most from this demonstration, I suggest that\nyou print the illustration in the attached image file. Find a pencil (preferably one with an eraser!) and\nstraightedge, and duplicate the steps illustrated below. A \u201cTry This!\u201d activity will follow this step-by-\nstep introduction, providing you a chance to go solo. Nature of Geographic Information 246\nBeginning a triangulated irregular network.\nStarting at the highest elevation, draw straight lines to the nearest neighboring spot elevations. Once\nyou have connected to all of the points that neighbor the highest point, begin again at the second\nhighest elevation. (You will have to make some subjective decisions as to which points are \u201cneighbors\u201d\nand which are not.) Taking care not to draw triangles across the stream, continue until the surface is\ncompletely triangulated.\nComplete TIN. Note that the triangle sides must not cross hydrologic features (i.e., the stream) on a\nterrain surface.\nThe result is a triangulated irregular network (TIN). A TIN is a vector representation of a 247 David DiBiase\ncontinuous surface that consists entirely of triangular facets. The vertices of the triangles are spot\nelevations that may have been measured in the field by leveling, or in a photogrammetrist\u2019s workshop\nwith a stereoplotter, or by other means. (Spot elevations produced photogrammetrically are called mass\npoints.) A useful characteristic of TINs is that each triangular facet has a single slope degree and\ndirection. With a little imagination and practice, you can visualize the underlying surface from the TIN\neven without drawing contours.\nWonder why I suggest that you not let triangle sides that make up the TIN cross the stream? Well, if\nyou did, the stream would appear to run along the side of a hill, instead of down a valley as it should. In\npractice, spot elevations would always be measured at several points along the stream, and along ridges\nas well. Photogrammetrists refer to spot elevations collected along linear features as breaklines (Maune,\n2007). I omitted breaklines from this example just to make a point.\nYou may notice that there is more than one correct way to draw the TIN. As you will see, deciding\nwhich spot elevations are \u201cnear neighbors\u201d and which are not is subjective in some cases. Related to\nthis element of subjectivity is the fact that the fidelity of a contour map depends in large part on the\ndistribution of spot elevations on which it is based. In general, the density of spot elevations should be\ngreater where terrain elevations vary greatly, and sparser where the terrain varies subtly. Similarly, the\nsmaller the contour interval you intend to use, the more spot elevations you need.\n(There are algorithms for triangulating irregular arrays that produce unique solutions. One approach\nis called Delaunay Triangulationwhich, in one of its constrained forms, is useful for representing\nterrain surfaces. The distinguishing geometric characteristic of a Delaunay triangulation is that a circle\nsurrounding each triangle side does not contain any other vertex.)\nTick marks drawn where elevation contours cross the edges of each TIN facet.\nNow draw ticks to mark the points at which elevation contours intersect each triangle side. For\ninstance, see the triangle side that connects the spot elevations 2360 and 2480 in the lower left corner\nof the illustration above? One tick mark is drawn on the triangle where a contour representing elevation Nature of Geographic Information 248\n2400 intersects. Now find the two spot elevations, 2480 and 2750, in the same lower left corner. Note\nthat three tick marks are placed where contours representing elevations 2500, 2600, and 2700 intersect.\nThis step should remind you of the equal interval classification scheme you read about in Chapter\n3. The right choice of contour interval depends on the goal of the mapping project. In general, contour\nintervals increase in proportion to the variability of the terrain surface. It should be noted that the\nassumption that elevations increase or decrease at a constant rate is not always correct, of course. We\nwill consider that issue in more detail later.\nThreading elevation contours through a TIN.\nFinally, draw your contour lines. Working downslope from the highest elevation, thread contours\nthrough ticks of equal value. Move to the next highest elevation when the surface seems ambiguous.\nKeep in mind the following characteristics of contour lines (Rabenhorst and McDermott, 1989):\n\u2022 Contours should always point upstream in valleys\n\u2022 Contours should always point downridge along ridges\n\u2022 Adjacent contours should always be sequential or equivalent\n\u2022 Contours should never split into two\n\u2022 Contours should never cross or loop\n\u2022 Contours should never spiral\n\u2022 Contours should never stop in the middle of a map\nHow does your finished map compare with the one I drew below? 249 David DiBiase\nTRY THIS!\nNow try your hand at contouring on your own. The purpose of this practice activity is to give you\nmore experience in contouring terrain surfaces.\n1. First, view an image of an irregular array of 16 spot elevations.\n2. Print the image.\n3. Use the procedure outlined in this lesson to draw contour lines that represent the terrain\nsurface that the spot elevations were sampled from. You may find this to be a moderately\nchallenging task that takes about a half hour to do well. TIP: label the tick marks to make it\neasier to connect them.\n4. When finished, compare your result to an existing map.\nHere are a couple of somewhat simpler problems and solutions in case you need a little more practice.\n\u2022 Practice Problem #1\n\u2022 Practice Problem #1 Solution\n\u2022 Practice Problem #2\n\u2022 Practice Problem #2 Solution\nYou will be asked to demonstrate your contouring ability again in the Lesson 7 Quiz and in the final\nexam.\nKevin Sabo (personal communication, Winter 2002) remarked that \u201cIf you were unfortunate enough\nto be hand-contouring data in the 1960\u2032s and 70\u2032s, you may at least have had the aid of a Gerber Variable\nScale. After hand contouring in Lesson 7, I sure wished I had my Gerber!\u201d Nature of Geographic Information 250\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 7 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about Contouring. You may take practice quizzes as\nmany times as you wish. They are not scored and do not affect your grade in any way.\n7.7. Digital Line Graph (DLG)\nIDENTIFICATION\nDigital Line Graphs (DLGs) are vector representations of most of the features and attributes shown\non USGS topographic maps. Individual feature sets (outlined in the table below) are encoded in\nseparate digital files. DLGs exist at three scales: small (1:2,000,000), intermediate (1:100,000) and\nlarge (1:24,000). Large-scale DLGs are produced intiles that correspond to the 7.5-minute topographic\nquadrangles from which they were derived.\nDescription of Digital Line Graph Layers\nLayer Features\nPublic Land Survey System (PLSS) Township, range, and section lines\nState, county, city, and other national and State lands such as forests and\nBoundaries\nparks\nTransportation Roads and trails, railroads, pipelines and transmission lines\nHydrography Flowing water, standing water, and wetlands\nHypsography Contours and supplementary spot elevations\nNon-vegetative features Glacial moraine, lava, sand, and gravel\nSurvey control and markers Horizontal and vertical monuments (third order or better)\nMan-made features Cultural features, such as building, not collected in other data categories\nWoods, scrub, orchards, and\nVegetative surface cover\nvineyards\nLayers and contents of large-scale Digital Line Graph files. Not all layers available for all quadrangles\n(USGS, 2006). 251 David DiBiase\nPortion of three Digital Line Graph (DLG) layers for USGS Bushkill, PA quadrangle; imaged with\nGlobal Mapper (dlgv32 Pro) software. Transportation features are arbitrarily colored red, hydrography\nblue, and hypsography brown. The square symbols are nodes and the triangles represent polygon\ncentroids.\nDATA QUALITY\nLike other USGS data products, DLGs conform to National Map Accuracy Standards. In addition,\nhowever, DLGs are tested for the logical consistency of the topological relationships among data\nelements. Similar to the Census Bureau\u2019s TIGER\/Line, line segments in DLGs must begin and end at\npoint features (nodes), and line segments must be bounded on both sides by area features (polygons).\nSPATIAL REFERENCE INFORMATION\nDLGs are heterogenous. Some use UTM coordinates, others State Plane Coordinates. Some are based on\nNAD 27, others on NAD 83. Elevations are referenced either to NGVD 29 or NAVD 88 (USGS, 2006a).\nENTITIES AND ATTRIBUTES\nThe basic elements of DLG files are nodes (positions), line segments that connect two nodes, and areas\nformed by three or more line segments. Each node, line segment, and area is associated with two-\npart integer attribute codes. For example, a line segment associated with the attribute code \u201c050 0412\u2033\nrepresents a hydrographic feature (050), specifically, a stream (0412).\nDISTRIBUTION\nNot all DLG layers are available for all areas at all three scales. Coverage is complete at 1:2,000,000. At\nthe intermediate scale, 1:100,000 (30 minutes by 60 minutes), all hydrography and transportation files Nature of Geographic Information 252\nare available for the entire U.S., and complete national coverage is planned. At 1:24,000 (7.5 minutes\nby 7.5 minutes), coverage remains spotty. The files are in the public domain, and can be used for any\npurpose without restriction.\nLarge- and Intermediate -scale DLGs are available for download through EarthExplorer system. You\ncan plot 1:2,000,000 DLGs on-line at the USGS\u2019 National Atlas of the United States.\nDIGITAL LINE GRAPH HYPSOGRAPHY\nIn one sense, DLGs are as much \u201clegacy\u201d data as the out-of-date topographic maps from which they\nwere produced. Still, DLG data serve as primary or secondary sources for several themes in the USGS\nNational Map, including hydrography, boundaries, and transportation. DLG hypsography data are not\nincluded in the National Map, however. It is assumed that GIS users can generate elevation contours as\nneeded from DEMs. DLG hypsography and hydrography layers are the preferred sources from which\nUSGS DEMs are produced, however.\nPortion of the hypsography and hydrography layers of a large-scale Digital Line Graph (DLG). USGS\nBushkill, PA quadrangle; imaged with Global Mapper (dlgv32 Pro) software.\nHypsography refers to the measurement and depiction of the terrain surface, specifically with contour\nlines. Several different methods have been used to produce DLG hypsography layers, including:\n\u2022 Scanning contour lines on photographic film or paper maps, converting the scanned raster\ndata to vectors, then editing and attributing the vector features;\n\u2022 Manually digitizing and attributing contour lines on photographic film or paper maps; and\n\u2022 Producing contours by photogrammetric processes.\nThe preferred method is to manually digitize contour lines in vector mode, then to key-enter the\ncorresponding elevation attribute data. 253 David DiBiase\nThe highlighted contour line has been selected, and its attributes reported in a Global Mapper window.\nNotice that the line feature is attributed with a unique Element ID code (LE01, 639) and an elevation\n(1000 feet).\nTRY THIS!\nEXPLORING DLGS WITH GLOBAL MAPPER (DLGV32 PRO)\nNow I\u2019d like you to use Global Mapper (or dlgv32 Pro) software to investigate the characteristics of the\nhypsography layer of a USGS Digital Line Graph (DLG). The instructions below assume that you have\nalready installed software on your computer. (If you haven\u2019t, return to installation instructions presented\nearlier in Chapter 6). First you\u2019ll download and a sample DLG file. In a following activity you\u2019ll have a\nchance to find and download DLG data for your area.\n1. If you haven\u2019t done so already, create a directory called \u201cUSGS Data\u201d on your hard disk,\nwhere you file your course materials.\n2. Next, Download the DLG.zip data archive. The ZIP archive is 1.2 Mb in size and will take\napproximately 15 seconds to download via high speed DSL or cable, or about 4 minutes and\n15 seconds minutes via 56 Kbps modem.\n3. Now decompress the archive into a directory on your hard disk.\n\u25e6 Open the archive DLG.zip.\n\u25e6 Create a subdirectory called \u201cDLG\u201d within the directory in which you save data for\nthis class.\n\u25e6 Extract all files in the ZIP archive into your new subdirectory. Nature of Geographic Information 254\nThe end result will be five subdirectories, each of which includes the data files that make up a\nDLG \u201clayer,\u201d along with a master directory.\n4. Launch Global Mapper or dlgv32 Pro.\n5. Open a Digital Line Graph by choosing File > Open as New\u2026, then navigate to the directory\n\u201cDLG\/Hypso.\u201d Open the file \u2018Hp01catd.ddf\u2019 (you can open up to four files at once in the trial\nversion of Global Mapper.) The data correspond with the 7.5 minute quadrangle for Bushkill,\nPA. The file is encoded in Spatial Data Transfer Standard (SDTS) format. For information\nabout SDTS, see the SDTS Tutorial(PDF format).\n6. Global Mapper may ask you to direct it to a \u2018Master Data Dictionary\u2019 file. If so, navigate to,\nand select, the file \u2018Dlg\/MasterDlg\/Dlg3mdir.ddf\u2019\n7. Experiment with Global Mapper\u2019s tools. Use Zoom and Pan to magnify and scroll across the\nDLG. The Full View button (the one with the house icon) refreshes the initial full view of\nthe data set.\n8. The Feature Info tool allows you to query the attributes of a particular feature. Try clicking\na single line segment. Note that you can display the attributes of a feature in the lower left\nportion of the application window by simply hovering over the feature.\n9. The Measure tool (ruler icon) allows you to not only measure distance as the crow flies, but\nalso to see the area enclosed by a series of line segments drawn by repeated mouse clicks.\nNote again the location information that is given to you near the bottom of the application\nwindow.\n10. Certain tools, e.g., the 3D Path Profile\/Line of Sight tool (next to the Feature Info tool) are\nnot functional in the free (unregistered) version of Global Mapper.\n11. The trial version of Global Mapper allows you to open and view up to four files at once. You\nmight find it interesting to open and compare the Bushkill DLG hypsography file and the\ncorresponding DRG you viewed in Lesson 6. Note that you can turn layers on and off, and\neven adjust their transparency at Tools > Control Center. How do the contours in the DLG\ncompare with those in the DRG? What explains the difference?\n12. Global Mapper provides the metadata you\u2019ll need to answer questions in a practice quiz. To\naccess the metadata, navigate to Tools > Control Center, then click the Metadata button.\n7.8. Digital Elevation Model (DEM)\nThe term \u201cDigital Elevation Model\u201d has both generic and specific meanings. In general, a DEM is any\nraster representation of a terrain surface. Specifically, a DEM is a data product of the U.S. Geological\nSurvey. Here we consider the characteristics of DEMs produced by the USGS Later in this chapter we\u2019ll\nconsider sources of global terrain data.\nIDENTIFICATION\nUSGS DEMs are raster grids of elevation values that are arrayed in series of south-north profiles. Like\nother USGS data, DEMs were produced originally in tiles that correspond to topographic quadrangles.\nLarge scale (7.5-minute and 15-minute), intermediate scale (30 minute), and small scale (1 degree) series 255 David DiBiase\nwere produced for the entire U.S. The resolution of a DEM is a function of the east-west spacing of the\nprofiles and the south-north spacing of elevation points within each profile.\nDEMs corresponding to 7.5-minute quadrangles are available at 10-meter resolution for much, but not\nall, of the U.S. Coverage is complete at 30-meter resolution. In these large scale DEMs elevation profiles\nare aligned parallel to the central meridian of the local UTM zone, as shown in the illustration below. See\nhow the DEM tile in the illustration below appears to be tilted? This is because the corner points\nare defined in unprojected geographic coordinates that correspond to the corner points of a USGS\nquadrangle. The farther the quadrangle is from the central meridian of the UTM zone, the more it is\ntilted.\nArrangement of elevation profiles in a large scale USGS Digital Elevation Model (USGS, 1987).\nAs shown below, the arrangement of the elevation profiles is different in intermediate- and small-\nscale DEMs. Like meridians in the northern hemisphere, the profiles in 30-minute and 1-degree DEMs\nconverge toward the north pole. For this reason the resolution of intermediate- and small-scale DEMs\n(that is to say, the spacing of the elevation values) is expressed differently than for large-scale\nDEMs. The resolution of 30-minute DEMs is said to be 2 arc seconds and 1-degree DEMs are 3 arc\nseconds. Since an arc second is 1\/3600 of a degree, elevation values in a 3 arc second DEM are spaced\n1\/1200 degree apart, representing a grid cell about 66 meters \u201cwide\u201d by 93 meters \u201ctall\u201d at 45\u00ba latitude. Nature of Geographic Information 256\nArrangement of elevation profiles in a small scale USGS Digital Elevation Model (USGS, 1987).\nThe preferred method for producing the elevation values that populate DEM profiles is\ninterpolation from DLG hypsography and hydrography layers (including the hydrography layer\nenables analysts to delineate valleys with less uncertainty than hypsography alone). Some older DEMs\nwere produced from elevation contours digitized from paper maps or during photogrammetric\nprocessing, then smoothed to filter out errors. Others were produced photogrammtrically from aerial\nphotographs.\nDATA QUALITY\nThe vertical accuracy of DEMs is expressed as the root mean square error (RMSE) of a sample of at\nleast 28 elevation points. The target accuracy for large-scale DEMs is seven meters; 15 meters is the\nmaximum error allowed.\nSPATIAL REFERENCE INFORMATION\nLike DLGs, USGS DEMs are heterogenous. They are cast on the Universal Transverse Mercator\nprojection used in the local UTM zone. Some DEMs are based upon the North American Datum of 1983,\nothers on NAD 27. Elevations in some DEMs are referenced to either NGVD 29 or NAVD 88.\nENTITIES AND ATTRIBUTES\nEach record in a DEM is a profile of elevation points. Records include the UTM coordinates of the\nstarting point, the number of elevation points that follow in the profile, and the elevation values that\nmake up the profile. Other than the starting point, the positions of the other elevation points need not be\nencoded, since their spacing is defined. (Later in this lesson you\u2019ll download a sample USGS DEM file.\nTry opening it in a text editor to see what I\u2019m talking about.) 257 David DiBiase\nDISTRIBUTION\nDEM tiles are available for free download through many state and regional clearinghouses. You can find\nthese sources by searching theGEODATA portion of the Data.Gov site, formerly the separate Geospatial\nOne Stop site.\nAs part of its National Map initiative, the USGS has developed a \u201cseamless\u201d National Elevation\nDataset that is derived from DEMs, among other sources. NED data are available at three resolutions:\n1 arc second (approximately 30 meters), 1\/3 arc second (approximately 10 meters), and 1\/9 arc second\n(approximately 3 meters). Coverage ranges from complete at 1 arc second to extremely sparse at 1\/9 arc\nsecond. An extensive FAQ on NED data is published here. The second of the two following activities\ninvolves downloading NED data and viewing it in Global Mapper.\nTRY THIS!\nEXPLORING DEMS WITH GLOBAL MAPPER (DLGV32 PRO)\nGlobal Mapper time again! This time you\u2019ll investigate the characteristics of a USGS DEM. The\ninstructions below assume that you have already installed the software on your computer. (If you\nhaven\u2019t, return to installation instructions presented earlier in Chapter 6). The instructions will remind\nyou how to open a DEM in dlgv32 Pro. In the practice quiz that follows you\u2019ll be asked questions require\nyou to explore the data for answers.\n1. First Download the DEM.zip data archive. The ZIP archive is 2.5 Mb in size and will take\nabout 30 seconds to download via high speed DSL or cable, or nearly 9 minutes via 56 Kbps\nmodem. If you can\u2019t download the file, contact my teaching assistant or me right away so we\ncan help you resolve the problem.\n2. Now decompress the archive into a directory on your hard disk.\n\u25e6 Open the archive DEM.zip.\n\u25e6 Create a subdirectory called \u201cDEM\u201d within the directory in which you save class\ndata.\n\u25e6 Extract all files in the ZIP archive into your new subdirectory.\nThe end result will be two subdirectories, one of which contains a 30-meter DEM, the other\na 10-meter DEM. These datasets are in the earlier distribution format of USGS DEM data \u2014\nelevation data in horizontal (pixel) units of meters and representative of the area covered by a\n1:24,000 topo map sheet. In the Try This that follows this one you will see that the distribution\nformat options have expanded.\n3. Launch Global Mapper.\n4. Open a Digital Elevation Model by choosing File > Open Data File(s)\u2026, then navigate to\nthe directory DEM_30m or DEM_10m, then open the file bushkill_pa.dem\n5. Use the Zoom and Pan tools to magnify and scroll across the DEM. The Full View button\n(house icon) refreshes the initial full view of the dataset.\n6. Global Mapper provides access to the metadata you\u2019ll need to answer questions in a practice Nature of Geographic Information 258\nquiz. To access the metadata, navigate to Tools > Control Center, then click\nthe Metadata button.\nYou can change the appearance of the DEM in the Options section of the Control Center. You can also\nalter the appearance of the DEM by choosing Tools > Configure, and changing the settings in, especially,\nVertical Options and Shader Options. To see the DEM data with(out) hill shading, find the Enable\/\nDisable Hill Shading button on the Shader toolbar (it has a sunburst in the lower left corner).\nTRY THIS!\nDOWNLOAD YOUR OWN NATIONAL ELEVATION DATASET (NED) DATA\n1. Go to the Elevation page of the USGS National Map site.\nRead any of the information there that you choose.\n2. Follow the link to The National Map Viewer.\nIf you wish, also follow the link to the detailed instructions that you see under The National\nMap Viewer link. The following instructions in this Try This should also suffice, and perhaps\nelaborate at bit more.You will not see Elevation data listed in the left hand Overlays pane.\nThe USGS is in the process of adding more visualization options when it comes to elevation\ndata. See the Hill Shade button at the upper right of the map area.\n3. Use the GIS tools, found above the map area, to pan to and zoom in on an area of interest.\nThen, click the Download Data button.\nChoose a reference area from the pick list. The default is the index of the areas covered by\nthe 1:24,000 topo map series.\nYou could also chose the entire current map extent, but depending upon your zoom level that\nmay be a huge dataset.\nThe instructions found via the Help link mentioned above mention that you can define an\narea based on creating a custom polygon, but at this point I do not see how that is done\u2026\n4. Then click on the map to highlight a specific area of interest. A link to the available data sets\nwill appear in the left hand pane under theSelection tab. (The All Results button will list the\nmultiple areas you click on.) Follow the Download link of the area you are interested in.\n5. In the USGS Available Data window that opens, select Elevationfrom the Theme column,\nand choose a file format from the pick list in the Format column.\nI know that both the GeoTIFF and ArcGRID formats are compatible with Global Mapper.\n(ArcGRID is the Esri company\u2019s raster format. You\u2019ll be using the Esri software in future\ncourses.)\nClick the Next button.\n6. You will be given a list of Elevation Product choices.\nThe choices that show Dynamic as the Type will be those that match the Format choice you\nmade in the previous window. The other Stageddatasets are prepackaged and in the formats\nstated in the Product column, and apparently listed regardless of the Format choice you\nmade.If multiple resolutions are available they will be listed.\nFrom the Product list, check the box for what you wish to download.\nClick the Next button. 259 David DiBiase\nGo to the Cart pane on the right. (It may open automatically.)\nGo to Checkout, supply your e-mail address, and submit your order via the Place\nOrder button.\nYou will receive a message telling you that your order has been placed, and that will soon be\nfollowed by an e-mail regarding your order. About an hour and a half after I submitted my\nrequest I received a second e-mail containing a download link.\n7. The system will produce a ZIP archive that you can save to your hard disk (e.g.,\n\u201c09647011.zip\u201d)\n8. Launch Global Mapper and open the ZIP archive. The software can read the data even in its\ncompressed form; you should not need to extract the contents from the .zip file. (It would be\na good idea to look at the contents of the .zip archive, though, if only to see the number and\ntype of files included.)\n9. An image of the DEM data should appear in the Global Mapper window, similar to what you\nsee shown below (even though the image below is from an older version of Global Mapper).\n10. Again, you can view the metadata associated with the DEM data via the Tools > Control\nCenter menu. Note the PIXEL dimensions reported in arc degrees, as opposed to something\nlike meters.\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 7 folder in ANGEL (via the Resources Nature of Geographic Information 260\nmenu to the left) to take a self-assessment quiz about DLGs and DEMs. You may take practice quizzes\nas many times as you wish. They are not scored and do not affect your grade in any way.\n7.9. Interpolation\nDEMs are produced by various methods. The method preferred by USGS is to interpolate elevations\ngrids from the hypsography and hydrography layers of Digital Line Graphs.\nA USGS 7.5-minute DEM and the DLG hypsography and hydrography layers from which it was\nproduced.\nThe elevation points in DLG hypsography files are not regularly spaced. DEMs need to be regularly\nspaced to support the slope, gradient, and volume calculations they are often used for. Grid point\nelevations must be interpolated from neighboring elevation points. In the figure below, for example, the\ngridded elevations shown in purple were interpolated from the irregularly spaced spot elevations shown\nin red. 261 David DiBiase\nElevation values in DEMs are interpolated from irregular arrays of elevations measured through\nphotogrammetric methods, or derived from existing DLG hypsography and hydrography data.\nHere\u2019s another example of interpolation for mapping. The map below shows how 1995 average\nsurface air temperature differed from the average temperature over a 30-year baseline period\n(1951-1980). The temperature anomalies are depicted for grid cells that cover 3\u00b0 longitude by 2.5\u00b0\nlatitude. Nature of Geographic Information 262\n1995 Surface Temperature Anomalies. (National Climatic Data Center, 2005).\nThe gridded data shown above were estimated from the temperature records associated with the very\nirregular array of 3,467 locations pinpointed in the map below. The irregular array is transformed into a\nregular array through interpolation. In general, interpolation is the process of estimating an unknown\nvalue from neighboring known values.\nThe Global Historical Climate Network. (Eischeid et al., 1995).\nElevation data are often not measured at evenly-spaced locations. Photogrammetrists typically take\nmore measurements where the terrain varies the most. They refer to the dense clusters of measurements\nthey take as \u201cmass points.\u201d Topographic maps (and their derivatives, DLGs) are another rich source\nof elevation data. Elevations can be measured from contour lines, but obviously contours do not form\nevenly-spaced grids. Both methods give rise to the need for interpolation. 263 David DiBiase\nInterpolating an intermediate value on a number line.\nThe illustration above shows three number lines, each of which ranges in value from 0 to 10. If you\nwere asked to interpolate the value of the tick mark labeled \u201c?\u201d on the top number line, what would\nyou guess? An estimate of \u201c5\u2033 is reasonable, provided that the values between 0 and 10 increase at a\nconstant rate. If the values increase at a geometric rate, the actual value of \u201c?\u201d could be quite different,\nas illustrated in the bottom number line. The validity of an interpolated value depends, therefore, on the\nvalidity of our assumptions about the nature of the underlying surface.\nAs I mentioned in Chapter 1, the surface of the Earth is characterized by a property called spatial\ndependence. Nearby locations are more likely to have similar elevations than are distant locations.\nSpatial dependence allows us to assume that it\u2019s valid to estimate elevation values by interpolation.\nMany interpolation algorithms have been developed. One of the simplest and most widely used\n(although often not the best) is theinverse distance weighted algorithm. Thanks to the property of\nspatial dependence, we can assume that estimated elevations are more similar to nearby elevations than\nto distant elevations. The inverse distance weighted algorithm estimates the value z of a point P as\na function of the z-values of the nearest n points. The more distant a point, the less it influences the\nestimate. Nature of Geographic Information 264\nThe inverse distance weighted interpolation procedure.\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 7 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about Interpolation. You may take practice quizzes as\nmany times as you wish. They are not scored and do not affect your grade in any way.\n7.10. Slope\nSlope is a measure of change in elevation. It is a crucial parameter in several well-known predictive\nmodels used for environmental management, including the Universal Soil Loss Equation and\nagricultural non-point source pollution models.\nOne way to express slope is as a percentage. To calculate percent slope, divide the difference between\nthe elevations of two points by the distance between them, then multiply the quotient by 100. The\ndifference in elevation between points is called the rise. The distance between the points is called the\nrun. Thus, percent slope equals (rise \/ run) x 100. 265 David DiBiase\nCalculating percent slope. A rise of 100 feet over a run of 100 feet yields a 100 percent slope. A\n50-foot rise over a 100-foot run yields a 50 percent slope.\nAnother way to express slope is as a slope angle, or degree of slope. As shown below, if you visualize\nrise and run as sides of a right triangle, then the degree of slope is the angle opposite the rise. Since\ndegree of slope is equal to the tangent of the fraction rise\/run, it can be calculated as the arctangent of\nrise\/run.\nA rise of 100 feet over a run of 100 feet yields a 45\u00b0 slope angle. A rise of 50 feet over a run of 100\nfeet yields a 26.6\u00b0 slope angle.\nYou can calculate slope on a contour map by analyzing the spacing of the contours. If you have\nmany slope values to calculate, however, you will want to automate the process. It turns out that slope\ncalculations are much easier to calculate for gridded elevation data than for vector data, since elevations\nare more or less equally spaced in raster grids.\nSeveral algorithms have been developed to calculate percent slope and degree of slope. The simplest\nand most common is called theneighborhood method. The neighborhood method calculates the slope\nat one grid point by comparing the elevations of the eight grid points that surround it. Nature of Geographic Information 266\nThe neighborhood algorithm estimates percent slope in cell 5 by comparing the elevations of\nneighboring grid cells.\nThe neighborhood algorithm estimates percent slope at grid cell 5 (Z5) as the sum of the absolute\nvalues of east-west slope and north-south slope, and multiplying the sum by 100. The diagram below\nillustrates how east-west slope and north-south slope are calculated. Essentially, east-west slope is\nestimated as the difference between the sums of the elevations in the first and third columns of the 3 x 3\nmatrix. Similarly, north-south slope is the difference between the sums of elevations in the first and third\nrows (note that in each case the middle value is weighted by a factor of two).\nThe neighborhood algorithm for calculating percent slope.\nThe neighborhood algorithm calculates slope for every cell in an elevation grid by analyzing each 3 x\n3 neighborhood. Percent slope can be converted to slope degree later. The result is a grid of slope values\nsuitable for use in various soil loss and hydrologic models.\n7.11. Relief Shading\nYou can see individual pixels in the zoomed image of a 7.5-minute DEM below. I used dlgv32 Pro\u2019s\n\u201cGradient Shader\u201d to produce the image. Each pixel represents one elevation point. The pixels are\nshaded through 256 levels of gray. Dark pixels represent low elevations, light pixels represent high ones. 267 David DiBiase\nA digital elevation model in which light pixels represent high elevations, and dark pixels represent\nlow elevations.\nIt\u2019s also possible to assign gray values to pixels in ways that make it appear that the DEM is\nilluminated from above. The image below, which shows the same portion of the Bushkill DEM as the\nimage above, illustrates the effect, which is called terrain shading, hill shading or shaded relief. Nature of Geographic Information 268\nShaded terrain image produced from the same DEM as shown in the above figures, using dlgv32 Pro\u2019s\nDaylight Shader option, with the Surface Color set to gray.\nThe appearance of a shaded terrain image depends on several parameters, including vertical\nexaggeration. Click the buttons under the image below to compare the four terrain images of North\nAmerica shown below, in which elevations are exaggerated 5 times, 10 times, 20 times, and 40 times\nrespectively. (You will need to have the Adobe Flash player installed in order to complete this exercise.\nIf you do not already have the Flash player, you can download it for free from Adobe.)\nEffects of vertical exaggeration on a shaded terrain image\nAnother influential parameter is the angle of illumination. Click the buttons to compare terrain\nimages that have been illuminated from the northeast, southeast, southwest, and northwest. Does the\nterrain appear to be inverted in one or more of the images? To minimize the possibility of terrain\ninversion, it is conventional to illuminate terrain from the northwest.\nEffects of illumination angle on a shaded terrain image.\n7.12. Lidar\nFor many applications, 30-meter DEMs whose vertical accuracy is measured in meters are simply not\ndetailed enough. Greater accuracy and higher horizontal resolution can be produced by photogrammetric\nmethods, but precise photogrammetry is often too time-consuming and expensive for extensive areas.\nLidar is a digital remote sensing technique that provides an attractive alternative. 269 David DiBiase\nLidar stands for LIght Detection And Ranging. Like radar (RAdio Detecting And Ranging), lidar\ninstruments transmit and receive energy pulses, and enable distance measurement by keeping track of\nthe time elapsed between transmission and reception. Instead of radio waves, however, lidar instruments\nemit laser light (laser stands for Light Amplifications by Stimulated Emission of Radiation).\nLidar instruments are typically mounted in low altitude aircraft. They emit up to 5,000 laser pulses\nper second, across a ground swath some 600 meters wide (about 2,000 feet). The ground surface,\nvegetation canopy, or other obstacles reflect the pulses, and the instrument\u2019s receiver detects some of\nthe backscatter. Lidar mapping missions rely upon GPS to record the position of the aircraft, and upon\ninertial navigation instruments (gyroscopes that detect an aircraft\u2019s pitch, yaw, and roll) to keep track of\nthe system\u2019s orientation relative to the ground surface.\nIn ideal conditions, lidar can produce DEMs with 15-centimeter vertical accuracy, and horizontal\nresolution of a few meters. Its cost is prohibitive for small missions, but is justified for larger projects\nin which detail is essential. For example, lidar has been used successfully to detect subtle changes in the\nthickness of the Greenland ice sheet that result in a net loss of over 50 cubic kilometers of ice annually.\nImage of Greenland, viewed from the south, showing changes in ice thickness measured by airborne\nlidar. Ice sheet thickness decreasing at 40-60 cm per year in darker blue areas (Goddard Space Flight\nCenter, n.d.).\nTo learn more about the use of lidar in mapping changes in the Greenland ice sheet, visit NASA\u2019s\nScientific Visualization Studio.\n7.13. Global Elevation Data\nThis page profiles three data products that include elevation (and, in one case, bathymetry) data for all\nor most of the Earth\u2019s surface. Nature of Geographic Information 270\nETOPO1\nShaded and colored terrain image produced from ETOPO1 data. (National Geophysical Data Center,\n2009).\nETOPO1 is a digital elevation model that includes both topography and bathymetry for the entire\nworld. It consists of more than 233 million elevation values which are regularly spaced at 1 minute of\nlatitude and longitude. At the equator, the horizontal resolution of ETOPO1 is approximately 1.85\nkilometers. Vertical positions are specified in meters, and there are two versions of the dataset: one\nwith elevations at the \u201cIce Surface\u201d of the Greenland and Antarctic ice sheets, and one with elevations\nat \u201cBedrock\u201d beneath those ice sheets. Horizontal positions are specified in geographic coordinates\n(decimal degrees). Source data, and thus data quality, vary from region to region.\nYou can download ETOPO1 data from the National Geophysical Data Center.\nGTOPO30 271 David DiBiase\nShaded and colored terrain image produced from GTOPO30 data. Data are distributed as 33 tiles\n(USGS, 2006b).\nGTOPO30 is a digital elevation model that extends over the world\u2019s land surfaces (but not under the\noceans). GTOPO30 consists of more than 2.5 million elevation values, which are regularly spaced at\n30 seconds of latitude and longitude. At the equator, the resolution of GTOPO30 is approximately\n0.925 kilometers \u2014 two times greater than ETOPO1. Vertical positions are specified to the nearest\nmeter, and horizontal positions are specified in geographic coordinates. GTOPO30 data are distributed\nas tiles, most of which are 50\u00b0 in latitude by 40\u00b0 in longitude.\nGTOPO30 tiles are available for download from USGS\u2019 EROS Data Center. GTOPO60, a resampled\nand untiled version of GTOPO30, is available through the USGS\u2019 Seamless Data Distribution Service.\nSHUTTLE RADAR TOPOGRAPHY MISSION (SRTM)\nFrom February 11 to February 22, 2000, the space shuttle Endeavor bounced radar waves off the Earth\u2019s\nsurface, and recorded the reflected signals with two receivers spaced 60 meters apart. The mission\nmeasured the elevation of land surfaces between 60\u00b0 N and 57\u00b0 S latitude. The highest resolution data\nproducts created from the SRTM mission are 30 meters. Access to 30-meter SRTM data for areas\noutside the U.S. are restricted by the National Geospatial-Intelligence Agency, which sponsored the\nproject along with the National Aeronautics and Space Administration (NASA). A 90-meter SRTM data\nproduct is available for free download without restriction (Maune, 2007).\nAnaglyph stereo image derived from Shuttle Radar Topography Mission data (NASA Jet Propulsion\nLaboratory, 2006).\nThe image above shows Viti Levu, the largest of the some 332 islands that comprise the Sovereign Nature of Geographic Information 272\nDemocratic Republic of the Fiji Islands. Viti Levu\u2019s area is 10,429 square kilometers (about 4000 square\nmiles). Nakauvadra, the rugged mountain range running from north to south, has several peaks rising\nabove 900 meters (about 3000 feet). Mount Tomanivi, in the upper center, is the highest peak at 1324\nmeters (4341 feet).\nLearn more about the Shuttle Radar Topography Mission at Web sites published by NASA and USGS.\n7.14. Bathymetry\nThe term bathymetry refers to the process and products of measuring the depth of water bodies. The U.S.\nCongress authorized the comprehensive mapping of the nation\u2019s coasts in 1807, and directed that the\ntask be carried out by the federal government\u2019s first science agency, the Office of Coast Survey (OCS).\nThat agency is now responsible for mapping some 3.4 million nautical square miles encompassed by the\n12-mile territorial sea boundary, as well as the 200-mile Exclusive Economic Zone claimed by the U.S.,\na responsibility that entails regular revision of about 1,000 nautical charts. The coastal bathymetry data\nthat appears on USGS topographic maps, like the one shown below, is typically compiled from OCS\ncharts.\n\u201dIsobaths\u201d (the technical term for lines of constant depth) shown on a USGS topographic map.\nEarly hydrographic surveys involved sampling water depths by casting overboard ropes weighted with\nlead and marked with depth intervals called marks and deeps. Such ropes were called leadlines for the\nweights that caused them to sink to the bottom. Measurements were called soundings. By the late 19th\ncentury, piano wire had replaced rope, making it possible to take soundings of thousands rather than just\nhundreds of fathoms (a fathom is six feet). 273 David DiBiase\nSeaman paying out a sounding line during a hydrographic survey of the East coast of the U.S. in 1916.\n(NOAA, 2007).\nEcho sounders were introduced for deepwater surveys beginning in the 1920s. Sonar (SOund\nNAvigation and Ranging) technologies have revolutionized oceanography in the same way that aerial\nphotography revolutionized topographic mapping. The seafloor topography revealed by sonar and\nrelated shipborne remote sensing techniques provided evidence that supported theories about seafloor\nspreading and plate tectonics.\nBelow is an artist\u2019s conception of an oceanographic survey vessel operating two types of sonar\ninstruments: multibeam and side scan sonar. On the left, a multibeam instrument mounted in the ship\u2019s\nhull calculates ocean depths by measuring the time elapsed between the sound bursts it emits and the\nreturn of echoes from the seafloor. On the right, side scan sonar instruments are mounted on both sides\nof a submerged \u201ctowfish\u201d tethered to the ship. Unlike multibeam, side scan sonar measures the strength\nof echoes, not their timing. Instead of depth data, therefore, side scanning produces images that resemble\nblack-and-white photographs of the sea floor. Nature of Geographic Information 274\nMultibeam and side scan sonar in use for bathymetric mapping. (NOAA, 2002).\nA detailed report of the recent bathymetric survey of Crater Lake, Oregon, USA, is published by the\nUSGS here.\n7.15. Statistical Surfaces\nStrategies used to represent terrain surfaces can be used for other kinds of surfaces as well. For example,\none of my first projects here at Penn State was to work with a distinguished geographer, the late Peter\nGould, who was studying the diffusion of the Acquired Immune Deficiency Syndrome (AIDS) virus in\nthe United States. Dr. Gould had recently published the map below. 275 David DiBiase\nOblique view of contour lines representing distribution of AIDS cases in the U.S. 1988. (Gould, 1989.\n\u00a9 Association of American Geographers. All rights reserved. Reproduced here for educational purposes\nonly).\nGould portrayed the distribution of disease in the same manner as another geographer might portray\na terrain surface. The portrayal is faithful to Gould\u2019s conception of the contagion as a continuous\nphenomenon. It was important to Gould that people understood that there was no location that did not\nhave the potential to be visited by the epidemic. For both the AIDS surface and a terrain surface, a\nquantitative attribute (z) exists for every location (x,y). In general, when a continuous phenomenon is\nconceived as being analogous to the terrain surface, the conception is called a statistical surface.\n7.16. Theme: Hydrography\nThe NSDI Framework Introduction and Reference (FGDC, 1997) envisions the hydrography theme in\nthis way:\nFramework hydrography data include surface water features such as lakes and ponds, streams and Nature of Geographic Information 276\nrivers, canals, oceans, and shorelines. Each of these features has the attributes of a name and feature\nidentification code. Centerlines and polygons encode the positions of these features. For feature\nidentification codes, many federal and state agencies use the Reach schedule developed by the U.S.\nEnvironmental Protection Agency (EPA).\nMany hydrography data users need complete information about connectivity of the hydrography\nnetwork and the direction in which the water flows encoded in the data. To meet these needs, additional\nelements representing flows of water and connections between features may be included in framework\ndata (p. 20).\nIDENTIFICATION\nFGDC had the National Hydrography Dataset (NHD) in mind when they wrote this description. NHD\ncombines the vector features ofDigital Line Graph (DLG) hydrography with the EPA\u2019s Reach files.\nReaches are segments of surface water that share similar hydrologic characteristics. Reaches are of three\ntypes: transport, coastline, and waterbody. DLG lines features represent the transport and coastline types;\npolygon features are used to represent waterbodies. Every reach segment in the NHD is assigned a\nunique reach code, along with a host of other hydrological attributes including stream flow direction\n(which is encoded in the digitizing order of nodes that make up each segment), network connectivity, and\nfeature names, among others. Because the order of reach codes are sequential from reach to reach, point-\nsource data (such as a pollutant spill) can be geocoded to the affected reach. Used in this way, reaches\ncomprise alinear referencing system comparable to postal addresses along streets (USGS, 2002).\nHow flow attributes are associated with reaches in the National Hydrography Dataset (USGS, 2000).\nNHD parses the U.S. surface drainage network into four hierarchical categories of units: 21 Regions,\n222 Subregions, 352 Accounting units, and 2150 Cataloging units (also called Watersheds). Features\ncan exist at multiple levels of the hierarchy, though they might not be represented in the same way. For\nexample, while it might make the most sense to represent a given stream as a polygon features at the\nWatershed level, it may be more aptly represented as a line feature at the Region or Subregion level.\nNHD supports this by allowing multiple features to share the same reach codes. Another distinctive\nfeature of NHD is artificial flowlines\u2013centerline features that represent paths of water flow through\npolygon features such as standing water bodies. NHD is complex because it is designed to support\nsophisticated hydrologic modeling tasks, including point-source pollution modeling, flood potential,\nbridge construction, among others (Ralston, 2004). 277 David DiBiase\nHow vector features are used to represent various types of reaches in the National Hydrography\nDataset (USGS, 2000).\nNHD are available at three levels of detail (scale): medium (1:100,000, which is available for the\nentire U.S.), high (1:24,000, production of which is underway, \u201caccording to the availability of matching\nresources from NHD partners\u201d (USGS, 2002, p. 2), and local (larger scales such as 1:5,000), which \u201cis\nbeing developed where partners and data exist\u201d for select areas (USGS, 2006c; USGS, 2009; USGS\n2013).\nSPATIAL REFERENCE INFORMATION\nNHD coordinates are decimal degrees referenced to the NAD 83 horizontal datum.\nDISTRIBUTION\nTRY THIS!\nDOWNLOAD AND VIEW AN EXTRACT FROM THE NATIONAL HYDROGRAPHY DATASET\n1. From the NHD home page click the Get Data link and then follow the link to the NHD\nViewer. (There is a Help button next to the viewer link.)\n2. Use the GIS tools, found above the map area, to pan to and zoom in on an area of interest.\nThen, click the Download Data button.\nChoose a reference area from the pick list. (You could also chose the entire current map\nextent, but depending upon your zoom level that may be a huge dataset.)\nThen click on the map to highlight a specific area of interest. A link to the available data sets\nwill appear in the left hand pane under theSelection tab. (The All Results button will list the\nmultiple areas you click on.) Follow the Download link of the area you are interested in.\n3. In the USGS Available Data window that opens, selectHydrography from\nthe Theme column, and choose a file format from the pick list in the Format column. I\nchose Shapefile format for my extract, because I know it is compatible with Global Mapper \/\ndlgv32 Pro. If you were working in ArcGIS you could choose the File Geodatabase option.\nRalston (2004, p.187) observes that NHD \u201cis precisely the type of information that could Nature of Geographic Information 278\nbenefit from an integrated data model in an object relational database.\u201d\nClick the Next button.\n4. From the list of Hydrography Products check the box for what you wish to download. To be\nassured of getting the data in Shapefile format select a product referred to as a Dynamic\nExtract.\nClick the Next button.\nGo to the Cart pane on the right. (It may open automatically.)\nGo to Checkout, supply your e-mail address, and submit your order via the Place\nOrder button.\nYou will receive a message telling you that your order has been placed, and that will soon be\nfollowed by an e-mail regarding your order. About an hour and a half after I submitted my\nrequest I received a second e-mail containing a download link.\n5. Extract the contents of the .zip file and view the Shapefile data set(s) in Global Mapper.\n6. Use the Identify pointer tool to reveal attributes of the reaches. In the example below I have\nhighlighted a flowline associated with Cedar Creek in western Michigan. 279 David DiBiase\n7.17. Theme: Transportation\nTransportation network data are valuable for all sorts of uses, including two we considered in Chapter 4:\ngeocoding and routing. The Federal Geographic Data Committee (1997, p. 19) specified the following\nvector features and attributes for the transportation framework theme:\nTransportation Framework Attributes\nFeature Attributes\nCenterlines, feature identification code (using linear referencing systems where available),\nRoads\nfunctional class, name (including route numbers), and street address ranges\nCenterlines, feature identification code (using linear referencing systems where available), name,\nTrails\nand type\nRailroads Centerlines, feature identification code (using linear referencing systems where available), and type\nCenterlines, feature identification code (using linear referencing systems where available), and\nWaterways\nname\nAirports\nFeature identification code and name\nand ports\nBridges\nand Feature identification code and name\ntunnels\nIDENTIFICATION\nAs part of the National Map initiative, USGS and partners are developing a comprehensive national\ndatabase of vector transportation data. The transportation theme \u201cincludes best available data from\nFederal partners such as the Census Bureau and the Department of Transportation, State and local\nagencies\u201d (USGS, 2007).\nAs envisioned by FGDC, centerlines are used to represent transportation routes. Like the lines\npainted down the middle of two-way streets, centerlines are 1-dimensional vector features that\napproximate the locations of roads, railroads, and navigable waterways. In this sense, road centerlines\nare analogous to the flowpaths encoded in the National Hydrologic Dataset (see previous page). Also\nlike the NHD (and TIGER), road topology must be encoded to facilitate analysis of transportation\nnetworks.\nTo get a sense of the complexity of the features and attributes that comprise the transportation theme,\nsee the Transportation Data Model(This is a 36\u2033 x 48\u2033 poster in a 5.2 Mb PDF file.) [The link to the\nTransportation Data Model poster recently became disconnected. Instead look at the model diagrams in\nthe Part 7: Transportation Baseof the FGDC Geographic Framework Data Content Standard.]\nIn the U.S. at least, the best road centerline data is that produced by NAVTEQ and Tele Atlas, which\nlicense transportation data to routing sites like Google Maps and MapQuest, and to manufacturers of in-\ncar GPS navigation systems. Because these data are proprietary, however, USGS must look elsewhere\nfor data that can be made available for public use. TIGER\/Line data produced by the Census Bureau will\nlikely play an important role after the TIGER\/MAF Modernization project is complete (see Chapter 4). Nature of Geographic Information 280\nDISTRIBUTION\nTRY THIS!\nVIEW AND DOWNLOAD NATIONAL MAP TRANSPORTATION DATA\n1. Access the Viewer here.\n2. Expand the pane containing the layer options by clicking on Overlays at the upper-left.\n3. Under Base Data Layers, click on Transportation. You can expand the Transportation list and\nsub-select different layers.\n4. As you zoom in to larger map scales (using the slider bar at the upper-left of the map),\nadditional transportation layers will become visible.\n5. If you wish to download an extract from the transportation database, click the Download\nData button in the upper-right of the viewer interface and decide how you wish to extract the\ndata. The Transportation data comes down in ESRI\u2019s geodatabase format. Additional\ninformation regarding downloading data can be found via the Help button in the upper-right\nof the viewer interface.\n7.18. Theme: Governmental Units\nThe FGDC framework also includes boundaries of governmental units, including:\n\u2022 Nation\n\u2022 States and statistically equivalent areas\n\u2022 Counties and statistically equivalent areas\n\u2022 Incorporated places and consolidated cities\n\u2022 Functioning legal minor civil divisions\n\u2022 Federal- or state-recognized American Indian reservations and trustlands\n\u2022 Alaska native regional corporations\nFGDC specifies that:\nEach of these features includes the attributes of name and the applicable Federal Information\nProcessing Standard (FIPS) code. Features boundaries include information about other features (such as\nroad, railroads, or streams) with which the boundaries are associated and a description of the association\n(such as coincidence, offset, or corridor. (FGDC, 1997, p. 20-21)\nIDENTIFICATION\nThe USGS National Map aspires to include a comprehensive database of boundary data. In addition\nto the entities outlined above, the National Map also lists congressional districts, school districts, and\nZIP Code zones. Sources for these data include \u201cFederal partners such as the U.S. Census Bureau, other\nFederal agencies, and State and local agencies.\u201d (USGS, 2007). 281 David DiBiase\nTo get a sense of the complexity of the features and attributes that comprise this theme, see\nthe Governmental Units Data Model (This is a 36\u2033 x 48\u2033 poster in a 2.4 Mb PDF file.) [The link\nto the Governmental Units Data Model poster recently became disconnected. Instead look at the\nmodel diagrams in the Part 5: Governemntal unit and other geographic area boundaries of the FGDC\nGeographic Framework Data Content Standard.]\nDISTRIBUTION\nTRY THIS!\nVIEW AND DOWNLOAD NATIONAL MAP GOVERNMENTAL UNITS DATA\n1. Access the Viewer here.\n2. Expand the pane containing the layer options by clicking on Overlays at the upper-left.\n3. Under Base Data Layers, click on Governmental Unit Boundaries. You can expand the this\nlist and sub-select different boundary layers.\n4. As you zoom in to larger map scales (using the slider bar at the upper-left of the map),\nadditional boundary layers will become visible.\n5. If you wish to download an extract from the Governmental Unit Boundaries database, click\nthe Download Data button in the upper-right of the viewer interface and decide how you wish\nto extract the data. The Governmental Unit Boundaries data comes down in ESRI\u2019s\ngeodatabase format. Additional information regarding downloading data can be found via the\nHelp button in the upper-right of the viewer interface.\n7.19. Theme: Cadastral\nFGDC (1997, p. 21) points out that:\nCadastral data represent the geographic extent of the past, current, and future rights and interests\nin real property. The spatial information necessary to describe the geographic extent and the rights\nand interests includes surveys, legal description reference systems, and parcel-by-parcel surveys and\ndescriptions.\nHowever, no one expects that legal descriptions and survey coordinates of private property boundaries\n(as depicted schematically in the portion of the plat map shown below) will be included in the USGS\nNational Map any time soon. As discussed at the outset of Chapter 6, this is because local governments\nhave authority for land title registration in the U.S., and most of these governments have neither the\nincentive nor the means to incorporate such data into a publicly-accessible national database. Nature of Geographic Information 282\nPlat maps are supplementary records that depict property parcel boundaries in graphic form. The\ngeometric accuracy of plats is notoriously poor. The investment required to convert plat maps to properly\ngeoreferenced digital data is substantial. Many local governments have converted these records to digital\nform, or are in the process of doing so.\nFGDC\u2019s modest goal for the cadastal theme of the NSDI framework is to include:\n\u2026cadastral reference systems, such as the Public Land Survey System (PLSS) and similar systems\nnot covered by the PLSS \u2026 and publicly administered parcels, such as military reservations, national\nforests, and state parks. (Ibid, p. 21)\nFGDC\u2019s Cadastral Data Content Standard is published here.\nThe colored areas on the map below show the extent of the United States Public Land Surveys,\nwhich commenced in 1784 and took nearly a century to complete (Muehrcke and Muehrcke, 1998). The\npurpose of the surveys was to partition \u201cpublic land\u201d into saleable parcels in order to raise revenues\nneeded to retire war debt, and to promote settlement. A key feature of the system is its nomenclature,\nwhich provides concise, unique specifications of the location and extent of any parcel. 283 David DiBiase\nExtent of the U.S. Public Land Survey (Thompson, 1988).\nEach Public Land Survey (shown in the colored areas above) commenced from an initial point at\nthe precisely surveyed intersection of a base line and principal meridian. Surveyed lands were then\npartitioned into grids of townships each approximately six miles square.\nTownships are designated by their locations relative to the base line and principal meridian of a Nature of Geographic Information 284\nparticular survey. For example, the township highlighted in gold above is the second township south of\nthe baseline and the third township west of the principal meridian. The Public Land Survey designation\nfor the highlighted township is \u201cTownship 2 South, Range 3 West.\u201d Because of this nomenclature, the\nPublic Land Survey System is also known as the \u201ctownship and range system.\u201d Township T2S, R3W is\nshown enlarged below.\nTownships are subdivided into grids of 36 sections. Each section covers approximately one square\nmile (640 acres). Notice the back-and-forth numbering scheme. Section 14, highlighted in gold above,\nis shown enlarged below. 285 David DiBiase\nInidividual property parcels are designated as shown above. For instance, the NE 1\/4 of Section 14,\nTownship 2 S, Range 3W, is a 160-acre parcel. Public Land Survey designations specify both the\nlocation of a parcel and its area. Nature of Geographic Information 286\nThe influence of the Public Land Survey grid is evident in the built environment of much of the\nAmerican Midwest. As Mark Monmonier (1995, p. 114) observes:\nThe result [of the U.S. Public Land Survey] was an \u2018authored landscape\u2019 in which the survey grid\nhad a marked effect on settlement patterns and the shapes of counties and smaller political units. In the\ntypical Midwestern county, roads commonly following section lines, the rural population is dispersed\nrather than clustered, and the landscape has a pronounced checkerboard appearance.\nFor more information about the Public Land Survey System, see this article in the in the USGS\u2019\nNational Atlas.\n7.20. Summary\nNSDI framework data represent \u201cthe most common data themes [that] users need\u201d (FGDC, 1997, p.\n3), including geodetic control, orthoimagery, elevation, hydrography, transportation, governmental unit\nboundaries, and cadastral reference information. Some themes, like transportation and governmental\nunits, represent things that have well-defined edges. In this sense we can think of things like roads and\npolitical boundaries as discrete phenomena. The vector approach to geographic representation is well\nsuited to digitizing discrete phenomena. Line features do a good job of representing roads, for example,\nand polygons are useful approximations of boundaries.\nAs you recall from Chapter 1, however, one of the distinguishing properties of the Earth\u2019s surface\nis that it is continuous. Some phenomena distributed across the surface are continuous too. Terrain 287 David DiBiase\nelevations, gravity, magnetic declination and surface air temperature can be measured practically\neverywhere. For many purposes, rasterdata are best suited to representing continuous phenomena.\nAn implication of continuity is that there is an infinite number of locations at which phenomena\ncan be measured. It is not possible, obviously, to take an infinite number of measurements. Even if it\nwere, the mass of data produced would not be usable. The solution, of course, is to collect a sample\nof measurements, and to estimate attribute values for locations that are left unmeasured. Chapter 7\nalso considers how missing elevations in a raster grid can be estimated from existing elevations, using\na procedure called interpolation. The inverse distance weighted interpolation procedure relies upon\nanother fundamental property of geographic data, spatial dependence.\nThe chapter concludes by investigating the characteristics and current status of the hydrography,\ntransportation, governmental units, and cadastral themes. You had the opportunity to access, download,\nand open several of the data themes using viewers provided by USGS as part of its National Map\ninitiative. In general, you should have found that although neither the NSDI or National Map visions\nhave been fully realized, substantial elements of each is in place. Further progress depends on the\nAmerican public\u2019s continuing commitment to public data, and to the political will of our representatives\nin government.\nQUIZ\nRegistered Penn State students should return now to the Chapter 7 folder in ANGEL (via the Resources\nmenu to the left) to access the graded quiz for this chapter. This one counts. You may take graded\nquizzes only once.\nThe purpose of the quiz is to ensure that you have studied the text closely, that you have mastered\nthe practice activities, and that you have fulfilled the chapter\u2019s learning objectives. You are welcome to\nreview the chapter during the quiz.\nOnce you have submitted the quiz and posted any questions you may have to either our discussion\nforums or chapter pages, you will have completed Chapter 7.\nCOMMENTS AND QUESTIONS\nRegistered students are welcome to post comments, questions, and replies to questions about the\ntext. Particularly welcome are anecdotes that relate the chapter text to your personal or professional\nexperience. In addition, there are discussion forums available in the ANGEL course management system\nfor comments and questions about topics that you may not wish to share with the whole world.\nTo post a comment, scroll down to the text box under \u201cPost new comment\u201d and begin typing in the text\nbox, or you can choose to reply to an existing thread. When you are finished typing, click on either the\n\u201cPreview\u201d or \u201cSave\u201d button (Save will actually submit your comment). Once your comment is posted,\nyou will be able to edit or delete it as needed. In addition, you will be able to reply to other posts at any\ntime.\nNote: the first few words of each comment become its \u201ctitle\u201d in the thread.\n7.21. Bibliography\nFederal Geographic Data Committee (1997). Framework introduction and guide. Washington DC:\nFederal Geographic Data Committee. Nature of Geographic Information 288\nEischeid, J. D., Baker, C. B., Karl, R. R., Diaz, H. F. (1995). The quality control of long-term\nclimatological data using objective data analysis. Journal of Applied Meteorology, 34, 27-88.\nGould, P. (1989). Geographic dimensions of the AIDS epidemic.Professional Geographer, 41:1,\n71-77.\nMaune, D. F. (Ed.) (2007). Digital elevation model technologies and applications: The DEM users\nmanual, 2nd edition. Bethesda, MD: American Society for Photogrammetric Engineering and Remote\nSensing.\nMonmonier, M. S. (1982). Drawing the line: tales of maps and cartocontroversy. New York, NY:\nHenry Holt.\nMuehrcke, P. C. and Muehrcke, J. O. (1998) Map use, 4th Ed. Madison, WI: JP Publications.\nNational Aeronautics and Space Administration, Jet Propulsion Laboratory (2006). Shuttle radar\ntopography mission. Retrieved May 10, 2006, from http:\/\/www.jpl.nasa.gov\/srtm\nGoddard Space Flight Center, National Aeronautics and Space Administration (n.d.). Greenland\u2019s\nreceding ice. Retrieved Feburary 26, 2008, from http:\/\/svs.gsfc.nasa.gov\/stories\/greenland\/\nNational Geophysical Data Center (2010). ETOPO1 global gridded 1 arc-minute database. Retrieved\nMarch 2, 2010, fromhttp:\/\/www.ngdc.noaa.gov\/mgg\/global\/global.html\nNational Oceanic and Atmospheric Administration, National Climatic Data Center (n. d.). Merged\nland-ocean seasonal temperature anomalies. Retrieved August 18, 1999,\nfromhttp:\/\/www.ncdc.noaa.giv\/onlineprod\/landocean\/seasonal\/form.html(expired)\nNational Oceanic and Atmospheric Administration (2002). Side scan and multibeam sonar. Retrieved\nFebruary 18, 2008, fromhttp:\/\/www.nauticalcharts.noaa.gov\/hsd\/hydrog.htm\nNational Oceanic and Atmospheric Administration (2007). NOAA History. Retrieved February 27,\n2008, fromhttp:\/\/www.history.noaa.gov\/\nRabenhorst, T. D. and McDermott, P. D. (1989). Applied cartography: source materials for\nmapmaking. Columbus, OH: Merrill.\nRaitz, E. (1948). General cartography. New York, NY: McGraw-Hill.\nRalston, B. A. (2004). GIS and public data. Clifton Park NY: Delmar Learning.\nThompson, M. M. (1988) Maps for america, 3rd Ed. Reston, VA: United States Geological Survey.\nUnited States Geological Survey (1987) Digital elevation models. Data users guide 5. Reston, VA:\nUSGS.\nUnited States Geological Survey (1999) The National Hydrography Dataset. Fact Sheet 106-99.\nReston, VA: USGS. Retrieved February 19, 2008 from http:\/\/erg.usgs.gov\/isb\/pubs\/factsheets\/\nfs10699.html\nUnited States Geological Survey (2000) The National Hydrography Dataset: Concepts and Contents.\nReston, VA: USGS. Retrieved February 19, 2008 fromhttp:\/\/nhd.usgs.gov\/chapter1\/\nchp1_data_users_guide.pdf\nUnited States Geological Survey (2002) The National Map \u2013 Hydrography. Fact Sheet 060-02.\nReston, VA: USGS. Retrieved February 19, 2008 fromhttp:\/\/erg.usgs.gov\/isb\/pubs\/factsheets\/\nfs06002.html Retrieved September 22, 2013 from http:\/\/pubs.er.usgs.gov\/publication\/fs06002\nUnited States Geological Survey (2006a) Digital Line Graphs (DLG). Reston, VA: USGS. Retrieved\nFebruary 18, 2008 fromhttp:\/\/edc.usgs.gov\/products\/map\/dlg.html (In 2010 the site\nbecamehttp:\/\/eros.usgs.gov\/#\/Find_Data\/Products_and_Data_Available\/DLGs)\nUnited States Geological Survey (2006b) GTOPO30. Retrieved February 27, 2008\nfromhttp:\/\/edc.usgs.gov\/products\/elevation\/gtopo30\/gtopo30.html since moved\nto http:\/\/www1.gsi.go.jp\/geowww\/globalmap-gsi\/gtopo30\/gtopo30.html\nUnited States Geological Survey (2006c) National Hydrography Dataset (NHD) \u2013 High-resolution 289 David DiBiase\n(Metadata). Reston, VA: USGS. Retrieved February 19, 2008 fromhttp:\/\/nhdgeo.usgs.gov\/metadata\/\nnhd_high.htm\nUnited States Geological Survey (2007). Vector data theme development of The National\nMap. Retrieved 24 February 2008 fromhttp:\/\/bpgeo.cr.usgs.gov\/model\/ (expired or moved)\nUnited States Geological Survey (2009) The National Map \u2013 Hydrography Dataset. Reston, VA:\nUSGS. Retrieved September 22, 2013 from http:\/\/pubs.usgs.gov\/fs\/2009\/3054\/pdf\/FS2009-3054.pdf\nUnited States Geological Survey (2013) National Hydrography Dataset (NHD) \u2013 Get NDH Data.\nReston, VA: USGS. Retrieved September 22, 2013 from http:\/\/nhd.usgs.gov\/data.html Chapter 8\n290 Remotely Sensed Image Data\nDavid DiBiase\n8.1. Overview\nChapter 7 concluded with the statement that the raster approach is well suited not only to terrain surfaces,\nbut to other continuous phenomena as well. This chapter considers the characteristics and uses of raster\ndata produced with satellite remote sensing systems. Remote sensing is a key source of data for land\nuse and land cover mapping, agricultural and environmental resource management, mineral exploration,\nweather forecasting, and global change research.\nObjectives\nThe overall goal of the lesson is to acquaint you with the properties of data produced by satellite-based\nsensors. Specifically, in the lesson you will learn to:\n1. Compare and contrast the characteristics of image data produced by photography and digital\nremote sensing systems;\n2. Use the Web to find Landsat data for a particular place and time;\n3. Explain why and how remotely sensed image data are processed; and\n4. Perform a simulated unsupervised classification of raster image data.\nComments and Questions\nRegistered students are welcome to post comments, questions, and replies to questions about the\ntext. Particularly welcome are anecdotes that relate the chapter text to your personal or professional\nexperience. In addition, there are discussion forums available in the ANGEL course management system\nfor comments and questions about topics that you may not wish to share with the whole world.\nTo post a comment, scroll down to the text box under \u201cPost new comment\u201d and begin typing in the text\nbox, or you can choose to reply to an existing thread. When you are finished typing, click on either the\n\u201cPreview\u201d or \u201cSave\u201d button (Save will actually submit your comment). Once your comment is posted,\nyou will be able to edit or delete it as needed. In addition, you will be able to reply to other posts at any\ntime.\nNote: the first few words of each comment become its \u201ctitle\u201d in the thread.\n8.2. Checklist\nThe following checklist is for Penn State students who are registered for classes in which this text,\nand associated quizzes and projects in the ANGEL course management system, have been assigned. You\nmay find it useful to print this page out first so that you can follow along with the directions.\n291 Nature of Geographic Information 292\nChapter 8 Checklist (for registered students only)\nStep Activity Access\/Directions\nThis is the second page of the Chapter. Click on the links at the bottom\nof the page to continue or to return to the previous page, or to go to the\n1 Read Chapter 8\ntop of the chapter. You can also navigate the text via the links in the\nGEOG 482 menu on the left.\nSubmit four practice\nquizzesincluding:\n\u2022 Nature of Image Data\n\u2022 Visible and Infrared\nData\nGo to ANGEL > [your course section] > Lessons tab > Chapter 8 folder\n2\n\u2022 Image Processing > [quiz]\n\u2022 Microwave Data\nPractice quizzes are not graded\nand may be submitted more\nthan once.\nPerform \u201cTry this\u201d\nactivitiesincluding:\n\u2022 Study remote sensing\nfundamentals and\ncase studies at\nUSGS\u2019 Earthshots\nsite\n\u2022 View the global\ndistribution of\nLandsat scenes at\nUSGS\u2019 Spacetracks\n3 site Instructions are provided for each activity.\n\u2022 Find, preview and\nacquire Landsat data\nat the USGS\nEarthExplorer site\n\u2022 Perform a simulated\nunsupervised\nclassification of\nraster image data\n\u201cTry this\u201d activities are not\ngraded.\nSubmit theChapter 8 Graded ANGEL > [your course section] > Lessons tab > Chapter 8 folder >\n4\nQuiz Chapter 8 Graded Quiz. See the Calendar tab in ANGEL for due dates.\nRead comments and\nquestionsposted by fellow Comments and questions may be posted on any page of the text, or in a\n5\nstudents. Add comments and Chapter-specific discussion forum in ANGEL.\nquestions of your own, if any. 293 David DiBiase\n8.3. Nature of Remotely Sensed Image Data\nData, as you know, consist of measurements. Here we consider the nature of the phenomenon that\nmany, though not all, remote sensing systems measure: electromagnetic energy. Many of the objects\nthat make up the Earth\u2019s surface reflect and emit electromagnetic energy in unique ways. The appeal of\nmultispectral remote sensing is that objects that are indistinguishable at one energy wavelength may be\neasy to tell apart at other wavelengths. You will see that digital remote sensing is a little like scanning a\npaper document with a desktop scanner, only a lot more complicated.\n8.4. Electromagnetic Spectrum\nMost remote sensing instruments measure the same thing: electromagnetic radiation. Electromagnetic\nradiation is a form of energy emitted by all matter above absolute zero temperature (0 Kelvin or -273\u00b0\nCelsius). X-rays, ultraviolet rays, visible light, infrared light, heat, microwaves, and radio and television\nwaves are all examples of electromagnetic energy.\nA portion of the electromagnetic spectrum, ranging from wavelengths of 0.1 micrometer (a\nmicrometer is one millionth of a meter) to one meter, within which most remote sensing systems operate.\n(Adapted from Lillesand & Kiefer, 1994).\nThe graph above shows the relative amounts of electromagnetic energy emitted by the Sun and the\nEarth across the range of wavelengths called the electromagnetic spectrum. Values along the horizontal\naxis of the graph range from very short wavelengths (ten millionths of a meter) to long wavelengths\n(meters). Note that the horizontal axis is logarithmically scaled, so that each increment represents a ten-\nfold increase in wavelength. The axis has been interrupted three times at the long wave end of the scale\nto make the diagram compact enough to fit on your screen. The vertical axis of the graph represents the\nmagnitude of radiation emitted at each wavelength.\nHotter objects radiate more electromagnetic energy than cooler objects. Hotter objects also radiate\nenergy at shorter wavelengths than cooler objects. Thus, as the graph shows, the Sun emits more energy\nthan the Earth, and the Sun\u2019s radiation peaks at shorter wavelengths. The portion of the electromagnetic\nspectrum at the peak of the Sun\u2019s radiation is called the visible band because the human visual\nperception system is sensitive to those wavelengths. Human vision is a powerful means of sensing\nelectromagnetic energy within the visual band. Remote sensing technologies extend our ability to sense\nelectromagnetic energy beyond the visible band, allowing us to see the Earth\u2019s surface in new ways,\nwhich in turn reveals patterns that are normally invisible. Nature of Geographic Information 294\nThe electromagnetic spectrum divided into five wavelength bands. (Adapted from Lillesand & Kiefer,\n1994).\nThe graph above names several regions of the electromagnetic spectrum. Remote sensing systems\nhave been developed to measure reflected or emitted energy at various wavelengths for different\npurposes. This chapter highlights systems designed to record radiation in the bands commonly used for\nland use and land cover mapping: the visible, infrared, and microwave bands.\nThe transmissivity of the atmosphere across a range of wavelengths. Black areas indicate wavelengths\nat which the atmosphere is partially or wholly opaque. (Adapted from Lillesand & Kiefer, 1994).\nAt certain wavelengths, the atmosphere poses an obstacle to satellite remote sensing by absorbing\nelectromagnetic energy. Sensing systems are therefore designed to measure wavelengths within the\nwindows where the transmissivity of the atmosphere is greatest.\n8.5. Spectral Response Patterns\nThe Earth\u2019s land surface reflects about three percent of all incoming solar radiation back to space.\nThe rest is either reflected by the atmosphere, or absorbed and re-radiated as infrared energy. The\nvarious objects that make up the surface absorb and reflect different amounts of energy at different\nwavelengths. The magnitude of energy that an object reflects or emits across a range of wavelengths is\ncalled its spectral response pattern.\nThe graph below illustrates the spectral response patterns of water, brownish gray soil, and grass\nbetween about 0.3 and 6.0 micrometers. The graph shows that grass, for instance, reflects relatively\nlittle energy in the visible band (although the spike in the middle of the visible band explains why\ngrass looks green). Like most vegetation, the chlorophyll in grass absorbs visible energy (particularly in\nthe blue and red wavelengths) for use during photosynthesis. About half of the incoming near-infrared\nradiation is reflected, however, which is characteristic of healthy, hydrated vegetation. Brownish gray\nsoil reflects more energy at longer wavelengths than grass. Water absorbs most incoming radiation\nacross the entire range of wavelengths. Knowing their typical spectral response characteristics, it is\npossible to identify forests, crops, soils, and geological formations in remotely sensed imagery, and to\nevaluate their condition. 295 David DiBiase\nThe spectral response patterns of brownish-gray soil (mollisol), grass, and water. To explore the\nspectral response characteristics of thousands of natural and man made materials, visit the ASTER\nSpectral Library at http:\/\/speclib.jpl.nasa.gov\/. (California Institute of Technology, 2002).\nThe next graph demonstrates one of the advantages of being able to see beyond the visible spectrum.\nThe two lines represent the spectral response patterns of conifer and deciduous trees. Notice that the\nreflectances within the visual band are nearly identical. At longer, near- and mid-infrared wavelengths,\nhowever, the two types are much easier to differentiate. As you\u2019ll see later, land use and land cover\nmapping were previously accomplished by visual inspection of photographic imagery. Multispectral data\nand digital image processing make it possible to partially automate land cover mapping, which in turn\nmakes it cost effective to identify some land use and land cover categories automatically, all of which\nmakes it possible to map larger land areas more frequently. Nature of Geographic Information 296\nThe spectral response patterns of conifer trees and deciduous trees (California Institute of Technology,\n1999).\nSpectral response patterns are sometimes called spectral signatures. This term is misleading,\nhowever, because the reflectance of an entity varies with its condition, the time of year, and even the\ntime of day. Instead of thin lines, the spectral responses of water, soil, grass, and trees might better be\ndepicted as wide swaths to account for these variations.\n8.6. Raster Scanning\nRemote sensing systems work in much the same way as the digital flatbed scanner you may have\nattached to your personal computer. A desktop scanner creates a digital image of a document by\nrecording, pixel by pixel, the intensity of light reflected from the document. The component that\nmeasures reflectance is called the scan head, which consists of a row of tiny sensors that convert light to\nelectrical charges. Color scanners may have three light sources and three sets of sensors, one each for the\nblue, green, and red wavelengths of visible light. When you push a button to scan a document, the scan\nhead is propelled rapidly across the image, one small step at a time, recording new rows of electrical\nsignals as it goes. Remotely sensed data, like the images produced by your desktop scanner, consist of\nreflectance values arrayed in rows and columns that make up raster grids. 297 David DiBiase\nDesktop scanner, circa 2000.\nAfter the scan head converts reflectances to electrical signals, another component, called the analog-\nto-digital converter, converts the electrical charges into digital values. Although reflectances may vary\nfrom 0 percent to 100 percent, digital values typically range from 0 to 255. This is because digital values\nare stored as units of memory called bits. One bit represents a single binary integer, 1 or 0. The more\nbits of data that are stored for each pixel, the more precisely reflectances can be represented in a scanned\nimage. The number of bits stored for each pixel is called the bit depth of an image. An 8-bit image is\nable to represent 28 (256) unique reflectance values. A color desktop scanner may produce 24-bit images\nin which 8 bits of data are stored for each of the blue, green, and red wavelengths of visible light.\nArtist\u2019s rendition of the Landsat 7 remote sensing satellite. The satellite does not really cast a four-\nsided beam of light upon the Earth\u2019s surface, of course. Instead, it merely records electromagnetic energy\nreflected or emitted by the Earth. (NASA, 2001). Nature of Geographic Information 298\nAs you might imagine, scanning the surface of the Earth is considerably more complicated than\nscanning a paper document with a desktop scanner. Unlike the document, the Earth\u2019s surface is too\nlarge to be scanned all at once, and so must be scanned piece by piece, and mosaicked together later.\nDocuments are flat, but the Earth\u2019s shape is curved and complex. Documents lay still while they are\nbeing scanned, but the Earth rotates continuously around its axis at a rate of over 1,600 kilometers per\nhour. In the desktop scanner, the scan head and the document are separated only by a plate of glass;\nsatellite-based sensing systems may be hundreds or thousands of kilometers distant from their targets,\nseparated by an atmosphere that is nowhere near as transparent as glass. And while a document in\na desktop scanner is illuminated uniformly and consistently, the amount of solar energy reflected or\nemitted from the Earth\u2019s surface varies with latitude, the time of year, and even the time of day. All\nof these complexities combine to yield data with geometric and radiometric distortions that must be\ncorrected before the data are useful for analysis. Later in this chapter you\u2019ll learn about some of the\nimage processing techniques used to correct remotely sensed image data.\n8.7. Resolution\nSo far you\u2019ve read that remote sensing systems measure electromagnetic radiation, and that they record\nmeasurements in the form of raster image data. The resolution of remotely sensed image data varies\nin several ways. As you recall, resolution is the least detectable difference in a measurement. In this\ncontext, three of the most important kinds are spatial resolution, radiometric resolution and spectral\nresolution.\nSpatial resolution refers to the coarseness or fineness of a raster grid. The grid cells in high resolution\ndata, such as those produced by digital aerial imaging, or by the Ikonos satellite, correspond to ground\nareas as small or smaller than one square meter. Remotely sensed data whose grid cells range from 15\nto 80 meters on a side, such as the Landsat ETM+ and MSS sensors, are considered medium resolution.\nThe cells in low resolution data, such as those produced by NOAA\u2019s AVHRR sensor, are measured in\nkilometers. (You\u2019ll learn more about all these sensors later in this chapter.)\nSpatial resolution is a measure of the coarseness or fineness of a raster grid.\nThe higher the spatial resolution of a digital image, the more detail it contains. Detail is valuable 299 David DiBiase\nfor some applications, but it is also costly. Consider, for example, that an 8-bit image of the entire\nEarth whose spatial resolution is one meter could fill 78,400 CD-ROM disks, a stack over 250 feet high\n(assuming that the data were not compressed). Although data compression techniques reduce storage\nrequirements greatly, the storage and processing costs associated with high resolution satellite data often\nmake medium and low resolution data preferable for analyses of extensive areas.\nA second aspect of resolution is radiometric resolution, the measure of a sensor\u2019s ability to\ndiscriminate small differences in the magnitude of radiation within the ground area that corresponds to\na single raster cell. The greater the bit depth (number of data bits per pixel) of the images that a sensor\nrecords, the higher its radiometric resolution. The AVHRR sensor, for example, stores 210 bits per pixel,\nas opposed to the 28 bits that the Landsat sensors record. Thus although its spatial resolution is very\ncoarse (~4 km), the Advanced Very High Resolution Radiometer takes its name from its high radiometric\nresolution.\nRadiometric resolution. The area under the curve represents the magnitude of electromagnetic energy\nemitted by the Sun at various wavelengths. Sensors with low radiometric resolution are able to detect\nonly relatively large differences in energy magnitude (as represented by the lighter and thicker purple\nband). Sensors with high radiometric resolution are able to detect relatively small differences\n(represented by the darker and thinner band).\nFinally, there is spectral resolution, the ability of a sensor to detect small differences in wavelength.\nFor example, panchromatic film is sensitive to a broad range of wavelengths. An object that reflects a\nlot of energy in the green portion of the visible band would be indistinguishable in a panchromatic photo\nfrom an object that reflected the same amount of energy in the red band, for instance. A sensing system\nwith higher spectral resolution would make it easier to tell the two objects apart. Nature of Geographic Information 300\nSpectral resolution. The area under the curve represents the magnitude of electromagnetic energy\nemitted by the Sun at various wavelengths. Low resolution sensors record energy within relatively wide\nwavelength bands (represented by the lighter and thicker purple band). High-resolution sensors record\nenergy within narrow bands (represented by the darker and thinner band)\n8.8. Site visit to USGS Earthshots\nTRY THIS!\nThe following exercise involves a site visit to Earthshots, a World Wide Web site created by the USGS\nto publicize the many contributions of remote sensing to the field of environmental science. There you\nwill view and compare examples of images produced from Landsat data.\nThe USGS has recently revised the Earthshots website and made it more layman friendly.\nUnfortunately the new site is much less valuable to our education mission. Fortunately, though, the older\nweb pages are still available. So, after taking you briefly to the new Earthshots homepage, in step 1, I\nwill direct you to the older pages that are more informative for us.\n1. To begin, point your browser to the newer Earthshots site. Go ahead and explore this site. Note the\ninformation found by following theAbout Earthshots button. 301 David DiBiase\n2. Next go to the USGS Earthshots site. Nature of Geographic Information 302\n3. View images produced from Landsat data Follow the link to the Garden City, Kansas example.\nYou\u2019ll be presented with an image created from Landsat data of Garden City, Kansas in 1972. By\nclicking the date link below the lower left corner of the image, you can compare images produced from\nLandsat data collected in 1972 and 1988. 303 David DiBiase\n4. Zoom in to a portion of the image Four yellow corner ticks outline a portion of the image that is\nlinked to a magnified view. Click within the ticks to view the magnified image. Nature of Geographic Information 304\n5. View a photograph taken on the ground Click on one of the little camera icons arranged one above\nthe other in the western quarter of the image. A photograph taken on the ground will appear.\n6. Explore articles linked to the example Find answers to the following questions in the related articles\nentitled What the colors mean, How images represent Landsat data, MSS and TM bands, andBeyond\nlooking at pictures.\n1. What is the spectral sensitivity of the Landsat MSS sensor used to captured the image data?\n2. Which wavelength bands are represented in the image?\n3. What does the red color signify?\n4. How was \u201ccontrast stretching\u201d used to enhance the images?\n5. What is the spatial resolution of the MSS data from which the images were produced?\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 8 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about the Nature of Image Data.\nYou may take practice quizzes as many times as you wish. They are not scored and do not affect your\ngrade in any way. 305 David DiBiase\n8.9. Visible and Infrared Image Data\nNext we explore examples of remotely sensed image data produced by measuring electromagnetic\nenergy in the visible, near-infrared, and thermal infrared bands. Aerial photography is reconsidered as an\nanalog to digital image data. Characteristics of panchromatic data produced by satellite-based cameras\nand sensors like KVR 1000, IKONOS, and DMSP are compared, as well as multispectral data produced\nby AVHRR, Landsat, and SPOT. We conclude with an opportunity to shop for satellite image data online.\n8.10. Aerial Imaging\nNot counting human vision, aerial photography is the earliest remote sensing technology. A Parisian\nphotographer allegedly took the first air photo from a balloon in 1858. If you are (or were) a\nphotographer who uses film cameras, you probably know that photographic films are made up of layers.\nOne or more layers consist of emulsions of light-sensitive silver halide crystals. The black and white\nfilm used most often for aerial photography consists of a single layer of silver crystals that are sensitive\nto the entire visible band of the electromagnetic spectrum. Data produced from photographic film and\ndigital sensors that are sensitive to the entire visible band are called panchromatic.\nWhen exposed to light, silver halide crystals are reduced to black metallic silver. The more light a\ncrystal absorbs, the darker it becomes when the film is developed. A black and white panchromatic photo\nthus represents the intensities of visible electromagnetic energy recorded across the surface of the film\nat the moment of exposure. You can think of a silver halide crystal as a physical analog for a pixel in a\ndigital image.\nA vertical aerial photograph produced from panchromatic film.\nExperienced film photographers know to use high-speed film to capture an image in a low-light\nsetting. They also know that faster films tend to produce grainier images. This is because fast films\ncontain larger silver halide grains, which are more sensitive to light than smaller grains. Films used for Nature of Geographic Information 306\naerial photography must be fast enough to capture sharp images from aircraft moving at hundreds of feet\nper second, but not so fast as to produce images so grainy that they mask important details. Thus, the\ngrain size of a photographic film is a physical analog for the spatial resolution of a digital image. Cowen\nand Jensen (1998) estimated the spatial resolution of a high resolution aerial photograph to be about\n0.3-0.5 meters (30-50 cm). Since then, the resolution that can be achieved by digital aerial imaging has\nincreased to as great as 0.05 meters (5 cm). For applications in which maximum spatial and temporal\nresolutions are needed, aerial (as opposed to satellite) imaging still has its advantages.\nEarlier in the course you learned (or perhaps you already knew) that the U.S. National Agricultural\nImagery Program (NAIP) flies much of the lower 48 states every year. Organizations that need more\ntimely imagery typically hire private aerial survey firms to fly custom photography missions. Most\norganizations would prefer to have image data in digital form, if possible, since digital image processing\n(including geometric and radiometric correction) is more efficient than comparable darkroom methods,\nand because most users want to combine imagery with other data layers in GIS databases. Digital\nimage data are becoming a cost-effective alternative for many applications as the spatial and radiometric\nresolution of digital sensors increases.\n8.11. High Resolution Panchromatic Image Data\nJust as digital cameras have replaced film cameras for many of us on the ground, digital sensors are\nreplacing cameras for aerial surveys. This section describes two sources of digital panchromatic imagery\nwith sufficient geometric resolution for some, though certainly not all, large-scale mapping tasks. Also\nconsidered is a panchromatic sensing system with sufficient radiometric resolution to detect from space\nthe light emitted by human settlements at night.\nKVR-1000 \/ SPIN-2\nHigh-resolution panchromatic image data first became available to civilians in 1994, when the Russian\nspace agency SOVINFORMSPUTNIK began selling surveillance photos to raise cash in the aftermath of\nthe breakup of the Soviet Union. The photos are taken with an extraordinary camera system called KVR\n1000. KVR 1000 cameras are mounted in unmanned space capsules very much like the one in which\nRussian cosmonaut Yuri Gagarin first traveled into space in 1961. After orbiting the Earth at altitudes\nof 220 kilometers for about 40 days, the capsules separate from the Cosmos rockets that propelled them\ninto space, and spiral slowly back to Earth. After the capsules parachute to the surface, ground personnel\nretrieve the cameras and transport them to Moscow, where the film is developed. Photographs are then\nshipped to the U.S., where they are scanned and processed by Kodak Corporation. The final product is\ntwo-meter resolution, georeferenced, and orthorectified digital data called SPIN-2 (Space Information\n2-Meter). A firm called Aerial Images Inc. was licensed in 1998 to distribute SPIN-2 data in the U.S\n(SPIN-2, 1999). 307 David DiBiase\nPortion of a SPIN-2 image of Dallas, Texas.\n\u00a9 2006 Aerial Images, Inc. All rights reserved. Used by Permission.\nIKONOS\nAlso in 1994, when the Russian space agency first began selling its space surveillance imagery, a new\ncompany called Space Imaging, Inc. was chartered in the U.S. Recognizing that high-resolution images\nwere then available commercially from competing foreign sources, the U.S. government authorized\nprivate firms under its jurisdiction to produce and market remotely sensed data at spatial resolutions as\nhigh as one meter. By 1999, after a failed first attempt, Space Imaging successfully launched its Ikonos\nI satellite into an orbital path that circles the Earth 640 km above the surface, from pole to pole, crossing\nthe equator at the same time of day every day. Such an orbit is called asun synchronous polar orbit,\nin contrast with the geosynchronousorbits of communications and some weather satellites that remain\nover the same point on the Earth\u2019s surface at all times. Nature of Geographic Information 308\nPortion of a 1-meter resolution panchromatic image of Washington, DC produced by the\nIkonos I sensor. \u00a9 2001 Space Imaging, inc. All Rights Reserved. Used by permission.\nIkonos\u2019 panchromatic sensor records reflectances in the visible band at a spatial resolution of one\nmeter, and a bit depth of eleven bits per pixel. The expanded bit depth enables the sensor to record\nreflectances more precisely, and allows technicians to filter out atmospheric haze more effectively than\nis possible with 8-bit imagery. Archived, unrectified, panchromatic Ikonos imagery within the U.S. is\navailable for as little as $7 per square kilometer, but new orthorectified imagery costs $28 per square\nkilometer and up.\nA competing firm called ORBIMAGE acquired Space Imaging in early 2006, after ORBIMAGE\nsecured a half-billion dollar contract with the National Geospatial-Intelligence Agency. The merged\ncompanies were called GeoEye, Inc. In early 2013 GeoEye was merged into\ntheDigitalGlobe corporation. A satellite named GeoEye-1 was launched in 2008 and provides sub-meter\n(0.41 meter) panchromatic resolution (GeoEye, 2007). In 2013 a new satellite named GeoEye-2 is due\nto become operational. It will have a panchromatic resolution of 0.34 meters.\nDMSP\nThe U.S. Air Force initiated its Defense Meteorology Satellite Program (DMSP) in the mid-1960s. By\n2001, they had launched fifteen DMSP satellites. The satellites follow polar orbits at altitudes of about\n830 km, circling the Earth every 101 minutes.\nThe program\u2019s original goal was to provide imagery that would aid high-altitude navigation by Air\nForce pilots. DMSP satellites carry several sensors, one of which is sensitive to a band of wavelengths\nencompassing the visible and near-infrared wavelengths (0.40-1.10 \u00b5m). The spatial resolution of this\npanchromatic sensor is low (2.7 km), but its radiometric resolution is high enough to record moonlight\nreflected from cloud tops at night. During cloudless new moons, the sensor is able to detect lights\nemitted by cities and towns. Image analysts have successfully correlated patterns of night lights with 309 David DiBiase\npopulation density estimates produced by the U.S. Census Bureau, enabling analysts to use DMSP\nimagery (in combination with other data layers, such as transportation networks) to monitor changes in\nglobal population distribution.\nComposite image of the Earth at night showing lights from cities and towns throughout the world.\nThis image was recorded by DMSP satellite sensors. (Geophysical Data Center, 2005).\n8.12. Multispectral Image Data\nThe previous section highlighted the one-meter panchromatic data produced by the IKONOS satellite\nsensor. Pan data is not all that IKONOS produces, however. It is a multispectral sensor that records\nreflectances within four other (narrower) bands, including the blue, green, and red wavelengths of the\nvisible spectrum, and the near-infrared band. The range(s) of wavelengths that a sensor is able to\ndetect is called its spectral sensitivity.\nIKONOS I (1999-)\nSpectral Sensitivity Spatial Resolution\n0.45 \u2013 0.90 \u03bcm (panchromatic) 1m\n0.45 \u2013 0.52 \u03bcm (visible blue) 4m\n0.51 \u2013 0.60 \u03bcm (visible green) 4m\n0.63 \u2013 0.70 \u03bcm (visible red) 4m\n0.76 \u2013 0.85 \u03bcm (near IR) 4m\nSpectral sensitivities and spatial resolution of the IKONOS I sensor. Wavelengths are expressed in\nmicrometers (millionths of a meter). Spatial resolution is expressed in meters.\nThis section profiles two families of multispectral sensors that play important roles in land use and\nland cover characterization: AVHRR and Landsat.\nAVHRR\nAVHRR stands for \u201cAdvanced Very High Resolution Radiometer.\u201d AVHRR sensors have been onboard\nsixteen satellites maintained by the National Oceanic and Atmospheric Administration (NOAA) since Nature of Geographic Information 310\n1979 (TIROS-N, NOAA-6 through NOAA-15). The data the sensors produce are widely used for large-\narea studies of vegetation, soil moisture, snow cover, fire susceptibility, and floods, among other things.\nAVHRR sensors measure electromagnetic energy within five spectral bands, including visible red,\nnear infrared, and three thermal infrared. The visible red and near-infrared bands are particularly useful\nfor large-area vegetation monitoring. The Normalized Difference Vegetation Index (NDVI), a widely\nused measure of photosynthetic activity that is calculated from reflectance values in these two bands, is\ndiscussed later.\nAVHRR (1979-)\nSpectral Sensitivity Spatial Resolution\n0.58 \u2013 0.68 \u03bcm (visible red) 1-4 km*\n0.725 \u2013 1.10 \u03bcm (near IR) 1-4 km*\n3.55 \u2013 3.93 \u03bcm (thermal IR) 1-4 km*\n10.3 \u2013 11.3 \u03bcm (thermal IR) 1-4 km*\n11.5 \u2013 12.5 \u03bcm (thermal IR) 1-4 km*\nSpectral sensitivities and spatial resolution of the AVHRR sensor. Wavelengths are expressed in\nmicrometers (millionths of a meter). Spatial resolution is expressed in kilometers (thousands of meters).\n*Spatial resolution of AVHRR data varies from 1 km to 16 km. Processed data consist of uniform 1 km\nor 4 km grids.\nThe NOAA satellites that carry AVHRR sensors trace sun-synchronous polar orbits at altitudes of\nabout 833 km. Traveling at ground velocities of over 6.5 kilometers per second, the satellites orbit the\nEarth 14 times daily (every 102 minutes), crossing over the same locations along the equator at the same\ntimes every day. As it orbits, the AVHRR sensor sweeps a scan head along a 110\u00b0-wide arc beneath\nthe satellite, taking many measurements every second. (The back and forth sweeping motion of the\nscan head is said to resemble a whisk-broom.) The arc corresponds to a ground swath of about 2400\nkm. Because the scan head traverses so wide an arc, its instantaneous field of view (IFOV: the ground\narea covered by a single pixel) varies greatly. Directly beneath the satellite, the IFOV is about 1 km\nsquare. Near the edge of the swath, however, the IFOV expands to over 16 square kilometers. To achieve\nuniform resolution, the distorted IFOVs near the edges of the swath must be resampled to a 1 km grid\n(Resampling is discussed later in this chapter). The AVHRR sensor is capable of producing daily global\ncoverage in the visible band, and twice daily coverage in the thermal IR band.\nFor more information, visit the USGS\u2019 AVHRR home page.\nLANDSAT MSS\nTelevision images of the Earth taken from early weather satellites (such as TIROS-1, launched in\n1960), and photographs taken by astronauts during the U.S. manned space programs in the 1960s, made\nscientists wonder about how such images could be used for environmental resource management. In\nthe mid 1960s, U.S. National Aeronautics and Space Administration (NASA) and the Department of\nInterior began work on a plan to launch a series of satellite-based orbiting sensors. The Earth Resource\nTechnology Satellite program launched its first satellite, ERTS-1, in 1972. When the second satellite\nwas launched in 1975, NASA renamed the program Landsat. Since then, there have been six successful 311 David DiBiase\nLandsat launches (Landsat 6 failed shortly after takeoff in 1993; Landsat 7 successfully launched in\n1999).\nTwo sensing systems were on board Landsat 1 (formerly ERTS-1): a Return Beam Videcon (RBV)\nand a Multispectral Scanner (MSS). The RBV system is analogous to today\u2019s digital cameras. It sensed\nradiation in the visible band for an entire 185 km square scene at once, producing images comparable to\ncolor photographs. The RBV sensor was discontinued after Landsat 3, due to erratic performance and a\ngeneral lack of interest in the data it produced.\nThe MSS sensor, however, enjoyed much more success. From 1972 through 1992 it was used to\nproduce an archive of over 630,000 scenes. MSS measures radiation within four narrow bands: one that\nspans visible green wavelengths, another that spans visible red wavelengths, and two more spanning\nslightly longer, near-infrared wavelengths.\nLandsat MSS (1972-1992)\nSpectral Sensitivity Spatial Resolution\n0.5 \u2013 0.6 \u03bcm (visible green) 79 \/ 82 m*\n0.6 \u2013 0.7 \u03bcm (visible red) 79 \/ 82 m*\n0.7 \u2013 0.8 \u03bcm (near IR) 79 \/ 82 m*\n0.8 \u2013 1.1 \u03bcm (near IR) 79 \/ 82 m*\nSpectral sensitivities and spatial resolution of the Landsat MSS sensor. Wavelengths are expressed in\nmicrometers (millionths of a meter). Spatial resolution is expressed in meters. *MSS sensors aboard\nLandsats 4 and 5 had nominal resolution of 82 m, which includes 15 meters of overlap with previous\nscene.\nLandsats 1 through 3 traced near-polar orbits at altitudes of about 920 km, orbiting the Earth 14 times\nper day (every 103 minutes). Landsats 4 and 5 orbit at 705 km altitude. The MSS sensor sweeps an\narray of six energy detectors through an arc of less than 12\u00b0, producing six rows of data simultaneously\nacross a 185 km ground swath. Landsat satellites orbit the Earth at similar altitudes and velocities as the\nsatellites that carry AVHRR, but because the MSS scan swath is so much narrower than AVHRR, it takes\nmuch longer (18 days for Landsat 1-3, 16 days for Landsats 4 and 5) to scan the entire Earth\u2019s surface.\nThree scenes produced by a Landsat Multispectral Scanner. Images reveal Amazonian rainforest Nature of Geographic Information 312\ncleared in the Brazilian state of Rondonia between 1975 and 1992. Red areas represent healthy\nvegetation (USGS, 2001).\nThe sequence of three images shown above cover the same portion of the state of Rondonia, Brazil.\nReflectances in the near-infrared band are coded red in these images; reflectances measured in the visible\ngreen and red bands are coded blue and green. Since vegetation absorbs visible light, but reflects infrared\nenergy, the blue-green areas indicate cleared land. Land use change detection is one of the most valuable\nuses of multispectral imaging.\nFor more information, visit USGS\u2019 Landsat home page\nLANDSAT TM AND ETM+\nAs NASA prepared to launch Landsat 4 in 1982, it replaced the unsuccessful RBV sensor with a new\nsensing system called Thematic Mapper (TM). TM was a new and improved version of MSS that\nfeatured higher spatial resolution (30 meters in most channels) and expanded spectral sensitivity (seven\nbands, including visible blue, visible green, visible red, near-infrared, two mid-infrared, and thermal\ninfrared wavelengths). An Enhanced Thematic Mapper Plus (ETM+) sensor, which includes an eighth\n(panchromatic) band with a spatial resolution of 15 meters, was onboard Landsat 7 when it successfully\nlaunched in 1999.\nLandsat TM & ETM+ (1982-)\nSpectral Sensitivity Spatial Resolution\n0.522 -0.90 \u03bcm (panchromatic)* 15 m*\n0.45 \u2013 0.52 \u03bcm (visible blue) 30 m\n0.52 \u2013 0.60 \u03bcm (visible green) 30 m\n0.63 \u2013 0.69 \u03bcm (visible red) 30 m\n0.76 \u2013 0.90 \u03bcm (near IR) 30 m\n1.55 \u2013 1.75 \u03bcm (mid IR) 30 m\n10.40 \u2013 12.50 \u03bcm (thermal IR) 120 m (Landsat 4-5) 60 m (Landsat 7)\n2.08 \u2013 2.35 \u03bcm (mid IR) 30 m\nSpectral sensitivities and spatial resolution of the Landsat TM and ETM sensors. Wavelengths are\nexpressed in micrometers (millionths of a meter). Spatial resolution is expressed in meters. Note\nthe lower spatial resolution in thermal IR band, which allows for increased radiometric resolution.\n*ETM+\/Landsat 7 only.\nThe spectral sensitivities of the TM and ETM+ sensors are attuned to both the spectral response\ncharacteristics of the phenomena that the sensors are designed to monitor, as well as to the windows\nwithin which electromagnetic energy are able to penetrate the atmosphere. The following table outlines\nsome of the phenomena that are revealed by each of the wavelengths bands, phenomena that are much\nless evident in panchromatic image data alone. 313 David DiBiase\nPhenomena revealed by different bands of Landsat TM\/ETM data\nBand Phenomena Revealed\n0.45 \u2013 0.52 \u03bcm (visible blue) Shorelines and water depths (these wavelenths penetrate water)\n0.52 \u2013 0.60 \u03bcm (visible green) Plant types and vigor (peak vegitation reflects these wavelengths strongly)\n0.63 \u2013 0.69 \u03bcm (visible red) Photosynthetic activity (plants absorb these wavelengths during photosynthesis)\n0.76 \u2013 0.90 \u03bcm (near IR) Plant vigor (healthy plant tissue reflects these wavelengths strongly)\n1.55 \u2013 1.75 \u03bcm (mid IR) Plant water stress, soil moisture, rock types, cloud cover vs. snow\n10.40 \u2013 12.50 \u03bcm (themal IR) Relative amounts of heat, soil moisture\n2.08 \u2013 2.35 \u03bcm (mid IR) Plant water stress, mineral and rock types Nature of Geographic Information 314\nImages produced from 8 bands of Landsat 7 ETM data of Denver, CO. Each image in the illustration\nrepresents reflectance values recorded in each wavelength band. False color images are produced by\ncoloring three bands (for example, the visible green, visible red, and near-infrared bands) using blue,\ngreen, and red, like the layers in color photographic film.\nUntil 1984, Landsat data were distributed by the U.S. federal government (originally by the USGS\u2019s 315 David DiBiase\nEROS Data Center, later by NOAA). Data produced by Landsat missions 1 through 4 are still available\nfor sale from EROS. With the Land Remote Sensing Commercialization Act of 1984, however, the\nU.S. Congress privatized the Landsat program, transferring responsibility for construction and launch of\nLandsat 5, and for distribution of the data it produced, to a firm called EOSAT.\nDissatisfied with the prohibitive costs of unsubsidized data (as much as $4,400 for a single 185 km\nby 170 km scene), users prompted Congress to pass the Land Remote Sensing Policy Act of 1992. The\nnew legislation returned responsibility for the Landsat program to the U.S. government. Data produced\nby Landsat 7 is distributed by USGS at a cost to users of $600 per scene (about 2 cents per square\nkilometer). Scenes that include data gaps caused by a \u201cscan line corrector\u201d failure are sold for $250;\n$275 for scenes in which gaps are filled with earlier data.\nTRY THIS!\nYou may choose to visit the USGS\u2019 EarthNow! Landsat Image Viewer, which allows you to view live\nacquisition of Landsat 5 and Landsat 7 images. This site has a link to the USGS Global Visualization\nViewer where you can search for images based on percent cloud cover.\nA snapshot of the live EarthNow! Landsat Image Viewer (USGS, 2011).\n8.13. Using EarthExplorer to Find Landsat Data\nTRY THIS!\nThis activity involves using the USGS EarthExplorer system to find Landsat data that corresponds with\nthe scene of the Denver, Colorado area illustrated earlier. At the end of the experiment you can search\nfor data in your own area of interest.\nEarthExplorer is a Web application that enables users to find, preview, and download or order digital Nature of Geographic Information 316\ndata published by the U.S. Geological Survey. In addition to Landsat MSS, TM, and ETM+ data,\nAVHRR, DOQ, aerial photography, and other data are also available from the site.\nBegin by pointing your browser to EarthExplorer. (Clicking on this link opens a separate window\nfeaturing the EarthExplorer Web site. You may enlarge the window and work within it, or if you prefer,\nopen a separate browser and type in the EarthExplorer Web address.)\n\u2022 You don\u2019t have to register to use EarthExplorer, unless you want to download data.\n\u2022 In order to uncompress the data files that you might choose to download you will need an\napplication that is capable of uncompressing a .tar.gz file. One such application is 7-Zip. You\ncan download 7-Zip here\n1. Enter your search criteria\n\u2022 Enter Address\/Place name: Denver on the first tab Search Criteria\n\u2022 Click the Address\/Place name Show button\n\u2022 \u201cDenver, CO, USA\u201d is returned (as are several other matches on the \u201cDenver\u201d string), along\nwith latitude and longitude coordinates needed to perform a spatial search of EarthExplorer\u2019s\ndatabase. Click on the Denver, CO, USA choice from the list. It may take several seconds,\nbut the display on the left will change to show only the location coordinates for Denver, CO,\nand a location marker will appear on the map. See below. 317 David DiBiase\nEarthExplorer home page, March 2011.\n2. Select your Data Set(s) Our objective is to find the Landsat ETM+ data that is illustrated, band by\nband, in the previous page.\n\u2022 In the frame in the left side of the window click on the second tabData Sets\n\u2022 Mark the checkbox to select ETM+ (1999-2003) under Landsat Legacy.\n3. View your Results\n\u2022 The list of Results will show up on the fourth tab. Nature of Geographic Information 318\n\u2022 Click the image icon for one of the results to show a full display of that result, including\nattribute information.\n\u2022 Click the \u201cShow Browse Overlay\u201d icon or the \u201cShow Footprint\u201d icon to bring up and overlay\nor footprint over the Google map.\n\u2022 Click \u201cDownload\u201d to dowload a specific result. (NOTE: You will need to login or register\nand then login to the USGS to download data.) 319 David DiBiase\nOverlay and footprint image of Landsat scene and download dialog box, EarthExplorer, March 2011.\nDownloaded data arrives on your desktop in a double-compressed archive format. For instance, the\narchive I downloaded is named \u201celp033r033_7t20000914.tar.gz\u201d To open and view the data in Global\nMapper \/ dlgv32 Pro, I had to first extract the .tar archive from the .gz archive, then extract .tif files from\nthe .tar archive. I used the 7-Zip application, that I mentioned above, to extract the files: right-click on an\narchive, then choose 7-Zip > Extract files\u2026. The screen capture below shows one of the eight Landsat\nimages (corresponding to the eight ETM+ bands) in Global Mapper. Nature of Geographic Information 320\nLandsat scene viewed in Global Mapper software.\nUse EarthExplorer to find Landsat data for your own area of interest\n\u2022 Use the Redefine Criteria link at the bottom of the Results page to begin a new search. Try\nsearching for your hometown or a place you\u2019ve always wanted to visit.\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 8 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about Visible and Infrared Data.\nYou may take practice quizzes as many times as you wish. They are not scored and do not affect your\ngrade in any way.\n8.14. Multispectral Image Processing\nOne of the main advantages of digital data is that they can be readily processed using digital computers.\nOver the next few pages we focus on digital image processing techniques used to correct, enhance, and\nclassify remotely sensed image data.\n8.15. Image Correction\nAs suggested earlier, scanning the Earth\u2019s surface from space is like scanning a paper document with a 321 David DiBiase\ndesktop scanner, only a lot more complicated. Raw remotely sensed image data are full of geometric and\nradiometric flaws caused by the curved shape of the Earth, the imperfectly transparent atmosphere, daily\nand seasonal variations in the amount of solar radiation received at the surface, and imperfections in\nscanning instruments, among other things. Understandably, most users of remotely sensed image data are\nnot satisfied with the raw data transmitted from satellites to ground stations. Most prefer preprocessed\ndata from which these flaws have been removed.\nGEOMETRIC CORRECTION\nYou read in Chapter 6 that scale varies in unrectified aerial imagery due to the relief displacement\ncaused by variations in terrain elevation. Relief displacement is one source of geometric distortion in\ndigital image data, although it is less of a factor in satellite remote sensing than it is in aerial imaging\nbecause satellites fly at much higher altitudes than airplanes. Another source of geometric distortions\nis the Earth itself, whose curvature and eastward spinning motion are more evident from space than at\nlower altitudes.\nThe Earth rotates on its axis from west to east. At the same time, remote sensing satellites like\nIKONOS, Landsat, and the NOAA satellites that carry the AVHRR sensor, orbit the Earth from pole to\npole. If you were to plot on a cylindrical projection the flight path that a polar orbiting satellite traces\nover a 24-hour period, you would see a series of S-shaped waves. As a remote sensing satellite follows\nits orbital path over the spinning globe, each scan row begins at a position slightly west of the row that\npreceded it. In the raw scanned data, however, the first pixel in each row appears to be aligned with\nthe other initial pixels. To properly georeference the pixels in a remotely sensed image, pixels must be\nshifted slightly to the west in each successive row. This is why processed scenes are shaped like skewed\nparallelograms when plotted in geographic or plane projections, as shown in the illustration you saw\nearlier that showed eight bands of a Landsat 7 ETM+ scene.\nIn addition to the systematic error caused by the Earth\u2019s rotation, random geometric distortions result\nfrom relief displacement, variations in the satellite altitude and attitude, instrument misbehaviors, and\nother anomalies. Random geometric errors are corrected through a process known as rubber sheeting.\nAs the name implies, rubber sheeting involves stretching and warping an image to georegister control\npoints shown in the image to known control point locations on the ground. First, a pair of plane\ncoordinate transformation equations is derived by analyzing the differences between control point\nlocations in the image and on the ground. The equations enable image analysts to generate a rectified\nraster grid. Next, reflectance values in the original scanned grid are assigned to the cells in the rectified\ngrid. Since the cells in the rectified grid don\u2019t align perfectly with the cells in the original grid,\nreflectance values in the rectified grid cells have to be interpolated from values in the original grid. This\nprocess is calledresampling. Resampling is also used to increase or decrease the spatial resolution of an\nimage so that its pixels can be georegistered with those of another image.\nRADIOMETRIC CORRECTION\nThe reflectance at a given wavelength of an object measured by a remote sensing instrument varies in\nresponse to several factors, including the illumination of the object, its reflectivity, and the transmissivity\nof the atmosphere. Furthermore, the response of a given sensor may degrade over time. With these\nfactors in mind, it should not be surprising that an object scanned at different times of the day or year\nwill exhibit different radiometric characteristics. Such differences can be advantageous at times, but they\ncan also pose problems for image analysts who want to mosaic adjoining images together, or to detect\nmeaningful changes in land use and land cover over time. To cope with such problems, analysts have Nature of Geographic Information 322\ndeveloped numerous radiometric correction techniques, including Earth-sun distance corrections, sun\nelevation corrections, and corrections for atmospheric haze.\nTo compensate for the different amounts of illumination of scenes captured at different times of day,\nor at different latitudes or seasons, image analysts may divide values measured in one band by values\nin another band, or they may apply mathematical functions that normalize reflectance values. Such\nfunctions are determined by the distance between the Earth and the sun and the altitude of the sun above\nthe horizon at a given location, time of day, and time of year. Analysts depend on metadata that includes\nthe location, date, and time at which a particular scene was captured.\nImage analysts may also correct for the contrast-diminishing effects of atmospheric haze. Haze\ncompensation resembles the differential correction technique used to improve the accuracy of GPS data\nin the sense that it involves measuring error (or, in this case, spurious reflectance) at a known location,\nthen subtracting that error from another measurement. Analysts begin by measuring the reflectance of\nan object known to exhibit near-zero reflectance under non-hazy conditions, such as deep, clear water in\nthe near-infrared band. Any reflectance values in those pixels can be attributed to the path radiance of\natmospheric haze. Assuming that atmospheric conditions are uniform throughout the scene, the haze\nfactor may be subtracted from all pixel reflectance values. Some new sensors allow \u201cself calibration\u201d by\nmeasuring atmospheric water and dust content directly.\nGeometric and radiometric correction services are commonly offered by government agencies and\nprivate firms that sell remotely sensed data. For example, although the USGS offers raw (Level Zero\nR) Landsat 7 data for just $475 per 185 km by 170 km scene, many users find the $600 radiometrically\ncorrected, orthorectified, and custom projected Level One G data well worth the added expense. GeoEye\n(formerly Space Imaging) routinely delivers preprocessed IKONOS data that has been radiometrically\ncorrected, orthorectified, projected and mosaicked to user specifications. Four levels of geometric\naccuracy are available, from 12 meters (which satisfies National Map Accuracy Standards at 1:50,000\nscale) to 1 meter (1:2,400 NMAS).\n8.16. Image Enhancement\nCorrection techniques are routinely used to resolve geometric, radiometric, and other problems found\nin raw remotely sensed data. Another family of image processing techniques is used to make image\ndata easier to interpret. These so-called image enhancement techniques include contrast stretching,\nedge enhancement, and deriving new data by calculating differences, ratios, or other quantities from\nreflectance values in two or more bands, among many others. This section considers briefly two common\nenhancement techniques, contrast stretching and derived data. Later you\u2019ll learn how vegetation indices\nderived from two bands of AVHRR imagery are used to monitor vegetation growth at a global scale.\nCONTRAST STRETCHING\nConsider the pair of images shown side by side below. Although both were produced from the same\nLandsat MSS data, you will notice that the image on the left is considerably dimmer than the one on the\nright. The difference is a result of contrast stretching. As you recall, MSS data have a precision of 8 bits,\nthat is, reflectance values are encoded as 256 (28) intensity levels. As is often the case, reflectances in the\nnear-infrared band of the scene partially shown below ranged from only 30 and 80 in the raw image data.\nThis limited range results in an image that lacks contrast and, consequently, appears dim. The image on\nthe right shows the effect of stretching the range of reflectance values in the near-infrared band 323 David DiBiase\nfrom 30-80 to 0-255, and then similarly stretching the visible green and visible red bands. As you\ncan see, the contrast-stretched image is brighter and clearer.\nPair of images produced from Landsat MSS data captured in 1988. The near-infrared band is shown\nin red, the visible red is shown in green, and the visible green band is shown in blue. The right and left\nimages show the before and after effects of contrast stretching. The images show agricultural patterns\ncharacteristic of center-pivot irrigation in a portion of a county in southwestern Kansas. (USGS, 2001a).\nDERIVED DATA: NDVI\nOne advantage of multispectral data is the ability to derive new data by calculating differences, ratios,\nor other quantities from reflectance values in two or more wavelength bands. For instance, detecting\nstressed vegetation amongst healthy vegetation may be difficult in any one band, particularly if\ndifferences in terrain elevation or slope cause some parts of a scene to be illuminated differently than\nothers. The ratio of reflectance values in the visible red band and the near-infrared band compensates for\nvariations in scene illumination, however. Since the ratio of the two reflectance values is considerably\nlower for stressed vegetation regardless of illumination conditions, detection is easier and more reliable.\nBesides simple ratios, remote sensing scientists have derived other mathematical formulae for\nderiving useful new data from multispectral imagery. One of the most widely used examples is the\nNormalized Difference Vegetation Index (NDVI). As you may recall, the AVHRR sensor measures\nelectromagnetic radiation in five wavelengths bands. NDVI scores are calculated pixel-by-pixel using\nthe following algorithm:\nNDVI = (NIR \u2013 R) \/ (NIR + R)\nR stands for the visible red band (AVHRR channel 1), while NIR represents the near-infrared band\n(AVHRR channel 2). The chlorophyll in green plants strongly absorbs radiation in AVHRR\u2019s visible\nred band (0.58-0.68 \u00b5m) during photosynthesis. In contrast, leaf structures cause plants to strongly\nreflect radiation in the near-infrared band (0.725-1.10 \u00b5m). NDVI scores range from -1.0 to 1.0. A pixel\nassociated with low reflectance values in the visible band and high reflectance in the near-infrared band\nwould produce an NDVI score near 1.0, indicating the presence of healthy vegetation. Conversely, the\nNDVI scores of pixels associated with high reflectance in the visible band and low reflectance in the Nature of Geographic Information 324\nnear-infrared band approach -1.0, indicating clouds, snow, or water. NDVI scores near 0 indicate rock\nand non-vegetated soil.\nApplications of the NDVI range from local to global. At the local scale, the Mondavi Vineyards in\nNapa Valley California can attest to the utility of NDVI data in monitoring plant health. In the 1993, the\nvineyards suffered an infestation of phylloxera, a species of plant lice that attacks roots and is impervious\nto pesticides. The pest could only be overcome by removing infested vines and replacing them with more\nresistant root stock. The vineyard commissioned a consulting firm to acquire high-resolution (2-3 meter)\nvisible and near-infrared imagery during consecutive growing seasons using an airborne sensor. Once\nthe data from the two seasons were georegistered, comparison of NDVI scores revealed areas in which\nvine canopy density had declined. NDVI change detection proved to be such a fruitful approach that the\nvineyards adopted it for routine use as part of their overall precision farming strategy (Colucci, 1998).\nThe example that follows outlines the image processing steps involved in producing a global NDVI\ndata set.\n8.17. Processing the 1Km Global Land Dataset\nThe Advanced Very High Resolution Radiometer (AVHRR) sensors aboard NOAA satellites scan the\nentire Earth daily at visible red, near-infrared, and thermal infrared wavelengths. In the late 1980s and\nearly 1990s, several international agencies identified the need to compile a baseline, cloud-free, global\nNDVI data set in support of efforts to monitor global vegetation cover. For example, the United Nations\nmandated its Food and Agriculture Organization to perform a global forest inventory as part of its Forest\nResources Assessment project. Scientists participating in NASA\u2019s Earth Observing System program also\nneeded a global AVHRR data set of uniform quality to calibrate computer models intended to monitor\nand predict global environmental change. In 1992, under contract with the USGS, and in cooperation\nwith the International Geosphere Biosphere Programme, scientists at the EROS Data Center in Sioux\nFalls, South Dakota, started work. Their goals were to create not only a single 10-day composite image,\nbut also a 30-month time series of composites that would help Earth system scientists to understand\nseasonal changes in vegetation cover at a global scale. This example highlights the image processing\nprocedures used to produce the data set. Further information is available in Eidenshink & Faundeen\n(1994) and at the project home page.\nFrom 1992 through 1996, a network of 30 ground receiving stations acquired and archived tens of\nthousands of scenes from an AVHRR sensor aboard one of NOAA\u2019s polar orbiting satellites. Individual\nscenes were stitched together into daily orbital passes like the ones illustrated below. Creating orbital\npasses allowed the project team to discard the redundant data in overlapping scenes acquired by different\nreceiving stations. 325 David DiBiase\nFalse color images produced from AVHRR data acquired on June 24, 1992 for the 1-Km AVHRR\nGlobal Land Dataset project. The images represent orbital passes created by splicing consecutive scenes.\nThe 2400-km wide swaths cover Europe, Africa, and the Near East. Note the cloud cover and geometric\ndistortion. (Eidenshink & Faundeen, 1994).\nOnce the daily orbital scenes were stitched together, the project team set to work preparing cloud-\nfree, 10-day composite data sets that included Normalized Difference Vegetation Index (NDVI) scores.\nThe image processing steps involved included radiometric calibration, atmospheric correction, NDVI\ncalculation, geometric correction, regional compositing, and projection of composited scenes. Each step\nis described briefly below.\nRADIOMETRIC CALIBRATION\nRadiometric calibration means defining the relationship between reflectance values recorded by a sensor\nfrom space and actual radiances measured with spectrometers on the ground. The accuracy of the\nAVHRR visible red and near-IR sensors degrade over time. Image analysts would not be able to produce\nuseful time series of composite data sets unless reflectances were reliably calibrated. The project team\nrelied on research that showed how AVHRR data acquired at different times could be normalized using\na correction factor derived by analyzing reflectance values associated with homogeneous desert areas. Nature of Geographic Information 326\nATMOSPHERIC CORRECTION\nSeveral atmospheric phenomena, including Rayleigh scatter, ozone, water vapor, and aerosols, were\nknown to affect reflectances measured by sensors like AVHRR. Research yielded corrections to\ncompensate for some of these.\nOne proven correction was for Rayleigh scatter. Named for an English physicist who worked in\nthe early 20th century, Rayleigh scatter is the phenomenon that accounts for the fact that the sky\nappears blue. Short wavelengths of incoming solar radiation tend to be diffused by tiny particles in the\natmosphere. Since blue wavelengths are the shortest in the visible band, they tend to be scattered more\nthan green, red, and other colors of light. Rayleigh scatter is also the primary cause of atmospheric haze.\nBecause the AVHRR sensor scans such a wide swath, image analysts couldn\u2019t be satisfied with\napplying a constant haze compensation factor throughout entire scenes. To scan its 2400-km wide swath,\nthe AVHRR sensor sweeps a scan head through an arc of 110\u00b0. Consequently, the viewing angle between\nthe scan head and the Earth\u2019s surface varies from 0\u00b0 in the middle of the swath to about 55\u00b0 at the edges.\nObviously the lengths of the paths traveled by reflected radiation toward the sensor vary considerably\ndepending on the viewing angle. Project scientists had to take this into account when compensating for\natmospheric haze. The farther a pixel was located from the center of a swath, the greater its path length,\nand the more haze needed to be compensated for. While they were at it, image analysts also factored in\nterrain elevation, since that too affects path length. ETOPO5, the most detailed global digital elevation\nmodel available at the time, was used to calculate path lengths adjusted for elevation. (You learned about\nthe more detailed ETOPO1 in Chapter 7.)\nNDVI CALCULATION\nThe Normalized Difference Vegetation Index (NDVI) is the difference of near-IR and visible red\nreflectance values normalized over the sum of the two values. The result, calculated for every pixel in\nevery daily orbital pass, is a value between -1.0 and 1.0, where 1.0 represents maximum photosynthetic\nactivity, and thus maximum density and vigor of green vegetation.\nGEOMETRIC CORRECTION AND PROJECTION\nAs you can see in the stitched orbital passes illustrated above, the widerange of view angles produced\nby the AVHRR sensor results in a great deal of geometric distortion. Relief displacement makes matters\nworse, distorting images even more towards the edges of each swath. The project team performed both\northorectification and rubber sheeting to rectify the data. The ETOPO5 global digital elevation model\nwas again used to calculate corrections for scale distortions caused by relief displacement. To correct\nfor distortions caused by the wide range of sensor view angles, analysts identified well-defined features\nlike coastlines, lakeshores, and rivers in the imagery that could be matched to known locations on the\nground. They derived coordinate transformation equations by analyzing differences between positions\nof control points in the imagery and known locations on the ground. The accuracy of control locations\nin the rectified imagery was shown to be no worse than 1,000 meters from actual locations. Equally\nimportant, the georegistration error between rectified daily orbital passes was shown to be less than one\npixel.\nAfter the daily orbital passes were rectified, they were transformed into a map projection called\nGoode\u2019s Homolosine. This is an equal-area projection that minimizes shape distortion of land masses by\ninterrupting the graticule over the oceans. The project team selected Goode\u2019s projection in part because\nthey knew that equivalence of area would be a useful quality for spatial analysis. More importantly, the 327 David DiBiase\ninterrupted projection allowed the team to process the data set as twelve separate regions that could be\nspliced back together later. The illustration below shows the orbital passes for June 24, 1992 projected\ntogether in a single global image based on Goode\u2019s projection.\nAVHRR orbital passes acquired on June 24, 1992, projected together in a Goode\u2019s Homolosine\nprojection of the world. (Eidenshink & Faundeen, 1994).\nCOMPOSITING\nOnce the daily orbital passes for a ten-day period were rectified, every one-kilometer square pixel could\nbe associated with corresponding pixels at the same location in other orbital passes. At this stage, with\nthe orbital passes assembled into twelve regions derived from the interrupted Goode\u2019s projection, image\nanalysts identified the highest NDVI value for each pixel in a given ten-day period. They then produced\nten-day composite regions by combining all the maximum-value pixels into a single regional data set.\nThis procedure minimized the chances that cloud-contaminated pixels would be included in the final\ncomposite data set. Finally, the composite regions were assembled into a single data set, illustrated\nbelow. This same procedure has been repeated to create 93 ten-day composites from April 1-10, 1992 to\nMay 21-30, 1996.\nTen-day composite AVHRR image. The greenest pixels represent the highest NDVI values.\n(Eidenshink & Faundeen, 1994).\n8.18. Image Classification\nAlong with military surveillance and weather forecasting, a common use of remotely sensed image\ndata is to monitor land cover and to inform land use planning. The term land cover refers to the kinds\nof vegetation that blanket the Earth\u2019s surface, or the kinds of materials that form the surface where\nvegetation is absent. Land use, by contrast, refers to the functional roles that the land plays in human\neconomic activities (Campbell, 1983).\nBoth land use and land cover are specified in terms of generalized categories. For instance, an early Nature of Geographic Information 328\nclassification system adopted by a World Land Use Commission in 1949 consisted of nine primary\ncategories, including settlements and associated non-agricultural lands, horticulture, tree and other\nperennial crops, cropland, improved permanent pasture, unimproved grazing land, woodlands, swamps\nand marshes, and unproductive land. Prior to the era of digital image processing, specially trained\npersonnel drew land use maps by visually interpreting the shape, size, pattern, tone, texture, and shadows\ncast by features shown in aerial photographs. As you might imagine, this was an expensive, time-\nconsuming process. It\u2019s not surprising then that the Commission appointed in 1949 failed in its attempt\nto produce a detailed global land use map.\nPart of the appeal of digital image processing is the potential to automate land use and land cover\nmapping. To realize this potential, image analysts have developed a family of image classification\ntechniques that automatically sort pixels with similar multispectral reflectance values into clusters that,\nideally, correspond to functional land use and land cover categories. Two general types of image\nclassification techniques have been developed: supervised and unsupervised techniques.\nSUPERVISED CLASSIFICATION\nHuman image analysts play crucial roles in both supervised and unsupervised image classification\nprocedures. In supervised classification, the analyst\u2019s role is to specify in advance the multispectral\nreflectance or (in the case of the thermal infrared band) emittance values typical of each land use\nor land cover class.\nPortion of Landsat TM scene acquired July 17, 1986 showing agricultural fields in Tippecanoe\nCounty, Indiana. Reflectances recorded in TM bands 2 (visible green), 3 (visible red), and 4 (near-\ninfrared) are shown in blue, green, and red respectively. Multispec image processing software \u00a9 2001\nPurdue Research Foundation, Inc.\nFor instance, to perform a supervised classification of the Landsat Thematic Mapper (TM) data shown\nabove into two land cover categories, Vegetation and Other, you would first delineate several training\nfields that are representative of each land cover class. The illustration below shows two training fields 329 David DiBiase\nfor each class, however, to achieve the most reliable classification possible, you would define as many\nas 100 or more training fields per class.\nTraining fields defined for two classes of land cover, vegetation and other. Multispec image\nprocessing software \u00a9 2001 Purdue Research Foundation, Inc.\nThe training fields you defined consist of clusters of pixels with similar reflectance or emittance\nvalues. If you did a good job in supervising the training stage of the classification, each cluster would\nrepresent the range of spectral characteristics exhibited by its corresponding land cover class. Once the\nclusters are defined, you would apply a classification algorithm to sort the remaining pixels in the scene\ninto the class with the most similar spectral characteristics. One of the most commonly used algorithms\ncomputes the statistical probability that each pixel belongs to each class. Pixels are then assigned to the\nclass associated with the highest probability. Algorithms of this kind are known as maximum likelihood\nclassifiers. The result is an image like the one shown below, in which every pixel has been assigned to\none of two land cover classes. Nature of Geographic Information 330\nTwo-class land cover map produced by supervised classification of Landsat TM data. Multispec image\nprocessing software \u00a9 2001 Purdue Research Foundation, Inc.\nUNSUPERVISED CLASSIFICATION\nThe image analyst plays a different role in unsupervised classification. They do not define training\nfields for each land cover class in advance. Instead, they rely on one of a family of statistical clustering\nalgorithms to sort pixels into distinct spectral classes. Analysts may or may not even specify the number\nof classes in advance. Their responsibility is to determine the correspondences between the spectral\nclasses that the algorithm defines and the functional land use and land cover categories established\nby agencies like the U.S. Geological Survey. The example that follows outlines how unsupervised\nclassification contributes to the creation of a high-resolution national land cover data set. 331 David DiBiase\nTwo-class land cover map produced by unsupervised classification of Landsat TM data. Multispec\nimage processing software \u00a9 2001 Purdue Research Foundation, Inc.\n8.19. Classifying Landsat Data for the National Land Cover Dataset\nThe USGS developed one of the first land use\/land cover classifications systems designed specifically\nfor use with remotely sensed imagery. The Anderson Land Use\/Land Cover Classificationsystem,\nnamed for the former Chief Geographer of the USGS who led the team that developed the system,\nconsists of nine land cover categories (urban or built-up; agricultural; range; forest; water; wetland;\nbarren; tundra; and perennial snow and ice), and 37 subcategories (for example, varieties of agricultural\nland include cropland and pasture; orchards, groves, vineyards, nurseries, and ornamental horticulture;\nconfined feeding operations; and other agricultural land). Image analysts at the U. S. Geological Survey\ncreated the USGS Land Use and Land Cover (LULC) data by manually outlining and coding areas on air\nphotos that appeared to have homogeneous land cover that corresponded to one of the Anderson classes.\nThe LULC data were compiled for use at 1:250,000 and 1:100,000 scales. Analysts drew outlines of\nland cover polygons onto vertical aerial photographs. Later, the outlines were transferred to transparent\nfilm georegistered with small-scale topographic base maps. The small map scales kept the task from\ntaking too long and costing too much, but also forced analysts to generalize the land cover polygons\nquite a lot. The smallest man-made features encoded in the LULC data are four hectares (ten acres)\nin size, and at least 200 meters (660 feet) wide at their narrowest point. The smallest non-man-made\nfeatures are sixteen hectares (40 acres) in size, with a minimum width of 400 meters (1320 feet). Smaller\nfeatures were aggregated into larger ones. After the land cover polygons were drawn onto paper and\ngeoregistered with topographic base maps, they were digitized as vector features, and attributed with\nland cover codes. A rasterized version of the LULC data was produced later.\nFor more information, visit the USGS\u2019 LULC home page.\nThe successor to LULC is the USGS\u2019s National Land Cover Data (NLCD). Unlike LULC, which\noriginated as a vector data set in which the smallest features are about ten acres in size, NLCD is a Nature of Geographic Information 332\nraster data set with a spatial resolution of 30 meters (i.e., pixels represent about 900 square meters on\nthe ground) derived from Landsat TM imagery. The steps involved in producing the NLCD include\npreprocessing, classification, and accuracy assessment, each of which is described briefly below.\nPREPROCESSING\nThe first version of NLCD\u2013NLCD 92\u2013was produced for subsets of ten federal regions that make up\nthe conterminous United States. The primary source data were bands 3, 4, 5, and 7 (visible red, near-\ninfrared, mid-infrared, and thermal infrared) of cloud-free Landsat TM scenes acquired during the\nspring and fall (when trees are mostly bare of leaves) of 1992. Selected scenes were geometrically\nand radiometrically corrected, then combined into sub-regional mosaics comprised of no more than 18\nscenes. Mosaics were then projected to the same Albers Conic Equal Area projection (with standard\nparallels at 29.5\u00b0 and 45.5\u00b0 North Latitude, and central meridian at 96\u00b0 West Longitude) based upon\nthe NAD83 horizontal datum.\nIMAGE CLASSIFICATION\nAn unsupervised classification algorithm was applied to the preprocessed mosaics to generate 100\nspectrally distinct pixel clusters. Using aerial photographs and other references, image analysts at USGS\nthen assigned each cluster to one of the classes in a modified version of the Anderson classification\nscheme. Considerable interpretation was required, since not all functional classes have unique spectral\nresponse patterns. 333 David DiBiase\nModified Anderson Land Use\/Land Cover Classification\nLevel I Classes Level II Classes\nWater 11 Open Water\n12 Perennial Ice\/Snow\nDeveloped 21 Low Intensity Residential\n22 High Intensity Residential\n23 Commercial\/Industrial\/Transportation\nBarren 31 Bare Rock\/Sand\/Clay\n32 Quarries\/Strip Mines\/Gravel Pits\n33 Transitional\nForrested Upland 41 Deciduous Forest\n42 Evergreen Forest\n43 Mixed Forest\nShrubland 51 Shrubland\nNon-Natural Woody 61 Orchards\/Vineyards\/Other\nHerbaceous Upland Natural\/Semi-natural Vegitation 71 Grasslands\/Herbaceous\nHerbaceous Planted\/Cultivated 81 Pasture\/Hay\n82 Row Crops\n83 Small Grains\n84 Fallow\n85 Urban\/Recreational Grasses\nWetlands 91 Woody Wetlands\n92 Emergent Herbaceous Wetlands\nModified Anderson Land Use\/Land Cover Classification used for the USGS National Land Cover\nDataset.\nACCURACY ASSESSMENT\nThe USGS hired private sector vendors to assess the classification accuracy of the NLCD 92 by\nchecking randomly sampled pixels against manually interpreted aerial photographs. Results from the\nfirst four completed regions suggested that the likelihood that a given pixel is correctly classified ranges\nfrom only 38 to 62 percent. Much of the classification error was found to occur among the Level II\nclasses that make up the various Level I classes, and some classes were much more error-prone than\nothers. USGS encourages users to aggregate the data into 3 x 3 or 5 x 5 pixel blocks (in other words, Nature of Geographic Information 334\nto decrease spatial resolution from 30 meters to 90 or 150 meters), or to aggregate the 21 Level II\nclasses into the nine Level I classes. Even in the current era of high-resolution satellite imaging and\nsophisticated image processing techniques, there is still no cheap and easy way to produce detailed,\naccurate geographic data.\nAn extract from NLCD 92 that corresponds to the same portion of the Bushkill, PA quadrangle\nmapped in other USGS data files provided with earlier chapters. The data viewer is ESRI\u2019s ArcExplorer\nversion 2. 335 David DiBiase\nMap legend for the National Land Cover Dataset.\nFor more information about NLCD 92 and its successor, NLCD 2001, visit the Multi-Resolution Land\nCharacteristics Consortium.\nGLOBAL LAND COVER DATA\nMeanwhile, the U.S. National Geospatial-Intelligence Agency (formerly the National Imagery and\nMapping Agency) hired a company called Earthsat (Now MDA Federal) to produce a 120-meter\nresolution, 13-class land use \/ land cover data set for the rest of the world. This product, called Geocover\nLC, is derived from 30-meter Landsat TM imagery from the 1990s and 2000. A team of image\nanalysts assigned 240 clusters produced by unsupervised classification into the thirteen land use\/\nland cover classes (Barrios, 2001). For more information about Geocover LC, visit MDA Information\nSystems and GeoCover LC.\n8.20. Unsupervised Classification By Hand\nTRY THIS!\nThis activity guides you through a simulated unsupervised classification of remotely sensed image data\nto create a land cover map. Begin by viewing and printing the Image Classification Activity PDF file. Nature of Geographic Information 336\n1. Plot the reflectance values.\nThe two grids on the top of the second page of the PDF file represent reflectance values in the visible\nred and near infrared wavelength bands measured by a remote sensing instrument for a parcel of land.\nUsing the graph (like the one below) on the first page of the PDF file you printed, plot the reflectance\nvalues for each pixel and write the number of each pixel (1 to 36) next to its location in the graph.\nPixel 1 has been plotted for you (Visible Red band = 22, Near Infrared band = 6).\n\u2022 After you have completed filling in the graph you can check your progress by following this\nlink to a completed graph.\n2. Identify four land cover classes.\nLooking at the completed plot from step one, identify and circle four clusters (classes) of pixels. Label\nthese four classes A, B, C, and D.\n\u2022 After you have circled the four clusters of pixels in the graph you can check your progress by\nfollowing this link to view the identified clusters.\n\u2022 Note: You may have labeled the clusters differently but the four clusters should contain the\nsame points, more or less, as the example.\n3. Complete the land cover map grid.\nUsing the clusters you identified in the previous step, fill in the land cover map grid with the letter that\nrepresents the land use class in which each pixel belongs. The result is a classified image. 337 David DiBiase\n\u2022 If you would like to check your land cover map you can follow this link to view a completed\nland cover map.\n\u2022 Note: If you labeled the clusters in step two differently than the example, your land cover\nmap may look different but the patterns should look similar.\n4. Complete a legend that explains the association.\nUsing the spectral response data provided on the second page of the PDF file, associate each of the four\nclasses with a land use class.\n\u2022 You can check your results by following this link to view a completed legend.\n\u2022 Note: Depending on how you labeled your clusters, your legend may differ from the example\nlegend, however, when you apply your legend to your Land Cover Map the land use classes\non your map should match the example map.\nYou have now completed the unsupervised classification activity in which you used remotely sensed\nimage data to create a land cover map. Nature of Geographic Information 338\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 8 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about Image Processing.\nYou may take practice quizzes as many times as you wish. They are not scored and do not affect your\ngrade in any way.\n8.21. Microwave Data\nThe remote sensing systems you\u2019ve studied so far are sensitive to the visible, near-infrared, and thermal\ninfrared bands of the electromagnetic spectrum, wavelengths at which the magnitude of solar radiation\nis greatest. IKONOS, AVHRR, and the Landsat MSS, TM, and ETM+ instruments are all passive\nsensors that only measure radiation emitted by other objects.\nThere are two main shortcomings to passive sensing of the visible and infrared bands. First, clouds\ninterfere with both incoming and outgoing radiation at these wavelengths. Secondly, reflected visible\nand near-infrared radiation can only be measured during daylight hours. This is why the AVHRR sensor\nonly produces visible and near-infrared imagery of the entire Earth once a day, although it is capable of\ntwo daily scans.\nThe electromagnetic spectrum divided into five wavelength bands. (Adapted from Lillesand & Kiefer,\n1994).\nLongwave radiation, or microwaves, are made up of wavelengths between about one millimeter and\none meter. Microwaves can penetrate clouds, but the Sun and Earth emit so little longwave radiation\nthat it can\u2019t be measured easily from space. Active remote sensing systems solve this problem. Active\nsensors like those aboard the European Space Agency\u2019s ERS satellites, the Japanese JERS satellites, and\nthe Canadian Radarsat, among others, transmit pulses of longwave radiation, then measure the intensity\nand travel time of those pulses after they are reflected back to space from the Earth\u2019s surface. Microwave\nsensing is unaffected by cloud cover, and can operate day or night. Both image data and elevation data\ncan be produced by microwave sensing, as you will discover in the sections on imaging radar and radar\naltimetry that follow.\n8.22. Imaging Radar\nOne example of active remote sensing that everyone has heard of is radar, which stands for RAdio\nDetection And Ranging. Radar was developed as an air defense system during World War II and is now\nthe primary remote sensing system air traffic controllers use to track the 40,000 daily aircraft takeoffs\nand landings in the U.S. Radar antennas alternately transmit and receive pulses of microwave energy.\nSince both the magnitude of energy transmitted and its velocity (the speed of light) are known, radar\nsystems are able to record either the intensity or the round-trip distance traveled of pulses reflected back\nto the sensor. Systems that record pulse intensity are called imaging radars.\nIn addition to its indispensable role in navigation, radar is also an important source of raster image 339 David DiBiase\ndata about the Earth\u2019s surface. Radar images look the way they do because of the different ways that\nobjects reflect microwave energy. In general, rough-textured objects reflect more energy back to the\nsensor than smooth objects. Smooth objects, such as water bodies, are highly reflective, but unless they\nare perpendicular to the direction of the incoming pulse, the reflected energy all bounces off at an angle\nand never returns to the sensor. Rough surfaces, such as vegetated agricultural fields, tend to scatter the\npulse in many directions, increasing the chance that some back scatter will return to the sensor.\nRadar image showing areas inundated by a flood of the Mississippi River in 1993. \u00a9 2001 Space\nImaging, Inc. All Rights Reserved. Used by permission.\nThe imaging radar aboard the European Resource Satellite (ERS-1) produced the data used to create\nthe image shown above. The smooth surface of the flooded Mississippi River deflected the radio signal\naway from the sensor, while the surrounding rougher-textured land cover reflected larger portions of the\nradar pulse. The lighter an object appears in the image, the more energy it reflected. Imaging radar can\nbe used to monitor flood extents regardless of weather conditions. Passive instruments like Landsat MSS\nand TM that are sensitive only to shorter wavelengths are useless as long as cloud-covered skies prevail.\n8.23. Radar Altimetry\nAltimetry is the measurement of elevation. Earlier chapters discussed land survey methods used to\ncalculate terrain elevations in the field (leveling and GPS), and photogrammetric methods used to\nmeasure terrain elevations from stereoscopic images produced from pairs of aerial photographs. Land\nsurveys and photogrammetric surveys yield high quality elevation data, but they are also time-\nconsuming and expensive to conduct.\nRadar (and laser) altimetry provides more efficient solutions when elevation data are needed for larger\nareas. For example, you have heard about the Shuttle Radar Topography Mission (SRTM), which\nused dual radar altimeters to produce 30-meter elevation data as well as stereoscopic terrain imagery for\nthe Earth\u2019s land surface between 60\u00b0 North and South latitude. Next we\u2019ll consider how radar altimetry\nhas been used to produce a global seafloor elevation data set. Nature of Geographic Information 340\nPREDICTING SEAFLOOR DEPTHS\nDetailed maps of the Earth\u2019s bathymetry (the topography of the ocean floor) are needed to study plate\ntectonics, to locate potential offshore oil and mineral deposits, and to route undersea telecommunications\ncables, among other things. Coarse global data sets (such as ETOPO2, with its 2-minute grid resolution)\nare inadequate for such purposes. Slow-moving surface vessels equipped with sonar instruments have\nmapped only a small fraction of the Earth\u2019s bathymetry.\nData produced by radar sensors like ERS-1 have been used to produce global seafloor elevation\ndata. Radar pulses cannot penetrate the deep ocean, but they can be used to accurately measure\nthe height of the sea surface relative to a global ellipsoid such as WGS 84. As you know, the\ngeoid is defined as mean sea level adjusted to account for the effects of gravity. Geodesists invent\nreference ellipsoids like WGS 84 to approximate the geoid\u2019s shape with a figure that is easier to\ndefine mathematically. Because gravity varies with mass, the geoid bulges slightly above the ellipsoid\nover seamounts and undersea volcanoes, which often rise 2000 meters or more above the ocean floor.\nSea surface elevation data produced by satellite altimeters can thus be used to predict fairly detailed\nbathymetry, as shown in the map below.\nGlobal bathymetry predicted from sea surface elevations measured by the ERS-1 radar sensing\nsystem. The predicted bathymetry reveals seamounts and undersea volcanoes greater than 1000 meters\nin elevation, more than half of which had not previously been charted. (Sandwell & Smith, 1998).\n8.24. Using Radar Altimetry to Monitor El Nino\nRemotely sensed data play crucial roles in global change research. One example is data produced by\nradar altimetry, which are used to monitor the global climatological phenomenon called El Ni\u00f1o. El Ni\u00f1o\nis the colloquial name for a periodic weakening of the trade winds and warming of the surface layers\nof the eastern and central equatorial Pacific Ocean. El Ni\u00f1o events occur irregularly at intervals of 2-7\nyears, and typically last 12-18 months. Poorly understood teleconnections between the ocean and the\natmosphere result in altered regional precipitation patterns that sometimes include severe floods. The\nanimation below illustrates the changes in sea surface temperatures that accompanied the 1997-98 El\nNi\u00f1o event. 341 David DiBiase\nSea surface temperature anomalies from January 1997 through March 1998, estimated from on-\nsite measurements and sea surface elevation data produced by the TOPEX-POSEIDON satellite\naltimeter. NOTE: To replay the animation, hold down the Shift key and reload the page.(NOAA-CRIES\nClimate Diagnostics Center, 2006).\nActive remote sensing provides an alternative to the expensive and tedious business of measuring sea\nsurface temperatures directly at many locations throughout the Pacific Ocean.\nResearchers collect data from one of the 70 buoys in the Tropical Atmosphere Ocean (TAO) array.\nTAO buoys are equipped with sea surface temperature monitoring instruments. Hourly observations are\nstored in instrument memory and must be retrieved by operators. (Tropical Atmosphere Ocean Project,\nn. d.).\nFrom 1992 through 2005, the TOPEX\/POSEIDON radar altimeter measured heights of the ocean\nsurface with centimeter accuracy. The sensor transmitted and received longwave energy at 6 km intervals\nalong ground tracks spaced 315 km apart. The satellite that carried the sensor completed a polar orbit\nevery 112 minutes at an altitude of 1,335 km, passing over the same point every 10 days. Sea level Nature of Geographic Information 342\ndeviations (differences between the geoid and measured sea level) were determined from measurements\nof the height of the ocean surface relative to the sensor, which is calculated from the time difference\nbetween the transmission and return of signals reflected from the ocean surface. Sea surface temperature\ncan be inferred from deviations of sea surface heights relative to long-term mean values.\nDeviations of sea surface elevations from long-term averages, measured by the TOPEX-POSEIDON\nradar altimeter. Sea level deviations are used as a surrogate measure of the warming of the eastern\nequatorial Pacific Ocean that indicates an El Ni\u00f1o event. The S-shaped curves trace the path of the\nsatellite\u2019s polar orbit as the Earth rotates beneath it. (NASA, Jet Propulsion Laboratory, 2006).\nPRACTICE QUIZ\nRegistered Penn State students should return now to the Chapter 8 folder in ANGEL (via the Resources\nmenu to the left) to take a self-assessment quiz about Microwave Data.\nYou may take practice quizzes as many times as you wish. They are not scored and do not affect your\ngrade in any way.\n8.25. Summary\nMost remotely sensed data are derived from measurements of electromagnetic radiation. Aerial\nphotographs are analog forms of data that record intensities of electromagnetic radiation within the\nvisible or near-infrared wavelength bands. Digital sensing systems extend the spectral sensitivity of\nphotographic film far beyond the visible band, enabling users to map phenomena that are otherwise\ninvisible. Because many objects exhibit unique spectral response characteristics across a range of\nwavelengths, multispectral sensing offers the potential to identify features of interest automatically.\nRecognizing this potential, analysts in many fields have adopted land remote sensing data for such\ndiverse applications as land use and land cover mapping, geological resource exploration, precision 343 David DiBiase\nfarming, archeological investigations, and even validating the computational models used to predict\nglobal environmental change. Once the exclusive domain of government agencies, an industry survey\nsuggests that the gross revenue earned by private land remote sensing firms exceeded $2.4 billion (U.S.)\nin 2001 (ASPRS, 2004).\nThe fact that remote sensing is first and foremost a surveillance technology deployed by government\nagencies cannot be overlooked. State-of-the-art spy satellites are rumored to be able to detect objects\nas small as six inches wide. Meanwhile, GeoEye and other private firms have been licensed to build\nand launch half-meter panchromatic sensors. As the resolution of remotely sensed imagery increases,\nand its price decreases, privacy concerns are bound to proliferate. For example, remotely sensed data\nwere pivotal in the case of an Arizona farmer who was fined for growing cotton illegally (Kerber,\n1998). Was the farmer right to claim that remote sensing constituted unreasonable search? More serious,\nperhaps, is the potential impact of the remote sensing industry on defense policy of the United States\nand other countries. In light of an expected $500 billion investment in commercial satellites (including\ncommunications satellites as well as land remote sensing systems) by 2010, some analysts believe that\n\u201cthe military will be called upon to defend American interests in space much as navies were formed to\nprotect sea commerce in the 1700s\u201d (Newman, 1999).\nWhile the ethical implications of remote sensing technologies must not be ignored, neither should\ntheir potential to help us to become more knowledgeable, and thus more effective stewards of our home\nplanet. Several challenges must be addressed before remote sensing can fulfill this potential. One is the\nneed to produce cost-effective, high-resolution data suitable for local scale mapping\u2013the scale at which\nmost land use decisions are made. Another is the need to develop more sophisticated image processing\nalgorithms that will enable analysts to extract vector features from raster source data with minimal\nintervention. Yet another challenge is to develop automated classification techniques to help derive\nmeaningful patterns from the data produced by a new generation of hyperspectral scanners\u2013sensing\nsystems that measure reflected and emitted radiation across 200 or more narrow wavelength bands\nsimultaneously.\nQUIZ\nRegistered Penn State students should return now to the Chapter 8 folder in ANGEL (via the Resources\nmenu to the left) to take a graded quiz for this chapter.\nThis one counts. You may take graded quizzes only once.\nThe purpose of the quiz is to ensure that you have studied the text closely, that you have mastered the\npractice activities, and that you have fulfilled the chapter\u2019s learning objectives. You are free to review\nthe chapter during the quiz.\nOnce you have submitted the quiz and posted any questions you may have to our Chapter 8 Discussion\nForum, you will have completed Chapter 8.\nCOMMENTS AND QUESTIONS\nRegistered students are welcome to post comments, questions, and replies to questions about the\ntext. Particularly welcome are anecdotes that relate the chapter text to your personal or professional\nexperience. In addition, there are discussion forums available in the ANGEL course management system\nfor comments and questions about topics that you may not wish to share with the whole world.\nTo post a comment, scroll down to the text box under \u201cPost new comment\u201d and begin typing in the text\nbox, or you can choose to reply to an existing thread. When you are finished typing, click on either the\n\u201cPreview\u201d or \u201cSave\u201d button (Save will actually submit your comment). Once your comment is posted, Nature of Geographic Information 344\nyou will be able to edit or delete it as needed. In addition, you will be able to reply to other posts at any\ntime.\nNote: the first few words of each comment become its \u201ctitle\u201d in the thread.\n8.26. Bibliography\nAmerican Society for Photogrammetry and Remote Sensing (2004). ASPRS\/NASA ten-year industry\nforecast. Photogrammetric Engineering and Remote Sensing, 70:1 Originally retrieved March 2, 2008\nfrom http:\/\/www.asprs.org\/news\/forecast\/ (expired). Retrieved November 30, 2011\nfrom http:\/\/www.asprs.org\/a\/news\/forecast\/10-year-ind-forecast-exec-summary.pdf\nCalifornia Institute of Technology. (2002). ASTER spectral library. Retrieved June 3, 2001\nfrom http:\/\/speclib.jpl.nasa.gov\nCampbell, J. B. (1983). Mapping the land: Aerial imagery for land use information. Washington,\nD.C.: Association of American Geographers.\nColucci, J. A. (1998). Uncorking technology: Better wine through remote sensing. EOM, May, pp.\n32-35.\nCowen, D. J. & Jensen, J. R. (1998). Extraction and Modeling of Urban Attributes Using Remote\nSensing Technology. In D. Liverman, E. F. Moran, R. R. Rindfuss & P. C. Stern (Eds.), People\nand Pixels: Linking Remote Sensing and Social Science (pp. 164-188). Washington, D. C.: National\nAcademy Press, National Research Council.\nEidenshink, J. C., & Faundeen, J. L. (1994). The 1-km AVHRR global land data set: First stages in\nimplementation. International Journal of Remote Sensing, 15, pp. 3443-3462.\nGeoEye (2007). GeoEye imagery products: GeoEye 1. Retrieved March 1, 2008,\nfromhttp:\/\/www.geoeye.com\/products\/imagery\/geoeye1\/default.htm(expired, or moved\nto http:\/\/launch.geoeye.com\/LaunchSite\/about\/ )\nGeophysical Data Center, National Oceanic and Atmospheric Administration (2005). EOG Defense\nMeteorological Satellite Program (DMSPP). Retrieved June 3, 2001, fromhttp:\/\/www.ngdc.noaa.gov\/\ndmsp\/dmsp.html\nJensen, J. R. (1996). Introductory digital image processing: A remote sensing perspective. Upper\nSaddle River, N.J.: Prentice Hall.\nJet Propulsion Laboratory. (2006). Ocean surface topography from space. National Aeronautics and\nSpace Administration. Retrieved June 20, 2006, from http:\/\/sealevel.jpl.nasa.gov\/\nKerber, R. (1998). When is a satellite photo an unreasonable search?Wall Street Journal, January 27,\n1998.\nLillesand, T. & Kiefer, R. (1994). Remote sensing and image interpretation (3rd ed.). New York, NY:\nJohn Wiley and Sons.\nNewman, R. J. (1999). The new space race. U.S. News and World Report, November 8, pp. 30-38.\nNational Aeronautics & Space Administration (2001). The Landsat Program. Retrieved June 3, 2001,\nfrom http:\/\/landsat.gsfc.nasa.gov\nNOAA-CIRES Climate Diagnostics Center. (2006). Retrieved June 20, 2006,\nfrom http:\/\/www.cdc.noaa.gov\/map\/clim\/sst_olr\/sst_anim.shtml\nSandwell, D. T. & Smith, W. H. F. (1998). Exploring the ocean basins with satellite altimeter data.\nRetrieved December 18, 1998, fromwww.ngdc.noaa.gov\/mgg\/bathymetry\/predicted\/explore.HTML\nSteinwand, D.R. (1994). Mapping raster imagery to the interrupted goode homolosine\nprojection. International Journal of Remote Sensing, 15:17, pp. 3463-3471. 345 David DiBiase\nTropical Atmosphere Ocean Project. (n. d.). TAO buoy photo gallery. Retrieved June 20, 2006,\nfromhttp:\/\/www.pmel.noaa.gov\/tao\/proj_over\/diagrams\/buoy.html\nUnited States Geological Survey (2001). Earthshots: satellite images of environmental change.\nRetrieved March 6, 2001, fromhttp:\/\/earthshots.usgs.gov\/\nUnited States Geological Survey. (2005). Global Land 1-Km AVHRR Project. Retrieved May 31,\n2006, fromhttp:\/\/edcsns17.cr.usgs.gov\/1KM\/\nUnited States Geological Survey (2011). EarthNow! Landsat Image Viewer. Retrieved November 30,\n2011 from http:\/\/earthnow.usgs.gov\/ Chapter 9\n346 Integrating Geographic Data\nDavid DiBiase\n9.1. Overview\nGeographic data are expensive to produce and maintain. Data often accounts for the lion\u2019s share of the\ncost of building and running geographic information systems. The expense of GIS is justifiable when\nit gives people the information they need to make wise choices in the face of complex problems. In\nthis chapter we\u2019ll consider one such problem: the search for suitable and acceptable sites for low level\nradioactive waste disposal facilities. Two case studies will demonstrate that GIS is very useful indeed for\nassimilating the many site suitability criteria that must be taken into account, provided that the necessary\ndata can be assembled in a single, integrated system. The case studies will allow us to compare vector\nand raster approaches to site selection problems.\nThe ability to integrate diverse geographic data is a hallmark of mature GIS software. The know-\nhow required to accomplish data integration is also the mark of a truly knowledgeable GIS user. What\nknowledgeable users also recognize, however, is that while GIS technology is well suited to answering\ncertain well defined questions, it often cannot help resolve crucial conflicts between private and public\ninterests. The objective of this final, brief chapter is to consider the challenges involved in using GIS\nto address a complex problem that has both environmental and social dimensions. Specifically, in this\nchapter you will learn to:\nObjectives\nChapter 9 should help prepare you to:\n\u2022 Recognize the characteristics of geographic data that must be taken into account to overlay\nmultiple data layers;\n\u2022 Compare and contrast vector and raster approaches to site suitability studies;\n\u2022 Have realistic expectations about what geographic data analysis can achieve.\nComments and Questions?\nRegistered students are welcome to post comments, questions, and replies to questions about the\ntext. Particularly welcome are anecdotes that relate the chapter text to your personal or professional\nexperience. In addition, there are discussion forums available in the ANGEL course management system\nfor comments and questions about topics that you may not wish to share with the whole world.\nTo post a comment, scroll down to the text box under \u201cPost new comment\u201d and begin typing in the text\nbox, or you can choose to reply to an existing thread. When you are finished typing, click on either the\n\u201cPreview\u201d or \u201cSave\u201d button (Save will actually submit your comment). Once your comment is posted,\nyou will be able to edit or delete it as needed. In addition, you will be able to reply to other posts at any\ntime.\nNote: the first few words of each comment become its \u201ctitle\u201d in the thread.\n347 Nature of Geographic Information 348\n9.2. Checklist\nThe following checklist is for Penn State students who are registered for classes in which this text, and\nassociated quizzes and projects in the ANGEL course management system, have been assigned. You\nmay find it useful to print this page out first so that you can follow along with the directions.\nChapter 9 Checklist (for registered students only)\nStep Activity Access\/Directions\nThis is the second page of the Chapter. Click on the links at the bottom\nof the page to continue or to return to the previous page, or to go to the\n1 ReadChapter 9\ntop of the chapter. You can also navigate the text via the links in the\nGEOG 482 menu on the left.\nChapter 9 includes no practice\n2\nquizzes.\nPerform\u201cTry this\u201d\nactivitiesincluding:\n\u2022 Use Global Mapper \/\n3 dlgv32 Pro software Instructions are provided for each activity.\nto create a slope map\n\u201cTry this\u201d activities are not\ngraded.\nSubmit theChapter 9 Graded ANGEL > [your course section] > Lessons tab > Chapter 9 folder >\n4\nQuiz Chapter 9 Graded Quiz. See the Calendar tab in ANGEL for due dates.\nReadcomments and\nquestionsposted by fellow Comments and questions may be posted on any page of the text, or in a\n5\nstudents. Add comments and Chapter-specific discussion forum in ANGEL.\nquestions of your own, if any.\n9.3. Context\nThis section sets a context for two case studies that follow. First, I will briefly define low level\nradioactive waste (LLRW). Then I discuss the legislation that mandated construction of a dozen or more\nregional LLRW disposal facilities in the U.S. Finally, I will reflect briefly on how the capability of\ngeographic information systems to integrate multiple data \u201clayers\u201d is useful for siting problems like the\nones posed by LLRW.\n9.4. Low Level Radioactive Waste\nAccording to the U.S. Nuclear Regulatory Commission (2004), LLRW consists of discarded items that\nhave become contaminated with radioactive material or have become radioactive through exposure to\nneutron radiation. Trash, protective clothing, and used laboratory glassware make up all but about 3 349 David DiBiase\npercent of LLRW. These \u201cClass A\u201d wastes remain hazardous less than 100 years. \u201cClass B\u201d wastes,\nconsisting of water purification filters and ion exchange resins used to clean contaminated water at\nnuclear power plants, remain hazardous up to 300 years. \u201cClass C\u201d wastes, such as metal parts of\ndecommissioned nuclear reactors, constitute less than 1 percent of all LLRW, but remain dangerous for\nup to 500 years.\nThe danger of exposure to LLRW varies widely according to the types and concentration of\nradioactive material contained in the waste. Low level waste containing some radioactive materials used\nin medical research, for example, is not particularly hazardous unless inhaled or consumed, and a person\ncan stand near it without shielding. On the other hand, exposure to LLRW contaminated by processing\nwater at a reactor can lead to death or an increased risk of cancer (U.S. Nuclear Regulatory Commission,\nn.d.).\nProduction trends and destinations of low level radioactive waste. (U.S. Nuclear Regulatory\nCommission, 2005).\nHundreds of nuclear facilities across the country produce LLRW, but only a very few disposal sites are\ncurrently willing to store it. Disposal facilities at Clive, Utah, Barnwell, South Carolina, and Richland,\nWashington, accepted over 4,000,000 cubic feet of LLRW in both 2005 and 2006, up from 1,419,000\ncubic feet in 1998. By 2008 the volume had dropped to just over 2,000,000 cubic feet (U.S. Nuclear Nature of Geographic Information 350\nRegulatory Commisssion, 2011a). Sources include nuclear reactors, industrial users, government sources\n(other than nuclear weapons sites), and academic and medical facilities. (We have a small nuclear reactor\nhere at Penn State that is used by students in graduate and undergraduate nuclear engineering classes.)\n9.5. Siting LLRW Storage Facilities\nThe U.S. Congress passed the Low Level Radioactive Waste Policy Act in 1980. As amended in 1985,\nthe Act made states responsible for disposing of the LLRW they produce. States were encouraged to\nform regional \u201ccompacts\u201d to share the costs of locating, constructing, and maintaining LLRW disposal\nfacilities. The intent of the legislation was to avoid the very situation that has since come to pass, that\nthe entire country would become dependent on a very few disposal facilities.\nRegional compacts formed by states in response to the LLRW Policy Act (U.S. Nuclear Regulatory\nCommission, 2011b).\nState government agencies and the consultants they hire to help select suitable sites assume that\nfew if any municipalities would volunteer to host a LLRW disposal facility. They prepare for worst-\ncase scenarios in which states would be forced to exercise their right of eminent domain to purchase\nsuitable properties without the consent of landowners or their neighbors. GIS seems to offer an impartial,\nscientific, and therefore defensible approach to the problem. As Mark Monmonier has written, \u201c[w]e\nhave to put the damned thing somewhere, the planners argue, and a formal system of map analysis offers 351 David DiBiase\nan \u2018objective,\u2019 logical method for evaluating plausible locations\u201d (Monmonier, 1995, p. 220). As we\ndiscussed in our very first chapter, site selection problems pose a geographic question that geographic\ninformation systems are well suited to address, namely, which locations have attributes that satisfy all\nsuitability criteria?\n9.6. Map Overlay Concept\nEnvironmental scientists and engineers consider many geological, climatological, hydrological, and\nsurface and subsurface land use criteria to determine whether a plot of land is suitable or unsuitable for\na LLRW facility. Each criterion can be represented with geographic data, and visualized as a thematic\nmap. In theory, the site selection problem is as simple as compiling onto a single map all the disqualified\nareas on the individual maps, and then choosing among whatever qualified locations remain. In practice,\nof course, it is not so simple.\nThere is nothing new about superimposing multiple thematic maps to reveal optimal locations. One\nof the earliest and most eloquent descriptions of the process was written by Ian McHarg, a landscape\narchitect and planner, in his influential book Design With Nature. In a passage describing the process\nhe and his colleagues used to determine the least destructive route for a new roadway, McHarg (1971)\nwrote:\n\u2026let us map physiographic factors so that the darker the tone, the greater the cost. Let us similarly\nmap social values so that the darker the tone, the higher the value. Let us make the maps transparent.\nWhen these are superimposed, the least-social-cost areas are revealed by the lightest tone. (p. 34).\nAs you probably know, this process has become known as map overlay. Storing digital data in multiple\n\u201clayers\u201d is not unique to GIS, of course; computer-aided design (CAD) packages and even spreadsheets\nalso support layering. What\u2019s unique about GIS, and important about map overlay, is its ability to\ngenerate a new data layer as a product of existing layers. In the example illustrated below, for example,\nanalysts at Penn State\u2019s Environmental Resources Research Institute estimated the agricultural pollution\npotential of every major watershed in the state by overlaying watershed boundaries, the slope of the\nterrain (calculated from USGS DEMs), soil types (from U.S. Soil Conservation Service data), land use\npatterns (from the USGS LULC data), and animal loading (livestock wastes estimated from the U.S.\nCensus Bureau\u2019s Census of Agriculture). Nature of Geographic Information 352\nDiagram illustrating the map overlay process used to evaluate potential agricultural pollution by\nwatershed in Pennsylvania.\nAs illustrated below, map overlay can be implemented in either vector or raster systems. In the vector\ncase, often referred to as polygon overlay, the intersection of two or more data layers produces new\nfeatures (polygons). Attributes (symbolized as colors in the illustration) of intersecting polygons are\ncombined. The raster implementation (known as grid overlay) combines attributes within grid cells that\nalign exactly. Misaligned grids must be resampled to common formats.\nMap overlay is a procedure for combining the attributes of intersecting features that are represented\nin two or more georegistered data layers.\nPolygon and grid overlay procedures produce useful information only if they are performed on data\nlayers that are properly georegistered. Data layers must be referenced to the same coordinate system\n(e.g., the same UTM and SPC zones), the same map projection (if any), and the same datum (horizontal\nand vertical, based upon the same reference ellipsoid). Furthermore, locations must be specified with\ncoordinates that share the same unit of measure.\n9.7. Pennsylvania Case Study\nIn response to the LLRW Policy Act, Pennsylvania entered into an \u201cAppalachian Compact\u201d with the\nstates of Delaware, Maryland, and West Virginia to share the costs of siting, building, and operating a\nLLRW storage facility. Together, these states generated about 10 percent of the total volume of LLRW\nthen produced in the U.S. Pennsylvania, which generated about 70 percent of the total produced by the\nAppalachian Compact, agreed to host the disposal site. 353 David DiBiase\nIn 1990, the Pennsylvania Department of Environmental Protection commissioned Chem-Nuclear\nSystems Incorporated (CNSI) to identify three potentially suitable sites to accommodate two to three\ntruckloads of LLRW per day for 30 years. CNSI, the operator of the Barnwell South Carolina site, would\nalso operate the Pennsylvania site for profit.\nSketch of the proposed Pennsylvania LLRW disposal facility (Pennsylvania Department of\nEnvironmental Protection, 1998).\nCNSI\u2019s plan called for storing LLRW in 55-gallon drums encased in concrete, buried in clay,\nsurrounded by a polyethylene membrane. The disposal facilities, along with support and administration\nbuildings and a visitors center, would occupy about 50 acres in the center of a 500-acre site. (Can you\nimagine a family outing to the Visitors Center of a LLRW disposal facility?) The remaining 450 acres\nwould be reserved for a 500 to 1000 foot wide buffer zone.\nThe three stage siting process agreed to by CNSI and the Pennsylvania Department of Environmental\nProtection corresponded to three scales of analysis: statewide, regional, and local. All three stages relied\non vector geographic data integrated within a GIS.\n9.8. Vector Approach\nCNSI and its subcontractors adopted a vector approach for its GIS-based site selection process. When\nthe process began in 1990, far less geographic data was available in digital form than it is today. Most\nof the necessary data was available only as paper maps, which had to be converted to digital form. In\none of its interim reports, CNSI described two digitizing procedures used, \u201cdigitizing\u201d and \u201cscanning.\u201d\nHere\u2019s how it described \u201cdigitizing:\u201d\nIn the digitizing process, a GIS operator uses a hand-held device, known as a cursor, to trace the boundaries\nof selected disqualifying features while the source map is attached to a digitizing table. The digitizing table\ncontains a fine grid of sensitive wire imbedded within the table top. This grid allows the attached computer\nto detect the position of the cursor so that the system can build an electronic map during the tracing. In this\nproject, source maps and GIS-produced maps were compared to ensure that the information was transferred\naccurately. (Chem Nuclear Systems, 1993, p. 8).\nOne aspect overlooked in the CNSI description is that operators must encode the attributes of features\nas well as their locations. Some of you know all too well that tablet digitizing (illustrated in the photo\nbelow left) is an extraordinarily tedious task, so onerous that even student interns resent it. One wag here Nature of Geographic Information 354\nat Penn State suggested that the acronym \u201cGIS\u201d actually stands for \u201cGetting it (the data) In Stinks.\u201d You\ncan substitute your own \u201cS\u201d word if you wish.\nVector digitizing with a tablet (left); raster digitizing with a drum scanner (right) (USGS).\nCompared to the drudgery of tablet digitizing, electronically scanning paper maps seems simple and\nefficient. Here\u2019s how CNSI describes it:\nThe scanning process is more automated than the digitizing process. Scanning is similar to photocopying, but\ninstead of making a paper copy, the scanning device creates an electronic copy of the source map and stores the\ninformation in a computer record. This computer record contains a complete electronic picture (image) of the\nmap and includes shading, symbols, boundary lines, and text. A GIS operator can select the appropriate feature\nboundaries from such a record. Scanning is useful when maps have very complex boundaries lines that can not\nbe easily traced. (Chem Nuclear Systems, Inc., 1993, p. 8)\nI hope you noticed that CNSI\u2019s description glosses over the distinction between raster and vector data. If\nscanning is really as easy as they suggest, why would anyone ever tablet-digitize anything? In fact, it is\nnot quite so simple to \u201cselect the appropriate feature boundaries\u201d from a raster file, which is analogous to\na remotely sensed image. The scanned maps had to be transformed from pixels to vector features using\na semi-automated procedure called raster to vector conversion, otherwise known as \u201cvectorization.\u201d\nTime-consuming manual editing is required to eliminate unwanted features (like vectorized text), correct\ndigital features that were erroneously attached or combined, and to identify the features by encoding\ntheir attributes in a database.\nIn either the vector or raster case, if the coordinate system, projection, and datums of the original\npaper map were not well defined, the content of the map first had to be redrawn, by hand, onto another\nmap whose characteristics are known.\n9.9. Stage One: Statewide Screening\nCNSI considered several geological, hydrological, surface and subsurface land use criteria in the first\nstage of its LLRW siting process. [View a table that lists all the Stage One criteria.] CNSI\u2019s GIS\nsubcontractors created separate digital map layers for every criterion. Sources and procedures used to\ncreate three of the map layers are discussed briefly below. 355 David DiBiase\nAreas underlain by limestone and other carbonate rocks were digitized from the Pennsylvania\nGeological Survey\u2019s Geologic Map of Pennsylvania. (Chem-Nuclear Systems, 1991).\nOne of the geological criteria considered was carbonate lithology. Limestone and other carbonate\nrocks are permeable. Permeable bedrock increases the likelihood of ground water contamination in the\nevent of a LLRW leak. Areas with carbonate rock outcrops were therefore disqualified during the first\nstage of the screening process. Boundaries of disqualified areas were digitized from the 1:250,000-scale\nGeologic Map of Pennsylvania (1980). What concerns would you have about data quality given a\n1:250,000-scale source map?\nCoastal flood plains were digitized from 100-year flood contours compiled from FEMA Flood\nInsurance Rate Maps onto USGS topographic maps. (Chem-Nuclear Systems, 1991).\nAnalysts needed to make sure that the LLRW disposal facility would never be inundated with water in\nthe event of a coastal flood, or a rise in sea level. To determine disqualified areas, CNSI\u2019s subcontractors\nrelied upon the Federal Emergency Management Agency\u2019s Flood Insurance Rate Maps (FIRMs). The\nmaps were not available in digital form at the time, and did not include complete metadata. According\nto the CNSI interim report, \u201c[t]he 100-year flood plains shown on maps obtained from FEMA \u2026 were Nature of Geographic Information 356\ntransferred to USGS 7.5-minute quad sheet maps. The 100-year flood plain boundaries were digitized\ninto the GIS from the 7.5-minute quad sheet maps.\u201d (Chem Nuclear Systems, 1991, p. 11) Why would\nthe contractors go to the trouble of redrawing the floodplain boundaries onto topographic maps\nprior to digitizing?\n\u201cExceptional value watersheds\u201d were delineated on topographic maps, then digitized. (Chem-Nuclear\nSystems, 1991).\nAreas designated as \u201cexceptional value watersheds\u201d were also disqualified during Stage One.\nPennsylvania legislation protected 96 streams. Twenty-nine additional streams were added during\nthe site screening process. \u201cThe watersheds were delineated on county [1:50,000 or 1:100,000-scale\ntopographic] maps by following the appropriate contour lines. Once delineated, the EV stream and\nits associated watershed were digitized into the GIS.\u201d (Chem Nuclear Systems, 1991, p. 12) What\ndigital data sets could have been used to delineate the watersheds automatically, had the data been\navailable?\nAfter all the Stage One maps were digitized, georegistered, and overlayed, approximately 23 percent\nof the state\u2019s land area was disqualified.\n9.10. Stage Two: Regional Screening\nCNSI considered additional disqualification criteria during the second, \u201cregional\u201d stage of the LLRW\nsiting process. [View a table that lists all the Stage Two criteria.] Some of the Stage Two criteria had\nalready been considered during Stage One, but were now reassessed in light of more detailed data\ncompiled from larger-scale sources. In its interim report, CNSI had this to say about the composite\ndisqualification map shown below:\nWhen all the information was entered in to Stage Two database, the GIS was used to draw the maps showing\nthe disqualified land areas. \u2026 The map shows both additions\/refinements to the Stage One disqualifying\nfeatures and those additional disqualifying features examined during Stage Two. (Chem Nuclear Systems,\n1993, p. 19) 357 David DiBiase\nComposite map showing approximately 46 per cent of the state disqualified as a result of Stages One\nand Two of the LLRW site selection process. (Chem-Nuclear Systems, 1993).\nCNSI added this disclaimer:\nThe Stage Two Disqualifying maps found in Appendix A depict information at a scale of 1:1.5 million. At\nthis scale, one inch on the map represents 24 miles, or one mile is represented on the map by approximately\nfour one-hundreds of an inch. A square 500-acre area measures less than one mile on a side. Printing of such\nfine detail on the 11\u2033 \u00d7 17\u2033 disqualifying maps was not possible, therefore, it is possible that small areas of\nsufficient size for the LLRW disposal facility site may exist within regions that appear disqualified on the\nattached maps. [Emphasis in the original document] The detailed boundary information for these small areas\nis retained within the GIS even though they are not visually illustrated on the maps. (Chem Nuclear Systems,\n1993, p. 20)\nAs I mentioned back in Chapter 2, CNSI representatives took some heat about the map scale problem in\npublic hearings. Residents took little solace in the assertion that the data in the GIS were more truthful\nthan the data depicted on the map.\n11. Stage Three: Local Disqualification\nMany more criteria were considered in Stage Three. [View a table that lists all the Stage Three criteria.]\nAt the completion of the third stage, roughly 75 percent of the state\u2019s land area had been disqualified.\nOne of the new criteria introduced in Stage Three was slope. Analysts were concerned that\nprecipitation runoff, which increases as slope increases, might increase the risk of surface water\ncontamination should the LLRW facility spring a leak. CNSI\u2019s interim report (1994a) states that \u201c[t]he\ndisposal unit area which constitutes approximately 50 acres \u2026 may not be located where there are slopes\ngreater than 15 percent as mapped on U.S. Geological Survey (USGS) 7.5-minute quadrangles utilizing\na scale of 1:24,000 \u2026\u201d (p. 9).\nSlope is change in terrain elevation over a given horizontal distance. It is often expressed as a\npercentage. A 15 percent slope changes at a rate of 15 feet of elevation for every 100 feet of horizontal\ndistance. Slope can be measured directly on topographic maps. The closer the spacing of elevation\ncontours, the greater the slope. CNSI\u2019s GIS subcontractors were able to identify areas with excessive Nature of Geographic Information 358\nslope on topographic maps using plastic templates called \u201cland slope indicators\u201d that showed the\nmaximum allowable contour spacing.\nFortunately for the subcontractors, 7.5-minute USGS DEMs were available for 85 percent of the state\n(they\u2019re all available now). Several algorithms have been developed to calculate slope at each grid point\nof a DEM. As described in chapter 7, the simplest algorithm calculates slope at a grid point as a function\nof the elevations of the eight points that surround it to the north, northeast, east, southeast, and so on.\nCNSI\u2019s subcontractors used GIS software that incorporated such an algorithm to identify all grid points\nwhose slopes were greater than 15 percent. The areas represented by these grid points were then made\ninto a new digital map layer.\nTRY THIS!\nYou can create a slope map of the Bushkill PA quadrangle with Global Mapper (dlgv32 Pro) software.\n\u2022 Launch Global Mapper\n\u2022 Open the file \u201cbushkill_pa.dem\u201d that you downloaded earlier (either the 10-meter or\n30-meter version)\n\u2022 Change from the default \u201cHSV\u201d shader to the \u201cSlope\u201d shader.\nBy default, pixels with 0 percent slope are lightest, and pixels with 30 percent slope or more are\ndarkest. You can adjust this at Tools > Configure > Shader Options. 359 David DiBiase\nNotice that the slope symbolization does not change even as you change the vertical exaggeration of\nthe DEM (Tools > Configure > Vertical Options).\n9.12. Buffering\nSeveral of the disqualification criteria involve buffer zones. For example, one disqualifying criterion\nstates that \u201c[t]he area within 1\/2 mile of an existing important wetland \u2026 is disqualified.\u201d Another states\nthat \u201cdisposal sites may not be located within 1\/2 mile of a well or spring which is used as a public water\nsupply.\u201d (Chem-Nuclear Systems, 1994b). As I mentioned in the chapter 1 (and as you may know from\nexperience), buffering is a GIS procedure by which zones of specified radius or width are defined\naround selected vector features or raster grid cells.\nLike map overlay, buffering has been implemented in both vector and raster systems. The vector\nimplementation involves expanding a selected feature or features, or producing new surrounding\nfeatures (polygons). The raster implementation accomplishes the same thing, except that buffers consist\nof sets of pixels rather than discrete features.\nBuffer zones (yellow) surround vector and raster representations of a pond and stream.\n9.14. Outcomes\nTo date, neither Pennsylvania nor New York has built a LLRW disposal facility. Both states gave up on\ntheir unpopular siting programs shortly after Republicans replaced Democrats in the 1994 gubernatorial\nelections.\nThe New York process was derailed when angry residents challenged proposed sites on account of\ninaccuracies discovered in the state\u2019s GIS data, and because of the state\u2019s failure to make the data\naccessible for citizen review in accordance with the Freedom of Information Act (Monmonier, 1995).\nPennsylvania\u2019s $37 million siting effort succeeded in disqualifying more than three quarters of\nthe state\u2019s land area, but failed to recommend any qualified 500-acre sites. With the volume of its\nLLRW decreasing, and the Barnwell South Carolina facility still willing to accept Pennsylvania\u2019s waste\nshipments, the search was suspended \u201cindefinitely\u201d in 1998.\nTo fulfill its obligations under the LLRW Policy Act, Pennsylvania has initiated a \u201cCommunity\nPartnering Plan\u201d that solicits volunteer communities to host a LLRW disposal facility in return for jobs, Nature of Geographic Information 360\nconstruction revenues, shares of revenues generated by user fees, property taxes, scholarships, and other\nbenefits. The plan has this to say about the GIS site selection process that preceded it: \u201cThe previous\napproach had been to impose the state\u2019s will on a municipality by using a screening process based\nprimarily on technical criteria. In contrast, the Community Partnering Plan is voluntary.\u201d (Chem Nuclear\nSystems, 1996, p. 3)\nThe New York and Pennsylvania state governments turned to GIS because it offered an impartial and\nscientific means to locate a facility that nobody wanted in their backyard. Concerned residents criticized\nthe GIS approach as impersonal and technocratic. There is truth to both points of view. Specialists\nin geographic information need to understand that while GIS can be effective in answering certain\nwell-defined questions, it does not ease the problem of resolving conflicts between private and public\ninterests.\nMeanwhile, a Democrat replaced a Republican as governor of South Carolina in 1998. The new\ngovernor warned that the Barnwell facility might not continue to accept out-of-state LLRW. \u201cWe don\u2019t\nwant to be labeled as the dumping ground for the entire country,\u201d his spokesperson said (Associated\nPress, 1998).\nNo volunteer municipality has yet come forward in response to Pennsylvania\u2019s Community Partnering\nPlan. If the South Carolina facility does stop accepting Pennsylvania\u2019s LLRW shipments, and if no\nLLRW disposal facility is built within the state\u2019s borders, then nuclear power plants, hospitals,\nlaboratories, and other facilities may be forced to store LLRW on site. It will be interesting to see if the\nGIS approach to site selection is resumed as a last resort, or if the state will continue to up the ante in its\nattempts to attract volunteers, in the hope that every municipality has its price. If and when a volunteer\ncommunity does come forward, detailed geographic data will be produced, integrated, and analyzed to\nmake sure that the proposed site is suitable after all.\nTRY THIS!\nTo find out about LLRW-related activities where you live, use your favorite search engine to search the\nWeb on \u201cLow-Level Radioactive Waste [your state or area of interest]\u201c. If GIS is involved in your state\u2019s\nLLRW disposal facility site selection process, your state agency that is concerned with environmental\naffairs is likely to be involved. Add a comment to this page to share your discovery.\n9.15. Conclusion\nSite selection projects like the ones discussed in this chapter require the integration of diverse geographic\ndata. The ability to integrate and analyze data organized in multiple thematic layers is a hallmark\nof geographic information systems. To contribute to GIS analyses like these, you need to be both a\nknowledgeable and skillful GIS user. The objective of this text, and the associated Penn State course,\nhas been to help you become more knowledgeable about geographic data.\nKnowledgeable users are well versed in the properties of geographic data that need to be taken into\naccount to make data integration possible. Knowledgeable users understand the distinction between\nvector and raster data, and know something about how features, topological relationships among\nfeatures, attributes, and time can be represented within the two approaches. Knowledgeable users\nunderstand that in order for geographic data to be organized and analyzed as layers, the data must be both\northorectified and georegistered. Knowledgeable users look out for differences in coordinate systems,\nmap projections, and datums that can confound efforts to georegister data layers. Knowledgeable users\nknow that the information needed to register data layers is found in metadata. "}