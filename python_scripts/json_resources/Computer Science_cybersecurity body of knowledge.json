{"text":"TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nCybersecurityisbecominganimportantelementincurriculaatalleducationlevels.However,\nthe foundational knowledge on which the field of cyber security is being developed is frag-\nmented, and as a result, it can be difficult for both students and educators to map coherent\npaths of progression through the subject. By comparison, mature scientific disciplines like\nmathematics,physics,chemistry,andbiologyhaveestablishedfoundationalknowledgeand\nclear learning pathways. Within software engineering, the IEEE Software Engineering Body\nof Knowledge [3] codifies key foundational knowledge on which a range of educational pro-\ngrammes may be built. There are a number of previous and current efforts on establishing\nskills frameworks, key topic areas, and curricular guidelines for cyber security. However, a\nconsensushasnotbeenreachedonwhatthediversecommunityofresearchers,educators,\nandpractitionersseesasestablishedfoundationalknowledgeincybersecurity.\nTheCyberSecurityBodyofKnowledge(CyBOK)aimstocodifythefoundationalandgenerally\nrecognised knowledge on cyber security. In the same fashion as SWEBOK, CyBOK is meant\nto be a guide to the body of knowledge; the knowledge that it codifies already exists in lit-\nerature such as textbooks, academic research articles, technical reports, white papers, and\nstandards. Our focus is, therefore, on mapping established knowledge and not fully replicat-\ning everything that has ever been written on the subject. Educational programmes ranging\nfrom secondary and undergraduate education to postgraduate and continuing professional\ndevelopmentprogrammescanthenbedevelopedonthebasisofCyBOK.\nThis introduction sets out to place the 19 Knowledge Areas (KAs) of the CyBOK into a co-\nherentoverallframework.EachKAassumesabaselineagreementontheoverallvocabulary,\ngoals, and approaches to cyber security, and here we provide that common material which\nunderpins the whole body of knowledege. We begin with an overview of cyber security as\na topic, and some basic definitions, before introducing the knowledge areas. The KAs and\ntheir groupings into categories are, of course, not orthogonal and there are a number of de-\npendenciesacrosstheKAswhicharecross-referencedandalsoseparatelycapturedvisually\nontheCyBOKwebsite(https:\/\/www.cybok.org).WethendiscusshowtheknowledgeintheKAs\ncanbedeployedtounderstandthemeansandobjectivesofcybersecurity,mitigateagainst\nfailuresandincidents,andmanagerisks.\nAlthoughwehavenecessarilydividedtheCyBOKintoanumberofdiscreteKnowledgeAreas\n(KAs),itisclearthattherearemanyinter-relationshipsamongthem.Thosewithprofessional\nresponsibilityforoneareamusttypicallyhaveatleastamoderategraspoftheadjacenttop-\nics;someoneresponsibleforarchitectingasecuresystemmustunderstandmany.Thereare\na number of unifying principles and crosscutting themes \u2014 security economics; verification\nandformalmethods;andsecurityarchitectureandlifecycle\u2014thatunderpinthedevelopment\nof systems that satisfy particular security properties. We conclude the introduction by dis-\ncussingsuchprinciplesandthemes.\n1.1 CYBER SECURITY DEFINITION\nThe CyBOK Knowledge Areas assume a common vocabulary and core understanding of a\nnumberoftopicscentraltothefield.WhilstthisBodyofKnowledgeisdescriptiveofexisting\nknowledge (rather than seeking to innovate, or constrain), it is evident that use of widely-\nsharedterminologyinanestablishedconceptmapiscrucialtothedevelopmentofthedisci-\npline as awhole. Since our mainaim is to providea guideto the Bodyof Knowledge, we will\nprovidereferencestootherdefinitions,ratherthanintroducingourown.\nCybersecurity hasbecomeanencompassingterm,asourworkingdefinitionillustrates:\nKAIntroduction |October2019 Page2 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nDefinition: Cyber security refers to the protection of information systems (hardware,\nsoftwareandassociatedinfrastructure),thedataonthem,andtheservicestheyprovide,\nfrom unauthorised access, harm or misuse. This includes harm caused intentionally\nby the operator of the system, or accidentally, as a result of failing to follow security\nprocedures.\nUKNationalCyberSecurityStrategy[4]\nThis is a succinct definition but expresses the breadth of coverage within the topic. Many\notherdefinitionsareinuse,andadocumentfromENISA[5]surveysanumberofthese.\nTheconsiderationofhumanbehavioursisacrucialelementofsuchadefinition\u2014butarguably\nstill missing is a mention of the impact on them from loss of information or reduced safety,\nor of how security and privacy breaches impact trust in connected systems and infrastruc-\ntures.Moreover,securitymustbebalancedwithotherrisksandrequirements\u2014fromahuman\nfactorsperspectivethereisaneednottodisrupttheprimarytask.\nAlargecontributortothenotionofcybersecurityisInformationSecurity,widelyregardedas\ncomprisedofthreemainelements:\nDefinition:Informationsecurity.Preservationofconfidentiality,integrityandavailability\nofinformation.\nIn addition, other properties, such as authenticity, accountability, non-repudiation, and\nreliabilitycanalsobeinvolved.\nISO27000definition[6]\nFordefinitionsofthesubsidiaryterms,thereaderisreferredtotheISO27000definitions[6].\nThrough the developing digital age other \u2018securities\u2019 have had prominence, including Com-\nputerSecurity andNetworkSecurity;relatednotionsincludeInformationAssurance,andSys-\ntems Security \u2014 perhaps within the context of Systems Engineering or Security Engineering.\nThese terms are easily confused, and it seems that often one term is used when another is\nmeant.\nManyofthosetermsweresubjecttothecriticismthattheyplaceanover-relianceontechni-\ncalcontrols,andfocusalmostexclusivelyoninformation.Stretchingthemtorelatetocyber-\nphysicalsystemsmaybetakingthemtoofar:indeed,ourworkingdefinitionaboveprivileges\nthenotionofinformation(whilstalsomentioningservices)\u2014whereasinthecaseofnetwork-\nconnectedactuators,thepressingchallengeistopreventunwantedphysicalactions.\nMoreover,insomeaccountsofthetopic,cyberspaceisbestunderstoodasa\u2018place\u2019inwhich\nbusinessisconducted,humancommunicationstakeplace,artismadeandenjoyed,relation-\nships are formed and developed, and so on. In this place, cyber crime, cyber terrorism, and\ncyber war may occur, having both \u2018real\u2019 and \u2018virtual\u2019 impacts. Taken as a whole, the CyBOK\ndelineatesalargerangeoftopicswhichappeartobewithinthebroadscopeofcybersecurity,\nevenifasuccinctreductionofthoseintoashortdefinitionremainselusive.Thefullscopeof\nCyBOKmayserveasanextendeddefinitionofthetopic\u2014assummarisednext.\nKAIntroduction |October2019 Page3 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nFigure1.1:The19KnowledgeAreas(KAs)intheCyBOKScope\n1.2 CYBOK KNOWLEDGE AREAS\nTheCyBOKisdividedintonineteentop-levelKnowledgeAreas(KAs),groupedintofivebroad\ncategories, as shown in Figure 1.1. Clearly, other possible categorisations of these KAs may\nbe equally valid, and ultimately some of the structure is relatively arbitrary. The CyBOK Pref-\nacedescribestheprocessbywhichtheseKAswereidentifiedandchosen.\nOurcategoriesarenotentirelyorthogonal.Theseareintendedtocaptureknowledgerelating\nto cyber security per se: in order to make sense of some of that knowledge, auxiliary and\nbackground knowledge is needed \u2014 whether in the design of hardware and software, or in\ndiverseotherfields,suchaslaw.\nKAIntroduction |October2019 Page4 Human,Organisational,andRegulatoryAspects\nRiskManagement& Securitymanagementsystemsandorganisationalsecuritycontrols,includingstandards,\nGovernance bestpractices,andapproachestoriskassessmentandmitigation.\nInternationalandnationalstatutoryandregulatoryrequirements,complianceobligations,and\nLaw&Regulation\nsecurityethics,includingdataprotectionanddevelopingdoctrinesoncyberwarfare.\nUsablesecurity,social&behaviouralfactorsimpactingsecurity,securitycultureand\nHumanFactors\nawarenessaswellastheimpactofsecuritycontrolsonuserbehaviours.\nTechniquesforprotectingpersonalinformation,includingcommunications,applications,and\ninferencesfromdatabasesanddataprocessing.Italsoincludesothersystemssupporting\nPrivacy&OnlineRights\nonlinerightstouchingoncensorshipandcircumvention,covertness,electronicelections,and\nprivacyinpaymentandidentitysystems.\nAttacksandDefences\nMalware&Attack Technicaldetailsofexploitsanddistributedmalicioussystems,togetherwithassociated\nTechnologies discoveryandanalysisapproaches.\nThemotivations,behaviours,&methodsusedbyattackers,includingmalwaresupplychains,\nAdversarialBehaviours\nattackvectors,andmoneytransfers.\nSecurityOperations& Theconfiguration,operationandmaintenanceofsecuresystemsincludingthedetectionof\nIncidentManagement andresponsetosecurityincidentsandthecollectionanduseofthreatintelligence.\nThecollection,analysis,&reportingofdigitalevidenceinsupportofincidentsorcriminal\nForensics\nevents.\nSystemsSecurity\nCoreprimitivesofcryptographyaspresentlypractised&emergingalgorithms,techniquesfor\nCryptography\nanalysisofthese,andtheprotocolsthatusethem.\nOperatingsystemsprotectionmechanisms,implementingsecureabstractionofhardware,\nOperatingSystems&\nandsharingofresources,includingisolationinmultiusersystems,securevirtualisation,and\nVirtualisationSecurity\nsecurityindatabasesystems.\nSecuritymechanismsrelatingtolarger-scalecoordinateddistributedsystems,including\nDistributedSystems\naspectsofsecureconsensus,time,eventsystems,peer-to-peersystems,clouds,multitenant\nSecurity\ndatacentres,&distributedledgers.\nAuthentication,\nAllaspectsofidentitymanagementandauthenticationtechnologies,andarchitecturesand\nAuthorisation,&\ntoolstosupportauthorisationandaccountabilityinbothisolatedanddistributedsystems.\nAccountability\nSoftwareandPlatformSecurity\nKnowncategoriesofprogrammingerrorsresultinginsecuritybugs,&techniquesforavoiding\nSoftwareSecurity theseerrors\u2014boththroughcodingpracticeandimprovedlanguagedesign\u2014andtools,\ntechniques,andmethodsfordetectionofsucherrorsinexistingsystems.\nIssuesrelatedtowebapplicationsandservicesdistributedacrossdevicesandframeworks,\nWeb&MobileSecurity\nincludingthediverseprogrammingparadigmsandprotectionmodels.\nSecureSoftware Theapplicationofsecuritysoftwareengineeringtechniquesinthewholesystems\nLifecycle developmentlifecycleresultinginsoftwarethatissecurebydefault.\nInfrastructureSecurity\nSecurityaspectsofnetworking&telecommunicationprotocols,includingthesecurityof\nNetworkSecurity routing,networksecurityelements,andspecificcryptographicprotocolsusedfornetwork\nsecurity.\nSecurityinthedesign,implementation,&deploymentofgeneral-purposeandspecialist\nHardwareSecurity\nhardware,includingtrustedcomputingtechnologiesandsourcesofrandomness.\nSecuritychallengesincyber-physicalsystems,suchastheInternetofThings&industrial\nCyber-PhysicalSystems\ncontrolsystems,attackermodels,safe-securedesigns,andsecurityoflarge-scale\nSecurity\ninfrastructures.\nPhysicalLayer&\nSecurityconcernsandlimitationsofthephysicallayerincludingaspectsofradiofrequency\nTelecommunications\nencodingsandtransmissiontechniques,unintendedradiation,andinterference.\nSecurity\nFigure1.2:ShortdescriptionsofCyBOKKnowledgeAreas TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n1.3 DEPLOYING CYBOK KNOWLEDGE TO ADDRESS\nSECURITY ISSUES\n1.3.1 Means and objectives of cyber security\nImplicitinthedefinitionsaboveisthatcybersecurityentailsprotectionagainstanadversary\nor, possibly, against some other physical or random process. The latter implies some over-\nlapbetweenthenotionsofsafetyandsecurity,althoughitisarguablypossibletohaveeither\nwithouttheother.Withinthesecuritydomain,ifourmodellingaccountsformalice,itwillnec-\nessarily encompass accidents and random processes. Therefore, core to any consideration\nof security is the modelling of these adversaries: their motives for attack, the threats they\nposeandthecapabilitiestheymayutilise.\nIn considering those threats, cyber security is often expressed in terms of instituting a num-\nber of controls affecting people, process, and technology. Some of these will focus on the\nprevention of bad outcomes, whereas others are better approached through detection and\nreaction.SelectionofthosecontrolsisgenerallyapproachedthroughaprocessofRiskMan-\nagement(seebelow,andtheRiskManagement&GovernanceKnowledgeArea(Chapter2))\n\u2014althoughincreasingemphasisisplacedonHumanFactors(seetheHumanFactorsKnowl-\nedgeArea(Chapter4)),notingtheneedtoleveragehumansasalynchpinforimprovingcyber\nsecurity cultures, as well as supporting them to protect their privacy online (see the Privacy\n&OnlineRightsKnowledgeArea(Chapter5)).\nEqually,securityrequiresananalysisofvulnerabilitieswithinthesystemunderconsideration:\na (hypothetical) system without vulnerabilities would be impervious to all threats; a highly\nvulnerablesystemplacedintotallybenigncircumstances(nothreats)wouldhavenosecurity\nincidents,either.\nTheintendeduseofsecuritycontrolsgivesrisetoitsownquestionsaboutwhethertheyare\ndeployed appropriately, and whether they are effective: these belong to the domain of secu-\nrity assurance, which has processes and controls of its own. These will involve residual risk\nanalysis (see below, and the Risk Management & Governance Knowledge Area (Chapter 2))\nwhichincludesanattempttomeasureandquantifythepresenceofvulnerabilities.\n1.3.2 Failures and Incidents\nWhenadversariesachievetheirgoal(whollyorpartially)\u2014whenattackssucceed\u2014thecollec-\ntionofsecuritycontrolsmaybesaidtohavefailed.Alternatively,wemaysaythatinsufficient\nor ineffective controls were in place. Operationally speaking, one or more failures may give\nrisetoasecurityincident.Typicallysuchincidentsmaybedescribedintermsoftheharmto\nwhich they give rise: according to our definition of cyber security, these typically amount to\nharmfromtheftordamageofinformation,devices,services,ornetworks.Thecyber-physical\ndomain (see the Cyber-Physical Systems Security Knowledge Area (Chapter 19)) gives rise\ntomanyadditionalpotentialharms\u2014harmstohumansmaycomefromeitherinformation,or\nfromunintendedphysicalaction,orfromboth.\nA significant sub-discipline of operational security considers detection of security failures,\nandreactionstothem(remediationwherepossible).TheSecurityOperations&IncidentMan-\nagementKnowledgeArea(Chapter8)addressesthecontext;theMalware&AttackTechnol-\nogy Knowledge Area (Chapter 6) deals with analysis of attack vectors while the Forensics\nKAIntroduction |October2019 Page6 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nKnowledge Area (Chapter 9) considers the technical details and processes for post-attack\nanalysisinarobustandreliablemanner.\nA recurrent theme in security analysis is that it is not sufficient to define good security con-\ntrols solely within a particular abstraction or frame of reference: it is necessary also to con-\nsiderwhatmayhappenifanadversarychoosestoignorethatabstractionorframe.\nThisarises,forexample,incommunicationsidechannels,whereanadversarymayinfermuch\nfrom capturing radio frequency emissions from a cable, say, without needing to tap that ca-\nble physically. Similar eavesdropping effects have been observed against cryptography im-\nplemented on smartcards: simple analysis of the powerconsumption of the processor as it\naddresses each bit in turn can be sufficient to disclose the cryptographic key (see Cryptog-\nraphy,HardwareSecurityandSoftwareSecurityKnowledgeAreas).\nTheseproblemsoccurateverylevelinthesystemdesign.Insoftware,theSQLinjectionattack\narises(seeSoftwareSecurityandWeb&MobileSecurityKnowledgeAreas)becauseastring\nofcharactersintendedtobeinterpretedasadatabaseentryisforcedtobecomeadatabase\ncommand. Files holding secrets written by one application may give up those secrets when\nreadbyanother,orbyageneral-purposedebuggerordumpprogram.\nMathematical theories of refinement (and software development contracts) explore the re-\nlationship of an \u2018abstract\u2019 expression of an algorithm and a more \u2018concrete\u2019 version which\nis implemented: but security properties proven of the one may not be true of the other (for\nexample,reducinguncertaintycanincreaseinformationcontentandleadtotheleakofinfor-\nmation such as a cryptographic key), so great care must be taken in the construction of the\ntheories.\u2018Black-boxtesting\u2019reliesonthesamenotionand,sinceitcannotpossiblytestevery\ninput, may easily miss the particular combination of circumstances which \u2014 by accident or\ndesign\u2014destroysthesecurityoftheprogram.\nOperationalsecurityofasystemmaybepredicatedupontheoperatorsfollowingaparticular\nprocedure or avoiding particular dangerous circumstances: there is an assumption that if\npeoplearetoldinaprofessionalcontext(not)todosomething,thentheywill(not)doit.This\nisdemonstrablyfalse(seetheHumanFactorsKnowledgeArea(Chapter4)).\nThese \u2014 and an endless array of other \u2014 security problems arise because it is necessary to\nthink(anddesignsystems)usingabstractions.Notonlycannoindividualcomprehendevery\ndetailoftheoperationofanetworkedcomputingsystem(fromthedevicephysicsupwards),\neven if they had the requisite knowledge they must work in abstractions in order to make\nprogress and avoid being overwhelmed with detail. But, for the majority of security controls,\nthe abstraction is no more than a thinking tool: and so the adversary is able to disregard it\nentirely.\nSince abstractions are usually built in layers (and computing systems are usually explicitly\ndesigned in that way), this is sometimes known as the \u2018layer below\u2019 problem [7] because\nthe adversary often attacks the layer below the one in which the abstraction defining the\ncontrol sits (see, for example, the threats and attacks discussed in the Operating Systems\n& Virtualisation Knowledge Area (Chapter 11) and the Hardware Security Knowledge Area\n(Chapter18)).\nKAIntroduction |October2019 Page7 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n1.3.3 Risk\nThere is no limit in principle to the amount of effort or money that might be expended on\nsecurity controls. In order to balance these with the available resources and the harms and\nopportunitiesthatmightarisefromemergingthreatstosecurity,acommonover-archingap-\nproach to security analysis is a process of Risk Assessment \u2014 and selection of controls, a\nprocessofRiskManagement.TheseareexploredindepthintheRiskManagement&Gover-\nnanceKnowledgeArea(Chapter2).\nAs with any process of risk management, a key calculation relates to expected impact, be-\ning calculated from some estimate of likelihood of events that may lead to impact, and an\nestimateoftheimpactarisingfromthoseevents.Thelikelihoodhastwoelements:thepres-\nenceofvulnerabilities(knownorunknown\u2014thelatternotalwaysbeingcapableofbeingmiti-\ngated),andthenatureofthethreat.Themanagementresponsetotheriskassessmentmay\ntakemanyforms,includingadditionalcontrolstoreducetheimpactorlikelihoodofathreat,\naccepting the risk, or transferring\/sharing it with a third party (e.g., insurance), or in some\ncasesdecidingnottoproceedbecausealloftheseoutcomesareunacceptable.\nSecurity management encompasses all the management and security actions necessary\nto maintain the security of a system during its lifetime. Important in this context, but out-\nside of the scope of the CyBOK, are quality management practices. Such practices are long-\nestablishedinindustry,essentiallyrequiringthatallworkfollowsdocumentedprocesses,and\nthattheprocessesprovidemetricswhichare,inturn,reviewedandusedtocorrectprocesses\nthatarenotfitforpurpose(\u2018nonconformities\u2019).\nThe analogy between quality management and security is not perfect because the threat\nenvironment is not static; however, the trend is for security management standards such\nas ISO\/IEC 27001 to embody standard quality management processes which are then spe-\ncialisedforsecurity.Theprimaryspecialisationistheperiodicuseofriskmanagement(see\ntheRiskManagement&GovernanceKnowledgeArea(Chapter2)),whichmustalsotakeac-\ncount of the changing threat environment. It is necessary to supplement periodic risk man-\nagementwithcontinuousmeasuresoftheeffectivenessofthesecurityprocesses.Forexam-\nple, system patching and maintenance can be continuously reviewed via vulnerability scan-\nning, logs relating to failed access attempts, user lock-outs or password resets can provide\nindicatorsoftheusabilityofsecurityfeatures.\nThefunctionswithinasecuritymanagementsystemcanbegroupedintoPhysical,Personnel,\nInformation Systems and Incident Management and are a mixture of standard IT system\nmanagementfunctionsandthosethatarespecifictocybersecurity.\nPhysical security includes physical protection of the system, including access control, as-\nsetmanagementandthehandlingandprotectionofdatastoragemedia.Theseaspectsare\noutsidethescopeoftheCyBOK.\nPersonnelsecurityisconcernedwithawiderangeofsecurityusabilityandbehaviourshaping,\nincludingeducationandtraining(seetheHumanFactorsKnowledgeArea(Chapter4)).Italso\nincludesformalhuman-resourcemanagementelementssuchastheselectionandvettingof\nstaff, terms and conditions of acceptable usage for IT systems (see the Law & Regulation\nKnowledgeArea(Chapter3))anddisciplinarysanctionsforsecuritybreaches.\nInformationsystemmanagementincludesaccessmanagement(seetheAuthentication,Au-\nthorisation & Accountability (AAA) Knowledge Area (Chapter 13)) and system logging (see\ntheSecurityOperations&IncidentManagementKnowledgeArea(Chapter8)).Theauditfunc-\nKAIntroduction |October2019 Page8 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntionisdividedintosecuritymonitoring(seetheSecurityOperations&IncidentManagement\nKnowledge Area (Chapter 8)) and other IT functions, such as volumetric review for system\nprovisioning. Management of the information system also involves standard IT functions\nsuchasbackupandrecovery,andthemanagementofsupplierrelationships.\nIncidentmanagementfunctions(seetheSecurityOperations&IncidentManagementKnowl-\nedgeArea(Chapter8))arespecifictocybersecurityandincludesecuritymonitoring,incident\ndetectionandresponse.\n1.4 PRINCIPLES\nSoundthinkingandgoodpracticeinsecurityhasbeencodifiedbyanumberofauthors.The\nprinciplestheydescribetouchmanydifferentKAs,andtakentogetherhelptodevelopaholis-\nticapproachtothedesign,development,anddeploymentofsecuresystems.\n1.4.1 Saltzer and Schroeder Principles\nTheearliestcollecteddesignprinciplesforengineeringsecuritycontrolswereenumeratedby\nSaltzerandSchroederin1975[8].Thesewereproposedinthecontextofengineeringsecure\nmulti-useroperatingsystemssupportingconfidentialitypropertiesforuseingovernmentand\nmilitary organisations. This motivation does bias them in some ways, however they have\nalso stood the test of time in being applicable to the design of security controls much more\nbroadly.\nTheeightprinciplestheyenumerateareasfollows:\n\u2022 Economy of mechanism. The design of security controls should remain as simple as\npossible,toensurehighassurance.Simplerdesignsareeasiertoreasonaboutformally\nor informally, to argue correctness. Further, simpler designs have simpler implementa-\ntionsthatareeasiertomanuallyauditorverifyforhighassurance.Thisprincipleunder-\nliesthenotionofTrustedComputingBase(TCB)\u2014namelythecollectionofallsoftware\nand hardware components on which a security mechanism or policy relies. It implies\nthat the TCB of a system should remain small to ensure that it maintain the security\npropertiesexpected.\n\u2022 Fail-safedefaults.Securitycontrolsneedtodefineandenableoperationsthatcanposi-\ntivelybeidentifiedasbeinginaccordancewithasecuritypolicy,andrejectallothers.In\nparticular, Saltzer and Schroeder warn against mechanisms that determine access by\nattemptingtoidentifyandrejectmaliciousbehaviour.Maliciousbehaviour,asitisunder\nthecontroloftheadversaryandwillthereforeadapt,isdifficulttoenumerateandiden-\ntify exhaustively. As a result basing controls on exclusion of detected violation, rather\nthaninclusionofknowngoodbehaviour,iserrorprone.Itisnotablethatsomemodern\nsecuritycontrolsviolatethisprincipleincludingsignaturebasedanti-virussoftwareand\nintrusiondetection.\n\u2022 Complete mediation. All operations on all objects in a system should be checked to\nensurethattheyareinaccordancewiththesecuritypolicy.Suchcheckswouldusually\ninvolveensuringthatthesubjectthatinitiatedtheoperationisauthorisedtoperformit,\npresumingarobustmechanismforauthentication.However,modernsecuritycontrols\nmay not base checks on the identity of such a subject but other considerations, such\nasholdinga\u2018capability\u2019.\nKAIntroduction |October2019 Page9 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n\u2022 Opendesign.Thesecurityofthecontrolmustnotrelyonthesecrecyofhowitoperates,\nbutonlyonwellspecifiedsecretsorpasswords.Thisprincipleunderpinscybersecurity\nasafieldofopenstudy:itallowsscholars,engineers,auditors,andregulatorstoexam-\ninehowsecuritycontrolsoperatetoensuretheircorrectness,oridentifyflaws,without\nundermining their security. The opposite approach, often called \u2018security by obscurity\u2019,\nis fragile as it restricts who may audit a security control, and is ineffective against in-\nsiderthreatsorcontrolsthatcanbereverseengineered.\n\u2022 Separation of privilege. Security controls that rely on multiple subjects to authorise an\noperation, provide higher assurance than those relying on a single subject. This princi-\nple is embodied in traditional banking systems, and carries forward to cyber security\ncontrols.However,whileitisusuallythecasethatincreasingthenumberofauthorities\ninvolvedinauthorisinganoperationincreasesassurancearoundintegrityproperties,it\nusuallyalsodecreasesassurancearoundavailabilityproperties.Theprinciplealsohas\nlimits, relating to over diluting responsibility leading to a \u2018tragedy of the security com-\nmons\u2019 in which no authority has incentives to invest in security assuming the others\nwill.\n\u2022 Least privilege. Subjects and the operations they perform in a system should be per-\nformedusingthefewestpossibleprivileges.Forexample,ifanoperationneedstoonly\nread some information, it should not also be granted the privileges to write or delete\nthis information. Granting the minimum set of privileges ensures that, if the subject is\ncorruptorsoftwareincorrect,thedamagetheymaydotothesecuritypropertiesofthe\nsystemisdiminished.Definingsecurityarchitecturesheavilyreliesonthisprinciple,and\nconsists of separating large systems into components, each with the least privileges\npossible\u2014toensurethatpartialcompromisescannotaffect,orhaveaminimaleffect\non,theoverallsecuritypropertiesofawholesystem.\n\u2022 Least common mechanism. It is preferable to minimise sharing of resources and sys-\ntem mechanisms between different parties. This principle is heavily influenced by the\ncontext of engineering secure multi-user systems. In such systems common mecha-\nnisms(suchassharedmemory,disk,CPU,etc.)arevectorsforpotentialleaksofconfi-\ndentialinformationfromoneusertotheother,aswellaspotentialinterferencefromone\nuserintotheoperationsofanother.Itsextremerealisationseessystemsthatmustnot\ninterferewitheachotherbeing\u2018air-gapped\u2019.Yet,theprinciplehaslimitswhenitcomes\nto using shared infrastructures (such as the Internet), or shared computing resources\n(suchasmulti-useroperatingsystems,thatnaturallyshareCPUsandotherresources).\n\u2022 Psychologicalacceptability.Thesecuritycontrolshouldbenaturallyusablesothatusers\n\u2018routinely and automatically\u2019 apply the protection. Saltzer and Schroeder, specifically\nstate that \u2018to the extent that the user\u2019s mental image of his protection goals matches\nthe mechanisms he must use, mistakes will be minimised\u2019. This principle is the basis\nfortheHumanFactorsKnowledgeArea(Chapter4).\nSaltzerandSchroederalsoprovidetwofurtherprinciples,butwarnthatthoseareonlyimper-\nfectlyapplicabletocybersecuritycontrols:\n\u2022 Work factor. Good security controls require more resources to circumvent than those\navailable to the adversary. In some cases, such as the cost of brute forcing a key, the\nwork factor may be computed and designers can be assured that adversaries cannot\nbe sufficiently endowed to try them all. For other controls, however, this work factor is\nharder to compute accurately. For example, it is hard to estimate the cost of a corrupt\nKAIntroduction |October2019 Page10 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ninsider,orthecostoffindingabuginsoftware.\n\u2022 Compromise recording. It is sometimes suggested that reliable records or logs, that\nallowdetectionofacompromise,maybeusedinsteadofcontrolsthatpreventacom-\npromise. Most systems do log security events, and security operations heavily rely on\nsuch reliable logs to detect intrusions. The relative merits \u2014 and costs \u2014 of the two\napproachesarehighlycontext-dependent.\nThose principles in turn draw on much older precedents such as Kerckhoff\u2019s principles re-\nlatingtocryptographicsystems[9].Kerchoffhighlightsthatcryptographicsystemsmustbe\npractically secure, without requiring the secrecy of how they operate (open design). He also\nhighlightsthatkeysshouldbeshortandmemorable,theequipmentmustbeeasytouse,and\napplicable to telecommunications \u2014all of which relatetothe psychological acceptability of\nthedesigns.\n1.4.2 NIST Principles\nMore contemporary principles in systems design are enumerated by NIST[10, Appendix F].\nTheyincorporateandextendtheprinciplesfromSaltzerandSchroeder.Theyarecategorised\ninto three broad families relating to: \u2018Security Architecture and Design\u2019 (i.e., organisation,\nstructure and interfaces); \u2018Security Capability and Intrinsic Behaviours\u2019 (i.e., what the protec-\ntions are about); and \u2018Life Cycle Security\u2019 (i.e., those related to process and management).\nAs such those principles specifically refer to security architecture, specific controls, as well\nasengineeringprocessmanagement.\nAnumberoftheNISTprinciplesmapdirectlytothosebySaltzerandSchroeder,suchasLeast\nCommon Mechanism, Efficiently Mediated Access, Minimised Sharing, Minimised Security\nElements, Reduced Complexity, Least Privilege, Secure Defaults and Predicate Permission,\nandAcceptableSecurity.\nNotably, new principles deal with the increased complexity of modern computing systems\nand emphasise clean modular design, i.e. with Clear Abstraction, Modularity and Layering,\nPartially Ordered Dependencies, Secure Evolvability. Other principles recognise that not all\ncomponents in a secure system may operate at the same level of assurance, and call for\nthosetobenefitfromaHierarchicalTruststructure,inwhichthesecurityfailureofsomecom-\nponentsdoesnotendangerallpropertiesinthesystem.TheprincipleofInverseModification\nThresholdstatesthatthosecomponentsthatarethemostcriticaltosecurity,shouldalsobe\nthemostprotectedagainstunauthorisedmodificationortampering.Hierarchicalprotection\nstatesthatleastcriticalsecuritycomponentsneednotbeprotectedfrommorecriticalones.\nTheNISTframeworkalsorecognisesthatmodernsystemsareinterconnected,andprovides\nprinciplesofhowtosecurethem.TheseshouldbenetworkedusingTrustedCommunication\nChannels. They should enjoy Secure Distributed Composition, meaning that if two systems\nthat enforce the same policy are composed, their composition should also at least enforce\nthe same policy. Finally, the principle of Self-Reliant Trustworthiness states that a secure\nsystemshouldremainsecureevenifdisconnectedfromotherremotecomponents.\nThe NIST principles expand on what types of security mechanisms are acceptable for real-\nworld systems. In particular the principles of Economic Security, Performance Security, Hu-\nman Factored Security, and Acceptable Security state that security controls should not be\noverly expensive, overly degrade performance, or be unusableor otherwiseunacceptable to\nusers. This is a recognition that security controls support functional properties of systems\nKAIntroduction |October2019 Page11 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nandarenotagoalinthemselves.\nBesides principles, NIST also outlines three key security architecture strategies. The Refer-\nence Monitor Concept is an abstract control that is sufficient to enforce the security proper-\nties of a system. Defence in Depth describes a security architecture composed on multiple\noverlappingcontrols.Isolationisastrategybywhichdifferentcomponentsarephysicallyor\nlogicallyseparatedtominimiseinterferenceorinformationleakage.\nBoth NIST, as well as Saltzer and Schroeder, highlight that principles provide guidance only,\nandneedtobeappliedwithskilltospecificproblemsathandtodesignsecurearchitectures\nand controls. Deviation from a principle does not automatically lead to any problems, but\nsuch deviations need to be identified to ensure that any issues that may arise have been\nmitigatedappropriately.\n1.4.3 Latent Design Conditions\nAsmoreandmorecyber-physicalsystemsareconnectedtoothersystemsandtheInternet,\nthe inherent complexity emerging from such large-scale connectivity and the safety critical\nnature of some of the cyber-physical systems means other principles also become highly\nrelevant. One such principle is that of Latent Design Conditions from research in the safety-\ncriticalsystemsdomainbyJamesReason[11].Inthecontextofcybersecurity,latentdesign\nconditionsarisefrompastdecisionsaboutasystem(orsystems).Theyoftenremainhidden\n(or unconsidered) and only come to the fore when certain events or settings align \u2014 in the\ncase of cyber-physical systems security vulnerabilities being exposed as they become con-\nnected to other systems or the Internet. Reason refers to this as the Swiss Cheese model\nwhere different holes in the slices align. These issues are discussed further in the Human\nFactorsKnowledgeArea(Chapter4).Thekeypointtonoteisthatwecannolongerjustcon-\nsider information loss as a potential consequence of cyber security breaches \u2014 but must\nalso consider safety implications. Furthermore, security by design is not always a possibil-\nity and, as legacy systems become connected to other networked environments, one must\nconsiderthelatent(insecure)designconditionsthatmaybemanifestedandhowtomitigate\ntheirimpact.\n1.4.4 The Precautionary Principle\nAstheparticipatorydataeconomyleadstoarangeofinnovativeproductsandservices,there\nare also growing concerns about privacy and potential misuse of data as has been high-\nlighted by recent cases of interference in democratic processes. As such the Precautionary\nPrinciple\u2014reflectingonthepotentialharmfuleffectofdesignchoicesbeforetechnological\ninnovations are put into large-scale deployment \u2014 also becomes relevant. Designers must\nconsider the security and privacy implications of their choices from conception, through to\nmodelling,implementation,maintenance,evolutionandalsodecommissioningoflarge-scale\nconnected systems and infrastructures on which society increasingly relies. Function creep\nas the system evolves over its lifetime and its impact on the society-at-large must also be\nconsidered[12].\nKAIntroduction |October2019 Page12 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n1.5 CROSSCUTTING THEMES\nA number of topics and themes recur across various KAs \u2014 implicitly or explicitly \u2014 and\nprovide a context or unification of ideas across those KAs which cuts across the structure\nchosenfortheCyBOK.InadifferentdecompositionoftheCyBOKtheymighthavebeenKAs\nintheirownright.Theseareanimportantpartofthebodyofknowledge,andsowedocument\nherethemostsubstantialofthem.\n1.5.1 Security Economics\nEconomics of information security is a synthesis between computer and social science. It\ncombines microeconomic theory, and to a lesser extent game theory, with information se-\ncurity to gain an in-depth understanding of the trade-offs and misaligned incentives in the\ndesignanddeploymentoftechnicalcomputersecuritypoliciesandmechanisms[13,14].For\nexample, Van Eeten and Bauer studied the incentives of legitimate market players \u2014 such\nasInternetServiceProviders(ISPs)andsoftwarevendors\u2014whenconfrontedwithmalware1\nand how the actions driven by such incentives lead to optimal or sub-optimal security for\nthe wider interconnected system. Attacker economics is gaining importance as well (for ex-\nample, [15, 16, 17]). Attacker economics exposes cost-benefit analyses of attackers to ex-\nploit vulnerabilities in the security of the victim target, to subsequently formulate protective\ncountermeasuresforlaw-abidingentities[18].Lastly,thereistheeconomicsofdeviantsecu-\nrity[19].Thissubdisciplineofattackereconomicsfocusesonunderstandinghowcybercrim-\ninals apply, i.e., practice, security to defend their systems and operations against disruption\nfrom law enforcement (e.g., resilience mechanisms built into botnets [20] or anti-forensics\ntechniques[21]).\nSecurity economics is, therefore, of high relevance across the various attacks and counter-\nmeasures discussed within the different KAs within CyBOK. It also plays a key role in under-\nstanding the cost of security to legitimate users of the system and to the cybercriminals \u2014\nthestrengthofsuchasocio-technicalapproachisitsacknowledgementthatsecurityisvery\nmuchahumanproblem,andthecostversusbenefitstrade-offsarekeytoincreasingourun-\nderstandingofthedecisionsofdefendersandattackerstorespectivelysecuretheirsystems\noroptimiseattacks[13].\n1.5.2 Verification and Formal Methods\nHumanfrailtymeansthatflawsfrequentlyariseinsystemdesignorcoding,andtheseoften\ngiverisetosecurityvulnerabilities.TheSoftwareEngineeringdisciplinehasexpendedmuch\neffortinattemptingtominimisetheintroductionofsuchfaults,andtoaidtheirearlydetection\nwhentheyarise.\nAtitsmostbasic,verificationandvalidationofsoftwaresystemsentailstesting\u2014forconsis-\ntency, uniform\/predicted behaviour, and conformance to specifications. By its nature, such\ntestingcanneverbecompleteorexhaustiveonanyrealisticsystem,anditwillnecessarilybe\npoor at finding deliberate flaws or systemic design failures. Approaches to verification and\nmodelling seek to reason about designs and implementations in order to prove mathemati-\ncallythattheyhavetherequiredsecurityproperties.\nFormal methods are approaches to modelling and verification based on the use of formal\n1http:\/\/www.oecd.org\/internet\/ieconomy\/40722462.pdf\nKAIntroduction |October2019 Page13 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nlanguages, logic and mathematics to express system and software specifications, and to\nmodel designs of protocols and systems. For security modelling and verification the adver-\nsary model is also incorporated into the reasoning, so that designs can be verified with re-\nspect to their security requirements in the context of particular classes of threat. Rigorous\nproofs establish that no attack of a particular class is possible, establishing security of the\ndesign against particular kinds of adversary. There are two principal approaches to formal\nmodelling:computational,andsymbolic.\nThecomputationalmodellingapproach[22]isclosetotherealsystem:itisaformalmethod-\nology at a more fundamental mathematical level, where messages are bitstrings, crypto-\ngraphic functions are defined as functions on bitstrings, system participants are generally\ninteractiveTuringmachines,andsecurityparametersgiveasymptoticmetricstothismethod-\nology:thelengthofkeys,complexityofalgorithms,ormeasureofprobabilities,varywiththe\nsecurityparameter.TheadversaryisconsideredtobeaprobabilisticpolynomialtimeTuring\nmachine.Precisedefinitionsofcryptographicfunctionscanbecapturedandanalysedwithin\nthemodel.Securityrequirementsareexpressedaspropertiesonthemodelincludingthead-\nversary, and a security property is generally considered to hold if the probability that it does\nnotholdisnegligibleinthesecurityparameter.\nFormalmodellinghasbeenusedwithinthefieldofsecurityforsomedecades,acrossmany\noftheKAsclassifiedinCyBOKunderSystemsSecurity,InfrastructureSecurity,andSoftware\n&PlatformSecurity.Forexample,intheareaofaccesscontrol,theBell-LaPadulamodel[23]\nprovidesanabstractmodeloftherulesdeterminingwhetherasubjectwithacertainsecurity\nclearance should have a particular kind of access to an object with a given security classi-\nfication. The aim of this model is to prevent data declassification; later work generalized\nthistomethodsforpreventingcertaininformationflows.Otheraccesscontrolmodelshave\nbeenproposedtoachieveotherproperties,suchasintegrity(e.g.,theBibamodel[24],orthe\nClark-Wilson model [25]). Formal methods enable key security properties to be expressed\nand proven in the formal model. Non-interference properties have been formalised [26] in\nterms of executions using transition systems, and system descriptions with transition sys-\ntemsemanticscanbeevaluatedagainstsuchproperties.\nThe symbolic modelling approach is more abstract than the computational approach, and\nhasbeenappliedinavarietyofflavourstothemodellingandanalysisofsecurityprotocols\u2014\nsequencesofinteractionsbetweenagentstoachieveasecuritygoalsuchasauthentication\norkey-exchange.Logic-basedapproachessuchastheBANlogic[27]providealanguagefor\nexpressingrequirementssuchasconfidentialityandauthentication,factsaroundthesending\nand receiving of protocol messages, and inference rules to enable reasoning about correct-\nness. Language-based approaches such as Applied Pi (e.g., [28, 29, 30]) provide languages\nto describe protocols explicitly, and construct a model of all possible executions including\nadversarialsteps,inordertoreasonabouttheguaranteesthattheprotocolcanprovide.Secu-\nritypropertiesareexpressedintermsofwhatmustbetrueforeveryexecutioninthemodel,\ne.g.,ifBobbelievesattheendofaprotocolrunthathesharesasessionkeywithAlice,then\ntheadversaryisnotalsoinpossessionofthatsessionkey.\nAlthoughthefoundationsofformalapproachesaremature,thechallengehasbeeninmaking\nthem practical. The application of formal approaches requires the careful management of\nintricatedetail,whichinpracticerequirestoolsupporttoenablemechanisedverificationand\ntocheckproofs.Toolsupportforthesymbolicapproachcomeseitherfromgeneralpurpose\nformalmethodstoolsappliedtosecurityproblemssuchasIsabelle\/HOL[31],orFDR[32],or\nfromtoolstailoredspecificallytosecuritysuchasTamarin[33]orProVerif[34].Thesetools\nKAIntroduction |October2019 Page14 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntypically take either a theorem-proving approach or else a model-checking approach where\nthestatespaceisexploredexhaustively.\nVerificationusingthecomputationalmodellingapproacheshavebeenmoremathematicalin\nnature,thoughtoolssuchasCryptoVerif[35]andEasyCrypt[36]havenowbeendevelopedto\nsupportcomputationalproofs.Thesymbolicandcomputationalapproachesmaybeusedto-\ngether:anattackinasymbolicmodelwilltypicallygiverisetoanattackinthecomputational\nmodel,soitisvaluabletocarryoutasymbolicanalysisofasystemfirstinordertocheckfor\nanddesignoutanyidentifiedattacks.Onceasymbolicmodelisverified,thensomeadditional\nwork is needed to establish security in the computational model. This can either be carried\nout directly, or through the application of general techniques such as computational sound-\nness[37]whichgiveconditionsforsymbolicresultstoapplytothecomputationalmodel.\nThese tools are now becoming strong enough to verify deployed protocols such as TLS1.3,\nwhich has been verified using a combination of both approaches [38], but they still require\nexpertguidance.Furtherdevelopmentofthetoolsupportisanactiveresearcharea.\n1.5.3 Security Architecture and Lifecycle\nThe word \u2018architecture\u2019 is used at all levels of detail within a system; here we are concerned\nwith the high-level design of a system from a security perspective, in particular how the pri-\nmarysecuritycontrolsaremotivatedandpositionedwithinthesystem.This,inturn,isbound\nup with an understanding of the systems lifecycle, from conception to decommissioning.\nWithin this, the secure software lifecycle is crucial (the subject of the Secure Software Life-\ncycleKnowledgeArea).\nThefundamentaldesigndecisionishowasystemiscompartmentalised\u2014howusers,data,\nandservicesareorganisedtoensurethatthehighestriskpotentialinteractionsareprotected\nbythesimplestandmostself-containedsecuritymechanisms(seeSection1.4).Forexample,\nanetworkmaybedividedintofront-office\/back-officecompartmentsbyanetworkrouteror\nfirewallthatpermitsnoinwardconnectionsfromthefronttotheback.Suchamechanismis\nsimpler and more robust than one that uses access controls to separate the two functions\ninasharednetwork.\nThe first step is to review the proposed use of the system. The business processes to be\nsupportedshouldidentifytheinteractionsbetweentheusers,dataorservicesinthesystem.\nPotential high risk interactions between users (see the Adversarial Behaviours Knowledge\nArea(Chapter7)anddatashouldthenbeidentifiedwithanoutlineriskassessment(seethe\nRisk Management & Governance Knowledge Area (Chapter 2)) which will also need to take\naccountofexternalrequirementssuchascompliance(seetheLaw&RegulationKnowledge\nArea(Chapter3))andcontractualobligations.Ifuserswithalegitimateneedtoaccessspe-\ncificdataitemsalsoposeahighrisktothoseitems,orifanyuserhasunconstrainedauthority\nto effect an undesired security outcome, the business process itself must be revised. Often\nsuchcasesrequirea\u2018twoperson\u2019rule,forexample,counter-authorisationforpayments.\nThe next step is to group users and data into broad categories using role-access require-\nments, together with formal data classification and user clearance. Such categories are po-\ntential system compartments, for example, Internet users and public data, or engineers and\ndesigndata.Compartmentsshouldensurethatthehighestriskuser-datainteractionscross\ncompartment boundaries, and that common user-data interactions do not. Such compart-\nments are usually enforced with network partitioning controls (see the Network Security\nKnowledge Area (Chapter 17)). Detailed design is then required within compartments, with\nKAIntroduction |October2019 Page15 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nthe first steps being to focus on concrete user roles, data design and access controls (see\ntheAuthentication,Authorisation&Accountability(AAA)KnowledgeArea(Chapter13)),with\nmoredetailedriskassessmentsbeingconductedasthedesignmatures.\nSystemsbenefitfromauniformapproachtosecurityinfrastructure,forexample,themanage-\nmentofkeysandnetworkprotocols(seetheNetworkSecurityKnowledgeArea(Chapter17)),\nresource management and coordination (see the Distributed Systems Security Knowledge\nArea(Chapter12)),roles(seetheAuthentication,Authorisation&Accountability(AAA)Knowl-\nedgeArea(Chapter13)),useraccess(seetheHumanFactorsKnowledgeArea(Chapter4)),\nandintrusiondetection(seetheSecurityOperations&IncidentManagementKnowledgeArea\n(Chapter8)).CyBOKprovidesimportantfoundationknowledgeintheseareas,butneitherthis\nnorriskassessmentaresufficienttomotivatethedetailedimplementationofinfrastructure;\ntheyneedtobecomplementedbycurrentgoodpractice.Insomeindustriesbestpracticeis\nmandated (e.g., the Payment Card Industries). In other cases it may be available from open\nsources(e.g.,OWASP2)orasaresultofcorporatebenchmarking.\nOrthogonaltotheseconcernsareanumberoftopicswhichrelatetothecontextofthesystem\ndevelopment and operation. It is increasingly clear that a code of conduct, as prescribed by\nmanyprofessionalbodies,offersavaluableframeworkforsystemdesignersandthosewho\nexplore weaknesses and vulnerabilities within such systems. Initiatives around responsible\nresearch and innovation are gaining ground. The discovery of vulnerabilities necessitates\na disclosure policy \u2014 and the parameters of responsible disclosure have prompted much\ndebate,togetherwiththeroleofthisinasecurityequitiesprocess.\nThese broad consideration of architecture and lifecycle have been captured within the no-\ntions of \u2018security by design\u2019, and \u2018secure by default\u20193. The former term is often applied to\ndetailedpracticesinsoftwareengineering,suchasinputchecking,toavoidbufferoverflows\nand the like (see the Secure Software Lifecycle Knowledge Area (Chapter 16)). More gener-\nally, consideration of security throughout the lifecycle, including in the default configuration\n\u2018outofthebox\u2019(althoughnotmuchsoftwareisdeliveredinboxesthesedays),demonstrably\nleadstolessinsecurityindeployedsystems.\nWeinvitethereaderstoreadthedetaileddescriptionscapturedinthe19KnowledgeAreas\nthatfollowandutilisethemethods,tools,techniquesandapproachesdiscussedtherein\nwhentacklingthechallengesofcybersecurityintheincreasinglyconnecteddigitalworld\nthatweinhabit.\nACKNOWLEDGEMENTS.\nTheauthorsthankErikvandeSandtforpermissiontousetextfromhisPhDthesis[19]inthe\nsectiononSecurityEconomics.\n2https:\/\/www.owasp.org\n3Arelatednotionis\u2018privacybydesign\u2019(seethePrivacy&OnlineRightsKnowledgeArea(Chapter5)).\nKAIntroduction |October2019 Page16 I Human, Organisational\n& Regulatory Aspects\n17  Chapter 2\nRisk Management and\nGovernance\nPete Burnap Cardiff University\n19 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n2.1 INTRODUCTION\nThis Knowledge Area will explain the fundamental principles of cyber risk assessment and\nmanagementandtheirroleinriskgovernance,expandingonthesetocovertheknowledgere-\nquiredtogainaworkingunderstandingofthetopicanditssub-areas.Webeginbydiscussing\nthe relationship between everyday risk and why this is important in today\u2019s interconnected\ndigital world. We explain why, as humans, we need effective risk assessment and manage-\nment principles to support the capture and communication of factors that may impact our\nvalues.Wethenmoveontodescribedifferentperspectivesoncyberriskassessment\u2013from\nindividual assets, to whole-system goals and objectives. We unpick some of the major risk\nassessmentmethodsandhighlighttheirmainusesandlimitations,aswellasprovidingpoint-\nerstomoredetailedinformation.\nSecuritymetricsareanongoingtopicofdebateintheriskassessmentandmanagementdo-\nmain:whichsystemfeaturestomeasureforrisk,howtomeasurerisk,andwhymeasurerisk\natall?Thesequestionsareframedinthecontextofexistingliteratureonthistopic.Thislinks\ninto risk governance, which explains why effective governance is important to uphold cyber\nsecurityandsomeofthesocialandculturalfactorsthatareessentialtoconsiderwhendevel-\noping governance frameworks. Almost all systems still include a human element of control,\nwhich must be considered from the outset. Finally, even with well defined and executed risk\nassessmentandmanagementplans,itisstillpossiblethatariskwillturnintoreality.Insuch\ncases, incident response is required. We discuss the importance of incident response and\nitslinktotheriskgovernanceprocess.\n2.2 WHAT IS RISK?\n[39,40,41]\nRiskisattheheartofeverydaylife.Fromachildmakingadecisiontojumpoutofatreetoan\ninvestmentdecisionbytheCEOofamulti-billiondollarcompany,weallmakedecisionsthat\npotentially impact us as individuals, and impact our broader social networks and surround-\nings.Definingriskis,therefore,ahighlyphilosophicalandcontentiousmatter.Seminalworks\nby Slovic [40] and Renn [39] on risk perception capture the broad-reaching issues surround-\ning this debate, and provide a working definition that abstracts the question to allow us to\nengagewiththetopicofriskonasocio-technicallevel.Renn\u2019sworkingdefinitionofriskisthe\npossibility that human actions or events lead to consequences that have an impact on what\nhumans value. This fundamentally grounds risk in human value, which applies to both the\nchild and CEO examples. It also applies to cyber security contexts in a world where people\nandtechnologyareintrinsicallylinked.Thefailureofonetosupportthesuccessoftheother\ncanleadtosocial,economicandtechnicaldisaster.Theworkingdefinitionofimpactonval-\nues raises a further question of how to define the value and capture indicators that can be\nused to measure and manage the risk. Renn defines three basic abstract elements required\nforthis:outcomesthathaveanimpactonwhathumansvalue,possibilityofoccurrence(un-\ncertainty),andaformulatocombinebothelements.Theseelementsareatthecoreofmost\nriskassessmentmethods. Such methods aim to provide a structured approach to capturing\nthe entities of value and the likelihood of unwanted outcomes affecting the entities, while\nalsobearinginmindthatevensomethingwithverylowprobabilitymayberealisedandmay\nhave significant impact on a value. We, therefore, use Renn\u2019s working definition of risk for\ndiscussioninthisKAinthecontextofcyberrisk.\nKARiskManagementandGovernance |October2019 Page20 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nAkeychallengewithriskassessmentandmanagementismakingassumptionsexplicitand\nfindingthebalancebetweensubjectiveriskperceptionsandobjectiveevidence.Riskassess-\nmentis,therefore,aprocessofcollatingobservationsandperceptionsoftheworldthatcan\nbejustifiedbylogicalreasoningorcomparisonswithactualoutcomes[41].Riskmanagement,\nontheotherhand,istheprocessofdevelopingandevaluatingoptionstoaddresstherisksin\namannerthatisagreeabletopeoplewhosevaluesmaybeimpacted,bearinginmindagree-\nment on how to address risk may involve a spectrum of (in)tolerance \u2013 from acceptance to\nrejection. Risk Governance is an overarching set of ongoing processes and principles that\naims to ensure an awareness and education of the risks faced when certain actions occur,\nandtoinstilasenseofresponsibilityandaccountabilitytoallinvolvedinmanagingit.Itunder-\npins collective decision-making and encompasses both risk assessment and management,\nincluding consideration of the legal, social, organisational and economic contexts in which\nrisk is evaluated [41]. This Knowledge Area explores all these topics and provides insights\ninto risk assessment, management and governance from a cyber security science perspec-\ntivethatisaccessibletoindividuals,SMEsandlargeorganisationsalike.\n2.3 WHY IS RISK ASSESSMENT AND MANAGEMENT\nIMPORTANT?\n[40,41,42,43]\nRisk assessment involves three core components [41]: (i) identification and, if possible, esti-\nmationofhazard;(ii)assessmentofexposureand\/orvulnerability;and(iii)estimationofrisk,\ncombining the likelihood and severity. Identification relates to the establishment of events\nand subsequent outcomes, while estimation is related to the relative strength of the out-\ncome. Exposure relates to the aspects of a system open to threat actors (e.g., people, de-\nvices, databases), while vulnerability relates to the attributes of these aspects that could be\ntargeted (e.g., susceptibility to deception, hardware flaws, software exploits). Risk estima-\ntioncanbequantitative(e.g.,probabilistic)orqualitative(e.g.,scenario-based)andcaptures\nthe expected impact of outcomes. The fundamental concept of risk assessment is to use\nanalyticandstructuredprocessestocaptureinformation,perceptionsandevidencerelating\nwhat is at stake, the potential for desirable and undesirable events, and a measure of the\nlikelyoutcomesandimpact.Withoutanyofthisinformationwehavenobasisfromwhichto\nunderstand our exposure to threats nor devise a plan to manage them. An often overlooked\npartoftheriskassessmentprocessisconcernassessment.Thisstemsfrompublicriskper-\nceptionliteraturebutisalsoimportantforcybersecurityriskassessmentaswewilldiscuss\nlaterinthedocument.Inadditiontothemoreevidential,scientificaspectsofrisk,concernas-\nsessment includes wider stakeholder perceptions of: hazards, repercussions of risk effects,\nfear and dread, personal or institutional control over risk management and trust in the risk\nmanagers.\nTheriskmanagementprocessinvolvesreviewingtheinformationcollectedaspartoftherisk\n(and concern) assessments. This information forms the basis of decisions leading to three\noutcomesforeachperceivedrisk[41]:\n\u2022 Intolerable: the aspect of the system at risk needs to be abandoned or replaced, or if\nnotpossible,vulnerabilitiesneedtobereducedandexposurelimited.\n\u2022 Tolerable:riskshavebeenreducedwithreasonableandappropriatemethodstoalevel\naslowasreasonablypossible(ALARP)[44]oraslowasreasonablyallowable(ALARA).\nKARiskManagementandGovernance |October2019 Page21 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nA range of choices may include mitigating, sharing, or transferring risk [45], selection\nof which will depend on the risk managers\u2019 (and more general company) appetite for\ntakingrisks.\n\u2022 Acceptable: risk reduction is not necessary and can proceed without intervention. Fur-\nthermore, risk can also be used to pursue opportunities (also known as \u2018upside risk\u2019),\nthustheoutcomemaybetoacceptandembracetheriskratherthanreduceit.Hillson\ndiscussesthisperspectiveinfurtherdetail[42].\nDecidingwhichtoselectwillbedependentonanumberoffactors,forexample(assuggested\ninISO31000:2018[46]),tangibleandintangibleuncertainty,consequencesofriskrealisation\n(goodorbad),appetiteforrisk,organisationalcapacitytohandlerisketc.\nBeyond this decision framework Renn defines four types of risk that require different risk\nmanagementplans[41].Theseinclude:\n\u2022 Routine risks: these follow a fairly normal decision-making process for management.\nStatisticsandrelevantdataareprovided,desirableoutcomesandlimitsofacceptability\nare defined, and risk reduction measures are implemented and enforced. Renn gives\nexamplesofcaraccidentsandsafetydevices.\n\u2022 Complexrisks:whererisksarelessclearcut,theremaybeaneedtoincludeabroader\nsetofevidenceandconsideracomparativeapproachsuchascost-benefitanalysisor\ncost-effectiveness.Scientificdissentsuchasdrugtreatmenteffectsorclimatechange\nareexamplesofthis.\n\u2022 Uncertainrisks:wherealackofpredictabilityexists,factorssuchasreversibility,persis-\ntenceandubiquitybecomeusefulconsiderations.Aprecautionaryapproachshouldbe\ntaken with a continual and managed approach to system development whereby nega-\ntivesideeffectscanbecontainedandrolled-back.Resiliencetouncertainoutcomesis\nkeyhere.\n\u2022 Ambiguous risks: where broader stakeholders, such as operational staff or civil soci-\nety, interpret risk differently (e.g., different viewpoints exist or lack of agreement on\nmanagementcontrols),riskmanagementneedstoaddressthecausesforthediffering\nviews.Rennusestheexampleofgeneticallymodifiedfoodswherewell-beingconcerns\nconflictwithsustainabilityoptions.Inthisinstance,riskmanagementmustenablepar-\nticipatory decision-making, with discursive measures aiming to reduce the ambiguity\ntoanumberofmanageableoptionsthatcanbefurtherassessedandevaluated.\nManagement options, therefore, include a risk-based management approach (risk-benefit\nanalysis or comparative options), a resilience-based approach (where it is accepted that\nrisk will likely remain but needs to be contained, e.g. using ALARA\/ALARP principles), or a\ndiscourse-basedapproach(includingriskcommunicationandconflictresolutiontodealwith\nambiguities). Without effective consideration of the acceptability of risk and an appropriate\nrisk reduction plan, it is likely that the response to adverse outcomes will be disorganised,\nineffective,andlikelyleadtofurtherspreadingofundesirableoutcomes.\nEffectiveriskmanagementthroughstructuredassessmentmethodsisparticularlyimportant\nbecause, although our working definition of risk is grounded in consequences of interest to\npeople,we(asasociety)arenotverygoodatassessingthisrisk.Slovic\u2019sarticleonriskper-\nception highlights that perceptions related to dread risk (e.g., nuclear accidents) are ranked\nhighestriskbylaypeople,butmuchlowerbydomainexpertswhounderstandtheevidencere-\nlatingtosafetylimitationsandcontrolsforsuchsystems.Expertriskrankingtendstofollow\nKARiskManagementandGovernance |October2019 Page22 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nexpectedorrecordedundesirableoutcomessuchasdeaths,whilelaypeopleareinfluenced\nmorebytheirintuitivejudgment(anuclearaccidentcouldimpactmywholefamily).Thereis,\ntherefore, a mismatch between perceived vs. actual risk. As people we tend to exaggerate\ndread-related but rare risks (e.g., nuclear incidents and terrorist attacks) but downplay com-\nmonones(e.g.,streetcrimeandaccidentsinthehome)\u2013eventhoughthelatterkillfarmore\npeople.\nThis is also why concern assessment is important in the risk management process along-\nside risk assessment. Schneier\u2019s book Beyond Fear[43] notes that we have a natural sense\nofsafetyinourownenvironmentandaheightenedsenseofriskoutsideofthis.Forinstance,\nwefeelsafewalkingdownastreetnexttoourhousebutonedgewhenarrivinginanewcity.\nAsasociety,werarelystudystatisticswhenmakingdecisions;theyarebasedonperceptions\nof exposure to threat, our perceived control over threats, and their possible impact. Risk as-\nsessmenthelpsuscapturequantitativeandqualitativeaspectsoftheworldthatenableusto\nputarealisticestimateofhowcertainwecanbethatadverseeventswillcometopass,and\nhowtheywillimpactonwhatwevaluemost.Thisappliestouspersonallyasindividuals,and\nasgroupsofpeoplewithacommonaim\u2013savingtheplanet,runningabusiness,oreducating\nchildren.Weneedtocaptureourgoals,understandwhatcouldleadtothefailuretoachieve\nthem, and put processes in place to align realistic measures to reduce harms inflicted upon\nourobjectives.\nWhen done well, risk assessment and management enables decision makers, who are re-\nsponsible, to ensure that the system operates to achieve the desired goals as defined by its\nstakeholders.Itcanalsoensurethesystemisnotmanipulated(intentionallyorotherwise)to\nproduceundesiredoutcomes,aswellashavingprocessesinplacethatminimisetheimpact\nshould undesirable outcomes occur. Risk assessment and management is also about pre-\nsenting information in a transparent, understandable and easily interpreted way to different\naudiences,sothataccountablestakeholdersareawareoftherisks,howtheyarebeingman-\naged,whoisresponsibleformanagingthem,andareinagreementonwhatistheacceptable\nlimitofriskexposure.Thisisabsolutelycrucialtosuccessfullymanagingriskbecause,ifthe\nrisks are not presented clearly to decision makers (be they technical, social, economic or\notherwise),theimpactofnotmanagingthemwillbeoverlooked,andthesystemwillremain\nexposed. Likewise, if the purpose of risk management is not made clear to the people at\ntheoperationallevel,alongsidetheirownresponsibilitiesandaccountabilityforriskimpacts,\nthey will not buy in to the risk management plan and the system will remain exposed. More\nbroadly, if wider stakeholder concerns (e.g., civil society) are not heard or there is lack of\nconfidenceintheriskmanagementplan,therecouldbewidespreadrejectionoftheplanned\nsystembeingproposed.\nAs important as it is to convey risks clearly to stakeholders, it is equally as important to\nstress that risks cannot always be removed. There is likely to be some residual risk to the\nthings we value, so discussions must be held between decision makers and those who are\ninvolved with the operations of a system. Ultimately, decision makers, who will be held to\naccountforfailuretomanagerisk,willdeterminethelevelofrisktolerance\u2013whetherriskis\naccepted,avoided,mitigated,shared,ortransferred.However,itispossiblethatwiderstake-\nholders,suchasthoseinvolvedwithsystemoperations,mayhavedifferingviewsonhowto\nmanagerisk,giventheyarelikelytohavedifferentvaluestheyaretryingtoprotect.Forsome,\nsavingmoneywillbekey.Forothers,reputationisthemainfocus.Forpeopleworkingwithin\nthe system it may be speed of process or ease of carrying out daily tasks. The purpose of\nriskassessmentandmanagementistocommunicatethesevaluesandensuredecisionsare\ntakentominimisetheriskstoanagreedsetofvaluesbymanagingthemappropriately,while\nKARiskManagementandGovernance |October2019 Page23 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nmaximising \u2018buy in\u2019 to the risk management process. In the broader health and safety risk\ncontext,thisconceptrelatestothenotionofALARP(aslowasreasonablypracticable)[44]\u2013\nbeingabletodemonstratethatsignificanteffortsandcomputationhavebeenmadetocalcu-\nlatethebalancebetweenriskacceptanceandmitigation,inthefavourofsecurityandsafety.\nAgain it is important to highlight here that concern assessment is an important part of risk\nassessmenttoensuretheriskassessmentpolicy(theagreedapproachtoriskassessment)\nisinformedbythoseresponsiblefor,andimpactedbyrisk,andthosewhoarerequiredtoact\ninawaythatupholdsthemanagementplanday-to-day.Crucially,itmustberecognisedthat\nthe impact of single events can often extend beyond direct harms and spread far wider into\nsupplychains.AsSlovicputsit,theresultsofaneventactlikeripplesfromastonedropped\ninto a pond, first directly within the company or system in which it occurred, and then into\nsub-systemsandinterdependentcompaniesandcomponents[40].\nOne of the major drivers for risk assessment and management is to demonstrate compli-\nance.Thiscanbearesultoftheneedtohaveauditedcomplianceapprovalfrominternational\nstandards bodies in order to gain commercial contracts; to comply with legal or regulatory\ndemands(e.g.,inEuropetheNetworkandInformationSystems(NIS)directive[47]mandates\nthat operators of essential services (such as critical national infrastructure) follow a set of\n14 goal-oriented principles [48]); or to improve the marketability of a company through per-\nceived improvements in public trust if certification is obtained. This can sometimes lead to\n\u2018tick-box\u2019 risk assessment whereby the outcome is less focused on managing the risk, and\nmore about achieving compliance. This can result in a false sense of security and leave the\norganisationexposedtorisks.ThisbringusbacktoRenn\u2019sworkingdefinitionofrisk.These\nexamples focus on managing risk of failing compliance with various policy positions, and\nas a result, they may neglect the broader focus on impact on values held by wider organisa-\ntional,societaloreconomicstakeholders.Thecontextandscopeofriskmanagementmust\ntakethisbroaderoutcomes-viewinordertobeausefulandvaluableexercisethatimproves\npreparednessandresiliencetoadverseoutcomes.\nBasedonthesefactors,riskassessmentandmanagementismostcertainlyaprocessnota\nproduct. It is something that, when done well, has the potential to significantly improve the\nresilience of a system. When done badly (or not at all) it can lead to confusion, reputational\ndamage, and serious impact on system functionality. It is a process that is sometimes per-\nceivedtobeunimportantbeforeoneneedsit,butcriticalforbusinesscontinuityinatimeof\ncrisis.Throughouttheprocessofriskassessmentwemustremainawarethatriskperception\nvaries significantly based on a variety of factors, and that despite objective evidence, it will\nnotchange.Touseanexamplefrom[40],providingevidencethattheannualriskfromliving\nnext to a nuclear power plant is equivalent to the risk of riding an extra 3 miles in an auto-\nmobile,doesnotnecessarilyreducetheperceptionofriskgiventhedifferencessurrounding\nthe general perception of the different scenarios. Intuitively, communication and a respect\nfor qualitative and quantitative measures of risk assessment are core to its practice. Both\nmeasures exhibit ambiguity (e.g., [49]) and often we lack quality data on risk so evidence\nonly goes so far. There will always be a need for subjective human judgment to determine\nrelevanceandmanagementplans[50],whichinitselfcomeswithitsownlimitationssuchas\nlackofexpertknowledgeandcognitivebias[51].\nKARiskManagementandGovernance |October2019 Page24 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n2.4 WHAT IS CYBER RISK ASSESSMENT AND\nMANAGEMENT?\n[52]\nThe introductory sections have made the case for risk assessment and management more\ngenerally, but the main focus of this document is to frame risk assessment and manage-\nment in a cyber security context. Digital technology is becoming evermore pervasive and\nunderpins almost every facet of our daily lives. With the growth of the Internet of Things,\nconnecteddevicesareexpectedtoreachlevelsofmorethan50billionby2022[53].Further,\nhumandecision-basedtaskssuchasdrivinganddecision-makingarebeingreplacedbyauto-\nmatedtechnologies,andthedigitalinfrastructuresthatweareincreasinglyreliantuponcan\nbedisruptedindiscriminatelyasaresultof,forexample,ransomware[54].Cybersecurityrisk\nassessmentandmanagementis,therefore,afundamentalspecialcasethateveryoneliving\nandworkingwithinthedigitaldomainshouldunderstandandbeaparticipantinit.\nThereareanumberofglobalstandardsthataimtoformaliseandprovideacommonframe-\nwork for cyber risk assessment and management, and, in this section, we will study some\nof them. We will begin with high level definitions of some of the foremost positions on risk.\nThe United Kingdom was ranked first in the 2018 Global Cybersecurity Index (GCI) [55], a\nscientifically grounded review of the cyber security commitment and situation at a global\ncountry-by-country level. The review covers five pillars: (i) legal, (ii) technical, (iii) organisa-\ntional,(iv)capacitybuilding,and(v)cooperation\u2013andthenaggregatesthemintoanoverall\nscore.AstheleadnationintheGCI,thetechnicalauthorityforcybersecurity,theUKNational\nCyberSecurityCentre(NCSC)haspublishedguidanceonriskmanagement[52].Importantly,\nthe NCSC is clear that there is no one-size-fits-all for risk assessment and management. In-\ndeedconductingriskassessmentandmanagementasatick-boxexerciseproducesafalse\nsenseofsecurity,whichpotentiallyincreasestheVulnerabilityofthepeopleimpactedbyrisk\nbecause they are not properly prepared. Cyber security is such a rapidly evolving domain\nthat we must accept that we cannot be fully cyber secure. However, we can increase our\npreparedness. The Potomac Institute for Policy Studies provides a framework for studying\ncyber readiness along with a country-specific profile for a range of nations (inc. USA, India,\nSouthAfrica,France,UK)andanassociatedcyberreadinessindex[56].\n2.5 RISK GOVERNANCE\n[57,58,59,60,61,62,63,64,65,66,67]\n2.5.1 What is risk governance and why is it essential?\nRisk assessment and developing mitigation principles to manage risk is only likely to be ef-\nfectivewhereacoordinatedandwellcommunicatedgovernancepolicyisputinplacewithin\nthesystembeingmanaged.Millstoneetal.[57]proposedthreegovernancemodels:\n\u2022 Technocratic: where policy is directly informed by science and evidence from domain\nexpertise.\n\u2022 Decisionistic: where risk evaluation and policy are developed using inputs beyond sci-\nencealone.Forinstance,incorporatingsocialandeconomicdrivers.\nKARiskManagementandGovernance |October2019 Page25 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n\u2022 Transparent (inclusive): where context for risk assessment is considered from the out-\nsetwithinputfromscience,politics,economicsandcivilsociety.Thisdevelopsamodel\nof\u2018pre-assessment\u2019\u2013thatincludestheviewsofwiderstakeholders\u2013thatshapesrisk\nassessmentandsubsequentmanagementpolicy.\nNone are correct or incorrect. There is a fine balance between the knowledge and findings\nofscientificexperts,andperceptionsofthelaypublic.Whilethetechnocraticapproachmay\nseemlogicaltosomeriskownerswhoworkonthebasisofreasoningusingevidence,itisab-\nsolutelycrucialforeffectiveriskgovernancetoincludethewiderstakeholderview.Rohrmann\nand Renn\u2019s work on risk perception highlights some key reasons for this [58]. They identify\nfourelementsthatinfluencetheperceptionofrisk:\n\u2022 intuitivejudgmentassociatedwithprobabilitiesanddamages;\n\u2022 contextualfactorssurroundingtheperceivedcharacteristicsoftherisk(e.g.,familiarity)\nandtherisksituation(e.g.,personalcontrol);\n\u2022 semantic associations linked to the risk source, people associated with the risk, and\ncircumstancesoftherisk-takingsituation;\n\u2022 trustandcredibilityoftheactorsinvolvedintheriskdebate.\nThese factors are not particularly scientific, structured or evidence-based but, as noted by\nFischoff et al. [59], such forms of defining probabilities are countered by the strength of be-\nliefpeoplehaveaboutthelikelihoodofanundesirableeventimpactingtheirownvalues.Ulti-\nmately, from a governance perspective, the more inclusive and transparent the policy devel-\nopment,themorelikelythesupportandbuy-infromthewiderstakeholdergroup\u2013including\nlaypeopleaswellasoperationalstaff\u2013fortheriskmanagementpoliciesandprinciples.\nThereareseveralelementsthatarekeytosuccessfulriskgovernance.Likemuchoftherisk\nassessmentprocess,thereisnoone-sizesolutionforallendeavours.However,amajorprinci-\npleisensuringthatthegovernanceactivity(seebelow)istightlycoupledwitheverydayactiv-\nityanddecision-making.Cyberriskisasimportantashealthandsafety,financialprocesses,\nand human resources. These activities are now well established in decision-making. For in-\nstance, when hiring staff, the HR process is at the forefront of the recruiter\u2019s activity. When\ntravelling overseas, employees will always consult the financial constraints and processes\nfor travel. Cyber security should be thought of in the same way \u2013 a clear set of processes\nthat reduce the risk of harm to individuals and the business. Everyone involved in the daily\nrunning of the system in question must understand that, for security to be effective, it must\nbe part of everyday operational culture. The cyber risk governance approach is key to this\nculturaladoption.\n2.5.2 The human factor and risk communication\nSasseandFlechais[60]identifiedhumanfactorsthatcanimpactsecuritygovernance,includ-\ningpeople:havingproblemsusingsecuritytoolscorrectly;notunderstandingtheimportance\nofdata,software,andsystemsfortheirorganisation;notbelievingthattheassetsareatrisk\n(i.e.,thattheywouldbeattacked);ornotunderstandingthattheirbehaviourputsthesystem\nat risk. This highlights that risk cannot be mitigated with technology alone, and that concern\nassessment is important. If risk perception is such that there is a widely held view that peo-\npledonotbelievetheirassetswillbeattacked(asnotedby[60]),despitestatisticsshowing\ncybersecuritybreachesareontheriseyear-on-year,thenthereislikelytobeaproblemwith\nthecybersecuritycultureintheorganisation.Educatingpeoplewithinanorganisationisvital\nKARiskManagementandGovernance |October2019 Page26 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntoensuringculturaladoptionoftheprinciplesdefinedintheriskmanagementplanandasso-\nciatedsecuritygovernancepolicy.Peoplewillgenerallyfollowthepathofleastresistanceto\ngetajobdone,orseekthepathofhighestreward.AsSasseandFlechaisnote,peoplefailto\nfollow the required security behaviour for one of two reasons: (1) they are unable to behave\nasrequired(oneexamplebeingthatitisnottechnicallypossibletodoso;anotherbeingthat\nthesecurityproceduresandpoliciesavailabletothemarelarge,difficulttodigest,orunclear)\n,(2)theydonotwanttobehaveinthewayrequired(anexampleofthismaybethattheyfind\niteasiertoworkaroundtheproposedlow-riskbuttimeconsumingpolicy;anotherbeingthat\ntheydisagreewiththeproposedpolicy).\nWeirich and Sasse studied compliance with password rules as an example of compliance\nwithsecuritypolicy[61]andfoundthatalackofcompliancewasassociatedwithpeoplenot\nbelieving that they were personally at risk and or that they would be held accountable for\nfailure to follow security rules. There is thus a need to ensure a sense of responsibility and\nprocessforaccountability,shouldtherebeabreachofpolicy.Thismust,ofcourse,bemindful\noflegalandethicalimplications,aswellastheculturalissuesaroundbreachingrules,which\nisabalancingact.Riskcommunication,therefore,playsanimportantroleingovernance[62]\n[39]includingaspects,suchas:\n\u2022 Education: particularly around risk awareness and day-to-day handling of risks, includ-\ningriskandconcernassessmentandmanagement;\n\u2022 Trainingandinducementofbehaviourchange:takingtheawarenessprovidedbyeduca-\ntionandchanginginternalpracticesandprocessestoadheretosecuritypolicy;\n\u2022 Creation of confidence: both around organisational risk management and key individu-\nals \u2013 develop trust over time, and maintain this through strong performance and han-\ndlingofrisks.\n\u2022 Involvement: particularly in the risk decision-making process \u2013 giving stakeholders an\nopportunitytotakepartinriskandconcernassessmentandpartakeinconflictresolu-\ntion.\nFinally, leading by example is of paramount importance in the risk communication process.\nPeople are likely to be resentful if it appears that senior management are not abiding by\nthe same risk management rules and principles. Visible senior engagement in an important\nculturalaspectofriskcommunication.\n2.5.3 Security culture and awareness\nDekker\u2019s principles on Just Culture [63] aim to balance accountability with learning in the\ncontext of security. He proposes the need to change the way in which we think about ac-\ncountabilitysothatitbecomescompatiblewithlearningandimprovingthesecurityposture\nof an organisation. It is important that people feel able to report issues and concerns, par-\nticularly if they think they may be at fault. Accountability needs to be intrinsically linked to\nhelpingtheorganisation,withoutconcernofbeingstigmatisedandpenalised.Thereisoften\nanissuewherethoseresponsibleforsecuritygovernancehavelimitedawarenessandunder-\nstanding ofwhat it means to practise it inthe operationalworld. In these casesthere needs\ntobeanawarenessthatthereispossiblynoclearrightorwrong,andthatpoorlythought-out\nprocesses and practices are likely to have been behind the security breach, as opposed to\nmalicious human behaviour. If this is the case, these need to be addressed and the person\nat fault needs to feel supported by their peers and free of anxiety. One suggestion Dekker\nKARiskManagementandGovernance |October2019 Page27 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nmakes is to have an independent team to handle security breach reports so people do not\nhave to go through their line manager. If people are aware of the pathways and outcomes\nfollowingsecuritybreachesitwillreduceanxietyaboutwhatwillhappenand,therefore,lead\ntoamoreopensecurityculture.\nGiven that security awareness and education is such an important factor in effective gover-\nnance, Jaquith [64] links security awareness with security metrics through a range of ques-\ntionsthatmaybeconsideredasusefulpointersforimprovingsecurityculture:\n\u2022 Are employees acknowledging their security responsibilities as users of information\nsystems?(Metric:%newemployeescompletingsecurityawarenesstraining).\n\u2022 Areemployeesreceivingtrainingatintervalsconsistentwithcompanypolicies?(Metric:\n%existingemployeescompletingrefreshertrainingperpolicy).\n\u2022 Do security staff members possess sufficient skills and professional certifications?\n(Metric:%securitystaffwithprofessionalsecuritycertifications).\n\u2022 Are security staff members acquiring new skills at rates consistent with management\nobjectives? (Metrics: # security skill mastered, average per employee and per security\nteammember,fulfillmentrateoftargetexternalsecuritytrainingworkshopsandclass-\nroomseminars).\n\u2022 Are security awareness and training efforts leading to measurable results? (Metrics:\nBybusinessunitoroffice,correlationofpasswordstrengthwiththeelapsedtimesince\ntraining classes; by business unit or office, correlation of tailgating rate with training\nlatency).\nMetricsmaybeacrudewaytocaptureadherencetosecuritypolicy,butwhenlinkedtoques-\ntions that are related to the initial risk assessment, they can provide an objective and mea-\nsurable way to continually monitor and report on the security of a system to the decision\nmakers, as well as those responsible for its governance in an understandable and mean-\ningful way. However, it is worth noting the complexity of metrics here with the use of the\nterm \u2018acknowledging\u2019 in the first bullet point. It does not necessarily mean the person will\nacknowledgetheirresponsibilitiesmerelybycompletingawarenesstraining.Thisreinforces\nthe points already made about the importance of human factors and security culture, and\nthefollowingsectiononenactingsecuritypolicy.\n2.5.4 Enacting Security Policy\nOverall,effectivecyberriskgovernancewillbeunderpinnedbyaclearandenactablesecurity\npolicy. This section focuses on the elements of risk assessment and management that are\nrelevant to achieving this. From the initial phase of the risk assessment there should be a\nclearfocusonthepurposeandscopeoftheriskassessmentexercise.Duringthisphase,for\nmorecomplexsystemsorwholesystemsecurity,thereshouldbeafocusonidentifyingthe\nobjectives and goals of the system. These should be achievable with clear links from objec-\ntives to the processes that underpin them. Risks should be articulated as clear statements\nthat capture the interdependencies between the vulnerabilities, threats, likelihoods and out-\ncomes(e.g.,causesandeffects)thatcomprisetherisk.Riskmanagementdecisionswillbe\ntaken to mitigate threats identified for these processes, and these should be linked to the\nsecurity policy, which will clearly articulate the required actions and activities taken (and by\nwhom),oftenalongwithacleartimeline,tomitigatetherisks.Thisshouldalsoincludewhat\nisexpectedtohappenasaconsequenceofthisriskbecomingareality.\nKARiskManagementandGovernance |October2019 Page28 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nFigure2.1:RiskGovernanceFrameworkfromIRGC-takenfrom[66]\nPresentation of risk assessment information in this context is important. Often heat maps\nandriskmatricesareusedtovisualisetherisks.However,researchhasidentifiedlimitations\nin the concept of combining multiple risk measurements (such as likelihood and impact)\ninto a single matrix and heat map [68]. Attention should, therefore, be paid to the purpose\nofthevisualisationandtheaccuracyoftheevidenceitrepresentsforthegoalofdeveloping\nsecuritypolicydecisions.\nHuman factors (see the Human Factors Knowledge Area (Chapter 4)), and security culture\nare fundamental to the enactment of the security policy. As discussed, people fail to follow\nthe required security behaviour because they are unable to behave as required, or they do\nnot want to behave in the way required [60]. A set of rules dictating how security risk man-\nagement should operate will almost certainly fail unless the necessary actions are seen as\nlinked to broader organisational governance, and therefore security policy, in the same way\nHR and finance policy requires. People must be enabled to operate in a secure way and not\nbe the subject of a blame culture when things fail. It is highly likely that there will be secu-\nrity breaches, but the majority of these will not be intentional. Therefore, the security policy\nmustbereflectiveandreactivetoissues,respondingtotheJustCultureagendaandcreating\na policy of accountability for learning, and using mistakes to refine the security policy and\nunderpinningprocesses\u2013notblameandpenalisepeople.\nSecurityeducationshouldbeaformalpartofallemployees\u2019continualprofessionaldevelop-\nment,withreinforcedmessagingaroundwhycybersecurityisimportanttotheorganisation,\nand the employee\u2019s role and duties within this. Principles of risk communication are an im-\nportant aspect of the human factor in security education. We have discussed the need for\ncredible and trustworthy narratives and stakeholder engagement in the risk management\nKARiskManagementandGovernance |October2019 Page29 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nprocess. There are additional principles to consider such as early and frequent communica-\ntion,tailoringthemessagetotheaudience,pretestingthemessageandconsideringexisting\nriskperceptionsthatshouldbepartoftheplanningaroundsecurityeducation.Extensivedis-\ncussion of such risk communication principles that are particularly relevant for messaging\nregardingriskcanbefoundin[67].\nPart of the final risk assessment and management outcomes should be a list of accepted\nrisks with associated owners who have oversight for the organisational goals and assets\nunderpinning the processes at risk. These individuals should be tightly coupled with review\nactivity and should be clearly identifiable as responsible and accountable for risk manage-\nment.\nFigure 2.1 summarises the core elements of the risk governance process as discussed so\nfar. This model from the International Risk Governance Council (IRGC) [66], which is heavily\ninspiredbyRenn\u2019swork[41],highlightsthatriskcommunicationsitsattheheartofthegover-\nnanceprocessanddrawsonproblemframing,riskandconcernassessment,riskevaluation,\nand risk management. The governance process is iterative, always seeking awareness of\nnew problems and evolving threats, and continually reflecting on best practice to manage\nnewrisks.\n2.6 RISK ASSESSMENT AND MANAGEMENT PRINCIPLES\n[47,52,64,66,69,70,71,72,73,74,75]\n2.6.1 Component vs. Systems Perspectives\nTheUKNCSCguidance[52]breaksdownriskmanagementintoComponent-drivenriskman-\nagement, which focuses on technical components, and the threats and vulnerabilities they\nface (also known as bottom up); and System-driven risk management, which analyses sys-\ntems as a whole (also known as top down). A major difference between the two is that\ncomponent-drivenapproachestendtofocusonthespecificrisktoanindividualcomponent\n(e.g., hardware, software, data, staff), while system-driven approaches focus more on the\ngoalsofanentiresystem\u2013requiringthedefinitionofahigherlevelpurposeandsubsequent\nunderstandingofsub-systemsandhowvariouspartsinteract.\nRasmussen\u2019s work [69] enables us to consider a hierarchy of abstraction and show how\nsystems-driven and component-driven risk assessment techniques are complementary. As\nillustratedinFigure2.2,thegoalsandpurposesofthesystemcanbeconsideredatthehigher\nlevel. Notably, this includes a focus on dependencies between sub-goals and also what the\nsystem must not do (pre-defined failure states). These are important to design into the sys-\ntemand,ifomitted,leadtohavingtoretrofitcybersecurityintoasystemthathasalreadybeen\ndeployed.Thelowerlevelsthenconsidercapabilitiesandfunctionalityneededtoachievethe\noverarching goals. At this level component-driven risk assessments of real-world artefacts\n(e.g., hardware, software, data, staff) consider how these may be impacted by adverse ac-\ntionsorevents.\nSystem-drivenapproachescanhelptobetterunderstandthecomplexitybetweensub-components\nandtheircomponents.Thesemayincludepeople,technology,andorganisationalprocesses\nforwhichtheinteractionsanddependenciesarenon-trivial.Takingsuchanapproach(which\nmayperhapsprovemoreresourceintensivethancomponentbasedapproaches,duetoiden-\nKARiskManagementandGovernance |October2019 Page30 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nFigure2.2:JensRasmussen\u2019sHierarchy\ntificationofinter-dependencies)isonlynecessarywherecomplexityactuallyexists.Ifinterac-\ntionsanddependenciesareclearandthesystemislesscomplex(e.g.,asimpleoffice-based\nITinfrastructure)thenacomponent-drivenapproachmaybemoreappropriate.\nTheNCSCguidanceprovidesasummarytable(reproducedhereasFigure2.3)thatishelpful\ninguidingtheselectionofcomponent-drivenorsystem-drivenmethodsbasedonthekindof\nrisk management problem being addressed. The major differentiator is that the component\nview is individual asset-based, where complexity is well-understood and expected function-\nality is clear. The system view supports an analysis of risk in situations of greater complex-\nity, before physical function is agreed and implemented, and to support discussions by key\nstakeholdersonwhatthesystemshouldandshouldnotdo.Thesediscussionsarecrucialin\nfindingthebalancebetweencomponent-levelandsystem-levelfailureandhowbesttoman-\nage the risk. Component-risk is likely to be more important to operational employees who\nneed the component to be functioning in order for their part of a bigger system to perform\n(e.g., staff, data, devices). Systems-level risk is likely to be more important to higher-level\nmanagers who have a vested interest in the strategic direction of the system. For them a\ncomponentfurtherdownthevalue\/supplychainmaynotbeperceivedtobeimportant,while\nfor the operational employee it\u2019s the number one risk. The challenge is to work with both\nperspectives to develop a representation of risk and an associated risk management policy\nenactedbyallparties.\n2.6.2 Elements of Risk\nWhile it is useful to avoid creating a universal definition of risk, to support inclusivity of dif-\nferentviewsandperspectives,itisimportanttohaveagreeddefinitionsoftheconceptsthat\nunderpin risk assessment and management. This ensures a common language throughout\ntheprocessandavoidstalkingatcrosspurposes.Therearefourconceptsthatarecoretoa\nriskassessmentinmostmodels\u2013vulnerability,threat,likelihoodandimpact.\nA Vulnerability is something open to attack or misuse that could lead to an undesirable out-\ncome. If the vulnerability were to be exploited it could lead to an impact on a process or\nsystem. Vulnerabilities can be diverse and include technology (e.g., a software interface be-\ning vulnerable to invalid input), people (e.g., a business is vulnerable to a lack of human re-\nsources),legal(e.g.,databasesbeingvulnerableandlinkedtolargelegalfinesifdataismis-\nhandledandexposed)etc.Thisisanon-exhaustivelist,buthighlightsthatvulnerabilitiesare\nKARiskManagementandGovernance |October2019 Page31 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nGoodFor\n\u2022 Analysingtherisksfacedbyindividualtechnicalcomponents.\n\u2022 Deconstructinglesscomplexsystems,withwell-understood\nComponent-driven\nconnectionsbetweencomponentparts.\nmethods\n\u2022 Workingatlevelsofabstractionwhereasystem\u2019sphysical\nfunctionhasalreadybeenagreedamongststakeholders.\n\u2022 Exploringsecuritybreacheswhichemergeoutofthecomplex\ninteractionofmanypartsofyoursystem.\n\u2022 Establishingsystemsecurityrequirementsbeforeyouhave\ndecidedonthesystem\u2019sexactphysicaldesign.\nSystem-driven\n\u2022 Bringingtogethermultiplestakeholders\u2019viewsofwhata\nmethods\nsystemshouldandshouldnotdo(e.g.,safety,security,legal\nviews).\n\u2022 Analysingsecuritybreacheswhichcannotbetrackedbackto\nasinglepointoffailure.\nFigure2.3:Guidelinesformappingriskmanagementproblemtypestocomponentorsystem\ndrivenmethods\nsocio-technical.\nA Threat is an individual, event, or action that has the capability to exploit a vulnerability.\nThreatsarealsosocio-technicalandcouldincludehackers,disgruntledorpoorlytrainedem-\nployees, poorly designed software, a poorly articulated or understood operational process\netc. To give a concrete example that differentiates vulnerabilities from threats \u2013 a software\ninterfacehasavulnerabilityinthatmaliciousinputcouldcausethesoftwaretobehaveinan\nundesirablemanner(e.g.,deletetablesfromadatabaseonthesystem),whilethethreatisan\naction or event that exploits the vulnerability (e.g., the hacker who introduces the malicious\ninputtothesystem).\nLikelihoodrepresentsameasurecapturingthedegreeofpossibilitythatathreatwillexploita\nvulnerability,andthereforeproduceanundesirableoutcomeaffectingthevaluesatthecore\nof the system. This can be a qualitative indicator (e.g., low, medium, high), or a quantitative\nvalue(e.g.,ascaleof1-10orapercentage).\nImpact is the result of a threat exploiting a vulnerability, which has a negative effect on the\nsuccess of the objectives for which we are assessing the risk. From a systems view this\ncould be the failure to manufacture a new product on time, while from a component view it\ncouldbethefailureofaspecificmanufacturingproductioncomponent.\nKARiskManagementandGovernance |October2019 Page32 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n2.6.3 Risk assessment and management methods\nThe purpose of capturing these four elements of risk is for use in dialogue that aims to rep-\nresent how best to determine the exposure of a system to cyber risk, and how to manage it.\nThere are a range of methods, some of which have been established as international stan-\ndards and guidelines, that provide a structured means to transform vulnerability, threat, like-\nlihood and impact into a ranked list in order to be able to prioritise and treat them. While\neach method has its own particular approach to risk assessment and management, there\naresomefeaturescommontoanumberofthemostwidelyusedmethodsthatareusefulfor\nframing risk assessment and management activities, which can be mapped back to Renn\u2019s\nseminalworkonriskgovernance[41]asdiscussedinearliersections.TheInternationalRisk\nGovernance Council (IRGC) capture these in its risk governance framework (developed by\nan expert group chaired by Renn), summarised in Figure 2.1, which includes four core areas\nand crosscutting components. Pre-assessment includes the framing of risk, identification\nof relevant actors and stakeholders, and captures perspectives on risk. Appraisal includes\nthe assessment of causes and consequences of risk (including risk concern), developing a\nknowledge base of risks and mitigation options (e.g., preventing, sharing etc). Characterisa-\ntion involves a decision process, making a judgment about the significance and tolerance\noftherisks.AppraisalandCharacterisationformsthebasisoftheimplementationofRenn\u2019s\nthreecorecomponentsofriskassessment[41].Managementprocessesincludedecidingon\ntheriskmanagementplanandhowtoimplementit,includingrisktolerance(accepting,avoid-\ning, mitigating, sharing, transferring). Cutting across all four is communication, engagement\nandcontextsettingthroughopenandinclusivedialogue.\nThe US Government NIST [70] guidelines capture the vulnerability, threats, likelihood and\nimpact elements inside the prepare (pre-assessment), conduct (appraisal and characterise),\ncommunicate (cross-cutting), maintain (management) cycle (see Figure 2.4). A step-by-step\ndetailedguidecanbefoundinthefulldocument,butwesummarisetheactionshere.\nPrepare involves identifying the purpose (e.g., establishing a baseline of risk or identifying\nvulnerabilities,threats,likelihoodandimpact)andscope(e.g.,whatpartsofasystem\/organ-\nisationaretobeincludedintheriskassessment?;whatdecisionsaretheresultsinforming?).\nItalsoinvolvesdefiningassumptionsandconstraintsonelementssuchasresourcesrequired\nand predisposing conditions that need to inform the risk assessment. The assessment ap-\nproachandtolerancesforriskarealsodefinedatthisstagealongwithidentifyingsourcesof\ninformationrelatingtothreats,vulnerabilitiesandimpact.\nConductisthephasewherethreats,vulnerabilities,likelihoodandimpactareidentified.There\nare a range of ways that this can be conducted, and this will vary depending on the nature\nofthesystembeingriskassessedandtheresultsofthepreparestage.NISThasaveryspe-\ncific set of tasks to be performed. These may not be relevant to all systems, but there are\nsome useful tasks that generalise across multiple system perspectives, including identify-\ning:threatsourcesandadversarycapability,intentandtargets;threateventsandrelevanceto\nthesysteminquestion;vulnerabilitiesandpredisposingconditions;likelihoodthatthethreats\nidentifiedwillexploitthevulnerabilities;andtheimpactsandaffectedassets.Notethattheor-\nderingofactionsintheNISTapproachputsthreatidentificationbeforevulnerabilities,which\npresupposesthatallthreatscanbeidentifiedandmappedtovulnerabilities.Itisworthhigh-\nlighting that risk assessment must also be effective in situations where threats are less ob-\nviousoryettobemainstream(e.g.,IoTBotnets)and,therefore,someorganisationsthatare\nparticularly ingrained in digital adoption may also wish to consider conducting a vulnerabil-\nity assessment independently or prior to the identification of likely threats to avoid making\nKARiskManagementandGovernance |October2019 Page33 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nFigure2.4:NISTSP-800-30RiskAssessmentProcess\nassumptionsonwhatorwhothethreatsactorsmaybe.\nCommunicate is one of the most important phases, and one often overlooked. Conducting\ntheriskassessmentgivesonethedatatobeabletoinformactionsthatwillimprovethesecu-\nrity of the system. However, it is crucial this is communicated using an appropriate method.\nExecutive boards will expect and need information to be presented in a different way to op-\nerationalteammembers,andgeneralorganisationalstaffwillneededucatingandguidingin\nanentirelydifferentway.Theresultsandevidenceoftheriskassessmentmustbecommuni-\ncatedinamanneraccessibletoeachstakeholderandinawaythatislikelytoengagethem\ninriskmanagementplanningandexecution.\nMaintain is an ongoing phase that is essential to continually update the risk assessment in\nthelightofchangestothesystemenvironmentandconfiguration.Securitypostureschange\nregularly in digital environments. For instance, Figure 2.5 shows the volume of IoT units in-\nstalled from 2014 to 2020 with a rapid increase in adoption of 2.63 million across the busi-\nness sector between 2014 and 2018. By 2020 this is projected to grow by a further 3.39\nmillion.ThiskindofrapidintegrationofdevicesintocorporateITsystemsislikelytochange\nthe exposure to risk and, therefore, the scope would need to be refined, new risk assess-\nments carried out, and action taken and communicated to all stakeholders to ensure that\nthenewriskismanaged.Thisscenarioindicatesthat(i)riskassessmentmaintenancemust\nbe proactive and undertaken much more regularly than an annual basis, and (ii) conduct-\ning risk assessment for compliance purposes (possibly only once a year) will leave the or-\nganisation wide open to new technological threats unless the maintain phase is taken seri-\nously. Risk factors should be identified for ongoing monitoring (e.g., changes in technology\nKARiskManagementandGovernance |October2019 Page34 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nFigure2.5:IoTDevicesUseFigures:Source:[53]\nuse within the system), frequency of risk factor monitoring should be agreed, and change-\ntriggered reviews should revisit and refine the scope, purpose and assumptions of the risk\nassessment\u2014rememberingtocommunicatetheresultseachtimenewrisksareidentified.\nThe international standard ISO\/IEC 27005 for risk management [71] contains analogous ac-\ntivities to the NIST guidance (see Figure 2.6). It includes an Establish Context phase, which\nis broadly aimed at achieving the outcomes of the Prepare phase of NIST and the IRGC Pre-\nassessment phase. The Risk Assessment phase is multi-layered, with identification, estima-\ntion, evaluation stages. This aligns with the IRGC\u2019s appraisal and characterisation phases.\nISO 27005 also has Risk Communication and Risk Monitoring and Review phases, which re-\nlate broadly to the aims of the NIST Communicate and Maintain phases, and IRGC\u2019s cross-\ncuttingcommunication,contextandengagementphases.ISO\/IEC27005hasadditionalele-\nments that explicitly capture risk management decision processes but it is not prescriptive\non how to implement them. The inclusion of the treatmentand acceptance phases linked to\ncommunication and review capture some of the fundamental management aspects, offer-\ningthechoiceoftreatmentoracceptanceaspartoftheassessmentprocess.Thisaspectof\nthe ISO\/IEC 27005 approach is analogous to the risk response element of the NIST-SP800-\n39 guidance on risk management [45], where the risk response options include acceptance,\navoidance, mitigation, or sharing\/transfer. The take-away message from this comparison is\nthat,whiletheriskassessmentmethodsmaydifferattheriskassessmentphase(depending\non the type of system being analysed and the scope of the study), the preparation, commu-\nnication, and continual monitoring phases are must-haves in both widely-used international\nguidelines, as are the important decisions around risk tolerance. ISO\/IEC 27005 is less pre-\nscriptivethanNISTsoofferstheoptiontoincludearangeofassessmentandmanagement\napproacheswithintheoverallprocess.\nKARiskManagementandGovernance |October2019 Page35 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nFigure2.6:ISO\/IEC27005Process-takenfrom[76]\nAlistofcommonlyusedcomponent-drivencyberriskmanagementframeworkscanbefound\nat [72]. The list also includes a brief description, an overview of how they work, who should\nuseit,andanindicationofcostandprerequisites.Whilenotwishingtoreproducethewhole\nlisthere,weprovideanoverviewforthepurposesofcomparison.\n\u2022 ISO\/IEC 27005:2018 is an international standard set of guidelines for information risk\nmanagement.Itdoesnotprescribeaspecificriskassessmenttechniquebutdoeshave\na component-driven focus and requires vulnerabilities, threats and impact to be speci-\nfied.\n\u2022 NIST SP800-30\/39 are the US Government\u2019s preferred risk assessment\/management\nmethodsandaremandatedforUSgovernmentagencies.Theyhaveastrongregulatory\nfocus,whichmaynotberelevantforcountriesotherthantheUS,buttheyhaveaclear\nset of guiding steps to support the whole risk assessment and management process\nfrom establishing context to risk tolerance, and effective controls, including determin-\ning likelihood of impact. They are freely available and consistent with ISO standards\n(whicharenotfreebutarelowcost).\n\u2022 The Information Security Forum (ISF) produced the IRAM 2 risk management method-\nologythatusesanumberofphasestoidentify,evaluateandtreatrisksusingthevulner-\nability,threatsandimpactmeasures.Itisprovidedto(paidup)membersoftheISFand\nrequires information risk management expertise to use it effectively, which may come\natadditionalcost.\nKARiskManagementandGovernance |October2019 Page36 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n\u2022 FAIR,initiallydevelopedbyJones[77]andsubsequentlycollaborativelydevelopedwith\nthe Open Group into OpenFAIR [78], proposes a taxonomy of risk factors and a frame-\nwork for combining them. Threat surface can be considered very broad and there is a\nclear focus on loss event frequency, threat capability, control strength and loss magni-\ntude. It also breaks financial loss factors into multiple levels and supports a scenario\nmodeltobuildcomparablelossprofiles.\n\u2022 Octave Allegro is oriented towards operational risk and security practices rather than\ntechnology.Qualitativeriskassessmentislinkedwithorganisationalgoals.Real-world\nscenarios are used to identify risks through threat and impact analysis. The risks are\nthenprioritisedandmitigationisplanned.Theapproachisdesignedforworkshopstyle\nrisk assessment and could be performed in-house possibly resulting in a lower cost\nthanaconsultant-ledriskassessment.\n\u2022 STRIDEisafailure-orientedthreatmodellingapproachfocusingonsixcoreareas:spoof-\ning (faking identity), tampering (unauthorised modification), repudiation (denying ac-\ntions), denial of service (slowing down or disabling a system), and elevation of privi-\nlege (having unauthorised control of the system). The approach considers threat tar-\ngets(includingwhatanattackermaydo),mitigationstrategy,andmitigationtechnique.\nThreats can be considered for multiple interactions on the same threat target in the\nsystemandcanincludepeople,processandtechnology.ShostackpresentsSTRIDEas\npart of a four-stage framework in his book [75] \u2013 model the system, find threats, ad-\ndress threats, validate. Threat modelling, of course, cannot guarantee that all failures\ncan be predicted, but the iterative process supports continual assessment of evolving\nthreatsiftimeandresourcesallow.\n\u2022 Attack Trees [79] formulate an overall goal based on the objectives of an attacker (the\nrootnode),anddevelopsub-nodesrelatingtoactionsthatwouldleadtothesuccessful\ncompromise of components within a system. Like STRIDE, attack trees are required\ntobeiterative,continuallyconsideringpruningthetreeandcheckingforcompleteness.\nAttacklibrariessuchasCommonVulnerabilitiesandExposuress(CVEs)andOpenWeb\nApplication Security Project (OWASP) can be used to augment internal knowledge of\nevolvingthreatsandattacks.\nUsing and extending the analysis developed in [80] and [72], we provide a comparison table\nbelowtoenableselectionbasedontheorganisationalandtechnicaldifferencesforeachof\nthesemethods(seeTable2.1).Whilecoreprinciplesofriskbasedaroundvulnerability,threat\nandimpactexistacrossallmethods,thereareindividualattributes(werefertoasstrengths)\nofeachmethod,aswellasresourceandreportingdifferences,thatmaymakethemabetter\nfit to an organisation depending on what the risk stakeholders require as evidence of expo-\nsure.\nKARiskManagementandGovernance |October2019 Page37 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nTable2.1:Riskassessmentandmanagementmethodsdifferences\nMethodology Assessment Team and Information Gathering\nCost andReporting\nISO\/IEC Covers people, process and tech- Aims to include a range Questionnaire, inter-\n2005 nology.Notprescriptiveinassess- ofrelevantbackgrounds views, document review,\n:2018 ment and management method in the assessment (cov- process observation.\n(i.e. other methods in this list ering people, process Documentation covers\ncouldbeusedtomanagerisk)but andtech)andapplicable allsecuritycontrols\ncoversthreats,vulnerabilities,and across varying sizes of\nimpacts.Intendedtotargethigher organisation. Typically\nlevel management and decision externally led due to\nmakers.Clearfocusonpeople-in- size and complexity\nternalandexternal in large organisations,\nStrength:Socio-technical which comes at a cost\nin addition to the cost\nof purchasing the doc-\numentation. Smaller\norganisations with less\ncomplexity can also\nfollow the principles\nin-house.\nNIST Focused on technical risk man- Includes roles and Questionnaire, inter-\nSP800- agement of IT systems with a should be usable by views, document re-\n30\/39 prescriptive approach. Includes organisations of all views. Checklist reports\nthreats, vulnerabilities, likelihood sizes (albeit it is very for operational, man-\nand impact - along with control US focused). Free to agement and technical\nmonitoringandcomplianceverifi- access. security\ncation. People not considered as\nacoreorganisationalasset.\nStrength:Technology-driven\nISF Broad business impact assess- Only available to mem- Information required\nment,practitionerled.Threat,vul- bersatcostandrequires on impact of losses.\nnerabilityandimpactbased a team with expertise in Reports on business\nStrength:Businessimpact-driven riskassessment impact, threat assess-\nment, vulnerability\nassessment, security\nrequirements evaluation\nandcontrolselection\nFAIR Taxonomy-based - loss events, Well-defined method Information sources\nthreat capability, control strength couldbeusedbyasmall may vary depending\nand loss magnitude. Scenario internal team. OpenFAIR who hold the necessary\ndriven with very well defined standard available via information. Reports\nmeasures on economic impact. theOpenGroup on financial loss magni-\nPeople are part of the method, tudes\nboth internal business and exter-\nnalthreatactors\nStrength:Economicimpact-driven\nKARiskManagementandGovernance |October2019 Page38 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nMethodology Assessment Team and Information Gathering\nCost andReporting\nOctave Covers people, technology and Collaborative assess- Workshops and ques-\nAllegro physical security. Identifies core ment team from within tionnaires. Baseline\nIT staff. Self-directed methods and across business reports profile of prac-\nintended for internal use, includ- including management, tices, threat profile, and\ning qualitative management and staff and IT. Free to vulnerabilities\nevaluation workshops linked to access. Documentation\nidentification of organisational states it is targeted at\ngoals and related assets. Fol- organisations with 300+\nlowedbythreatidentificationand employees\nmitigation. Qualitative risks (e.g.\nreputation,productivity)haverela-\ntive impact scores (low, medium,\nhighmultipliedbycategoricalrisk\nscore)tosupportprioritisation\nStrength: Qualitative goal-\norientedfocus\nSTRIDE Threat assessment method. Small threat modelling Threat workshops.\nCan include people, technology team from within and Graphical threat models\nand physical security. Well doc- across business includ- and tables capturing\numented and clear approach ing management and IT. STRIDE analysis for\nbased on threats, mitigation Freetoaccess systems elements and\n(including tolerance levels for interactions.\nrisk), and mitigation including\nwhosignsoffonrisk.\nStrength:Threat-driven\nAttack Similar threat assessment to Small attack modelling Attack modelling work-\nTrees STRIDE, but more attack-specific, team from within the shops. Attack trees and\nfocusing on key details of attack business with a techni- quantitative measures\nmethods. cal focus. Openly acces- of likelihood of attack\nStrength:Attack-driven siblemethod withassociatedimpact.\nA list of commonly used system-driven cyber risk management methods can be found at\n[73].Belowweprovideanoverviewandidentifytheattributesthatcanactasdifferentiators\nbased on the core focus of each method. These all focus on system-level risk and, as such,\nmayrequiresignificanthumanresourceeffortdependingonthesizeoftheorganisation.The\nmainobjectiveofthesemethodsistocaptureinteractionsandinterdependentaspectsofthe\nsystemandthusrequiresextensiveengagementwithprocessownersandseekingthe\u2018right\u2019\npeoplewithknowledgeofsub-systems.\n\u2022 Systems-Theoretic Accident Model and Process (STAMP) is an ensemble of methods\nused for modelling causation of accidents and hazards, developed at MIT [81]. Initially\nfocusedonsafetyasadynamiccontrolproblemincludingdirectandindirectcausality,\nit has also been applied to cyber security (e.g., STPA-Sec) and has a focus on socio-\ntechnical aspects of risk. The method uses a feedback loop with a controller and a\ncontrolled process linked via actuation and feedback. It is based on systems thinking\nandinvolves:identificationofsystempurpose,unacceptablelosses,hazards,andcon-\nstraints;developmentofahierarchicalcontrolstructure;identificationofunsafecontrol\nactions;andtheanalysisofcausalscenariosthatleadtotheseunsafecontrolactions.\nThiscanbesupplementedbyatimelineorsequenceofevents.\nStrength:Causality\u2013helpsidentifyrisksemergingfromsubsysteminteractions.\nKARiskManagementandGovernance |October2019 Page39 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n\u2022 The Open Group Architectural Framework (TOGAF) [82] is an enterprise architecture\nstandard that supports component-driven and system-driven approaches to manage\nrisk. The concept of an enterprise in this context encompasses all the business activi-\ntiesandcapabilities,information,andtechnologythatmakeuptheentireinfrastructure\nandgovernanceactivitiesoftheenterprise.Ifthisextendsintopartners,suppliers,and\ncustomers,aswellasinternalbusinessunits,thenthemodelcanalsoencompassthis\naspect.RiskassessmentinTOGAFisbasedonaqualitativeapproachcombiningeffect\nand frequency labels to produce an overall impact assessment. Risk assessment and\nmitigationworksheetsarethenmaintainedasgovernanceartefacts[83].\nStrength:Linkedtostructuredarchitecturalrepresentationoftheenterprise.\n\u2022 Dependency Modelling. The Open Group also developed the Open Dependency Mod-\nelling (O-DM) Framework for Goal-oriented risk modelling in a top-down method [84].\nThis method begins by asking \u2018What is the overall goal of the system or enterprise?\u2019\n(e.g.,continualmanufacturingoperations),thenasksafurtherquestion\u2018Whatdoesthis\ngoal depend on to be successful?\u2019 (e.g., functioning machinery, operational staff, sup-\nply of materials). The method then iterates the questions until a tree of dependencies\nis created. Goals are abstract so not dependent on actual processes, and allow a con-\nnectionist view of an enterprise, its suppliers, and customers to be developed. Recent\nworkhasdevelopedtoolstosupportthecapturingofdependenciesinaworkshopset-\nting and apply quantitative probabilities to goals, underpinning Bayesian analysis and\nmodellingcascadingfailure[85].\nStrength: Capturing interdependencies between abstract goals that sit above, and are\nlinkedto,actualbusinessprocesses.\n\u2022 SABSA [86] is another architecture-based approach. It includes four phases. The first\nphase identifies the risk associated with achieving objectives so mitigation plans can\nbeidentified.Theoutputthenfeedsintothedesignphasethatdeterminesthesecurity\nmanagement processes and how they will be used. The third phase implements, de-\nploys and tests the management processes by the operations teams. The final phase\nrelates to management and measurement, which collects security information and re-\nports to the governance stakeholders. The method is enacted by decomposing busi-\nness processes at different architectural layers, from high-level capabilities (context\nandconcept)downtologicalandphysicalaspects,technologycomponentsandactiv-\nities.Riskisaddressedateverylayerinatop-downapproachtomanagingriskthrough\nactivities in all layers, and filtering security requirements from top to bottom to en-\nsure cyber risk is considered throughout. Cutting through all layers is a focus on as-\nsets (what), motivation (why), process (how), people (who), location (where) and time\n(when).\nStrength:Matrix-structuredlayeredapproachlinkedtobusinessmodel(couldsitwithin\nTOGAF).\nKARiskManagementandGovernance |October2019 Page40 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n2.6.4 Risk assessment and management in cyber-physical systems and\noperational technology\nWestartwithanoteonsecurityvs.safety.WhiletraditionalITsecurity(e.g.,corporatedesk-\ntop computers, devices and servers) may generally take a risk assessment perspective fo-\ncused on minimising access (confidentiality), modification (integrity) and downtime (avail-\nability)withincomponentsandsystems,theworldofcyber-physicalsystemsandOperational\nTechnology (OT) typically has a greater focus on safety. These components and systems,\nalso known as Industrial Control Systems (ICSs) underpin Critical National Infrastructure\n(CNI)suchasenergyprovision,transportation,andwatertreatment.Theyalsounderpincom-\nplexmanufacturingsystemswhereprocessesaretooheavy-duty,monotonous,ordangerous\nforhumaninvolvement.Asaresult,OTriskswillmoreofteninvolveasafetyorreliabilitycon-\ntext due to the nature of failure impacting worker and general public safety and livelihood\nby having a direct impact in the physical world. This is perhaps a prime case for the use of\nsystems-drivenmethodsovercomponent-driven,astheformersupporttheabstractionaway\nfrom components to high-level objectives (e.g., avoiding death, complying with regulation).\nTaking this view can bridge the security and safety perspective and support discussion on\nhowtobestmitigateriskwithsharedsystem-levelobjectivesinmind.\nEfforts to continually monitor and control OT remotely have led to increasing convergence\nof OT with IT, linking the business (and its associated risks) to its safety critical systems.\nTechnology such as Supervisory Control and Data Acquisition (SCADA) provides capability\ntocontinuallymonitorandcontrolOTbutmustbesuitablydesignedtopreventrisksfromIT\nimpactingOT.InEuropetheNetworkandInformationSystems(NIS)directive[47]mandates\nthat operators ofessential services(such asCNI) followa setof 14goal-oriented principles\n[48],focusedonoutcomesbroadlybasedaroundriskassessment,cyberdefence,detection\nand minimising impact. Safety critical systems have a history of significant global impacts\nwhen failure occurs in the control systems (e.g., Chernobyl, Fukushima), and the addition of\nconnectivity to this environment has the potential to further increase the threat surface, in-\ntroducingtheadditionalriskelementsofglobalpoliticsandhighly-resourcedattackers(e.g.,\nStuxnet, BlackEnergy). Recent additions to this debate include the uptake and adoption of\nIoT devices, including, for example, smart tools on manufacturing shop-floors. These are a\nmore recent example of an interface to safety critical systems that could offer a window\nfor attackers to breach systems security. IoT security is in its infancy and the approach to\nrisk management is yet to be completely understood. The cyber security of cyber-physical\nsystems,includingvulnerabilities,attacksandcountermeasuresisbeyondthescopeofthis\nKAandisdiscussedindetailintheCyber-PhysicalSystemsSecurityKnowledgeArea(Chap-\nter19).\n2.6.5 Security Metrics\nSecurity metrics is a long-standing area of contention within the risk community as there is\ndebateoverthevalueofmeasuringsecurity.Itisoftendifficulttoquantify\u2013withconfidence\n\u2013howsecureanorganisationis,orcouldbe.Qualitativerepresentationssuchaslow,medium,\nhigh or red, amber, green are typically used in the absence of trusted quantitative data, but\nthereisoftenaconcernthatsuchvaluesaresubjectiveandmeandifferentthingstodifferent\nstakeholders. Open questions include: what features of a system should be measured for\nrisk?, how to measure risk?, and why measure risk at all? Some metrics may be related to\nrisklevels,sometosystemperformance,andothersrelatedtoserviceprovisionorreliability.\nJaquith provides some useful pointers on what constitutes good and bad metrics to help\nKARiskManagementandGovernance |October2019 Page41 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nselectappropriatemeasures[64].\nGoodmetricsshouldbe:\n\u2022 Consistentlymeasured,withoutsubjectivecriteria.\n\u2022 Cheaptogather,preferablyinanautomatedway.\n\u2022 Expressed as a cardinal number or percentage, not with qualitative labels like \"high\",\n\"medium\",and\"low\".\n\u2022 Expressedusingatleastoneunitofmeasure,suchas\"defects\",\"hours\",or\"dollars\".\n\u2022 Contextuallyspecificandrelevantenoughtodecision-makersthattheycantakeaction.\nIf the response to a metric is a shrug of the shoulders and \"so what?\", it is not worth\ngathering.[64]\nBadmetrics:\n\u2022 Are inconsistently measured, usually because they rely on subjective judgments that\nvaryfrompersontoperson.\n\u2022 Cannotbegatheredcheaply,asistypicaloflabour-intensivesurveysandone-offspread-\nsheets.\n\u2022 Do not express results with cardinal numbers and units of measure. Instead, they rely\nonqualitativehigh\/medium\/lowratings,trafficlights,andlettergrades.[64]\nMore extensive discussions of options to select metrics, along with case studies can be\nfoundinJaquith\u2019sbook[64].\nTheworkofHerrmann[74]providesamorepragmaticviewbasedonregulatorycompliance,\nresilience and return on investment. There are examples of metrics that could provide util-\nityindomainssuchashealthcare,privacyandnationalsecurity.Theperspectiveonmetrics\nis grounded in the understanding that we cannot be completely secure, so measuring ac-\ntual security against necessary security is arguably a defensible approach, and the metrics\ndescribedaretailoredtowardsmeasuringtheeffectivenessofvulnerabilitymanagement.Es-\nsentially,isitpossibletoquantifywhethertheriskmanagementplanandassociatedcontrols\nare fit for purpose based on the threats identified, and do the metrics provide evidence that\nthesecontrolsareappropriate?Furthermore,arethecontrolsputinplacelikelytoaddmore\nvalueinthesavingstheyproducethanthecostoftheirimplementation?Thispointispartic-\nularly pertinent in the current era of Artificial Intelligence technology being marketed widely\nataninternationalleveltoprotectdigitalinfrastructure.Withalargepricetagthereisaques-\ntion mark over an evidence-based understanding of the actual added-value of such security\nmechanismsandthecost-effectivenessofsuchsolutionsinthelightofpotentialsavings.\nJones and Ashenden [87] take an actor-oriented approach to security metrics, providing a\nrange of scenarios where threats are ranked based on a mixed qualitative and quantitative\nmethod. For instance, nation state threats are based on metrics such as population, liter-\nacy and cultural factors; terrorist groups on technical expertise, level of education and his-\ntory of activity; and pressure groups are ranked on spread of membership, number of ac-\ntivists, and funding. The framework provides a perspective on how to capture measures\nthat ground threat metrics in information that can support discursive, intelligence-led and\nculturally-groundedriskassessment.However,theapproachof\"thinkinglikeanattacker\"or\nprofilingtheadversaryhasbeenreportedtofailevenatnation-statelevel(withalotofinvest-\nmentandintelligence).InanarticlewithPresidentObamaonthecomplicationsandfailures\nKARiskManagementandGovernance |October2019 Page42 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nof risk management in the state of Libya, he notes that the US analytical teams underes-\ntimated the attacker profile (particularly socio-cultural aspects), which led to failure in risk\nmanagement [88]. Assuming knowledge of the adversary can be very risky, but metrics to\nprofile possible threats and attacks (while explicitly accepting our limitations in knowledge)\ncanbeusedaspartofathreatmodellingapproachsuchasSTRIDE[75]orAttackTrees[79].\nShostack(theauthorof[75])discussesthelimitationsofattackerprofilinginablogpost[89].\nWhilequantitativemetricsframedinthiswayappearpreferabletoqualitativemetrics,itisnot\nalwaysatrivialprocesstocollectconsistentlymeasureddata,eithermanuallyorautomated.\nThis brings us back to the point around communication and agreeing common language in\ntheriskassessmentphase.Whilemetricsmaybelimitedintheiraccessibilityandconsistent\ncollection,agreeingtheupperandlowerbounds,orspecificmeaningofqualitativelabelsalso\nprovides a degree of value to measuring the security of a system through well-defined links\nbetweenthreatsandtheirrelationshiptovulnerabilitiesandimpact.\n2.7 BUSINESS CONTINUITY: INCIDENT RESPONSE AND\nRECOVERY PLANNING\n[90,91]\nUltimately,despiteallbesteffortsofaccountableindividualsorboardswithinacompanywho\nhaveunderstoodandmanagedtherisktheyface,itislikelythatatsomepointcybersecurity\ndefences will be breached. An essential part of the risk assessment, management and gov-\nernanceprocessincludesconsiderationandplanningoftheprocessofmanagingincidents\nandrapidlyrespondingtocyberattacks.Theaimistounderstandtheimpactonthesystem\nand minimise it, develop and implement a remediation plan, and use this understanding to\nimprovedefencestobetterprotectagainstsuccessfulexploitationofvulnerabilitiesinfuture\n(feedbackloop).Thisisstillanascentareaofcybersecuritymaturity.Organisationstypically\nprefertokeepinformationaboutcybersecuritybreachesanonymoustopreventreputational\ndamageandcoveruplapsesinsecurity.However,itislikelythatotherorganisations,includ-\ning competitors will succumb to the same fate in the future, and could benefit from prior\nknowledgeoftheincidentthatoccurred.Atabroadscale,thisissomethingthatneedstobe\naddressed,especiallygiventheoffensivesideofcybersecuritywillcommunicateandcollab-\noratetoshareintelligenceaboutopportunitiesandvulnerabilitiesforexploitingsystems.Cer-\ntainindustriessuchasfinancialandpharmaceuticalsectorshavearrangementsforsharing\nsuch intelligence but it is yet to become commonplace for all types of organisations. Large\npublic consortia such as Cyber Defence Alliance Limited (CDA), Cyber Information Sharing\nPartnership(CISP),andtheOpenWebApplicationSecurityProject(OWASP)areallaimingto\nsupport the community in sharing and providing access to intelligence on the latest threats\nto cyber security. For more detailed information on incident management see the Security\nOperations&IncidentManagementKnowledgeArea(Chapter8).\nISO\/IEC 27035-1:2016 [91] is an international standard defining principles for incident man-\nagement. It expands on the aforementioned ISO\/IEC 27005 model and includes steps for\nincidentresponse,including:\n\u2022 PlanandPrepare:includingthedefinitionofanincidentmanagementpolicyandestab-\nlishingateamtodealwithincidents.\n\u2022 DetectionandReporting:observing,monitoringdetectingandreportingofsecurityinci-\nKARiskManagementandGovernance |October2019 Page43 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ndents.\n\u2022 Assessment and Decision: determining the presence (or otherwise) and associated\nseverityoftheincidentandtakingdecisiveactiononstepstohandleit.\n\u2022 Response:this may include forensic analysis,system patching, or containmentand re-\nmediationoftheincident.\n\u2022 Learning:akeypartofincidentmanagementislearning\u2013makingimprovementstothe\nsystemdefencestoreducethelikelihoodoffuturebreaches.\nTheNCSCalsoprovidestenstepstohelpguidetheincidentmanagementprocess[92]which,\nbroadlyspeaking,relatethetothePlan,Detect,Assess,RespondandLearnphasesofISO\/IEC\n27035.Insummary,thestepsinclude:\n\u2022 Establishincidentresponsecapability:includingfundingandresources,eitherin-house\nor externally to manage incidents. This should include reporting incidents and manag-\ninganyregulatoryexpectations.\n\u2022 Training:ensuringthatnecessaryexpertiseisinplacetomanageincidents(e.g.,foren-\nsicresponseandunderstandingofreportingexpectations).\n\u2022 Roles: assign duties to individuals to handle incidents and empower them to respond\nto incidents in line with a clear action plan \u2013 and make sure this person is well known\ntopeoplewhomaybelikelytoidentifyanincident.\n\u2022 Recovery: particularly for data and critical applications, make sure a backup is physi-\ncallyseparatedfromthesystem\u2013andtesttheabilitytorestorefrombackup.\n\u2022 Test: play out scenarios to test out the recovery plans; these should be refined based\nonpracticalandtimelyrestorationunderdifferentattackscenarios.\n\u2022 Report: ensure that information is shared with the appropriate personnel internally to\nimprove risk management and security controls, plus externally to ensure legal or reg-\nulatoryrequirementsaremet.\n\u2022 Gatherevidence:forensicresponsemaybecrucialfollowinganincident\u2013thepreserva-\ntionofevidencecouldbecriticaltolegalproceedingsor,ataminimum,understanding\ntheeventsthatledtothebreach.\n\u2022 Develop: take note of the actions taken as part of the incident response. What worked\nand what did not? Where could the process be improved? As well as defences, the re-\nsponseplanmayalsobenefitfromrefinement.Securityisanever-evolvingissueandre-\nquirescontinualreflection.Securitypolicies,training,andcommunicationmayallhelp\nreducetheimpactoffuturebreaches.\n\u2022 Awareness: continue to remind employees of their responsibilities and accountability\nregarding cyber security \u2013 remind them of how to report incidents and what to look\nout for. Vigilance is key whether it involves reporting suspicious behaviour or a known\npersonalerrorthathasledtoabreach.\n\u2022 Report:Cybercrimemustbereportedtorelevantlawenforcementagencies.\nAsafinalwordonbusinesscontinuitywehighlightthesignificanceofsupplychains.Incident\nmanagement approaches along with systems-level risk assessment methods are designed\ntoenablethecaptureofrisksrelatingtointeractionsandinterdependentaspectsofthesys-\ntem, which, of course, can and should include supply chains, but will only do so if due atten-\nKARiskManagementandGovernance |October2019 Page44 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntionisgiventhisaspectofrisk.Cybersecurityofsupplychainsrisk,whilenascentasatopic\nwithregardstoriskassessmentandgovernance[93][94],isanimportantissue.\n2.8 CONCLUSION\nWe have explained the fundamental concepts of risk, using a working definition of the pos-\nsibility that human actions or events may lead to consequences that have an impact on what\nhumansvalue,andplacedthisinthecontextofcyberriskmanagementandgovernance.Us-\ning academic foundations that have been widely adopted in international practice, we have\nexplained the links between pre-assessment and context setting, risk and concern assess-\nment, characterisation and evaluation, management, and governance. Risk governance is\nthe overarching set of ongoing processes and principles that underpin collective decision-\nmaking and encompasses both risk assessment and management, including consideration\nofthelegal,social,organisationalandeconomiccontextsinwhichriskisevaluated.Wehave\ndefinedsomeofthecoreterminologyusedaspartofthestructuredprocessesthatcapture\ninformation,perceptionsandevidencerelatingtowhatisatstake,thepotentialfordesirable\nandundesirableevents,andmeasuresoflikelyoutcomesandimpact\u2013whethertheybequal-\nitativeorquantitative.\nAmajoraspectofriskishumanperceptionandtoleranceofriskandwehaveframedthesein\ntheextantliteraturetoarguetheirsignificanceinriskgovernancealignedwithvaryingtypes\nof risk \u2013 routine, complex, uncertain and ambiguous. We have particularly drawn on factors\nthat influence the perception of risk and discussed how these link to the human factors of\ncyber security in the context of security culture. Training, behaviour change, creation ofcon-\nfidence and trust, and stakeholder involvement in the risk governance process have been\nhighlighted as crucial success factors. This is based on well-established literature that peo-\nple\u2019s intuition and bias will often outweigh evidence about risk likelihood if they believe the\nmanagementoftheriskisnottrustworthy,doesnotapplytothem,orisbeyondtheircontrol.\nWe need people to buy into risk governance rather than impose it upon them. Accordingly,\nwe introduced the concept of balancing accountability with learning, proposing that failures\nin the risk governance process should lead to feedback and improvement where individu-\nals that may have breached risk management policies should feel able to bring this to the\nattentionofriskmanagerswithoutfearofstigmatisation.\nWedifferentiatedbetweensystem-levelriskmanagementthatanalysestheriskofasystem\nas a whole and considers inter-dependencies between sub-systems; and component-level\nrisk management that focuses on risk to individual elements. A number of well-established\nrisk management methods from the systems and component perspectives were analysed\nwith core strengths of each highlighted and some insights into how the methods function,\ntheresources(humanandeconomic)required,andinformationgathering\/reportingrequire-\nments. While the core principles of risk \u2013 based around vulnerability, threat and impact \u2013\nexistacrossallmethods,thereareindividualattributes(wereferredtoasstrengths)ofeach\nmethodthatmaymakethemabetterfittoanorganisationdependingonwhattheriskstake-\nholders require as evidence of exposure. We reflected briefly on the context of safety in risk\nassessment for operational technology, which also included the growth of IoT and the need\ntoconsideradditionaldirectivesforcriticalnationalinfrastructurerisk.\nMeasuring security and the limitations of metrics were discussed in the context of possi-\nble options for security metrics, as well as differing views in the community on the benefits\nandlimitationsofmetricisedrisk.Finally,welinkedtoincidentresponseandrecovery,which\nKARiskManagementandGovernance |October2019 Page45 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nshouldprovideafeedbacklooptoriskmanagementplanningwithintheriskgovernancepro-\ncess. Even with the best laid plans, it is likely a breach of cyber security defences will occur\nat some pointand, in addition to the cultural aspects of learning andimprovements of staff,\nwe highlighted a number of key steps from international standards that are required to be\nconsideredaspartofthegovernanceprocess.\nRiskgovernanceisacyclicalanditerativeprocess,andnotsomethingthatcanbeperformed\nonce. The crosscutting aspects of communication, stakeholder engagement and context\nbind the risk assessment and management processes and are core to the continual reflec-\ntion and review of risk governance practices. Incidents, when they occur, must inform risk\nmanagement policy to improve cyber security in future \u2013 and we must accept that we will\nlikely never be completely secure. In line with this, human factors and security culture must\nrespond to the ever changing need to manage cyber risk, enabling and instilling continual\nprofessionaldevelopmentthrougheducationandJustCulturewherelessonscanbelearned\nandgovernancemethodsimproved.\nKARiskManagementandGovernance |October2019 Page46 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nCROSS-REFERENCE OF TOPICS VS REFERENCE MATERIAL\nSection Cites\n2.2Whatisrisk? [39,40,41]\n2.3Whyisriskassessmentandmanagementimportant? [40,41,42,43]\n2.4Whatiscyberriskassessmentandmanagement? [52]\n2.5Riskgovernance\n2.5.1Whatisriskgovernanceandwhyisitessential? [57,58,59]\n2.5.2Thehumanfactorandriskcommunication [60,61,62]\n2.5.3Securitycultureandawareness [63,64,65]\n2.5.4EnactingSecurityPolicy [65,66,67]\n2.6Riskassessmentandmanagementprinciples\n2.6.1Componentvs.SystemsPerspectives [52,69]\n2.6.2ElementsofRisk\n2.6.3Riskassessmentandmanagementmethods [66,70,71,72,73,75]\n2.6.4Riskassessmentandmanagementincyber-physicalsystemsand\n[47]\noperationaltechnology\n2.6.5SecurityMetrics [64,74]\n2.7Businesscontinuity:incidentresponseandrecoveryplanning [90,91]\nKARiskManagementandGovernance |October2019 Page47 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nKARiskManagementandGovernance |October2019 Page48 Chapter 3\nLaw & Regulation\nRobert Carolina Royal Holloway,\nUniversity of London\n49 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nNOTICEANDDISCLAIMER:Thisknowledgeareadoesnotconstitutethe\nprovisionoflegaladviceorlegalservicesandshouldnotbereliedupon\nassuch. Thework ispresented asan educationalaid forcyber security\npractitioners. Opinions expressed are solely those of the author. This\nwork does not represent official policy or opinion of the NCSC, the gov-\nernment of the United Kingdom, any state, any persons involved in its\nproduction or review, or any of their staff, employers, funders, or other\npersonsaffiliatedwithanyofthem.\nINTRODUCTION\nThe purpose of this knowledge area is to provide a snapshot of legal and regulatory topics\nthatmeritconsiderationwhenconductingvariousactivitiesinthefieldofcybersecuritysuch\nas:securitymanagement,riskassessment,securitytesting,forensicinvestigation,research,\nproductandservicedevelopment,andcyberoperations(defensiveandoffensive).Thehope\nistoprovideaframeworkthatshowsthecybersecuritypractitionerthemostcommoncate-\ngories of legal and regulatory risk that apply to these activities, and to highlight (where pos-\nsible)somesourcesoflegalauthorityandscholarship.\nThenatureandbreadthofthesubjectmatteraddressedrendersthisknowledgearea,andthe\nsources cited, a mere starting rather than ending point. Undoubtedly, some favoured, even\nsignificant,sourcesofauthorityandscholarshiphavebeenoverlooked.\nThe reader is assumed to hold no formal qualification or training in the subject of law. The\naudienceisfurtherassumedtobemultinational.Tomakethematerialpracticallyaccessible\ntosuchadiversebodyofcybersecuritydomainspecialists,subjectsarepresentedatalevel\nthat would be considered introductory for those who are already well educated in law or\npublicpolicy.\nThe rules of mathematics and physical sciences are both immutable and identical around\nthe world. Laws and regulations are not. The foundation of the world\u2019s legal and regulatory\nsystemshasformanycenturiesbeenbasedontheprincipleofterritorialsovereignty.Various\ninternationaleffortstoharmonisedifferencesinlawsandregulationshavemetwithvariable\ndegrees of success. In practice, this means that laws and regulations differ \u2013 sometimes\nsignificantly \u2013 from state to state. These differences are not erased simply because people\nactthroughtheinstrumentalityofcyberspace[95].\nThis knowledge area, however, addresses a multinational audience of practitioners who will\nbe called upon to conduct their activities under laws and regulations imposed by different\nstates-boththehomestateinwhichtheypractice,andforeignstateswithwhichtheymake\ncontact.Whilerespectingtherealitythatlegaldetails varybystate,thisknowledgeareawill\nattempttoidentifysomewidelysharednormsamongvarioussystemsofdomesticlawand\nregulation, and some aspects of public international law, that may (or should) influence the\nworkofthesecuritypractitioner.\nIn the search for generalisable norms that retain utility for the practitioner, this knowledge\narea focuses primarily on substantive law. Substantive law focuses on the obligations, re-\nsponsibilities, and behaviours, of persons. Examples include computer crime, contract, tort,\ndataprotection,etc.\nProceduralrulesaremostlyexcludedfromcoverage.Proceduralrulestendtofocusonman-\naging the dispute resolution process or specifying methods of communication with a state\nKALaw&Regulation |October2019 Page50 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nauthority. Examples include civil procedure,1 criminal procedure,2 and rules of evidence.3 Al-\nthoughthesearesignificanttotheadministrationofjustice,theyareoftenparochialinnature\nandboundupwithquirksoflocalpractice.Cybersecuritypractitionerswhoneedtobecome\nfamiliarwiththedetailsoftheserules(e.g.,forensicinvestigators,lawenforcementofficers,\nexpertwitnesses,andotherswhocollectorpresentevidencetotribunals)invariablyrequire\nspecialistguidanceortrainingfromrelevantlocallegalpractitionerswhounderstandthepro-\nceduralrulesofagiventribunal.4\nAs with many efforts at legal taxonomy, the difference between substance and procedure\nis imprecise at the boundary. The test for inclusion in this knowledge area is less to do with\ndiviningtheboundarybetweensubstanceandprocedure,andspringsinsteadfromthedesire\ntomakenormativestatementsthatremainusefultopractitionersinamultinationalcontext.\nSection 3.1 starts the knowledge area with an introduction to principles of law and legal re-\nsearch, contrasting the study of law and science and explaining the role of evidence and\nproof.Section3.2thenexploresvariousaspectsofjurisdictioninanonlineenvironment.\nSections3.3and3.4discussgeneralprinciplesofprivacylaw(includinginterceptionofcom-\nmunications) and the more detailed regulatory regime of data protection law. Section 3.5\npresents an outline of computer crime laws, and more specifically crimes against informa-\ntionsystems.\nSections3.6and3.7provideanintroductiontoprinciplesofcontractandtortlawofinterest\nto practitioners. Section 3.8 provides a general introduction to relevant topics in intellectual\nproperty,whileSection3.9providesanoverviewoflawsthatreduceliabilityofcontentinter-\nmediaries.\nSections 3.10 and 3.11 address a few specialist topics, with an exploration of rights and re-\nsponsibilities in trust services systems and a brief survey of other topics of interest such\nas export restrictions on cryptography products. Sections 3.12, 3.13, and 3.14, conclude the\nknowledgeareawithasurveyofpublicinternationallaw,ethics,andachecklistforlegalrisk\nmanagement.\nThe author of this knowledge area is trained in the common law5 (nearly ubiquitous in an-\nglophone territories) and experienced in international commercial legal practice conducted\nin London. Examples of legal norms are therefore drawn from common law (as interpreted\nby different states), various anglophone statutes and case decisions, European Union law,\nand public international law.6 The author welcomes thoughtful correspondence confirming,\nfurtherqualifying,orchallengingthenormativestatusofissuespresented.\nFinally, a note on terminology and presentation. \u2019Alice\u2019 and \u2019Bob\u2019 and similar terms are used\nin an effort to present ideas in a form likely to be familiar to security practitioners. There\nis one significant difference in how these terms are used. In most of the technical security\nliterature \u2019Alice\u2019 and \u2019Bob\u2019 refer to technological devices. In this knowledge area, however,\n\u2019Alice\u2019 and \u2019Bob\u2019 refer to persons.7 Unusually for CyBOK (but in common with legal research\nand scholarship) this knowledge area makes extensive use of notes. Notes are used for a\nvarietyofpurposes,includingprovidingspecificexamples,furtherexplanationofissues,and\nadditional argument in support of or against a given a proposition. In some circumstances\nnotes have been used to suggest potential future legal developments, subjects worthy of\nfurtherstudy,ortoprovideothercomments.8\nKALaw&Regulation |October2019 Page51 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nCONTENT\n3.1 INTRODUCTORY PRINCIPLES OF LAW AND LEGAL\nRESEARCH\nCyber security practitioners and researchers come from an incredibly wide array of educa-\ntionalbackgrounds.Experienceteachinglegalandregulatorysubjectstocybersecuritypost-\ngraduate students, and providing legal advice to cyber security practitioners, suggests that\nmuchofthisknowledgearea\u2019scontentwillbenoveltothosewhoseeducationisbasedinsci-\nence,technology,engineering,mathematics,manysocialsciences,andmanyofthehuman-\nities. These introductory observations are offered as an aid for those who are approaching\nthesubjectwithoutsignificantexperience.\n3.1.1 The nature of law and legal analysis\nAlthough the reader is assumed to have some degree of familiarity with the process of law\nmakingandlawenforcement,areviewofsomeofthemostcommonsourcesoflawshould\nhelptoorientthosewhoareunfamiliarwithlegalresearchandanalysis.\nLaw should be analysed with rigorous logic. Unlike scientific disciplines such as physics or\nmathematics, however, the study of law is not conceptualised as an effort to discover im-\nmutableprinciplesofourworld.Lawisboundtogetherwithsocialandpoliticalvalues,human\ndesire,andhumanfrailty[96].\nSociety influences the development and interpretation of law even as law influences the be-\nhaviour of members of society. Societies evolve and values change. Changes to law and to\nmethods of interpreting law tend to follow.9 This creates a number of challenges for legal\nscholarship,10 as the topic under study continues to change.11 Perhaps as a result the study\noflawisoftenpresentedintheformofhistoricaldialectic:examiningtheevolutionoflawand\nits interpretation over time, often through case studies. This method provides all-important\ncontext,aidsintheinterpretationoflawasitexists,andoftensuggeststhedirectionoffuture\ndevelopments.\nThestudyoflawendeavourstoshareatleastonecharacteristicwiththesciences:theability\ntopredictoutcomes.Whilescienceslikechemistrypredicttheoutcomeofeventssuchasthe\nintroductionofsolidsodiumtoliquidwater,thestudyoflawattemptstopredicttheoutcome\nofdisputessubmittedtoasuitablyexpertlegaltribunal.Althoughthestudyoflawcannever\npredictoutcomesofdisputewith100%certainty,instateswithwell-developedsystemsoflaw\nandwell-qualifiedadjudicators,itispossibletoachieveadegreeofpredictabilityofoutcome\nthatissufficientlyhightomaintainconfidenceinthesystemasawhole.12\nLegal studies often begin with a mechanistic review of the governance processes surround-\ningtheadoptionandenforcementoflaw.Lawsaremade(legislativeauthority),lawsareinter-\npreted(judicialauthority),andlawsareenforced(executiveauthority).Understandingdiffer-\nent governance structures adopted by states to manage these three processes requires an\nexaminationofcomparativeconstitutionallawwhichisbeyondthescopeofthisknowledge\narea.\nMost legal research and analysis proceeds on the basis of argument from authority, drawn\nfromananalysisofhistoricaltextsthatembodyexpressionsoflaw.Therefollowafewobser-\nvationsaboutdifferingsourcesoflegalauthorityandhowthesevaryindifferentcontexts.No\nKALaw&Regulation |October2019 Page52 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nstandardsbodyexiststoharmonisethedefinitionoflegaltermsofartastheyareusedbydif-\nferentstates.Confusionoverlegalterminologyisthereforecommonplaceinamultinational\ncontext.\nPrimarylegislation.Inbothcommonlaw13andcivillaw14jurisdictions,primarylegislation(typ-\nicallyastatutesuchasanActofParliamentintheUK,oranActofCongressintheUS)isthe\nmosteasilyunderstoodembodimentof\u2019thelaw\u2019.Incivillawjurisdictionsprimarylegislation\ntypicallytakestheformofadoptingoramendingacomprehensivelegalcode.15 Astatute(a\nlawpromulgatedbyalegislature)shouldbedistinguishedfromabill(adraftlawwhichmay\normaynotbeadoptedasastatute)16 whichnormallyhasnoforceoflaw.17\nSecondary legislation. Sometime a degree of law-making authority is delegated by a senior\nlegislativebody(suchastheUKParliamentortheUSCongress)tosomeotheragencyofthe\nstate (such as the Foreign Minister of the UK or the US Commerce Department). Delegation\nis often made for reasons of technical expertise, or the need for frequent periodic review of\nadopted rules. Laws promulgated by such subordinate agencies are generally termed sec-\nondarylegislation.Theterm\u2019regulation\u2019issometimesusedcolloquiallytorefertosecondary\nlegislationasdistinctfromprimarylegislation.\nEuropeanUnionlegislation.A\u2019Directive\u2019oftheEuropeanUnion(formerlyEuropeanEconomic\nCommunity) is a specific type of primary legislation addressed to the member states of the\nUnion. Each member state is required to examine the terms of the Directive, and then to im-\nplement these terms within its own domestic law within a specified time frame. Directives\nare normally said to lack \u2019direct effect\u2019 in member state law, with some exceptions. By con-\ntrast,aEuropeanUnion\u2019Regulation\u2019constitutesimmediatelyapplicablebindinglawwithinall\nmemberstates.18\nJudicialdecisions.Incommonlawjurisdictions,thepublisheddecisionsofdomesticcourts\nthat interpret the law tend to constitute significant and binding interpretative authority de-\npending upon the seniority and jurisdiction of the court. Decisions by the courts of foreign\nstates may constitute persuasive authority, or indeed their interpretation of the law may be\nignored entirely.19 In civil law jurisdictions, the decisions of judges are generally accorded\nlessinterpretiveauthoritythansimilardecisionsinacommonlawjurisdiction.\nCodes.Inlegalresearch,\u2019code\u2019canrefertoanysystemisedcollectionofprimarylegislation,20\nsecondary legislation,21 model laws,22 or merely a set of rules published by public or private\norganisations.23\nRestatements of the law. A restatement of the law is a carefully constructed work, normally\nundertaken by a committee of legal experts over a number of years, which seeks to explain,\nclarify,andcodifyexistinglaw.Althoughrestatementsarenotnormallyconsideredasource\nofmandatoryauthority,ascarefullyconsideredexpressionsofexpertopiniontheyareoften\nextremelyinfluential.24\nTreaties.Treatiesareinstrumentsofagreementamongandbetweenstates.Insomestates,\nthe legal terms of a treaty are automatically carried into operation of a contracting state\u2019s\ndomestic law once the state has fully acceded to the treaty. In others, domestic law is not\namended unless and until the domestic legislature acts to amend domestic law in accor-\ndancewiththetreatyrequirements.(PublicinternationallawisdiscussedinSection3.12.)\nScholarly articles. Within common law jurisdictions, scholarly articles written by legal aca-\ndemicscanconstituteatypeofpersuasive,albeitweak,authority.Judgestypicallyadoptthe\narguments of legal scholars only to the extent that the scholar\u2019s work persuades a jurist to\nKALaw&Regulation |October2019 Page53 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nadopttheirview.Inmanycivillawsystems,bycontrast,scholarlyarticlesbyleadinglegalaca-\ndemics may be accorded significant deference by tribunals who are called upon to interpret\nthelaw.\n3.1.2 Applying law to cyberspace and information technologies\nThebirthofcyberspacecausedagreatdealofanxietywithregardtotheapplicationoflaws\nandregulationstothisnewdomain.\nTwo prevailing schools of thought emerged. The first school posited that cyberspace is so\nradically different from anything in human experience, that old laws were unsuitable and\nshould be widely inapplicable to actions taken using this new domain. Law makers and\njudges were encouraged by this school to re-examine all doctrines afresh and to abandon\nlargeswathesofprecedentwhenconsideringdisputes.Radicalproponentsofthisviewwent\nsofarastodenytheauthorityofsovereignstatestoenforcelawsandregulationsinthecon-\ntextofInternet-relatedactivities[97].\nThe second school held instead that the Internet is, like so many tools developed in human\nhistory,merelyaninstrumentalityofhumanaction.Assuch,lawscould\u2013andperhapsshould\n\u2013continuetobeappliedtopersonswhousecyberspaceinmostrespectsjustastheyapplied\nbeforeitexisted[98,99,100].Membersofthissecondschooldescribeda\u2019cyberspacefallacy\u2019\n\u2013 the false belief that cyberspace was a legal jurisdiction somehow separate and distinct\nfromrealspace[101].25\nForthetimebeing,thesecondschoolhasalmostuniversallyprevailedwithstateauthorities\n[95,102,103,104].Thepractitionerisconfrontedwiththerealitythatexistinglaws,somecen-\nturiesoldandsomeamendedorbornaneweachyear,areappliedbystates,theirlawmakers,\njudges, police and defence forces to cyberspace-related activity whether or not cyberspace\nwasexpresslycontemplatedbythosesamelaws.26\nOnemustbecautiouswhenattemptingtomaplegalrulesontoactivities.Whilelawyersand\nlegalscholarsdividethelawintoneatcategories,real-lifeandcyberoperationsdonotalways\nfitneatlywithinasinglecategory.Forexample,asingledataprocessingactionthatdoesnot\ninfringe copyright and is not defamatory may still constitute a violation of data protection\nrights. Any given action should be assessed by reference to whatever laws or regulations\npresent risk. The problem of conflicting obligations that can arise as a result of multi-state\nregulationisintroducedinSection3.2.\nPractitioners increasingly ask questions concerning the application of law to artificial intel-\nligence. Laws are generally framed to influence and respond to the behaviours of persons,\nor to address the disposition or use of property. (This can be seen in the discussion of en-\nforcement jurisdiction in Section 3.2.3.) Instances of artificial intelligence are not currently\ndefinedaspersonsunderthelaw.27 ThereforeanAI,assuch,cannotbeguiltyofacrime,en-\nterintoacontract,ownproperty,orbeliableforatort.IfanobjectcontrolledbyanAIcauses\nharm,thelawwouldnormallybeexpectedtolookbeyondtheAItothepersonswhocreated\nor made use of it and the responsibility of such persons would be assessed using existing\nlegalstandards.ThissubjectisexploredbrieflyinSection3.7.2,whichtouchesuponcircum-\nstanceswherepersonscouldbecomestrictlyliableforAI-relatedactionswhichcausedeath\norpersonalinjury.28\nKALaw&Regulation |October2019 Page54 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.1.3 Distinguishing criminal and civil law\n3.1.3.1 Criminallaw\nCriminallawisthebodyoflawthatprohibitsbehaviourgenerallyabhorredbysociety.Crimi-\nnallawisnormallyenforcedbyanagencyofthestate.Examplesincludeprohibitionsagainst\nbank fraud and computer hacking. Depending upon the society in question, the purposes of\ncriminallawareusuallydescribedassomecombinationof:\n\u2022 deterrence(seekingtodeterbadbehaviour,forbothmembersofsocietygenerallyand\nacriminalspecifically);\n\u2022 incapacitation(limitingtheabilityofthecriminaltofurtherharmsociety);\n\u2022 retribution(causingacriminaltosuffersometypeoflossinresponsetocrime);\n\u2022 restitution(causingacriminaltocompensateavictimorsomerelatedperson);\n\u2022 rehabilitation(seekingtochangethelong-termbehaviourofacriminal).\nTerms such as \u2019guilty\u2019 and \u2019innocent\u2019 are normally reserved as descriptions of verdicts (out-\ncomes) in a criminal case. These terms should not be used when referring to outcomes of\ncivilactions.\nPunishmentsavailableincriminallawincludecustodialprisonsentences,criminalfinesnor-\nmallyremittedtothestate,seizureandforfeitureofcriminalproceeds,andfinancialorother\nrestitutionremittedtovictims.\nThere is often no requirement for an accused to have understood that their actions were\ndefined as criminal, although states normally must prove that the accused intended to take\nthose actions. Some crimes are defined in a fashion that guilt only attaches if the state can\nprove that the accused was aware that they were doing something \u2019wrong\u2019.29 An accused,\ntherefore,maynotbeabletoescapecriminalliabilitybysuggesting,orevenproving,thatan\nactwasundertakenwithgoodintentionsorotherwise\u2019inthepublicinterest\u2019.30\n3.1.3.2 Civil(non-criminal)law\nCivillaw31istheareaoflawthatregulatesprivaterelationshipsamongandbetweenpersons.\nExamplesincludethelawsofcontractandnegligence.Apersoninjuredasaresultofbreach\nofcivillawcannormallybringlegalactionagainsttheresponsibleparty.\nRemediesavailableundercivillaw(dependingonthecircumstances)mayincludesomecom-\nbinationof:\n\u2022 anorderfortheliablepartytopaycompensationtotheinjuredparty;\n\u2022 anordertoterminatesomelegalrelationshipbetweentheparties;\n\u2022 anorderfortheliablepartytodiscontinueharmfulactivity;or\n\u2022 anorderfortheliablepartytotakesometypeofaffirmativeact(e.g.,transferringown-\nershipofproperty).\nThe principles of civil law are often crafted in an effort to redress negative externalities of\nbehaviourinamoderneconomy.Thismakescivillawespeciallyinterestingincybersecurity,\naspoorsecurityinthedevelopmentofICTproductsandservicesisasadlyrecurringnegative\nexternality that often falls short of criminal behaviour [105]. Policy makers hope that people\nKALaw&Regulation |October2019 Page55 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nwhobecomeawarethatcertaintypesofrisk-takingcarryanassociatedliabilityforresulting\nharmwillaltertheirbehaviourforthebetter.\n3.1.3.3 Oneact:twotypesofliability&twocourts\nA single act or series of connected acts can create liability simultaneously under both crim-\ninal and civil law. Consider the act of Alice making unauthorised access to Bob\u2019s computer.\nHer actions in turn cause Bob\u2019s LAN and related infrastructure to fail. Alice\u2019s single hacking\nspreeresultsintwotypesofliability.ThestatecanprosecuteAlicefortherelevantcrime(i.e.,\nunauthorisedaccess,seeSection3.5)andBobcanbringacivillegalaction(i.e.,negligence,\nseeSection3.7.1)againstAlice.\nThe two types of legal action would normally be contested in two separate tribunals, and\nsubjecttotwodifferentstandardsofproof(seeSection3.1.4).32 Thepurposeofthecriminal\ncaseistoprotecttheinterestsofsocietyasawhole,whilethepurposeofthecivilcaseisto\ncompensateBob.\n3.1.4 The nature of evidence and proof\nTheconceptof\u2019proof\u2019inlawisdifferentfromthetermasitisusedinthefieldofmathematics\norlogic.Thiscancreateconfusionindiscussionsofcybersecuritytopicsandthelaw.\nInlaw,to\u2019prove\u2019somethingmeanssimplytousepermissibleevidenceinanefforttodemon-\nstrate the truth of contested events to a fact finder to a prescribed degree of certainty. Per-\nmissibleevidencecantakeavarietyofforms.Subjecttotherulesofdifferentlegalsystems,\nevidencemightincludedirectwitnesstestimony,businessrecords,correspondence,surveil-\nlancerecords,recordingsofinterceptedtelephoneconversations,33 serverlogs,etc.34\nAsagrossgeneralisation,legalanalysisinadisputeconsistsoftwoelements.A\u2019factfinder\u2019\n(ajudge,jury,regulator,etc.)mustfirstconsidercompetingversionsofeventsandestablisha\nfactualnarrativeor\u2019finding\u2019.Thisfactualnarrativeisthensubjectedtoanalysisunderrelevant\nlaw.\nA person who brings a legal action is said to carry the burden of proof with respect to the\nelements that define their right of action. This is also known as proving the claiming party\u2019s\nprima facie case. An accused then bears the burden to prove affirmative defences which\nmightservetoreduceoreliminatetheirliability.35\nTheapplicablestandardofproof,whichistosaythedegreeofcertaintythatmustbeachieved\nbythefactfindertoreachafindingonagivencontestedissue,dependsupontheissueunder\nconsideration.Anon-exhaustivesampleofdifferentstandardsofproofusedinvariouslegal\ncontextsispresentedinTable3.1.\nKALaw&Regulation |October2019 Page56 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.1.5 A more holistic approach to legal risk analysis\nThose who approach the study of law for the first time often fall victim to seeing only one\naspect of the law: \u2019the rules\u2019. More specifically, the elemental framework from a given law\nwhich defines the evidentiary burden to be met by a person seeking to prove the guilt or\nliabilityofasecondperson.Thisignoresotherfactorsthatmustbetakenintoaccountwhen\nanalysinglegalrisk.\nConsider a circumstance in which Alice has some right of action against Bob. (Alice could\nbeastateconsideringprosecutionofBobforacrimeorAlicecouldbeapersonconsidering\na civil law suit against Bob for breach of contract or tort.) Alice might pursue a legal action\nagainst Bob, or she might not. If Alice pursues legal action against Bob, she might win the\nactionorshemightlose.Bobmusttakedifferentfactorsintoconsiderationwhenanalysing\ntherelevantriskofAlicetakinglegalaction.\nItmayaidunderstandingtoconsiderafunction:\nR = f(P,D,Q,X)\ninwhich:\nR =the risk-weighted cost to Bob that Alice will commence and win this\nlegalaction;\nP =Alice\u2019srelativeability(usingadmissibleevidence)toproveherprimafa-\nciecaseagainstBob(adjustedbyBob\u2019sabilitytorebutsuchevidence);\nD =Bob\u2019s relative ability (using admissible evidence) to prove any affirma-\ntive defence that might reduce or eliminate Bob\u2019s liability (adjusted by\nAlice\u2019sabilitytorebutsuchevidence);\nQ =thetotalcosttoBob(otherthantransactioncosts)ifAlicepursuesand\nwinsherlegalaction;and\nX =avarietyofadditionalfactors,suchasAlice\u2019swillingnessandabilityto\ncommencelegalaction,Bob\u2019swillingnessandabilitytodefend,Alice\u2019s\nability to secure enforcement jurisdiction over Bob or his assets, plus\ntransaction costs such as investigation costs, legal costs, and court\ncosts.\nThepurposeofthefunctionaboveismerelytohighlightthatlegalriskanalysisinvolvesmore\nthanconsiderationof\u2019therules\u2019.36Thus,thediscussionsofsubstantivelawinthisknowledge\narea (e.g., data protection, criminal law, contract, tort) begin with some examination of the\nframeworkusedtoproveliability(P).Discussionalsotouchesonsomeaffirmativedefences\n(D) as well as relevant penalties and remedies (Q). The knowledge area gives significant,\nseparate, consideration to the problem of jurisdiction (which falls within X). In assessing\neach of these factors, one must also consider the probative value of available evidence as\nwellastherelevantstandardofprooftobemetineachelement(seeSection3.1.4).\nSome areas of risk, such as risks related to transaction costs including mechanisms that\nmay shift some transaction costs from winner to loser (which also fall within X), are highly\nindividualisedandprocess-orientedandbeyondthescopeofthisknowledgearea.\nTheissuesintroducedheresignificantlyunderpintheobservationsconcerninglegalriskman-\nagementinSection3.14.\nKALaw&Regulation |October2019 Page57 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nStandard of Degree of Certainty Re- Examplecontext\nproof quired\nBeyond a rea- Extremely high. Almost Statesaremostoftenrequiredtomeetthis,orasimilar\nsonabledoubt. incontrovertible. No other standard,inprovingtheelementsofacrimeforafact\nreasonable explanation findertoholdanaccusedpersonguilty.Thishigherstan-\nexists to make sense of dard is heavily influenced by notions of human rights\ntheevidence. lawbecauseindividuallifeandlibertyareatstake.\nClear and Reasonablyhighcertainty. This standard of proof is used in US law, for example,\nconvincing Much more than simply whenacourtisaskedtoinvalidateapreviouslygranted\nevidence. \u2019probable\u2019. patent. The burden of proof placed upon the person\nseekingtoinvalidatethepatentissethighbecausethis\nwould deprive a rights-holder of property previously\ngrantedbythepatentoffice.\nThis phrase is also used to describe the standard\nto be met by prisoners who challenge the validity of\ntheir criminal conviction in US federal courts using\na habeas corpus petition long after normal routes of\nappealhavebeenexhausted.Inthiscircumstance,the\nhigher standard is required as a means of preserving\nthe integrity of the original criminal justice process\n(including the original appeals) while not foreclosing\nallpossibilityofpost-convictionreview.37\nPreponderance Moreprobablethannot. The most common formulations of the standard of\nofevidence. proofrequiredtoprevailinacivilcase.\nGreaterthan50%.\nBalance of\nprobabilities. When weighed on the\nscales of justice, the\nevidence on one side is\nat least a feather-weight\ngreaterthantheother.\nProbablecause. The evidence suggests The standard required in the US to persuade a judicial\nthatthetargetofaninves- officertoissueasearchwarrantorarrestwarrant.This\ntigation has committed a standard serves to filter out trivial or unsubstantiated\ncrime, although evidence requeststointrudeintoprivacyordetainasuspect.\nisnotyetconclusive.\nReasonablesus- The standard typically required in the US to justify a\npicion. police officer temporarily stopping and questioning a\nperson.Thislowerstandardisoftenjustifiedonpolicy\ngrounds of minimising threats to the safety of police\nofficers.\nThis phrase has also been suggested by the United\nNations High Commissioner for Human Rights on the\nright to privacy in the digital age as a threshold for\njustifyingstateelectronicsurveillance[106].\nTable3.1:ExampleStandardsofProof\nKALaw&Regulation |October2019 Page58 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.2 JURISDICTION\n[95,107,108,109,110,111]\nCyberspaceenablespersonslocatedindifferentstatestocommunicatewithoneanotherin\nafashionthatisunprecedentedinhistory.Once-unusualinternationalcontactsandrelation-\nships have become commonplace. Those who face a potential threat of enforcement by a\nperson in a foreign state must consider a few threshold questions before the relevant legal\nriskcanbeanalysed:jurisdictionandconflictoflaw.\nJurisdiction describes scope of state authority and the mechanisms used by a state to as-\nsert power. Private international law, or conflict of law, examines how to determine which\ndomesticstatelaw(s)willbeappliedtoresolvecertainaspectsofagivendispute.Thissec-\ntion of the knowledge area discusses jurisdiction. Conflict of law is addressed separately in\nthecontextofindividualsubstantiveheadingsoflaw.\nMany of the principles concerning jurisdiction and conflict of law are not new. What has\nchanged are the larger numbers of people who benefit from considering these principles\nnowthatpersonsarefacingcross-borderlegalresponsibilitiesatincreasedrates.\n3.2.1 Territorial jurisdiction\nTheterm\u2019jurisdiction\u2019isoftenusedinaratherinformalmannertorefertoastate,oranypo-\nliticalsub-divisionofastate,thathastheauthoritytomakeorenforcelawsorregulations.38\nInthissense,thetermisnearlysynonymouswiththeterritoryofthatstateoritspoliticalsub-\ndivision. The purpose of this section, however, is to focus more specifically on the territorial\nextentofastate\u2019spower\u2013itsterritorialjurisdiction.39\nWhen reviewing legal risks from multi-state activities conducted via cyberspace, it may be\nhelpful to consider three different aspects of jurisdiction: prescriptive jurisdiction, juridical\njurisdiction,andenforcementjurisdiction.\nPrescriptive jurisdiction describes the scope of authority claimed by a state to regulate the\nactivities of persons or take possession of property. Law makers normally adopt laws for\nthe purpose of protecting the residents of their home state and may declare their desire to\nregulatetheactionsofforeign-residentpersonstotheextentthatsuchactionsareprejudicial\ntohomestate-residentpersons.\nJuridicaljurisdictiondescribestheauthorityofatribunaltodecideacaseorcontroversy.The\nrules of such jurisdiction vary widely from tribunal to tribunal. In civil cases, courts usually\ndemand a minimum degree of contact between the residential territory of the court and the\npropertyorpersonagainstwhichlegalactionistaken.Suchminimumcontactmightinvolve\nobvious examples such as the presence of a branch office. It might be extremely minimal,\nindeed, resting upon little more than correspondence soliciting business from a resident of\nthe court\u2019s territory.40 In the context of criminal prosecutions, courts normally demand the\nphysicalpresenceof anaccused before proceedingscommence.Some statesallow courts\ntomakeexceptionstothisruleandarepreparedtoconductacriminaltrialinabsentiaifthe\ndefendantcannotbefoundwithintheterritorialjurisdictionofthecourt.\nEnforcementjurisdictiondescribestheauthorityofastatetoenforcelaw.Thisissometimes\ndescribedaspolicepower,powertoarrestanddetain,authoritytouseforceagainstpersons,\netc. In civil matters, this may describe other methods used to project force over persons or\nproperty resident in a territory, such as seizing plant and equipment, evicting tenants from\nKALaw&Regulation |October2019 Page59 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nproperty, garnishing wages, seizing funds on deposit with a bank, etc. In practice, enforce-\nmentjurisdictionislimitedbytheabilityofthestateanditsagentstoprojectpoweroverthe\nobjectsofenforcement.41\n3.2.2 Prescriptive jurisdiction\nIthaslongbeencommonplaceforstatestoexertadegreeofprescriptiveandjuridicaljuris-\ndictionovernon-residentpersonswhosolicitbusinessrelationshipswithresidents.Atheory\noftenespousedisthatnon-residentpersonswhoremotelysolicitorenterintobusinessrela-\ntionships with residents avail themselves of the benefits of the domestic market and, there-\nfore,becomeamenabletotherulesofthatmarket.ThisprinciplelongpredatestheInternet.\nMore controversial are cases where a non-resident person is not soliciting business from\na state resident but may nonetheless be acting in a fashion which somehow harms state\nresidents. Some of the best-known examples arise in competition law (a.k.a. anti-trust law).\nThese cases follow a familiar pattern. A cartel of persons who produce commodities (e.g.,\nbananas,aluminium,woodpulp,diamonds)outsideofthestate\u2019sterritory,conveneameeting\nthatalsotakesplaceoutsidethestate\u2019sterritory.Inthismeetingthecartelmembersconspire\ntofixthewholesalepricesofagivencommodity.Thiskindofoffshoreprice-fixingconspiracy,\nwhich would be disallowed if it took place within the state\u2019s territory, eventually results in\ninflated prices inside the state as well. The only communication between the prohibited act\n(price fixing) and the state is the price inflation in the overseas (exporting) market, which in\nturncausesinflationofdomestic(importing)marketprices.\nAtthestartofthetwentiethcenturythenotionofapplyingastate\u2019sdomesticcompetitionlaw\nto such overseas activity was considered wholly inappropriate [112]. The growth of interna-\ntional trade in the modern economy, however, caused courts to reconsider this position. US\ncourts decided in 1945 that extending prescriptive jurisdiction to foreign price-fixing activity\nwas justified due to the consequential harm to the domestic market and the sovereign inter-\nest in protecting the functioning of that market [113]. A substantially similar (if not identical)\ndoctrine was announced in 1988 by the European Court of Justice when applying European\ncompetition law [114, 115]. Although these jurisdictional theories have been criticised, they\narenowexercisedroutinely.\nStates also claim prescriptive jurisdiction over some actions taken by their own nationals\nwhile present in a foreign state even if no express \u2019effect\u2019 is claimed within the territory of\nthe home state. Examples include laws prohibiting bribery of foreign officials [116] and laws\nagainstchildsextourism[117,118].Statesmayalsoclaimprescriptivejurisdictionoverviolent\nactscommittedagainstastate\u2019sownnationalsoutsideofthestate\u2019sterritorybyanyperson,\nespeciallyincasesofterrorism.42\nInstances where more than one state claims jurisdiction over a single act or occurrence are\nnotuncommon.Claimsofprescriptivejurisdictiontendtobefoundedonnotionsofprotect-\ning the interests of a state and its residents. Some of the rules of jurisdiction have been\nadopted with a view to reducing instances where persons might face irreconcilable conflict\nbetween the mandates of two states. Although such irreconcilable conflicts are less com-\nmon than some might believe, they still arise from time to time. In cases where a person\nfaces an irreconcilable conflict of mandates imposed by two states, the person is required\nto make hard choices. For businesses, these choices often involve changing business pro-\ncesses,structureorgovernancetoavoidorlimitthepotentialforsuchconflicts.\nKALaw&Regulation |October2019 Page60 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.2.2.1 Prescriptivejurisdictionoveronlinecontent\nNumerous court decisions around the world have confirmed the willingness of states to\nassert prescriptive jurisdiction over actions where criminal or tortious content originates\nfrom outside of the state\u2019s territory, is transferred via the internet, and displayed within the\nstate\u2019s territory. Examples of laws that have been enforced on this basis include copyright,\ndefamation, gaming\/gambling services, and state-specific subject matter prohibitions such\nas the prohibition against displaying or offering for sale Nazi memorabilia within France\n[95,107,108,119].\nThese exercises of jurisdiction do not necessarily rest on the more attenuated \u2019effects doc-\ntrine\u2019 used in competition law. Courts seem willing to interpret domestic law in a fashion\nwhich asserts prescriptive jurisdiction, and then to assert their own juridical jurisdiction on\nthe basis that content is visible to persons within the state irrespective of the location of\nthe server from which it originates. In this fashion, the offending act (e.g., copying, publish-\ning,transmitting,displaying,offeringforsale)issaidtotakeplacewithinthestateasserting\njurisdiction.\n3.2.2.2 Prescriptivejurisdictionovercomputercrime\nStatesadoptingcomputercrimelawsoftenlegislatetoincludecross-borderacts.Asaresult,\nit is common for a state with such laws on their books to exercise prescriptive jurisdiction\nover persons \u2013 no matter where they are located \u2013 who take actions directed to computer\nequipmentlocatedwithinthestate.Similarly,personswhoactwhilephysicallylocatedwithin\nthe state\u2019s territory are often caught within the scope of the criminal law when conducting\noffensive operations against computers resident in foreign states [109, 110, 111, 120, 121].\nPublic international law recognises such exercises of prescriptive jurisdiction as a function\nofterritorialsovereignty([104]atR.1-4,R.10).\nWhenahackerwhoisphysicallypresentinonestatedirectsoffensiveactivitytoacomputer\ninanotherstate,thathackermayviolatethecriminallawofbothstates.Iftherelevanthack-\ning activity does not constitute a crime in the first state for whatever reason,43 it may still\nconstitute a crime under the law of the second state where the target computer is located\n[120,121].\n3.2.2.3 Prescriptivejurisdictionanddataprotection(GDPR)\nGDPR brought about a significant change in the territorial prescriptive jurisdiction of Euro-\npeandataprotectionlaw[122].\nGDPR,incommonwithitspredecessor1995legislation,appliesfirsttoany\u2019processingofper-\nsonal data in the context of the activities of an establishment of a controller or a processor\nintheUnion,regardlessofwhethertheprocessingtakesplaceintheUnionornot\u2019(Art.3(1)).\nTheterm\u2019establishmentofacontroller\u2019asusedinEUdataprotectionlawgenerally,isextraor-\ndinarilybroadwhencomparedwithothercommonlyunderstoodlegalprinciples.Creatingor\nmaintaininganestablishmentintheterritoryoftheEUmerelymeanstheabilitytodirectbusi-\nness affairs or activities. This definition is not restricted by the usual niceties of corporate\norinternationaltaxlaw.AholdingcompanyintheUS,forexample,canbedeemedtohavea\npersonaldataprocessingestablishmentintheEUthroughthenon-processingactivitiesofits\nwholly owned subsidiary [123]. Thus, legal persons that have no \u2019permanent establishment\u2019\nor \u2019taxable presence\u2019 in the EU for purposes of analysing direct tax liability may nonetheless\nKALaw&Regulation |October2019 Page61 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nbe deemed to be carrying out data processing in the context of an \u2019establishment\u2019 in the EU\nforthepurposesofanalysingGDPRliability.\nGDPRnowalsoassertsprescriptivejurisdictionoverthepersonaldataprocessingactivities\nof any person, anywhere in the world, related to offering goods or services to data subjects\nin the EU (Art. 3(2)(a)). Prescriptive jurisdiction is believed to extend only to circumstances\nwhenthesuppliervolitionallyofferssuchgoodsorservicestodatasubjectsintheEU.\nFinally, GDPR applies to any person who monitors the behaviour of data subjects located in\nthe EU, to the extent that this monitored behaviour \u2019takes place in\u2019 the EU (Art. 3(2)(b)). This\nheading of jurisdiction appears to have been motivated primarily by the emergence of ser-\nviceswhichmonitorandanalyseavarietyofhumanbehavioursincludingactionsperformed\nbypersonsusingwebbrowsers,orphysicalmovementpatternsexhibitedbypersonsonthe\ngroundsuchasshoppingbehaviour.\nPersonslocatedoutsidetheEU,whoarenonethelesssubjecttotheprescriptivejurisdiction\nof GDPR because they offer goods or services to, or monitor the behaviour of, persons resi-\ndentintheEU,areoftenrequiredtoappointarepresentativeintheEU(Art27;Recital80).\nInterpretingthescopeofGDPR\u2019sterritorialjurisdictionalcanbedifficult,especiallygiventhe\nrapid emergence of new forms of online services. The European Data Protection Board is\nexpectedtofinaliseformalguidanceinduecourse[124].\n3.2.3 Enforcement jurisdiction\nWhileitisrelativelyeasytoimagineastateexercisingbroadprescriptiveandjuridicaljurisdic-\ntion over activities and controversies, more difficult questions arise with respect to enforce-\nmentjurisdiction:howastatepracticallyenforcesitsrules.\nAs a general proposition, one state has no right under public international law to exercise\nenforcementjurisdictionwithintheterritoryofanotherstate([104]atR.11).44\nThissectionconsiderssomeofthemorecommonenforcementmechanismsusedbystates\nin a cyber security context. Enforcing the law tends to turn on three different mechanisms\nof state power: power over persons (in personum jurisdiction), power over property (in rem\njurisdiction),andrequestsordemandsforinternationalassistance.\n3.2.3.1 Assetseizureandforfeituregenerally\nIt is common to assert in rem jurisdiction over the property or other legal rights that are\npresentwithinastate\u2019sterritoryandamenabletothatstate\u2019spolicepowers.Thestatemight\nseize such property in an effort to compel attendance at court proceedings, or eventually\nsell the property to meet the financial obligations of an absent person. Examples of objects\nseized for this purpose include immovable property such as office buildings or factories,\nmovable property such as plant and equipment, trucks, maritime vessels, or merchandise\nin transit, and intangibles such as intellectual property rights or rights to withdraw funds on\ndepositwithabank.\nKALaw&Regulation |October2019 Page62 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.2.3.2 Seizureandforfeitureofservers,domainnames,andregistries\nWhen a server located in a state is used to conduct activity that constitutes a crime in that\nstate, seizing the server as an enforcement mechanism might be considered. Moving be-\nyond the server, however, US law enforcement authorities have also used in rem jurisdiction\nfor seizure and forfeiture of domain names where the domain TLD registry is maintained in\ntheUS.Actionsforinfringementoftrademarkrightshaveusedsimilarinrempowersfordo-\nmainnameseizureandforfeiture.ThisisapotentiallyinterestingenforcementtoolintheUS,\nespecially as TLD registries administered and maintained from within the territory of the US\ninclude\u2019.com\u2019,\u2019.org\u2019and\u2019.net\u2019[125,126].\nSimilarinrempowershavebeenassertedbyvariousstatestoregulatetheadministrationof\nthe ccTLD registry associated with their state, or to forcibly transfer the administration and\noperationoftheccTLDtoadifferentin-stateadministrator[127].45\n3.2.3.3 Territoriallocationoftherighttodemandrepaymentofbankdeposits\nEffortstoenforcelawsthatfreezeorotherwiserestrictdepositoraccesstofundsondeposit\nhaveraiseddifficultquestionsabouttheterritorialscopeofstateenforcementauthority.As-\nset freeze orders directed to enemy states or their citizens are not unusual, especially at\ntimesofinternationalconflict.\nAcasehighlightinglimitsofthispowerarosefromthe1986orderissuedbytheUnitedStates\nmandatingthefreezeofassetsheldbythestateofLibya.ThisorderbytheReaganadminis-\ntration was unusual. In addition to mandating the freeze of money on deposit in the United\nStates,italsoorderedanyUSpersonwhomaintainedeffectivecontroloveranybankaccount\nanywhereintheworldtofreezemoneyondepositinanyoftheseglobalbankaccounts.\nTheLibyanArabForeignBank(astate-ownedLibyanbank)tooklegalactionagainstUSbanks\nin the courts of England demanding the repayment of deposits (denominated in US dollars)\nheldinLondonbranches.TheresultingEnglishcourtjudgmentmakesforinterestingreading,\nas the court discussed at length the extensive role of electronic funds transfer systems in\ninternationalbankingatthattime.Havinglookedatthequestion,however,thedematerialised\nnature of funds transfers ultimately had almost no impact on the outcome of the case. The\ncourt held that money deposited with the London branch of a bank constitutes a legal right\nforthedepositortodemandpaymentofthatmoneyinEngland[128,129].46\nInotherwords,abankaccountmaybeconceptualisedasbeingsituatedwithintheterritoryof\nthestateinwhichthebranchtowhichthedepositismadeislocated.Thisanalysiscontinues\ntoapplyiftherelationshipiscarriedoutentirelythroughonlineinteractions,andindeedeven\nifthedepositorremainsoffshoreandneverattendsthebranchinperson.\nKALaw&Regulation |October2019 Page63 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.2.3.4 Foreignrecognitionandenforcementofciviljudgments\nA civil judgment issued by the court of one state may under certain circumstances be en-\nforcedbythecourtsofafriendlysecondstate.Thisisnormallyachievedwhentheprevailing\nparty transmits the judgment to the courts of the second state where the adverse party has\nassets, requesting enforcement of the judgment against those assets. Foreign recognition\nandenforcementofciviljudgmentsisoftengrantedundertheprincipleofcomity:adoctrine\nwhichcanbeexpressedinthiscontextas,\u2019Wewillenforceyourciviljudgmentsbecause,as\nafriendlystate,weanticipateyouwillenforceours.\u201947\nA foreign court\u2019s willingness to enforce such civil judgments is not universal. Requests for\ncivil enforcement are sometimes rejected for policy reasons. Nonetheless, this remains a\nrelativelycommonmechanisminthecontextofjudgmentsformoneydamagesarisingfrom\nmanycontractandtortdisputes.\n3.2.3.5 Thearrestofnaturalpersonsinstateterritory\nItisnormallystraightforwardforpoliceofficerstoarrestpersonspresentwithintheirstate\u2019s\nterritory.Whenacriminalsuspectisoutsidethestate\u2019sterritory,officialsaresometimesable\nto arrest that suspect when they subsequently appear in state \u2013 whether or not it was an\nintended destination. Law enforcement officers can normally arrest the accused upon their\narrivalinstateterritory.48\nStateauthoritiescannormallyexercisethepowerofarrestonanyseagoingvesselwithinthe\nstate\u2019s territorial waters, as well as vessels registered under the flag of the arresting state\nwhenininternationalwaters.Additionalmaritimeenforcementscenariosarepossible[130].\n3.2.3.6 Extraditionofnaturalpersons\nIf an accused criminal is not present within the state, a traditional method of obtaining cus-\ntody is to request extradition from another state [109, 111]. Extradition is normally governed\nby bilateral extradition treaties, and is normally only allowed when the alleged criminal act\nconstitutesacrimeinbothstates(therequirementofdualcriminality).\nIftwostatesthatarecontractingpartiestotheBudapestConvention(seeSection3.5.1)main-\ntain a bilateral extradition treaty between them, the Convention obliges them to incorporate\nwithintheirextraditionproceduresthosecomputercrimesmandatedbytheConvention.The\nConventioncan(optionally)alsoserveasanindependentlegalbasisforextraditionbetween\ntwocontractingstateswhichdonotmaintainabilateralextraditiontreaty[120]atArticle24.\nExtradition has a troubled history in cyber security. Extradition requests for accused cyber\ncriminals might be denied by another state for a number of reasons: lack of an extradition\ntreatybetweenthetwostates,lackofdualcriminality,publicpolicyconcernsovertheseverity\nofpunishmenttobeimposedbytherequestingstate,andconcernsforthehealthorwelfare\nof the accused, are all reasons that have been cited for refusal to grant the extradition of\npersonsaccusedofcybercrime[107].\nKALaw&Regulation |October2019 Page64 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.2.3.7 Technologicalcontentfiltering\nTechnologicalinterventioncanbeadoptedasapracticalexpressionofstatepower\u2013either\nby a state directly ordering such intervention, or by other persons adopting a technical inter-\nventiontoavoidorlimitliability.\nContentfilteringismerelyonetypeoftechnologicalinterventionthatcanbeusedtoenforce\nlawortoreducetheriskofadverseenforcementactivity.Thisapproachfitsgenerallywithin\ntheconceptexploredbyLawrenceLessigandexpressedwiththephrase,\u2019codeislaw\u2019[98].49\nAn enforcing state can direct an enforcement order to a person mandating that they filter\ncontentatthepointoforigination,whetherthecontentishostedonanin-stateorout-of-state\nserver[119].Suchanordercarrieswithittheimplicitorexplicitthreatthatfailuretoimplement\ntheordercouldresultintheuseofother,moreaggressive,enforcementmechanismsdirected\ntoin-statepersonsorproperty.\nIf an out-of-state person who originates or hosts offending online content from out-of-state\ninfrastructurefailsorrefusestofilterit,theenforcingstatemightlooktoothertechnologically-\nbased enforcement methods. A state might issue an order to in-state ISPs to block the in-\nstate receipt of offending content [131]. Although such technical mechanisms are far from\nperfect (as is the case with any border enforcement technology), they may be sufficiently\neffectivetoaccomplishthepurposeoftheenforcingstate.\nFiltering efforts are also initiated in the absence of specific state enforcement activity. Per-\nsonscreateandimposetheirownfiltersatpointoforigintolimitcontenttransferstostates\nwhere filtered content might result in liability.50 Filtering efforts can be conducted collabora-\ntivelybetweenprivateandpublicsectoractors.51\n3.2.3.8 Orderstoin-statepersonsdirectingproductionofdataundertheircontrolwhether\nheldondomesticorforeignITsystems\nStatesmayalsoorderstate-residentpersonstoproducedataundertheircontrol,irrespective\noftheterritoriallocationofdatastorage.\nSuch orders are especially common under court procedural rules that govern disclosure\n(a.k.a. discovery) of potential evidence by the parties to a dispute. Those who find them-\nselves party to a dispute that is subject to the jurisdiction of a foreign court must quickly\nbecome familiar with that court\u2019s rules of mandated disclosure. Courts normally do not feel\nconstrained by the location of potential evidence \u2013 only that the parties to the dispute dis-\ncloseitasrequiredaccordingtoforumcourtrules.\nMore controversial are cases where a state, often in the context of a criminal investigation\nor intelligence gathering operation, demands the production of data under the control of a\nstate-residentpersonwhoisnotthetargetof(criminal)investigationorapartyto(civil)legal\naction.Criticsclaimthatsuchdemandsareinappropriateandthestateshouldbelimitedto\nsubmittingrequestsforinternationallegalassistance(seeSection3.2.3.9).Supportersargue\nthatsuchdemandsrepresentalegitimateexerciseofstateenforcementjurisdictionagainst\npersonspresentwithinstateterritory.\nAnearlyexampleinvolvedapreviouslysecretprograminwhichtheUnitedStatesdemanded\nlawful access to banking transaction records held by SWIFT. The orders to produce data\nwereaddressedtoUS-residentSWIFToffices.FailuretocomplywiththeUSdemandscould\nhave resulted in criminal prosecution of US-resident persons under US law. Complying with\nKALaw&Regulation |October2019 Page65 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nthese demands, however, very probably constituted a violation of the data protection law of\nBelgium(SWIFT\u2019sheadquarters),amongothers.Newsoftheprogrammeleakedin2007and\ncreated a diplomatic dispute between the US and Belgium (among others). This diplomatic\nissue was eventually resolved through negotiation and agreement concerning the scope of\nfutureinvestigatoryoperations[132].\nAnotherwell-knownexampleinvolvedarequestmadebyanunknownagencyoftheUSgov-\nernmentundertheStoredCommunicationsAct.ThegovernmentaskedtheUScourttoissue\nanordertotheMicrosoftCorporationintheUSdemandingtheproductionofthecontentsof\nanemail accountmaintainedbyMicrosoft onbehalfof anunnamedcustomerwhowas not\nresident in the US. The US court issued the order to Microsoft in the US, although the email\naccountitselfwasmaintainedonaserverinadatacentreinDublin,Ireland.US-residentstaff\nofMicrosofthadthetechnologicalabilitytoaccessthecontentsoftheDublinserver,andthe\nactofproducingtherequesteddatawouldhavebeentechnologicallytrivial.Microsoftasked\nthe court to quash (invalidate) this order, generally on the grounds that the relevant US law\ndidnotauthoriseanorderofthistypewithrespecttodatastoredoffshore.\nAfter multiple skirmishes in the District court, the US Court of Appeals (2nd Circuit) eventu-\nallyquashedtheorderagainstMicrosoftontheextremelynarrowbasisthattheStoredCom-\nmunications Act (adopted in 1986) did not expressly and unambiguously claim prescriptive\njurisdiction over data stored on equipment located outside the territorial United States [133,\n134, 135].52 This decision was appealed to the US Supreme Court where it was fully briefed\nandargued.Followingargumentbutbeforejudgment,theUSCongressin2018adoptedthe\nCLOUD Act. This legislation amended the Stored Communications Act to bring data stored\non foreign servers expressly into the prescriptive jurisdiction of that Act, and the US gov-\nernment immediately requested a replacement warrant under the revised law. The Supreme\nCourtthendismissedthependingappealwithoutissuingasubstantivejudgment,asthenew\nlaw had resolved any dispute about the scope of prescriptive jurisdiction claimed by the US\nCongress[136].53\n3.2.3.9 Internationallegalassistance\nStates can make requests for assistance from persons outside of their territory to gather\nevidenceinsupportofcriminalinvestigation.Traditionally,suchrequestsaremadepursuant\ntoamutuallegalassistancetreatyandaretransmittedbytheauthoritiesofafirststatetothe\ndesignatedauthorityofasecondstateforconsiderationandpossibleaction.Suchrequests\ncan also be made in the absence of a treaty, although the second state retains discretion\noverhowitchoosestorespondintheabsenceofinternationallegalobligation.\nThe Budapest Convention (see Section 3.5.1) imposes a series of requirements upon con-\ntracting states to provide mutual legal assistance in the investigation of cybercrime [120].\nThe Convention also sets a series of requirements concerning preservation of electronic ev-\nidence,includingmetadata.\nFormalstate-to-staterequestsformutuallegalassistancehavegainedareputationforbeing\nheavily bureaucratic and slow [109]. Although there are many examples of successful inter-\nnationalcooperationintheinvestigationofcybercrime,ithasbeenobservedthat\u2019theuseof\nformalcooperationmechanismsoccursonatimescaleofmonths,ratherthandays\u2019[137].\nTherearesomeoptionsavailabletogathercross-borderevidencethatdonotinvolveseeking\npermissionfromthestateinwhichevidenceresides.TheBudapestConventionprovidestwo\nadditional methods. Authorities of a given Convention State A may gather evidence from\nKALaw&Regulation |October2019 Page66 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\npublicly available (open sources) of data stored in a given Convention State B without prior\nnoticetoorauthorisationfromStateB [120]atArticle32a.\nConvention State A is also said to be allowed to use a computer in the territory of State A\nto access data from a closed source in Convention State B if State A \u2019obtains the lawful\nand voluntary consent of the person who has the lawful authority to disclose the data\u2019 [120]\nat Article 32b. A formal Guidance Note to the Convention cites the example of a criminal\nsuspectdetainedinStateAwhoprovidesconsenttoStateAauthoritiestoaccesstheiremail\nordocumentsstoredonaserverinStateB [138].54\nArticle 32b has been discussed at length by the Council of Europe\u2019s Cybercrime Convention\nCommittee (T-CY). An ad hoc subgroup of this Committee set out an extensive discussion\nof issues arising and specific examples in which use of this authority might be considered\n[139].The Committeeitself wenton to publisha Guidance Notewhich clarifiesthe authority\ngrantedbyArticle32b[138].\nPractitioners should note that Article 32 powers are permissive, not prohibitive. If State A\nis unable to demonstrate that a proposed evidence gathering activity complies with Article\n32bthisonlymeansthattheactivityisnotexpresslyauthorisedbytheBudapestConvention.\nArticle 32 of the Convention would not prohibit the proposed activity, although some other\nfeaturesofpublicinternationallawmight.SeeSection3.12.4.\nCriticsarguethatArticle32bconstitutesanunwelcomeintrusionintostatesovereignty.This\nhasbeencitedbysomestatesasareasonforrefusingtosigntheBudapestConvention([140]\natp.19,fn.39).\nAnothercross-borderinvestigationmethodintheabsenceofconsentbythesecondstateis\ndescribedinSection3.2.3.8.\n3.2.4 The problem of data sovereignty\nThe phrase \u2019data sovereignty\u2019 is sometimes used to struggle with the various jurisdictional\ndemandsoutlinedabove.Theextremelylowtechnologicalcostofstoringandthenretrieving\ndata outside the territory of a state, raises concerns about the number of states that might\nseektocompelsomeformofinterventionwithrespecttosuchdata.\nCloudservicesmerelyprovide\u2019asenseoflocationindependence\u2019ratherthanactuallocation\nindependence [141]. The location of a service provider\u2019s infrastructure and the location of\npersonswhomaintaineffectivecontroloverthatinfrastructurearebothimportantforunder-\nstandingwhichstatesmightbeabletoassertenforcementjurisdictionmandatingsometype\nofinterventionwithrespecttosuchdata[142].55\nUsersofcloudserviceshavebecomeincreasinglyawarethatlocatingadatastoragefacility\ninanygivenstateincreasesthatstate\u2019sopportunitytoexerciseenforcementjurisdictionover\nsuchfacilities.Practitionersshouldalsoconsiderenforcementjurisdictionopportunitiespre-\nsented to a state when persons within its territory have technical or organisational ability to\naccess or otherwise interfere with data held on infrastructure physically outside that state.\n(See the discussion in Section 3.2.3.8.) Enforcement risk can arise from the geo-location of\ndatastorageequipment,orthegeo-locationofpersonsabletoaccesssuchdata.56\nSomestateshaverespondedtopotentialjurisdictionalconflictsbymandatinglocalstorage\nand processing (localisation) for some types of data. Indeed, under its data protection laws\ntheEuropeanUnionhaslongimposedanEEAlocalisationrequirement(intheformofarule\nKALaw&Regulation |October2019 Page67 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nprohibiting export) for personal data although in practice there are multiple mechanisms\navailable to enable exports from the EEA (see Section 3.4.6). Other states outside the EEA\nhaveimposedlocalisationrequirementsforavarietyofreasons[143,144,145,146,147].\nSome states within the EEA have imposed single-state data localisation rules for certain\ntypesofsensitivedata,prohibitingexportseventofellowmemberstatesoftheEEA.Possibly\nin response to this single state localisation trend, the European Union adopted a Regulation\nin2018thatprohibitsmemberstatelegalrestrictionsonthefreemovementofnon-personal\ndata within the Union. (I.e., the Regulation does not prohibit member states from adopting\ndatalocalisationrequirementsforpersonaldata.)ThisRegulationalsoincludesmultipleex-\nceptions for member states that wish to impose localisation requirements for reasons of\nimportantpublicpolicy[148].57\n3.3 PRIVACY LAWS IN GENERAL AND ELECTRONIC\nINTERCEPTION\nThe concept of \u2019privacy\u2019 is both widely cited and challenging to articulate. This section ad-\ndresses privacy in the sense described in the seminal nineteenth century article, \u2019The Right\ntoPrivacy\u2019[149].Inthiscontext,privacyhasbeendescribedsimplyastherightforaperson58\ntobefreefromintrusionbyothersintopersonalaffairsorthe\u2019righttobeleftalone\u2019.\nIntheworkofacybersecuritypractitioner,theissueofprivacymostoftenarisesinthecon-\ntext of electronic surveillance and related investigatory activity, which is the focus of this\nsection. This area of law can be expected to continue to evolve quickly in response to new\nusecasesenabledbyclouddataprocessingservices.\nDataprotectionlawisaddressedinSection3.4andcrimesagainstinformationsystemsare\nconsidered in Section 3.5. Most of these areas of law stem from or are related to privacy\nconcepts.\n3.3.1 International norms: foundations from international human rights\nlaw\nPrivacyiswidelyrecognisedinternationallyasahumanright,althoughnotanabsoluteright.59\nTherighttoprivacyisconditional\u2013subjecttolimitationsandexceptions.\nThe 1948 Universal Declaration of Human Rights states at Art 12 that, \u2019No one shall be sub-\njectedtoarbitraryinterferencewithhisprivacy,family,homeorcorrespondence...\u2019[150].Free-\ndomfrominterferencewithprivacyextendsonlyto\u2019arbitrary\u2019interference,whichclearlycon-\ntemplatesthelegitimacyof\u2019non-arbitrary\u2019interference.Similarexpressions,withsimilarqual-\nifications,canbefoundinArticle8oftheEuropeanConventiononHumanRightsandagain\ninArticle7oftheCharterofFundamentalRightsoftheEuropeanUnion[151].60\nIn the more narrow context of limiting government authority, the Fourth Amendment of the\nUSConstitutionadoptedin1791states,\u2019Therightofthepeopletobesecureintheirpersons,\nhouses, papers, and effects, against unreasonable searches and seizures, shall not be vio-\nlated,andnowarrants[authorizingsearchorseizure]shallissue,butuponprobablecause...\u2019\n[152].Again,thisrightislimitedtoprotectonlyagainstsuchactionsthatare\u2019unreasonable\u2019.\nThe application of these principles to intangible data evolved significantly during the twenti-\neth century. In 1928, for example, the US Supreme Court interpreted the Fourth Amendment\nKALaw&Regulation |October2019 Page68 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nnarrowly as protecting persons only from physical intrusion into their property [153]. Four\ndecadeslater,afterelectroniccommunicationhadbecomeaubiquitousfeatureofeveryday\nlife, the Court changed its position and re-interpreted the Fourth Amendment to protect per-\nsons from unwarranted intrusion into electronic communications. The 1967 Court observed\nthat laws like the Fourth Amendment are intended to \u2019protect people not places\u2019 [154]. The\nprivacy right expressed in the European Convention on Human Rights has long been under-\nstoodtoapplytoelectroniccommunications[155].Bytheearlytwenty-firstcenturyitappears\nto have become a widely accepted international norm that privacy rights (however they are\ninterpreted)applytointangibleexpressionsofinformationaswellasphysicalspace[156].\nWhiletheprinciplesdescribedabovearewidelyacceptedintheinternationalcommunity,the\ninterpretation and implementation of these principles remains subject to significant diver-\ngence. Some laws extend a general right of privacy into almost every situation, while others\nfocussolelyonlimitingthepowerofthestatetointrudeintoprivateaffairs.61\nA given person\u2019s expectation of privacy may vary by reference to the nature of their relation-\nship with the party who seeks to intrude. For example, there tend to be few restrictions im-\nposedbyanystate\u2019slawswithrespecttointrusionbyaparentintotheaffairsoftheirminor\nchildren. By contrast, states vary significantly when considering when it is appropriate for\nemployerstointrudeintotheaffairsoftheiremployees.Inthelattercontext,theUNhaspub-\nlished recommended approaches to the application of human rights in a business setting\n[157].\nExpectations of privacy can also vary significantly between different societies. An intrusion\nviewedbyonesocietyasrelativelyinnocuousandtobeexpectedmightbeviewedbyanother\nsocietyasabreachofhumanrights.\nAs persons rely on cloud services to manage increasingly intimate aspects of their lives, ex-\npectations of privacy over the variety of data processed using these systems will continue\nto evolve.62 Policy makers, service providers, and civil society organisations, regularly seek\ntoexplainortoadjustexpectationsofprivacythrougheducationandadvocacy.\nAnadditionalaspectofprivacyrelatestolimitsimposeduponthedegreeofpermittedintru-\nsion.Incasesofstate-warrantedlawfulinterception,forexample,warrantsmaybenarrowly\ndrawntolimitinterceptiontonamedplaces,specifiedequipment,specifiedpersons,orspec-\nifiedcategoriesofpersons.\nPrivacy laws often treat metadata differently from content data, usually based on the the-\nory that persons have a lower expectation of privacy in metadata [158].63 This distinction is\nincreasingly criticised, and policy makers and courts are under pressure to reconsider the\nnatureofmetadatagiven:\n\u2022 theprivatequalityofsomeinformationdisclosedbymodernmetadatasuchasURLs,64\n\u2022 theincrediblegrowthinthevolumeandtypesofmetadataavailableintheageofubiq-\nuitouspersonalmobiledatacommunications;65 and\n\u2022 the growing volume of otherwise-private information that can be inferred from meta-\ndatausingmoderntrafficanalysisandvisualisationtechniques.66\nKALaw&Regulation |October2019 Page69 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.3.2 Interception by a state\nState intrusion into electronic communication for purposes of law enforcement or state se-\ncurity is often treated under specialist legal regimes that are highly heterogenous. There is\nbroad agreement in public international law dating to the mid-nineteenth century that each\nstatehastherighttointerceptorinterruptelectroniccommunicationsinappropriatecircum-\nstances[159].Theseprinciplescontinuetoapplytocyberspace[104,160].\nAs electronic communications (especially telephones) became commonplace and intercep-\ntionmethodsbecamemorecost-effectiveinthe1960sand1970s,atrendemergedtomove\nstate interception of communications activity away from informal or customary practice\nonto a more clearly regulated footing [155, 161]. Although legal governance processes and\nstandardsadoptedtoauthorisestateinterceptionhaveevolvedsignificantly,theselegalpro-\ncessesand standardsdiffer significantlyfrom stateto state.Some statesrequire aprior ex-\naminationofeachrequestforstateinterceptionbyanindependentjudicialofficer;somedel-\negate this decision-making authority broadly with limited oversight; and others adopt mech-\nanismsthatfallanywherebetweentheseextremes.\nAlthough there does not yet appear to be any obvious international harmonisation of le-\ngal standards and procedures concerning lawful interception, there are examples of recom-\nmended practice for states that wish to place their legal procedures onto a robust and pre-\ndictablefoundation[162].\nBy contrast, some technical standards for facilitating lawful access (such as the ETSI LI se-\nries) have developed successfully on a multilateral basis [163, 164]. These technical stan-\ndardsmakeitpossibleforproductandservicedeveloperstodesignlawfulaccesstechnolo-\ngies to a common multinational standard, while leaving substantive decision-making about\ntheiruseinthehandsofdomesticauthorities.67\nPractitioners who work in a police or state security environment must become familiar with\nthe rules that apply to their interception activity. Some state organisations employ large\nteamsoflawyersdedicatedsolelytoassessingthelegalityofvariousintelligence-gathering\nandinvestigationactivities.\nThose who work for communication service providers must also become familiar with obli-\ngationsimposedonthembyapplicablelawstoassistinstateinterceptionactivity.Thiscan\nbeespeciallychallengingformultinationalcommunicationserviceproviders,astheyarenor-\nmally subject to the prescriptive jurisdiction of each state where their service is supplied.68\nService providers often localise responsibility for compliance with lawful interception by do-\nmesticauthoritiesineachstatewheretheysupplyservices.\nStateregulationsconcerninglawfulinterceptiontendtoimposeacombinationofobligations\nupontheprovidersofpubliccommunicationsservices,suchas:\n\u2022 procuringandmaintainingfacilitiesdesignedtofacilitatelawfulinterceptionwithinthe\nservice provider\u2019s domain (this obligation may be imposed under telecommunication\nregulation as a condition of telecommunications licensing, especially for those that\noperatein-statephysicalinfrastructuresuchasPSTNoperators);\n\u2022 providingtechnicalassistanceinresponsetolawfulinterceptionrequests;and\n\u2022 maintaining the secrecy of the content of lawful interception requests, especially the\nidentityofinvestigationtargets.\nKALaw&Regulation |October2019 Page70 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nSome states impose additional legal obligations to maintain secrecy over the existence, na-\nture, or frequency, of lawful interception requests, the location or operation of interception\nfacilities,etc.Communicationserviceprovidersthatwishtoreportpubliclyaboutthenature\nandfrequencyofstateinterceptionrequests(a.k.a.transparencyreports)mustbecarefulto\nconductthisreportingincompliancewithapplicablelaw.69\nAs easy-to-use cryptographic technologies have become ubiquitous, and larger volumes of\nmessage traffic are transmitted as ciphertext, states conducting lawful access activity face\nincreasingdifficultyobtainingaccesstoplaintextmessages[161].Stateshaveattemptedto\nrecover plaintext by using a variety of creative legal mechanisms including warrants for the\nphysicalsearchandseizureofendpointdevicesandrequestsfortechnicalassistancefrom\ndevicemanufacturersorthird-partyanalysts.Theseproceduresareofvariableeffectiveness\nandremainsubjecttomuchdebate[161].Effortstocompelanendusertodecryptciphertext\nortodiscloserelevantpasswordsorkeysalsofaceavarietyoflegalchallenges[165,166].70\nSome states have adopted laws that specifically address compelled disclosure of plaintext\norkeysthatenabledecipherment.71\nThe emergence of virtual communication service providers (i.e., those that provide commu-\nnication services via third-party infrastructure \u2013 or \u2019over the top\u2019 service providers) have cre-\nated challenges for both states and service providers. These service providers remain sub-\nject to the jurisdiction of states in which their service is supplied, as states show a clear\nsovereign interest in services provided to persons within their territory.72 States have, how-\never, taken different approaches when choosing how and when to exercise jurisdiction over\nthese providers. Enforcement actions by states against such persons have included orders\nto facilitate in-territory lawful interception at the risk of a variety of sanctions including: pro-\nhibitingtheserviceproviderfromenteringintobusinessrelationshipswithin-stateresidents,\nor ordering third-party state-resident service providers to block or filter such services at the\nPSTN or IP layer, thus making it inaccessible to (many or most) in-state residents. Changes\ninenforcementpracticesarelikelyasthissubjectcontinuestodevelop.\n3.3.3 Interception by persons other than states\nLawsconcerninginterceptionactivitybynon-stateactorsarealsohighlyheterogenous.\nPersons that provide public telecommunications services are often specifically restricted\nfrom intercepting communications that transit their own public service networks [134, 167].\nThis might be framed legally as a restriction imposed only on providers of these public ser-\nvices,oramoregeneralrestrictionlimitingtheabilityofanypersontointerceptcommunica-\ntionsonpublicnetworks.\nInmanycases,effortstointerceptcommunicationswhiletransitingathird-partynetworkwill\nalsoconstituteacrimeundercomputeranti-intrusionlaws.Thiswasasignificantmotivating\nfactorintheadoptionoftheselaws(seeSection3.5).\nThe interception of communications by a person during the course of transmission over its\nownnon-publicnetwork,suchasinterceptiononarouter,bridgeorIMAPserveroperatedby\nthat person on their own LAN for purposes other than providing a public communications\nservice, presents other challenges to analysis. This type of interception activity would not\nnormally expect to fall foul of traditional computer crime legislation, as the relevant person\nisnormallyauthorisedtogainentrytotherelevantcomputer(seeSection3.5).Itmight,how-\never,beregulatedgenerallywithinthesamelegalframeworkusedtogoverntheinterception\nof communications, although interception by an owner\/controller on their own system is of-\nKALaw&Regulation |October2019 Page71 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nten treated more liberally [167]. Finally, in-house interception activity may also be limited by\nthetermsofgeneralprivacystatutesordataprotectionlaws(seeSection3.4).\n3.3.4 Enforcement of privacy laws \u2013 penalties for violation\nEnforcing a legal right of privacy brings a number of challenges. From an evidentiary per-\nspective,apersonwhoseprivacyrightshavebeenviolatedmightneverlearnthataviolation\nhas occurred. Some legal rules serve, among other things, to redress this knowledge imbal-\nance.Theseincludebreachnotificationrequirementswhichrevealinappropriatedisclosures\nof personal data to the effected person (see Section 3.4.7), criminal procedure rules that re-\nquire the disclosure of prosecutorial evidence to the accused which in turn reveals intrusive\ninvestigatorytechniques,73 andcivilprocedureruleswhichrequiresimilardisclosuresincivil\nlegalactions(e.g.,employmentdisputes).\nRemediesavailabletopersonswhoseprivacyrightshavebeenviolatedmightincludetheabil-\nity to bring a tort action against the violator claiming monetary compensation (see Section\n3.7.4).Theseindividualtortremediesarearegularfeatureofdataprotectionlawsaswellas\nvariousUSprivacylaws.TheUScriminalcourtsalsoemployanexclusionaryruleprohibiting\nthe introduction of evidence gathered in violation of the US Constitutional privacy rights of\ntheaccused[168].74\nFinally,someviolationsofprivacy\u2013especiallyunwarrantedinterceptionofcommunications\nduring the course of transmission on a public network or unauthorised intrusions into data\natrest\u2013aredefinedasandmaybeprosecutedascrimes[169].\n3.4 DATA PROTECTION\n[107,108,170,171]\nDataprotectionlawdevelopedfromafoundationofgeneralprivacylaw.Thisgeneralisation\ncanbeabitmisleading,however,asdataprotectionlawhasevolvedtoaddressanumberof\nrelatedissuesthatarisefrommoderndataprocessingtechniquesthatmightnottraditionally\nhavebeendefinedas\u2019privacy\u2019.\nDataprotectionisofsignificantinteresttocybersecuritypractitioners,asitincludesnumer-\nousobligationsrelatedtodatasecurity.Thissectionwillfocusprimarilyonissuesthatrecur\ninasecurity-relatedcontext.Dataprotectionlawisnot,however,ageneralisedsystemofreg-\nulationsthataddresseveryaspectofcybersecurity.Thefocusremainsonspecificprinciples\nadoptedtosupportindividualrightsinadataprocessingcontext.\nData protection law has developed primarily from European legislative initiatives. European\nUnionlawhasbeentremendouslyinfluentialaroundtheworldthroughvariousmechanisms,\nincluding states seeking \u2019adequacy determinations\u2019 from the European Union, which enable\nexports of personal data, and private law contract requirements imposed upon non-EU res-\nident data processors [172]. This international impact continues to grow as the EU now ex-\npressly claims prescriptive jurisdiction over personal data processing activity anywhere in\ntheworldthatrelatestodatasubjectspresentintheEU(seediscussioninSection3.2.2.3).\nThefoundationallawsthatdefinedataprotectionobligationsintheEUareRegulation2016\/679\n\u2013GDPR(EU-wideregulationapplicabletomostpersons)andDirective2016\/680(obligations\nto be imposed by member states in domestic law in the context of investigation or prosecu-\ntionofcrimebythestate)[122,173].75 Thissectionprimarilyaddressesobligationsimposed\nKALaw&Regulation |October2019 Page72 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nbyGDPR.Practitionersengagedbyastateinconductrelatedtoinvestigationorprosecution\nof crime must be aware of the modified obligations that apply to that activity described by\nDirective2016\/680astransposedintomemberstatelaw[174,175].\n3.4.1 Subject matter and regulatory focus\nThe overriding purpose of EU data protection law is to protect the interests of data subjects\n(GDPRatArticle1;Recital1,2,4,75,78,etal.).76Dataprotectionlawaccomplishesthisbyreg-\nulating acts of controllers and processors when processing data that incorporates personal\ndata. Any such processing activity activates the application of data protection law. Each of\nthesetermsisconsideredinthissection.\n3.4.1.1 Datasubject,personaldata(andPII)\nIndataprotectionlaw,theterms\u2019personaldata\u2019and\u2019datasubject\u2019aredefinedconcurrently:\npersonal data means any information relating to an identified or identifiable natural per-\nson(\u2019datasubject\u2019);anidentifiablenaturalpersonisonewhocanbeidentified,directlyor\nindirectly,inparticularbyreferencetoanidentifiersuchasaname,anidentificationnum-\nber, location data, an online identifier or to one or more factors specific to the physical,\nphysiological,genetic,mental,economic,culturalorsocialidentityofthatnaturalperson\n(GDPR,Art4(1))\nOnlynaturalpersons,notlegalpersons,aredatasubjects.GDPRdoesnotapplytopersonal\ndataofdeceasednaturalpersons,althoughmemberstatesmayindividuallyadoptsuchpro-\ntectionsiftheywish(GDPRatRecital27).\nBecause the definition of data subject extends to persons who are identified or identifiable,\ndatacanincorporatepersonaldataevenwhenthedataincludenoobviousinformationiden-\ntifying a data subject. It is sufficient that a data subject is capable of being identified, by\nanyone, through analysing the data or by applying additional information known to any per-\nson-evenifthisadditionalinformationisunknownandinaccessibletothepersoncontrolling\norprocessingdata.Pseudonymiseddataremainspersonaldata(GDPRatRecital26).\nThe Court of Justice of the European Union has held that a server log with IP address num-\nbersincorporatespersonaldata,asitremainspossibleforthirdparties(telecommunications\nservice providers) to match static or dynamic IP numbers to individual customer premises\nand from there to a living person. This made some server log entries \u2019related to\u2019 a data sub-\nject [176]. The fact that the holder of the server logs did not have access to the IP number\nallocationorcustomeridentificationdatawasirrelevant.\nAsde-anonymisationandsimilaranalysistechniquesincreasethecapabilitytoidentifyliving\npersonsfromdatathathasnoobviouspersonalidentifiers,itbecomesincreasinglydifficult\ntomaintaindatasetsthataretrulydevoidofpersonaldata[177,178].77\nTheterm\u2019personaldata\u2019isoftenconfusedinpracticewith\u2019personallyidentifiableinformation\u2019\n(PII). This confusion arises because of the ubiquity of the term \u2019PII\u2019 in cyber security as well\nassignificantvarianceinitsdefinition.\nDefinitions and detailed discussions of PII are found in Section 4.4 of ISO\/IEC 29100:2011,\nand Section 2.1 of NIST SP-800-122 [179, 180]. Although it is arguable whether the ISO and\nKALaw&Regulation |October2019 Page73 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nNIST definitions of PII are contiguous with the legal definition of personal data, both tech-\nnical standards clearly conclude that data containing no obvious personal identifiers may\nnonethelessconstitutePII.\nComplicating matters further, the phrase \u2019personally identifiable information\u2019 is used in a va-\nriety of US federal statutes and regulations, either without statutory definition, or with defi-\nnitions specifically addressed to individual use cases [181].78 In this specific context, some\nUS courts have interpreted this phrase narrowly to include only obvious personal identifiers.\nThus some US courts have held that data such as MAC codes and IP numbers do not fall\nwithinthemeaningof\u2019personallyidentifiableinformation\u2019asthatphraseisusedinsomeUS\nstatutes [182, 183, 184].79 As explained above, these same identifiers often constitute \u2019per-\nsonaldata\u2019asthattermisdefinedinEuropeanlaw.\nIrrespectiveofhowonedefinesPII,Europeandataprotectionlawcontainsaclearandbroad\ndefinition of \u2019personal data\u2019. It is this definition of personal data, not PII, that triggers the\napplicationofEuropeandataprotectionlaw.80\n3.4.1.2 Processing\nIndataprotectionlaw,thetermprocessingisdefinedas:\nanyoperationorsetofoperationswhichisperformedonpersonaldataoronsetsofper-\nsonal data, whether or not by automated means, such as collection, recording, organisa-\ntion, structuring, storage, adaptation or alteration, retrieval, consultation, use, disclosure\nbytransmission,disseminationorotherwisemakingavailable,alignmentorcombination,\nrestriction,erasureordestruction(GDPR,Art4(2))\nProcessingthereforeincorporatesalmostanyactiononecanimaginetakingwithrespectto\npersonaldata.\n3.4.1.3 Controllerandprocessor\nIndataprotectionlaw,thetermcontroller isdefinedas:\nthe natural or legal person, public authority, agency or other body which, alone or jointly\nwith others, determines the purposes and means of the processing of personal data;\nwhere the purposes and means of such processing are determined by Union or Mem-\nberStatelaw,thecontrollerorthespecificcriteriaforitsnominationmaybeprovidedfor\nbyUnionorMemberStatelaw(GDPR,Art4(7))\nIndataprotectionlaw,thetermprocessor isdefinedas:\nanaturalorlegalperson,publicauthority,agencyorotherbodywhichprocessespersonal\ndataonbehalfofthecontroller(GDPR,Art4(8))\nThesedefinitionsmakecleartherelationshipbetweencontrollerandprocessor.Acontroller\ndecides; a processor executes. In the history of data protection law, many policy makers\noriginallybelievedthatthemosteffectivewaytoprotectindividualrightswastofocusregula-\ntiononpersonswhooperatedandmaintainedcomputerequipment\u2013processors.Thefocus\nwas on the machine. As the PC revolution changed our social relationship with computers,\nKALaw&Regulation |October2019 Page74 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nhowever, policy makers began to appreciate that the focus should be turned to persons in a\npositiontocommandandcontrolhowthemachineswereused\u2013controllers.\nAs between these two persons, Directive 95\/46 tended to place the heaviest regulatory bur-\nden on controllers. Processors were advised that their obligation consisted primarily of fol-\nlowing directions provided by controllers. There are many valid reasons for placing primary\ncompliance responsibility on data controllers, especially because they are most often able\ntocommunicateandmanagerelationshipswiththerelevantdatasubjects.\nThis regulatory distinction started to break down as cloud services became ubiquitous \u2013\nespeciallySaaS.AtypicalSaaSprovidermightspendanenormousamountoftimeandeffort\ndesigningtheirsystemanduserinterfaces,andthenpresenttheoperationalcharacteristics\nof that system to controller-customers in a service level agreement on a \u2019take it or leave it\u2019\nbasis. As a technical matter, the SaaS provider might be keen to demonstrate that they are\nactingonlyinthecapacityofaprocessorandthattheircustomersareactingascontrollers\u2013\nshiftingtheburdenofassessingcompliancetoindividualcontrollers.Intherevisionstodata\nprotectionlawembodiedinGDPR,policymakershaverespondedbygenerallyincreasingthe\nregulatory responsibility of processors. Compliance responsibility under GDPR is now more\nevenlysharedbycontrollersandprocessors,althoughtheirresponsibilitiesdependupontheir\nrespectiveareaofcompetence.\n3.4.2 Core regulatory principles\nDataprotectionlawisbuiltonafoundationofregulatoryprinciplesgoverningprocessingof\npersonaldataoutlinedinGDPRArticle5,being:\n\u2022 lawfulness,fairnessandtransparency;\n\u2022 purposelimitation;\n\u2022 dataminimisation;\n\u2022 accuracy;\n\u2022 storagelimitation;\n\u2022 integrityandconfidentiality.\nThese core principles are well rehearsed and there are many published commentaries and\nguidelines available in forms accessible to practitioners to aid understanding [170, 171, 185,\n186].\nPractitionersshouldbeespeciallyalerttothepresenceofcertaintypesofsensitivepersonal\ndata in any system with which they are involved. Such data includes, \u2019personal data reveal-\ning racial or ethnic origin, political opinions, religious or philosophical beliefs, or trade union\nmembership,andtheprocessingofgeneticdata,biometricdataforthepurposeofuniquely\nidentifying a natural person, data concerning health or data concerning a natural person\u2019s\nsex life or sexual orientation\u2019 (GDPR, Art 9). Sensitive personal data triggers a series of ad-\nditionalprotectionsandgenerallyincreasedlevelsofregulatoryscrutiny,asimproperuseof\nsuchdataoftenpresentsadisproportionalrisktotheinterestsofthedatasubject.\nThetopicof\u2019consent\u2019indataprotectionlawisworthabriefcomment,asitremainsasubject\nofsomeconfusion.Asathresholdmatter,datasubjectconsentisnotalwaysrequiredwhen\nprocessing personal data. There may be multiple lawful grounds for processing personal\ndataotherthanconsentdependinguponcontext.Ifdatasubjectconsentisrequired,however,\nKALaw&Regulation |October2019 Page75 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ndataprotectionlawsetsaveryhighbarthatthismustbe\u2019freelygiven,specific,informedand\nunambiguous indication of the data subject\u2019s wishes by which he or she, by a statement or\nbyaclearaffirmativeaction,signifiesagreementtotheprocessingofpersonaldatarelating\nto him or her\u2019 (GDPR, Art 4(11)). A series of conditions that apply to consent are set out in\nGDPR,Art7(andArt8relatingtochildren\u2019sconsent).81\n3.4.3 Investigation and prevention of crime, and similar activities\nPractitioners engaged by a state benefit from certain reductions in data protection obliga-\ntionswhenprocessingpersonaldatarelatedtocriminalinvestigationandprosecution.These\nreducedobligationsaredescribedingeneralinDirective2016\/680andthentransposedinto\nmemberstatelaw.\nPractitionerswhoconductactivitieswithsimilargoals,butarenotengagedbyastate,remain\nsubject to GDPR. In this context, however, GDPR makes it clear that purposes such as fraud\nprevention constitute a legitimate interest of data controllers (GDPR at Recital 47). GDPR\nalso provides member states with the option to adopt in their domestic laws reduced data\nprotection obligations for non-state actors when conducting activities designed to prevent,\ninvestigate,detect,orprosecutecrime,etc.(GDPR,Art23;[187]ats.15&Sched2).\n3.4.4 Appropriate security measures\nData protection law imposes an obligation on controllers and processors to \u2019implement ap-\npropriate technical and organisational measures to ensure a level of security appropriate to\nthe risk\u2019 associated with processing personal data (GDPR, Art 32(1)). This security principle\nisalong-standingfeatureofdataprotectionlaw.\nThe obligation clearly encompasses both technical measures as well as human manage-\nment and oversight (i.e., \u2019organisational measures\u2019). Compliance requires that both compo-\nnents are appropriate. Compliance requires a consideration of the state of the art and an\nassessment of costs of various measures in comparison with risks presented. Assessing\nthis obligation to take appropriate security measures might therefore be aided by analogy\nwith the law of negligence which presents various frameworks used to assess \u2019reasonable\u2019\ncare(seediscussioninSection3.7.1.2).\nGDPR has expanded significantly the discussion of security measures to provide examples\nofmeasuresthatmightassistincreatingappropriatesecurity.Thisincludesmanypastprac-\nticesthatdevelopedorganicallysuchaspseudonymisationandencryptionofpersonaldata,\nassuring ongoing confidentiality, integrity, availability and resilience of systems, and robust\nincidentrecoveryplans.Tobeclear,GDPRdoesnotexpresslymandateencryptionofallper-\nsonal data. It simply highlights encryption as a technical measure that can be adopted to\nenhance security. As encryption methods or other security technologies become standard-\nisedandcostsfall,however,itbecomesincreasinglydifficulttojustifywhysuchtechnologies\narenotadopted.\nOrganisational methods used to protect the security of personal data may include contract\nobligations with supply chain partners and others. (See also the discussions in Sections\n3.4.6.2and3.6.2)\nAlthough security certification or compliance with security codes of practice might help to\nproveappropriatenessofsecuritymeasures,thesecertificationsarenotdispositiveofcom-\npliancewiththelaw(GDPR,Art32(3)).\nKALaw&Regulation |October2019 Page76 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.4.5 Assessment and design of processing systems\nSometimes, the most effective way to prevent violations of data protection law is to design\nasystemthatminimisestheabilityofpersonstotakeinappropriateaction.GDPR,therefore,\nhasadoptedanobligationtoimplementdataprotectionstrategiesbydesign,andbydefault.\nAs with the general security principle, this obligation extends to both technological and or-\nganisationmeasuresandisassessedonariskbalancingbasis.Thisobligationarisesatthe\nplanning phase, before processing commences, as controllers are required to consider this\nissue\u2019atthetimeofdeterminingthemeansofprocessing\u2019(GDPR,Art25).\nIfanewpersonaldataprocessingactivitypresentssignificantriskofharmtodatasubjects,\nespecially in the context of developing or migrating to systems that process large volumes\nof data, the controller is required to undertake a data protection impact assessment (GDPR,\nArt 35, Recital 91, et al.). If the assessment reveals significant risks, the controller is further\nrequired to consult with the relevant supervisory authority about the proposed processing\nactivity(GDPR,Art36).\n3.4.6 International data transfer\nEuropeandataprotectionlawimposesageneralprohibitiononthetransferofpersonaldata\ntoanystateoutsidetheEuropeanEconomicAreaortoanyinternationalgovernmentalorgan-\nisation (GDPR, Art 44). Such transfers remain commonplace, however, when enabled by an\nappropriateexportcompliancemechanism.\n3.4.6.1 AdequacydeterminationsandPrivacyShield\nTransfers of personal data can be made to territories in accordance with an adequacy deci-\nsion: a finding by the European Commission that the receiving territory (or IGO) has estab-\nlished adequate legal protections concerning personal data (GDPR, Art 45). The process of\nobtaining an adequacy decision is instigated at the request of the proposed receiving state\nandoftenrequiresyearsoftechnicalevaluationanddiplomaticnegotiation[172].\nAdequacy determinations fall into two categories: decisions that a receiving territory\u2019s laws\nare generally adequate to protect personal data, and decisions that a receiving territory\u2019s\nlaws are adequate provided that special conditions are met. Decisions concerning Canada\nand the United States both fall into the second category. In the case of Canada, adequacy\nis only assured with respect to transfers to the commercial for-profit sector, as the relevant\nCanadianlawsdonotapplytoprocessingbygovernmentsorcharities.\nThe US adequacy determination has a difficult history. The US has nothing like the EU\u2019s gen-\neralisedlegalprotectionsconcerningprocessingpersonaldata.Toenabletransfersofdata,\ntheUSandtheEUhavenegotiatedspecificagreementstosupportanadequacyfinding.This\nagreementenablesmostUSbusinesses,iftheywish,tooptintoaregulatorysystemthatpro-\nvidesadequacy.ThisregulatorysystemisthenenforcedbyagenciesoftheUSstateagainst\nopted-inUSbusinesses.Theoriginalsystem,SafeHarbour,wasinvalidatedbytheEuropean\nCourt of Justice in October 2015 in the Schrems case [188]. It was quickly replaced by the\nEU-USPrivacyShieldregimein2016,whichoperatesinafashionsimilartoSafeHarbourwith\nenhancedprotectionsfordatasubjects.\nKALaw&Regulation |October2019 Page77 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.4.6.2 Transferssubjecttosafeguards\nTransfers are also allowed when appropriate safeguards are put into place (GDPR, Art 46).\nThe most common safeguards normally encountered are binding corporate rules, and ap-\nproveddataprotectionclausesincontractsbetweenexportersandimporters.\nBindingcorporaterulesaregovernanceproceduresnormallyadoptedbymultinationalenter-\nprises in an effort to demonstrate to data protection authorities that they will comply with\ndataprotectionprinciples(GDPR,Art47).Tobeeffectivefordatatransfercompliance,such\nrulesmustbeapprovedbyrelevantpublicauthorities.Thiscantakeyearstonegotiate.While\nsuchruleswereoriginallydevelopedasatooltoenablesharingofpersonaldataamongthe\nmembersofamultinationaldatacontrollerenterprisethatoperatesbothinsideandoutside\ntheEEA,theyhavemorerecentlybeenadoptedbynon-residentcloudserviceprovidersasa\ncompliancetooltofacilitatebusinessfromcustomersintheEEA.Practitionersmaybecalled\nupon to assist in drafting or negotiating binding corporate rules, as they have a significant\nimpactonITservices,securityarchitecturesandgovernanceprocedures.\nApproved contract clauses are simply contract obligations between a data exporter and im-\nporterthatservetoprotecttheinterestsofdatasubjects.Theycanbeeitherstandardclauses\napprovedforusebytheCommission,orspecialclausessubmittedtotherelevantauthorities\nfor prior approval (GDPR, Art 46(2)(c)-(d) & 46(3)(a)). Although the Commission-approved\nclauses are standardised, to be effective the parties to the relevant contract are required to\nincorporate a significant amount of operational detail about the nature of the personal data\ntobetransferred,thepurposesofthedataprocessingtobeundertaken,etc.\n3.4.6.3 Transferspursuanttointernationalmutuallegalassistancetreaty\nTransfers of personal data that are otherwise prohibited by GDPR can be made in circum-\nstances such as requests for assistance by a foreign state police agency pursuant to the\nterms of a mutual legal assistance treaty (GDPR, Art 48). (See also Section 3.2.3.9.) Such\ntransfersareaddressedspecificallyinDirective2016\/680,GDPR,Art35-40.\n3.4.6.4 Derogationsallowingtransfers\nIn the absence of any other mechanism allowing a transfer, exports from the EEA are still\nallowedundercertainlimitedcircumstancessuchas:\n\u2022 thedatasubjectprovidesknowinginformedexpressconsenttothetransfer;\n\u2022 the transfer is necessary in order to perform acontractwith thedata subject, ora con-\ntractwithathirdpartyadoptedintheinterestsofthedatasubject;\n\u2022 thetransferservesanimportantpublicinterest;\n\u2022 thetransferisconnectedtothepursuitordefenceofalegalclaim;or\n\u2022 thetransferisnecessarytoprotectthelifeorwelfareofthedatasubject,whoisphysi-\ncallyunabletoconsent.\nThese derogations (GDPR, Art 49) are meant to be interpreted narrowly, and the European\nData Protection Board has issued guidance on the interpretation and application of these\nmeasures[189].\nKALaw&Regulation |October2019 Page78 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.4.7 Personal data breach notification\nLawsmandatingthenotificationofpersonaldatabreachestodatasubjects82begantoemerge\ninboththeEUandtheUSaroundtheturnofthetwenty-firstcentury[190,191].Inapatternthat\niscuriouslythereverseofthedevelopmentofdataprotectionlawsgenerally,EUnotification\nrequirementsarosefirstinnarrowlydefinedsubjectmatterareaswhileUSstates(beginning\nwith California) imposed a more general duty to notify effected persons of personal data\nbreaches.83\nGDPR marked the emergence in Europe of a general duty placed on processors and con-\ntrollers of personal data to make certain notifications following a \u2019personal data breach\u2019,\nwhich is defined as \u2019a breach of security leading to the accidental or unlawful destruction,\nloss, alteration, unauthorised disclosure of, or access to, personal data transmitted, stored\nor otherwise processed\u2019 (GDPR, Art 4(12)). Thus, events as diverse as personal data exfil-\ntration, the unauthorised modification of personal data and ransomware can all constitute\npersonaldatabreaches.\nAprocessorisfirstrequiredtonotifythecircumstancesofabreachtotherelevantcontroller\n\u2019withoutunduedelay\u2019.Thecontrolleristhenrequiredtonotifytherelevantsupervisoryauthor-\nityofthebreach\u2019withoutunduedelayand,wherefeasible,notlaterthan72hoursafterhaving\nbecome aware of it\u2019 (GDPR, Art 33(1)-(2)). The content of the notice is set out in Art 33(3).\nThere is a limited exception to the controller\u2019s duty to notify a supervisory authority if the\nbreach is \u2019unlikely to result in a risk to the rights and freedoms of natural persons\u2019. Whether\nor not notified to the supervisory authority, the controller is required to document all such\nbreacheventsandtheserecordsaresubjecttoperiodicreviewbythesupervisoryauthority.\nIfsuchabreachis\u2019likelytoresultinahighrisktotherightsandfreedomsofnaturalpersons\u2019,\nthen the controller is required to communicate the circumstances of the breach to the rel-\nevant data subjects without undue delay (GDPR, Art 34(1)-(2)). Communication to the data\nsubjects can be avoided if the controller has implemented methods that limit the harm that\nmight be caused by such a breach, such as encrypting data that was then exfiltrated as ci-\nphertext.Whilesuchciphertextremainspersonaldataforlegalpurposes,theencryptedstate\nofthedatareducesthepotentialharmtodatasubjecttosomedegree(dependinguponthe\ntype of encryption, etc.) This ability to avoid communication to data subjects when harm is\nunlikelyisausefulfeatureofGDPR.ManyUSstatenotificationlawsoriginallydemandedno-\ntifyingdatasubjectsirrespectiveoftherelevantriskspresentedbythebreach.84 Supervisory\nauthorities retain the right to compel communication to data subjects about the breach if\ntheydisagreewiththecontroller\u2019sriskassessment.\nVarious states around the world continue to adopt mandatory breach disclosure laws, each\nwiththeirownuniquecharacteristics[192].\nKALaw&Regulation |October2019 Page79 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.4.8 Enforcement and penalties\nEgregiousviolationsofdataprotectionlawcanbeprosecutedascrimesundermemberstate\ndomestic law. Relevant actions can be prosecuted simultaneously as crimes against infor-\nmationsystems(seeSection3.5)[193].\nData protection laws also enable data subjects to bring tort claims for violation of data pro-\ntection rights. Such claims implicate the risk of vicarious liability for employee misdeeds,\nespeciallyifalargegroupofdatasubjectsareabletobringaclaimasagrouporclass.(See\nthediscussionoftheMorrisonscaseatSection3.7.5.1)\nPublicenforcementauthoritiesarealsogivenpowerstoserveenforcementnotices,demand-\ning changes in processing behaviour to achieve compliance with the law (GDPR, Art 58.) In\nparticularly egregious cases, public authorities might serve a notice prohibiting large cate-\ngoriesofprocessingactivity.Breachingsuchanenforcementnoticeisanindependentcause\nformoresevereenforcementaction.\nPerhapsthegreatestchangetolegalriskpresentedbyEUdataprotectionlawinthepastfew\ndecadeshasbeenthesteadyandacceleratingincreaseinthesizeofpenaltiesassessedby\npublicauthorities.(AdoptingtheterminologyofSection3.1.5,thishasdramaticallyincreased\ntheQtermovertime.)\nHistorically, civil or administrative fines imposed by public authorities for violation of data\nprotection law were perceived in some member states as relatively minor. The disparity in\napproachamongmemberstatestodataprotectionlawwasamotivatingfactorfortheadop-\ntion of the original 1995 Directive, which tended to increase data protection rights in most\nmember states. Following the 1995 Directive, increasingly larger fines started to emerge as\nstate authorities began to increase enforcement pressure. By the time GDPR was adopted\nin 2016, administrative fines in the region of e500,000 were not uncommon for significant\nviolationsofthelaw.\nOneofthemost-discussedfeaturesofGDPRconcernstheauthoritygrantedtoimposelarge\nadministrativefines(GDPR,Art83).Violationsofsomeofthemoreproceduraloroperational\nrequirements of GDPR, including the requirement to adopt appropriate security measures,\ncan incur administrative fines of up to e10,000,000, or 2% of an undertaking\u2019s annual world-\nwideturnover,whicheverisgreater.ViolationsofmorefundamentalprinciplesofGDPR,such\nas failure to respect the rights of data subjects, processing personal data without lawful\nauthority, or exporting data in violation of the law, can incur administrative fines of up to\ne20,000,000,or4%ofanundertaking\u2019sannualworldwideturnover,whicheverisgreater.Au-\nthoritiesareinstructedtocalculatefinesataleveltomakethem\u2019effective,proportionateand\ndissuasive\u2019 in individual circumstances. GDPR lists a number of both mitigating and aggra-\nvating factors for consideration when setting these fines that are worth closer study (GDPR,\nArt83(2)).\nTheemergenceinGDPRofthepotentialfor\u2019eightfigure\u2019and\u2019ninefigure\u2019fines,togetherwith\ntheincreasedscopeofterritorialjurisdiction,instantlypromoteddataprotectionlawintothe\ncategory of a significant risk to be assessed and managed at senior leadership levels \u2013 a\npositionthatthislawhadrarelyoccupiedpriortothesechanges.Somepersonswhoprovide\nonline information services from outside the EU (who presumably fear that their business\nmodelsarenotcompatiblewithGDPRcompliance)respondedbywithdrawingfromtheEuro-\npeanmarketbyusinggeographicfilteringmechanisms(seeSection3.2.3.7).Otheroffshore\nservice providers have embraced the change and worked to comply with the rules (presum-\nablyastheyvaluetheirongoingcontactwiththeEuropeanmarket).\nKALaw&Regulation |October2019 Page80 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nIn July 2019, the Information Commissioner\u2019s Office of the United Kingdom issued two no-\nticesoftheirintentiontoissuelargefinesunderGDPR:aproposedfineofGB\u00a3183.39million\nto British Airways85 and a proposed fine of GB\u00a399.2 million to Marriott International, Inc.86\nAttimeofwriting,bothcompanieshaveexpressedtheirintentiontocontestthefines.\n3.5 COMPUTER CRIME\n[109,110,111]\nThe term \u2019cybercrime\u2019 is often used to identify three different categories of criminal activity:\ncrimes in which cyberspace infrastructure is merely an instrumentality of some other tradi-\ntionalcrime(e.g.,financialfraud),distributionofcriminalcontent(e.g.,pornographyandhate\nspeech),andcrimesdirectedagainstcyberspaceinfrastructureitself(e.g.,unlawfulintrusion\nintoacomputersystem).\nThis section is addressed solely to the last category, computer crimes or crimes against\ninformationsystems.Thesetend tobeofconcernas theyareofinteresttothosewhowork\nforstateenforcementauthorities,aswellasthosewhomanagecybersecurityrisk,research\ncybersecuritytechnologies,anddevelopcybersecurityproductsandservices.\nAlthough some practitioners are engaged by states in the investigation and prosecution of\ncrimes where cyberspace is an instrumentality of crime, it is difficult to draw out generalis-\nable statements about those crimes that remain useful in a multinational context. Crimes\nbased on message content are especially problematic, as these rest upon widely diverging\nopinionfromdifferentsocietiesaboutwhatconstitutes\u2019illegitimate\u2019contentworthyofcrimi-\nnalprosecution.87(Oneareainwhichthereappearstobegrowinginternationalconsensusfor\ncriminalisingmessagecontentconcernschildexploitationmaterials[110,120,194].Evenwith\nthissubjectmatter,wherehighlevelnormativeprinciplesmaybequicklyagreed,attempting\ntotranslatetheseprinciplesintowidelyagreedlegalstandardsremainschallenging[111].)\n3.5.1 Crimes against information systems\nIn the 1980s and 1990s, many states confronted the problem that an emerging set of anti-\nsocialbehavioursrelatedtocyberspaceinfrastructurewerenotclearlyidentifiedascrimes.88\nThe UK Parliament responded by adopting the Computer Misuse Act 1990, which defined a\nseriesofcomputer-relatedcriminaloffences.Thislawhasbeensubsequentlyamendedfrom\ntimetotime[195].\nIn 1984, the US Congress adopted the Computer Fraud and Abuse Act, which has also been\nregularlyamended[196,197].89 ManyUSstateshaveadditionallyadoptedtheirownstatutes\ntoprosecutecomputercrime.90 TheUSlandscape isespeciallycomplex,asa variety offed-\neral and state law enforcement agencies have varying subject matter jurisdiction over com-\nputercrimes[110].\nSimilar laws have been adopted by many, but not all, states around the world. The Council\nofEuropeConventiononCybercrime(a.k.a.theBudapestConvention)isamultilateraltreaty\nwhich has had a significant impact on harmonising both computer crime laws and rules of\nstate international assistance [120]. The Convention opened for signature in 2001, and as\nof July 2019 had been ratified by 44 member states of the Council of Europe and 19 non-\nEuropeanstatesincludingCanada,JapanandtheUS[198].\nKALaw&Regulation |October2019 Page81 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nIn2013,theEuropeanUnionadoptedDirective2013\/40.Thismandatesthatmemberstates\nmodify their criminal laws to address commonly recognised computer crimes which the Di-\nrectivedescribesascrimes\u2019againstinformationsystems\u2019[121].\nThis introductory section on crimes against information systems is influenced by the tax-\nonomy adopted by the Budapest Convention and further reflected in Directive 2013\/40. Al-\nthough these two international legal instruments are cited repeatedly, practitioners should\nkeep in mind that they are instruments of public international law and relevant crimes are\ndefinedby,andprosecutedunder,thedomesticlawofindividualstates.91\n3.5.1.1 Improperaccesstoasystem\nImpropersystemaccesslawscriminalisetheactofaccessingacomputersystem(inwhole\norinpart)withouttherighttodoso,colloquiallyknownashacking.92 (BudapestConvention\nat Art. 2; Directive 2013\/40 at Art 3.) The UK Computer Misuse Act 1990 at s.1, for example,\ndefines as criminal an action by a person which causes a computer to perform an act with\ntheintenttosecureunauthorisedaccesstoanyprogramordata[195].Thus,themereactof\nentering a password into a system without authorisation in an effort to access that system\nconstitutesacrimeundertheUKstatutewhetherornotaccessissuccessfullyachieved.\nSome debate persists concerning how to distinguish rightful from wrongful action in cases\nwhere an otherwise-authorised person exceeds the scope of permission granted to them.\nCriticsarguethatanoverly-broadinterpretationofstatutorytermslike\u2019unauthorisedaccess\u2019\ncanproducecriminalprosecutionbasedonlyonbreachinganacceptableusepolicyorweb-\nsite terms and conditions. This might serve to re-define as a crime what otherwise could be\na civil breach of contract claim [199]. The issue remains open to argument in some circum-\nstances[111,200,201,202].\n3.5.1.2 Improperinterferencewithdata\nImproper system interference with data laws criminalise the act of inappropriately \u2019deleting,\ndamaging, deteriorating, altering or suppressing\u2019 data. (Budapest Convention at Art. 4; Di-\nrective 2013\/40 at Art 5.) These laws can be used to prosecute actions such as release or\ninstallationofmalware,includingransomware.\n3.5.1.3 Improperinterferencewithsystems\nEarlycomputercrimelawstendedtofocusontheactofintrusionintoacomputersystem,or\nimproperlymodifyingthecontentsofthosesystems.WiththeemergenceofDoSandDDoS\nattacks,someoftheseearlycriminallawswerefoundtobeinadequatetoaddressthisnew\nthreateningbehaviour.\nThese laws now more commonly include a prohibition against acts that cause a material\ndegradation in the performance of an information system. (Budapest Convention at Art. 5;\nDirective2013\/40atArt4;ComputerMisuseAct1990ats.3,asamendedin2007-08.)\nKALaw&Regulation |October2019 Page82 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.5.1.4 Improperinterceptionofcommunication\nOftenasacorollarytovariousrightsofprivacy,manylegalsystemsdefinetheactofwrong-\nfully intercepting electronic communications as a crime. (Budapest Convention at Art. 3; Di-\nrective 2013\/40 at Art 6.) The rules and penalties tend to be most restrictive in the context\nof intercepting communications during the course of their conveyance on public networks.\nThissubjectisdiscussedinSection3.3.\n3.5.1.5 Producinghackingtoolswithimproperintentions\nMany states also define as crimes the production or distribution of tools with the intention\nthattheyareusedtofacilitateothercrimesagainstinformationsystems.(BudapestConven-\ntion at Art. 6; Directive 2013\/40, Art 7; Computer Misuse Act 1990, s.3A.) These laws can\ncreatechallengesforthosewhoproduceordistributesecuritytestingtools,asdiscussedin\nSection3.5.5.\n3.5.2 De minimis exceptions to crimes against information systems\nSomelawsmaylimitthedefinitionofcomputercrimetoactswhicharesomehowsignificant.\nDirective 2013\/40, for example, only mandates that member states criminalise acts against\nsystems\u2019whicharenotminor\u2019(Art3-7).Theconceptofa\u2019minor\u2019actagainstasystemisdis-\ncussedinRecital11totheDirective,whichsuggeststhatstatesmightdefinethisbyreference\ntotherelativeinsignificanceofanyriskcreatedordamagecausedbythegivenact[121].\nThis type of de minimis exception to the definition of computer crime is far from universal.\nEUmemberstatesremainfreetocriminalisesuchdeminimisacts.Atthetimeofwriting,the\nUKlegislationcontainsnosuchdeminimisexception.93\nThe very idea of a de minimis exception to crimes against information systems raises a re-\ncurringdebateoverthenatureoftheharmthatthesetypesoflawsseektoredress.Itisnot\nalways clear how to assess the relative damage or risk caused by any given act against in-\nformation systems. For some criminal acts such as remote intrusion into a chemical plant\nindustrial control system the risk presented or harm caused is clear to see, as the attack is\nconcentratedagainstasingleandvolatiletarget.Inothers,suchascontrollingtheactionsof\namultinationalbotnetcomprisingtensofthousandsofsubornedmachines,theriskcreated\norharmcausedmaybewidelydiffusedamongthebotsandmoredifficulttoquantify.94\n3.5.3 The enforcement of and penalties for crimes against information\nsystems\nStates normally have absolute discretion to decide whether or not to investigate alleged\ncrimes.Havinginvestigated,statesnormallyhaveabsolutediscretionregardingthedecision\ntoprosecuteacriminalmatter.95 Somestateshavesetoutguidancetoexplainhowthisdis-\ncretionisexercised[203].\nPenaltiesforcommittingacrimeagainstinformationsystemsvarywidely.Incriminalcases\ncustodialsentencesareoftenboundedinlawbyamaximum,andoccasionallybyaminimum,\nlengthofterm.Withinthesepolicy-imposedlimitsjudgesareusuallygivenawidedegreeof\ndiscretiontodecideanappropriatesentence.\nUnder the UK Computer Misuse Act, for example, a custodial sentence for the crime of im-\nproper system access is normally limited to a maximum of two years, while the crime of\nKALaw&Regulation |October2019 Page83 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ninterferingwithdataorsystemintegrityisnormallylimitedtoamaximumoffiveyears.Pros-\necution and sentencing history both suggest that actual sentences issued under the UK leg-\nislationforthesecrimesarerarely,ifever,thissevere.Bycontrast,intheUS,bothfederaland\nstate laws have consistently provided for longer maximum custodial sentences of 20 years\normoreforunlawfulintrusionorunlawfulinterferencewithdata.96\nThequestionofappropriatepunishmentforcrimesagainstinformationsystemsremainsthe\nsubject of review and debate. The emergence of the Internet of Things arguably increases\nthe risk that these crimes might pose to life and property.97 EU Directive 2013\/40, for exam-\nple, requires that member states provide for the possibility of longer custodial sentences\nwhenattacksaredirectedagainstcriticalnationalinfrastructureorwhentheyactuallycause\nsignificantdamage(Art9(b)-(c)).TheUKamendeditsComputerMisuseActin2015(s.3ZA)\nto increase the maximum available custodial sentence if criminals are proven to have cre-\nated significant risk or caused serious damage. Such a person could now be subjected to\na maximum custodial sentence of 14 years. In cases where the criminal act causes (or cre-\natessignificantriskof)seriousdamagetohumanwelfareornationalsecurity,themaximum\ncustodialsentenceunderUKlawincreasestolifeimprisonment(s.3ZA(7)).\nArguments continue over appropriate punishments for crimes against information systems.\nThis debate is complicated by difficulties in understanding or quantifying the degree of risk\northedegreeofharmcausedbythesecriminalacts.(SeethediscussioninSection3.5.2.)\n3.5.4 Warranted state activity\nWhen actionsrelated to investigation of crime orin defence of state securityare conducted\nwithstateauthorisationsuchasawarrant,thepersonusingthewarrantedtechniqueisoften\nexpresslyexemptedfromthatstate\u2019scriminalliabilityforintrusionintoinformationsystems\ntotheextentthattheintrusionconformswithexpresslywarrantedactivity.\nAnexamplecanbefoundintheUK\u2019sInvestigatoryPowersAct2016,whichholdsthatcertain\nactivity conducted with lawful authority under the terms of that Act are \u2019lawful for all other\npurposes\u2019 [167] in ss.6(2)-(3), 81(1), 99(11), 176(9), 252(8). In other words, actions in compli-\nancewithawarrantissuedpursuanttothe2016legislationwillnotconstituteacrimeagainst\ninformationsystemsundertheComputerMisuseAct1990etc.98\nState-sponsored acts of remote investigation into cyberspace infrastructure located in for-\neignstatesareconsideredinSection3.12.4.\n3.5.5 Research and development activities conducted by non-state per-\nsons\nThose who research cyber security issues and develop security products and services out-\nsideofthedomainofstate-sponsoredactivitycanfacedifficultiesiftheirplannedactivities\nconstitute a crime against information systems. Examples that may lead to difficulties in-\nclude:\n\u2022 uninvited remote analysis of security methods employed on third-party servers or se-\ncuritycertificateinfrastructures;\n\u2022 uninvitedremoteanalysisofthird-partyWiFiequipment;\n\u2022 uninvitedanalysisofthird-partyLANinfrastructure;\nKALaw&Regulation |October2019 Page84 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n\u2022 invited stress testing of live WAN environments, to the extent that this degrades per-\nformance of infrastructure operated by third parties who are unaware of the testing\nplan;\n\u2022 analysingmalwareandtestinganti-malwaremethods;\n\u2022 analysingbotnetcomponentsandperformance;\n\u2022 producingordistributingsecuritytestingtools;and\n\u2022 variouscovertintelligence-gatheringtechniques.\nWith respect to testing tools specifically, the law tends to criminalise production or distri-\nbution only when the state can prove an intent to facilitate other violations of the law. This\ncriminalactmayhavelesstodowiththeoperationalcharacteristicsofthetestingtoolthan\nthesubjectiveintentionofthepersonwhoisproducingordistributingit.99\nInsomestates,researchersmightbeabletodemonstratealackofcriminalresponsibilityfor\nthese acts under some type of de minimis exception, if one is available (see the discussion\ninSection3.5.2).100\nSomemayrestonthebeliefthat\u2019legitimate\u2019researcherswillbesavedfromcriminalliability\nasaresultofstatediscretiontorefrainfrominvestigatingorprosecutingdemimimiscriminal\nacts, judicial or jury intervention to find accused parties not guilty, or if found guilty, through\nthe imposition of only a token punishment. This situation is rather unsatisfactory for practi-\ntionerswhoattempttoassesspotentialcriminalliabilityarisingfromanotherwisecarefully\nrisk-managedresearchordevelopmenteffort.101\nEvenifpractitionersfindappropriateexceptionsunderrelevantlawsconcerningcrimesagainst\ninformationsystems,theymustalsobecarefultoconsiderwhethertheiractionswouldcon-\nstitutecrimesunderotherlawssuchasgeneralisedprivacyordataprotectionlaws.\n3.5.6 Self-help disfavoured: software locks and hack-back\n\u2019Self-help\u2019referstothepracticeofattemptingtoenforcelegalrightswithoutrecoursetostate\nauthority. A routinely cited example is the re-possession of movable property by a secured\nlender from a borrower in default of payment of obligations. (For example, repossessing an\nautomobile.)\nPublic policy is generally suspicious of self-help mechanisms, as they involve non-state ac-\ntors exercising powers normally considered to be the exclusive province of the state. Laws\nthatenablesuchactionsoftenimposemultipleconditionsthatlimittheactor.Inthecontext\nof cyber security, practitioners have occasionally designed or adopted methods that might\nbeclassifiedasself-help.\nTheseactionscomewiththeriskofpotentiallyviolatingcriminallaw.Personspursuingthese\nstrategiesshouldalsoremainawareofpotentialtortliability(seeSection3.7).\nKALaw&Regulation |October2019 Page85 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.5.6.1 Undisclosedsoftwarelocks\nVarious technologies serve to limit the use of software. Implementing a system that clearly\ndisclosestoauserthatoperationrequiresthepriorentryofauniqueactivationkeyisnormally\nnon-contentious,andisactivelyencouragedbycertainaspectsofcopyrightlaw(seeSection\n3.8.2.1).Similarly,SaaSprovidersusuallydonotfaceanysanctionswhensuspendingaccess\ntoacustomerwhoterminatestheservicerelationshiporfailstopaytheirservicefees.102\nProblems arise when a supplier (for whatever reason, including non-payment of promised li-\ncenseormaintenancefees)installsalockmechanismintoasoftwareproductafterthefact\nwithoutcustomeragreement.Alsoproblematicareinstanceswheresoftwaresoldasaprod-\nuctcontainsanundisclosedtime-lockdevicewhichlatersuspendsfunctionality(intheevent\nof non-payment or otherwise). These types of undisclosed or post-facto interventions have\nahistoryofbeingprosecutedascrimesagainstinformationsystemsandareotherwisecrit-\nicisedasbeingagainstpublicpolicy,whetherornotthevendorinquestionheldalegitimate\nrightofactionagainsttheenduserfornon-paymentoflicencefees[204,205].\n3.5.6.2 Hack-back\nHack-back is a term used to describe some form of counter-attack launched against cy-\nberspace infrastructure from which an attack appears to have originated. This strategy is\noftenconsideredinthecontextofanattackwhichappearstooriginatefromaforeignstate,\nand cooperation from the foreign state is deemed unlikely or untimely. Hack-back actions\nmight consist of a DoS attack, efforts to intrude into and disable the originating infrastruc-\nture,etc.\nHack-back activity, on its face, falls squarely within the definition of crimes against informa-\ntion systems [197]. Such an action might be prosecuted as a crime by the state where the\npersonconductingthehack-backislocated,thestateswherethemachinesusedtoconduct\nthe hack-back are located, or the state in which the hack-back target is located. In addition\ntotheriskofcriminalprosecution,ahack-back(ifsufficientlyaggressive)couldserveasthe\nbasisunderinternationallawforthestateofthehack-backtargettotakesovereigncounter-\nmeasuresagainstthepersonconductingthehack-backoragainstotherinfrastructureused\nto conduct the hack-back operation \u2013 even if the hack-back itself is not directly attributable\ntohoststate(seeSection3.12).\nManyhavedebatedadoptingexceptionsinlawspecificallytoenablehack-backbynon-state\nactors[197,206,207,208].103 Thesetypesofproposedexceptionshavenotyetfoundfavour\nwithlawmakers.\n3.6 CONTRACT\n[107,108]\nTheterm\u2019contract\u2019describesa(notionally)volitionallegalrelationshipbetweentwoormore\npersons. One extremely broad definition of contract is simply, \u2019a promise that the law will\nenforce\u2019[209].\nUnfortunately,theword\u2019contract\u2019isoftenusedcolloquiallytodescribeacommunicationthat\nembodies and expresses contractual promises (e.g., a piece of paper, email, or fax). This\nconfusionshouldbeavoided.Acontractisalegalrelationship,notapieceofpaper.Insome\nKALaw&Regulation |October2019 Page86 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ncircumstances, applicable law may exceptionally impose a requirement that some contract\nobligationsmustbeembodiedinaspecifiedform(seeSection3.10).\nThis section will discuss a few contract topics of recurring interest to cyber security practi-\ntioners.\n3.6.1 Online contracts: time of contract and receipt of contractual com-\nmunication\nThedefinitionof\u2019contract\u2019aboveimmediatelybegsafollow-upquestion:howdoesonedistin-\nguishalegallyenforceablepromisefromothertypesofcommunication?Althoughdifferent\nlegal systems have varying approaches to defining a contract, the elements required by law\ncan be classified into two categories: sufficiency of communication, and indicia of enforce-\nability.\nAsanexample,underthelawofEnglandacontractusuallyexistsonlywhenthepartieshave\ncommunicated an offer and an acceptance (collectively constituting sufficiency of commu-\nnication), supported by consideration and an intention to create legal relations (collectively\nconstitutingindiciaofenforceability).\nSufficiency of contract communication is a recurring issue when designing and implement-\ningonlinetransactionsystems.Understandingtheprecisetimewhenacontractcomesinto\nexistence, the so-called contractual trigger, is important in risk-managing the design of on-\nlinetransactionsystems[107,108].104Priortotheexistenceofacontractthepartiesgenerally\nremain free to walk away. Post-contract, however, the parties are legally bound by promises\nmade.\nSystemdesignersshouldconsiderfoursuccessivemomentsinthecontractcommunication\nprocess:\n1. thetimeatwhichAlicetransmitsheroffer105 toBob;\n2. thetimeatwhichBobreceivesAlice\u2019soffer;\n3. thetimeatwhichBobtransmitshisacceptancetoAlice;\n4. thetimeatwhichAlicereceivesBob\u2019sacceptance.\nMost common law systems would, by default, place the time of contract formation for on-\nline transactions into the last of these four times \u2013 the moment that Alice receives Bob\u2019s\nacceptance.\nPractitioners are urged not to conflate these four distinct moments in time, even when they\nappear to be instantaneous. System designers should consider the impact of a lost or in-\nterrupted transmission and, accordingly, technical design should be carefully mapped onto\nrelevantbusinessprocess.106\nA perennial question in the design of online systems concerns the precise point in time at\nwhich it can be said that Alice or Bob has \u2019received\u2019 a communication. The European Union\nattemptedtoaddressthisinArticle11oftheElectronicCommerceDirective2000[210].This\nmandates adoption of a rule that \u2019orders\u2019 and \u2019acknowledgements\u2019 of orders107 are generally\ndeemedtohavebeenreceivedatthemomenttheybecomeaccessibletothereceivingparty\n(e.g., when the acceptance is received in Alice\u2019s online commerce server log or Bob\u2019s IMAP\nfile).108 ThisrulecanbevariedbycontractualagreementinB2Bcommercesystems.\nKALaw&Regulation |October2019 Page87 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nDifferencesinapproachareworthyofinvestigationdependingontherelativevalueoftrans-\nactionssupportedandwhichstate(s)contractlaw(s)mightbeapplicable(seeSection3.6.7).\n3.6.2 Encouraging security standards via contract\nContractscanserveasamechanismtoencouragetheimplementationofsecuritystandards.\nThiscanariseinawidevarietyofcontractualrelationships.\n3.6.2.1 Supplychain\nAcommoncontracttechniqueistoincorporatetermswithinaprocurementagreementthat\nattempt to mandate some form of compliance by a supply chain partner with specified se-\ncurity standards: whether published standards such as ISO 27001, or sui generis standards\nadopted by the contracting parties. Although these contract terms can take many different\nlegal forms (e.g., warranty, representation, undertaking, condition, mandate to produce evi-\ndence of third-party certification, access and audit rights etc.) the general principle is that\nthese contract terms have become a common mechanism that is used in an attempt to in-\nfluencethesecuritybehaviourofsupplychainpartners.\nThe value of these clauses in managing supply chain behaviour, however, is worth a closer\nexamination.Considertherisk-weightedcosttoacontractingpartyofbreachingthetermsof\nsuch a clause (introduced in Section 3.1.5 as R). In a legal action for breach of contract, the\nenforcing party normally remains responsible for proving that the breach caused financial\nharm,aswellasthequantumoffinancialharmsufferedbytheenforcingpartyasaresultof\nthe breach (see Section 3.6.5). In the case of a breaching party\u2019s failure to comply with an\nobligation to maintain a third-party security certification, for example, it might be difficult or\nimpossiblefortheenforcingpartytoprovethatanyfinancialharmflowsfromsuchabreach\n(thuseffectivelyreducingtheQtermtozero).\nAsometimes-overlookedvalueofthesecontractualclausesariseswellbeforetheagreement\nis made. The process of inserting and then negotiating these clauses can operate as a due\ndiligence technique. A negotiating party obtains information about the maturity and opera-\ntionalcapabilityoftheproposedsupplychainpartnerduringnegotiations.\n3.6.2.2 Closedtradingandpaymentsystems\nMany high-value or high-volume electronic trading or payment platforms109 require persons\nto enter into participation contracts prior to using the platform. These systems may be gen-\nerallyreferredtoas\u2019closed\u2019systems:theyconstituteaclubthatmustbejoinedcontractually\nto enable members to trade with one another. These membership contracts typically adopt\ncomprehensive rules concerning forms of communication, connected equipment, and the\ntiming for finality of transactions. They also typically specify the adoption of certain secu-\nrity standards, authentication protocols, etc. The membership contract is thus a private law\nmechanism that is used to enforce certain security standards among the members. (See\nalsoSection3.10.2.)\nBreachingthetermsofthemembershipcontractmightjeopardisethesubjectmatterofthe\nagreement itself \u2013 the finality of trades or the ability to collect payment. As an example, a\nmerchant collecting payment via payment card that fails to comply with the authentication\nprocedures mandated by its merchant acquirer contract might face a loss of payment for a\ntransaction even though it has delivered (expensive) goods into the hands of a person who\nKALaw&Regulation |October2019 Page88 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nhas committed card fraud. Faced with such drastic financial consequences, the contracting\npartiesmayworkexceptionallyhardtomeetthemandatedauthenticationstandards.\nPerhaps the most well-known example of a widespread standard implemented using con-\ntract is PCI DSS adopted by the payment card industry. Failure to comply with this standard\nputsatriskaparty\u2019sabilitytoreceivepayment.Whilethereissomedebateaboutthedegree\ntowhichthisstandardhasbeeneffective,itisdifficulttodenythatithashadsomeimpacton\nraisingthestandardofsecuritypracticesemployedbymanymerchantswhenhandlingcard\ntransaction data \u2013 especially those that previously seemed to approach the subject with a\ncavalierattitude.\n3.6.2.3 Freedomofcontractanditslimitations\nWhen considering using a contract as a means of regulating security behaviour, one must\nconsiderthatthelawcananddoesinterferewithorotherwiselimittheenforceabilityofsome\ncontractterms.\nWhenconsideringPCIDSSstandards,forexample,theUSFairandAccurateCreditTransac-\ntionsActof2003[211]inSection113mandatesspecifictruncationrulesconcerningpayment\ncardnumbersdisplayedonprintedreceiptsprovidedatthepointofsale.110 Thus,merchants\nsubjecttoUSlawmustconsiderthesepubliclawrequirementsaswellasPCIDSS,andthose\nwho wish to modify the PCI DSS standards should do so in a manner that is sympathetic to\ntheexternalrequirementsimposedonthesemerchantsbyUSlaw.(Somestateshavetaken\ntheadditionalstepofadoptingthetermsofPCIDSSintotheirlaw.)\nInthecaseoffundstransferservices,publiclawalsoestablishesaframeworktobalancethe\nrightsandresponsibilitiesofprovidersandusersofpaymentserviceswhichincludesconsid-\neringtheadequacyofauthenticationmechanisms.ExamplescanbefoundinArticles97and\n4(30) of the EU Second Payment Services Directive (PSD2), as implemented in the laws of\nmemberstates[212],andArticle4A\u00a7202oftheUniformCommercialCode,asimplemented\ninthelawsofUSstates[213].\nLimitationsonthefreedomofpartiestodeviatefrompubliclawnormsincontractarefurther\ndiscussedinSections3.6.3and3.6.4.\n3.6.3 Warranties and their exclusion\nTheterm\u2019warranty\u2019111 describesacontractualpromiseconcerningthequalityorlegalstatus\nof deliverables, the adequacy of information provided by a party, the status of a signatory,\netc.\nThe contract laws of individual states normally imply certain minimum warranties into con-\ntracts concerning the quality of the goods and services supplied. The types of quality war-\nrantymostcommonlyimposedinclude:\n\u2022 Objective quality of goods. The product vendor promises that the goods delivered will\nbeobjectivelysatisfactorytoanormalpurchasergivenallofthecircumstancesofthe\ntransaction.112\n\u2022 Subjectivequalityofgoods.Theproductvendorpromisesthatthegoodsdeliveredwill\nbesufficienttomeetthesubjectivepurposeofanindividualpurchaser,whetherornot\nthegoodswereoriginallymanufacturedforthatintendedpurpose.113 Forthiswarranty\ntoapply,thepurchaserisnormallyrequiredtodisclosethepurchaser\u2019sspecificpurpose\nKALaw&Regulation |October2019 Page89 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ninadvancetothevendor.Asaresult,thistermisrarelydiscussedinthecontextofstan-\ndardonlinecommercesystems,whichoftendonotallowunstructuredcommunication\nbetweenvendorandpurchaserconcerningintendedusecases.\n\u2022 Objectivequalityofservices.Theserviceproviderpromisesthatitwillexerciseduecare\nintheprocessofservicedelivery.\nUpon consideration, a significant distinction emerges between the quality of goods and ser-\nviceswarranties.Compliancewiththegoodswarrantiesisassessedbyexaminingthegoods\nsupplied. A warranty that goods will be objectively satisfactory is breached if the goods are\npoor\u2013withoutregardtothecaretakenbythevendorinmanufacturing,sourcing,orinspect-\ning goods. By contrast, a warranty that a service provider will take due care is assessed by\nexaminingtheserviceprovider\u2019sactions,qualificationsandmethodology.Itispossiblefora\nserviceprovidertocomplywithawarrantyofduecareandyetproduceadeliverablewhichis\ndemonstrablypoororinaccurate.(Thebasisofthisdistinctionbetweenproductandservice\nis becoming increasingly difficult as persons place greater reliance on cloud services as a\nsubstituteforproducts.(SeealsodiscussioninSection3.7.2.)\nAlthoughvariouslawsimplythesestandardwarrantiesintocontractsasamatterofcourse,\nit is commonplace \u2013 nearly universal \u2013 for suppliers of information and communications\ntechnologiesandservicestoattempttoexcludethesetermsbyexpressagreement.Efforts\ntoexcludethesebaselinewarrantyprotectionsareviewedwithsuspicionunderthecontract\nlaws of various states. As a general proposition, it is more difficult and often impossible\nto exclude these baseline protections from standard form contracts with consumers. In the\ncontextofB2Bcontracts,however,therulesallowingtheseexclusionstendtobemoreliberal.\nInformation and communications technology vendors normally exclude these baseline im-\nplied warranties and replace them with narrowly drawn express warranties concerning the\nqualityofdeliverables.114 TherelativeutilityoftheseexpresswarrantiesprovidedbyICTven-\ndorsisquestionedwithsomeregularity,especiallyasregardscommercialoff-the-shelfsoft-\nware or hardware. It remains an open question to what degree these warranty standards\nencourageordiscouragedeveloperbehavioursinaddressingsecurity-relatedaspectsofICT\nproductsandservices[105].\n3.6.4 Limitations of liability and exclusions of liability\nPartiestocontractsoftenusethecontracttoimposebothlimitationsandexclusionsofliabil-\nitythatarisefromthecontractingrelationship.Anexclusionofliabilityreferstoacontractual\ntermthatseekstoavoidfinancialresponsibilityforentirecategoriesoffinanciallossarising\nasaresultofbreachofcontract,suchasconsequentialloss,lossofprofit,lossofbusiness\nopportunity,valueofwastedmanagementtime,etc.Alimitationofliability,ontheotherhand,\nseekstolimitoverallfinancialliabilitybyreferencetoafixedsumorfinancialformula.\nThe possibility of imposing and enforcing contractual limitations and exclusions of liability\ncreatesapowerfulincentiveforvendorstodraftandintroduceexpresstermsintotheircon-\ntractualrelationshipswithcustomers.Thecontractbecomesarisk-reductiontool.Asaresult,\ntheseexclusionsandlimitationsareubiquitousincontractsforICTgoodsandservices.\nAs with the exclusion of implied warranty terms, limitations and exclusions of liability are\nviewed with suspicion under most systems of contract law. Once again, limitations and ex-\nclusions of liability are most heavily disfavoured when contracting with consumers. Rules\nallowingtheseexclusionsandlimitationstendtobemoreliberalinB2Barrangements.\nKALaw&Regulation |October2019 Page90 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nThere is a wide variation among and between jurisdictions concerning the enforceability of\nthese limitations and exclusions. As a general proposition, civil law jurisdictions disfavour\ntheselimitationsandexclusionsmorethancommonlawjurisdictions.Requirementsofform\n(seeSection3.10.2)arecommon,andmanylegalmechanismslimittheenforceabilityofsuch\nterms.\nIt remains an open question to what degree the relative enforceability of these contractual\nlimitations and exclusions encourages or discourages developer behaviours in addressing\nsecurity-relatedaspectsofICTproductsandservices[105].\n3.6.5 Breach of contract & remedies\nWhen considering the obligations imposed by contract, it is also important to consider the\nlegal consequences of breaching a contract. (See Section 3.1.5.) A \u2019breach\u2019 of contract is\nsimplyafailuretofulfilapromiseembodiedinthecontract.Breachesexistonaspectrumof\nseverity.Anindividualbreachofcontractmightbeconsidereddeminimis,moderatelyserious,\nverysignificant,etc.115 Theseverityofbreachcanandoftendoesresultindifferentremedies\nfortheinjuredparty.\nIn the event of a breach of contract, various remedies provided by courts to non-breaching\npartiestypicallyfallintothefollowingcategories:116\n\u2022 Damages. Order the breaching party to pay monetary damages to the non-breaching\nparty that are sufficient to restore the net financial expectation that the harmed party\ncanprovewasforeseeablylostasaresultofthebreach.Thisisthemostcommonrem-\nedyavailable.Anon-breachingpartyisoftenobligedtotakestepstomitigatefinancial\nharm,andfailuretomitigatecanservetoreduceanawardofdamagesaccordingly.\n\u2022 Recision. Declare that the contract is at an end and excuse the non-breaching party\nfromfurtherperformance.Thisisamoreextremeremedy,normallyreservedforcases\ninwhichthebreachisverysevere.Alternatively,thetermsofthecontractmightspecif-\nicallylegislatefortheremedyofrecisionunderdefinedcircumstances.117\n\u2022 Specificperformance.Orderthebreachingpartytoperformtheir(non-monetary)promise.\nThisisalsoconsideredanextremeremedy.Thisremedyisoftenreservedforsituations\nwhen the breaching party can take a relatively simple action that is highly significant\nto the non-breaching party (e.g., enforcing a promise to deliver already-written source\ncode or to execute an assignment of ownership of copyright that subsists in a deliver-\nable).\n\u2022 Contractually mandated remedies. The contract itself may specify available remedies,\nsuch as service credits or liquidated damages. Courts often treat these remedies with\nsuspicion.Thelawconcerningenforceabilityofprivateremediesiscomplexandvaries\nsignificantlyfromjurisdictiontojurisdiction.\nThe remedies described above are normally cumulative in nature. Thus, a party can both\nrequestrecisionandclaimfordamagesasaresultofabreach.\nKALaw&Regulation |October2019 Page91 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.6.6 Effect of contract on non-contracting parties\nOne potential limitation of the utility of contracts is that enforcement may be limited to the\ncontractingpartiesalone.\nInthecontextofseekingaremedyforbreach,theruleofprivityofcontract(generallyfound\nin common law systems) normally restricts contract enforcement solely to the contacting\nparties.IfAliceandBobenterintoacontractandAlicebreaches,underthedoctrineofprivity\nBobisnormallytheonlypersonwhocantakelegalactionagainstAliceforbreachofcontract.\nCharlie,asanon-party,cannotnormallytakeactionagainstAliceforbreachofcontracteven\nif Charlie has been harmed as a result of the breach. Charlie may, however, be able to take\naction against Alice under tort law, as discussed in Section 3.7. In complex supply chains,\nBobmightbeabletoassignthebenefitofthecontractrights(suchaswarranties)toCharlie.\n(Even in common law systems, there are circumstances in which parties can expressly vest\ncontractrightsinthehandsofthirdparties.)\nIfAliceisasupplierofservicesandwishestolimitherpotentialliabilitytopersonswhorely\non the outputs of these services, a contractual limitation of liability might not be effective\nagainst a non-contracting person like Charlie who relies on her service but is not in privity\nof contract with Alice. This inability to limit liability to non-contracting parties is a recurring\nconsideration in the development of trust services, in which third parties who rely on trust\ncertificates may have no direct contract relationship with the certificate issuer. (See the dis-\ncussionatSection3.10.)\n3.6.7 Conflict of law \u2013 contracts\nDeciding which state\u2019s law will apply to various aspects of a contract dispute is normally\nvestedwithinthejurisdictionofthecourtdecidingthedispute.Therulesusedtodecidethis\nquestion can and do vary from state to state. Within the European Union, these rules have\nbeen harmonised for most types of contract \u2013 most recently through the mechanism of the\n\u2019Rome I\u2019 Regulation [214]. Individual US states, by contrast, remain free to adopt their own\nindividualrulesusedtodecidewhoselawshouldbeappliedtoaspectsofcontractdisputes.\nEvenwiththesevariationssomeusefulandgeneralisableprinciplescanbeidentified.\nExpress choice by the parties. It is widely accepted that persons who enter into a contract\nshouldhavesomedegreeoffreedomtochoosethelawthatwillbeusedtointerpretit.(Rome\nI, Art 3 [214].) Various policy justifications are available, often built upon notions of freedom\nof contract. If parties are free to specify the terms of their contractual relationship, this ar-\ngument suggests that the same parties should be free to incorporate within the agreement\nanythingthatassiststointerpretthetermsthathavebeenagreed\u2013includingthesubstantive\nsystemofcontractlawusedtointerprettheagreement.\nAbsenceofanexpresschoiceoflawbytheparties.Whenpartiesconnectedtodifferentstates\ndo not make an express choice of law in their contract, the court is faced with the dilemma\nof deciding whose law to apply to various aspects of the contract dispute. In the European\nUnion,rulesdeterminingtheapplicablelawintheabsenceofchoicearefoundinRomeI,Art\n4.Ofparticularinteresttothosewhodealwithonlinecontractingsystems,arethefollowing\ndefaultrulesintheabsenceofaclearchoicebytheparties:\n\u2022 Acontractforthesaleofgoodsorsupplyofserviceswillbegovernedbythelawofthe\nplacewherethesellerorserviceproviderhasitshabitualresidence.Art4(a)-(b).\nKALaw&Regulation |October2019 Page92 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n\u2022 Acontractforthesaleofgoodsbyauctionshallbegovernedbythelawofthecountry\nwheretheauctiontakesplace,ifsuchaplacecanbedetermined.Art4(g).\n\u2022 A contract concluded within a multilateral system which brings together or facilitates\nthe bringing together of multiple third-party buying and selling interests in financial in-\nstruments in accordance with non-discretionary rules and governed by a single law,\nshallbegovernedbythatlaw.Art4(h).\nThus,weseeinEuropeanlawabaselinepolicypreferencetoapplybydefaultthelawwhere\nthe vendor or market maker is resident, over the law where the buyers or bidders may be\nresident.\nContractswithconsumers.Whenoneofthepartiestoacross-bordercontractisaconsumer,\nthe rules are generally modified to provide additional protection for the consumer. In dis-\nputes in a European Union forum court, for example, if the cross-border vendor of products\nor services pursues their business activity in the place of the consumer\u2019s residence, or \u2019di-\nrects such activities to that country or to several countries including that country\u2019, then the\nfollowingspecialrulesusuallyapply:\n\u2022 Ifthereisnoexpresschoiceoflawinthecontract,theapplicablelawwillbethelawof\ntheconsumer\u2019shabitualresidence.Art6(1).\n\u2022 If some other law has been expressly chosen, that choice of law cannot deprive the\nconsumer of legal protections mandated by the law of the consumer\u2019s residence. Art\n6(2).\nAlthough the specific examples above are drawn from European legislation, they represent\nprinciples that regularly occur in other states that face conflict of law issues in consumer\ncontractdisputes.\n3.7 TORT\nAtortisanycivilwrongotherthanabreachofcontract.Unlikecontractualliability,tortliability\nisnotnecessarilypredicateduponavolitionalrelationshipbetweenthepersonwhocommits\natort(a\u2019tortfeasor\u2019)andthepersonharmedbythattortiousaction(a\u2019victim\u2019).\nThissectionwilladdressafewofthemorecommontortdoctrinesthatshouldbeconsidered\nby cyber security practitioners. Two substantive torts of interest (negligence and product\nliability)willbeexaminedinsomedetailtogetherwithaseriesofmoregeneraltortdoctrines\nsuch as causation and apportionment of liability. Rights of action granted to victims under\nother legal subject matter regimes (e.g., data protection, defamation, intellectual property,\netc) are also characterised as tort actions, and general tort concepts (see Sections 3.7.3,\n3.7.4,3.7.5&3.7.6)oftenapplytotheseaswell.\nKALaw&Regulation |October2019 Page93 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.7.1 Negligence\nMost legal systems recognise the idea that persons in society owe a certain duty to others\nin the conduct of their activities. If a person fails to fulfil this duty, and the failure causes\nharm to a victim, the victim is often given a right to take legal action against the tortfeasor\nforfinancialcompensation.\n3.7.1.1 Dutyofcare:howfardoesitextend\nLegalsystemsimplicitlyacknowledgethatapersonisnotalwaysresponsibletoeveryoneall\nofthetime.Somelimitationonthescopeofresponsibilityisnormal.ThecourtsofEngland,\nforexample,havesaidthatoneperson(Alice)owesadutyofcaretoanother(Bob)inrespect\nofagivenactivityifthreeconditionsarefulfilled:\n1. AliceandBobaresomehowproximatetooneanotherintimeandspace;\n2. it is reasonably foreseeable to Alice that her action (or inaction) could cause harm to\npersonsinapositionsimilartoBob;and\n3. with respect to Alice\u2019s action (or inaction), on the whole it seems fair and reasonable\nforpersonslikeAlicetoberesponsibletopersonsinapositionsimilartoBob.\nAlthough this three-pronged rule is not presented as a multinational norm, it illustrates the\ngeneral proposition that the scope of civil responsibility owed to others as a result of negli-\ngenceislimited.118\n\u2019Foreseeability\u2019 of harm is used routinely as a mechanism to limit the scope of liability in\nnegligencelaw.119 Foreseeabilityisnormallymeasuredbyreferencetowhetherornotanob-\njectively reasonable person would have foreseen harm. A tortfeasor is not excused from lia-\nbilityduetofailureofimagination,failuretoplan,oranaffirmativeefforttoavoidconsidering\npotentialvictims.120\nThis raises a number of related questions about possible duties of care in the context of\ncyber security, some of which are set out in Table 3.2. The purpose of Table 3.2 is merely\ntoconsidersomeofthetypesofrelationshipthatmightcreateadutyofcareunderexisting\nlaw.\nNegligence laws are tremendously flexible. As harm caused by cyber security failure be-\ncomes increasingly foreseeable, it seems likely that courts will increasingly interpret the\nconcept of duty of care to encompass various cyber-security related obligations owed to\nabroadergroupofvictims[216].\nThe concept of \u2019duty of care\u2019 does not normally depend on the existence of any business or\ncontractrelationshipbetweentortfeasorandvictim.Asacommonlyunderstoodnon-security\nexample,automobiledriversaresaidtooweadutyofcaretootherdrivers,tobicycleriders,to\npedestrians,andtootherswhoareexpectedtouseroadsandpathways.Onemighttherefore\nconsidertheextenttowhichthosewhosupplysoftwareonanon-commercialbasis,suchas\nopen source security software, might be found to owe a duty of care to those persons who\nforeseeablyrelyuponsuchsoftware.\nKALaw&Regulation |October2019 Page94 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nWhen this Conducts this activity Consider whether the potential tortfeasor owes a duty of\npotential in an unreasonable caretothesepotentialvictims:\ntortfeasor: manner:\nRetail mer- Maintaining secu- Cardholders;\nchant. rity of payment card\ndetails supplied by Merchantbanks;\ncustomers at point of\nsale. Cardissuingbanks.[215]\nEmail service Managing the security Servicesubscribers;\nprovider. of email servers and\nrelatedservices; Subscribers\u2019third-partyemailcorrespondents;\nMaking decisions Personsnamedinemailcorrespondence.\nabout the types of se-\ncuritytobeadopted.\nBusiness en- Managing the cyber Itsownstaffmembers;[216]121\nterprise. security of enterprise\nITorOT; Itscounter-partiesandsupplychainpartners;\nMaking decisions Unrelated third parties suffering harm when malicious\nabout the types of se- actorscompromisetheenterprise\u2019ssecuritymeasuresand\ncuritytobeadopted. usetheenterprise\u2019sITtolaunchonwardattacks;\nUnrelated third parties who suffer harm when compro-\nmisedOTcausespersonalinjuryorpropertydamage.\nDeveloper of Implementing stan- Merchants that adopt the web server software for online\nweb server dard cryptographic commerce;\nsoftware. communication proto-\ncols. SaaS providers that adopt the web server software for\ntheprovisionofvariousservicestocustomers;\nCustomerssubmittingpaymentcarddetails;\nBusiness customers that submit sensitive business\ndatatoaSaaSproviderthatadoptedtheserversoftware;\nBusiness enterprises that adopt the server within their\nITorOTinfrastructure.\nTrust service Registering the iden- Customerswhopurchasecertificates;\nprovider.122 tity to be bound to a\ncertificate; Thirdpartieswhoplacerelianceonthesecertificates;\nIssuingcertificates; Third parties who operate equipment which (without\ntheirknowledge)placesrelianceonthesecertificates.\nMaintaining the trust\ninfrastructure.\nWeb browser Selects root trust Naturalpersonswhousethewebbrowser.\ndeveloper. certificates for instal-\nlation into its web\nbrowser.\nTable3.2:Illustrationofpotentialdutyofcarerelationships\nKALaw&Regulation |October2019 Page95 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.7.1.2 Breachofduty:measuringreasonableness\nIf a person (Alice) owes a duty of care to another person (Bob) in the conduct of a given\nactivity, the question arises whether or not Alice has breached (failed to fulfil) her duty to\nBob.Theformulationofthesetwoelementstogether\u2013\u2019breachofadutyofcare\u2019\u2013isnormally\nsynonymouswith\u2019negligence\u2019.\nAtypicalstandardusedtoassessconductistoexaminewhetherornotAlicehasactedinan\nobjectively reasonable manner. In classic negligence law persons like Alice are not held to\na standard of perfection. Liability is based upon fault. In assessing fault, courts often make\nuseofrhetoricaldevicessuchastheobjectively\u2019reasonableperson\u2019similarlysituated.\nAsaframeworkformeasuringconduct,thereasonablepersonstandardhasprovenremark-\nablyresilientandflexibleovertime.Cybersecuritypractitionersoftenconvergewithopinions\non whether a given cyber security-related action (or inaction) was objectively reasonable or\nunreasonable. Changes in technology, development of new methods etc. can all serve to\nreviseopinionsonthedefinitionofwhatconstitutes\u2019reasonable\u2019securityconduct.\nThere is a temptation to conflate \u2019reasonable conduct\u2019 with efforts to define so-called \u2019best\npractice\u2019. Rapid advances in information technology (e.g., the falling cost of processing ca-\npability) routinely alter the cyber security landscape. Disruptive changes in the environment\n(e.g., the move to the cloud, the emergence of big data, the birth of the Internet of Things)\ncanrapidlyde-stabilisereceivedwisdom.\nThe highly respected US Judge Learned Hand warned of this in two famous decisions from\nthe mid-twentieth Century. Responding to an operator of an ocean-going cargo vessel that\nargued that the vessel\u2019s lack of a working radio did not constitute \u2019unreasonable\u2019 conduct,\nJudgeHandobservedinTheT.J.Hoopercasein1932that\u2019commonpracticeisnotthesame\nasreasonablepractice\u2019[217,218].Althoughthevesseloperatorconformedwithcommonin-\ndustrypracticeofthe1920s,JudgeHandclearlyexpressedtheideathatchangesintechnol-\nogyandthesurroundingenvironmentshouldspurre-examinationofmethodsandactivities.\nFifteen years later in the 1947 Carroll Towing case, Judge Hand announced a definition of\nreasonable conduct that may be helpful in assessing whether or not the time has arrived\nto adopt a given method of operation. He reasoned that when the burden (cost) of taking\na given precaution is less than: (1) the probability of loss in the absence of that precaution,\nmultipliedby(2)theamountofthelosstobeavoided,thenthe\u2019reasonable\u2019actionistoadopt\nthatprecaution[218,219,220].123Hisdecisionsetsoutatypeofcost-benefittest,althoughin\nthiscasethecost(the\u2019burden\u2019ofthepotentialprecaution)thatwouldbeincurredbyAlice(the\npersonwhoowesadutyofcare)iscomparedwithabenefit(i.e.,reducingtherisk-weighted\ncost of a potential loss) enjoyed by Bob (the person or set of similarly situated persons to\nwhomthatdutyofcareisowed).124\nThedoctrineof\u2019negligence,perse\u2019issometimesadoptedbycourtstoassessconduct.Using\nthis doctrine, a victim argues that the tortfeasor\u2019s conduct should be found to be unreason-\nable because that conduct violated a public law or widely-adopted technical standard. If Al-\nicemakesunauthorisedaccesstoBob\u2019scomputer(acrime,asdiscussedinSection3.5)and\ncausesdamagetothatcomputerorotherpartsofBob\u2019sinfrastructureasaresult,Bobcould\nplead that Alice is negligent, per se. This doctrine has already been pleaded together with\nstandardnegligenceclaimsinlegalactionarisingfromcybersecurity-relatedincidents[215].\nThis doctrine may become increasingly useful to victims as a result of increasing standardi-\nsation and regulation in the field of cyber security.125 The mere act of defining and adopting\nsecuritystandardsmaythereforeinfluencecourtsastheyseektechnicalframesofreference\nKALaw&Regulation |October2019 Page96 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nforassessingthe\u2019reasonableness\u2019ofconduct.\nAnother doctrine that may be useful in analysing cyber security failures is that of \u2019res ipsa\nloquitur\u2019 (i.e., \u2019the thing speaks for itself\u2019). Using this doctrine, a victim who might otherwise\nhavedifficultyprovingtheprecisenatureoftheactionthatcausedharm,claimsthatthemost\nappropriate inference to be drawn from the surrounding circumstances is that the accused\ntortfeasor bears the responsibility. This doctrine tends to be used against persons who are\nsupposedtomaintaincontroloverriskyordangerousprocessesthatotherwisecauseharm.\nA typical example might include legal action against a surgeon after a surgical instrument\nis discovered in the body of a post-operative patient, or a wild animal escapes from a zoo.\nIrrespectiveofthevictim\u2019sabilitytoprovealapseofcaution,themostappropriateinference\ntobedrawnfromthecircumstancesisalackofduecare.(Hence,thethingspeaksforitself.)\nIn the field of cyber security, one might imagine a case in which this doctrine is applied in a\nlegalactionagainstapersonwhocreatesanewformofmalwareforresearchpurposes,only\ntolosecontainment.126\nDoctrines similar to negligence per se and res ipsa loquitur might be defined in some legal\nsystemsasrulesconcerningthereasonabilityofconduct,ortheymightbedefinedasrulesof\nevidence\u2013relievingavictimofsomeoralloftheirburdentoproveunreasonableconduct,or\nshiftingtheburdentotheallegedtortfeasortoprovereasonableconduct.(Seethediscussion\nofevidenceinSection3.1.4.)\nAlthough they are not normally considered under the rubric of negligence law, other laws\nwhich influence cyber security practice define \u2019reasonable\u2019 conduct within their sphere of\ncompetence.AnexampleisfoundinthelawoffundstransferexpressedinArticle4A\u00a7202(c)\noftheUniformCommercialCodeasadoptedbyUSstates[213].\n3.7.1.3 Theinterpretationof\u2019fault\u2019differsbyplaceandchangesovertime\nAlthoughtheframeworkpresentedabovefordefining\u2019fault\u2019isgenerallywell-receivedbylegal\nsystems in most developed economies, this should not be mistaken for agreement on how\ntointerpretorapplythesestandards.\nTheinterpretationofboth\u2019dutyofcare\u2019and\u2019reasonable\u2019behaviourcanvarysignificantlyfrom\nstatetostate.Thisshouldnotbesurprising,asbothconceptsaresocialconstructsanchored\nbyopinionsaboutriskandresponsibilitythatprevailinagivensocietyatagiventime.\nTheinterpretationof\u2019dutyofcare\u2019has(withsomeexceptions)mostlyexpandedoverthepast\ncentury as the increasingly complicated and interconnected nature of modern life creates\nmore opportunity for the actions of one person to harm others. Similarly, the interpretation\nof \u2019reasonable\u2019 has generally moved in the direction of requiring more care, not less. These\ninterpretationscanbeexpectedtochangewithintheworkinglifeofapractitioner,especially\nastheharmcausedbycybersecurityfailurebecomesincreasinglyforeseeable,betterunder-\nstood,andeasiertoprovewithnewforensictools.\nSimilarly, practitioners are cautioned that potentially tortious acts committed in one state\nmight be assessed by the interpretation of standards of care adopted by another, more de-\nmanding,state.(SeethediscussioninSection3.7.6.)\nKALaw&Regulation |October2019 Page97 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.7.2 Strict liability for defective products\nIn the second half of the twentieth Century, a number of states with developed industrial\neconomies adopted rules of strict liability for defective products.127 This liability regime pro-\nvidesarightofactionforthosewhosufferpersonalinjury,death,orpropertydamage,caused\nby a defective product. A product is usually deemed to be defective when it fails to provide\nthe safety that a reasonable person would expect under the circumstances. Depending on\nthespecificlawinquestion,strictliabilitytypicallyattachestopersonswhoproduce,import\nor sell defective products or component products. Liability can attach to a tortfeasor who\nhasnopre-existingrelationshipwiththevictim.\nIn this type of liability, the focus of analysis shifts away from any notion of \u2019fault\u2019 by the\ntortfeasor and moves instead to an examination of the allegedly defective product. Liability\nis generally assessed without regard to the degree of reasonableness used in producing,\nexamining, or selecting products for sale. This type of strict liability is found throughout the\nlaws of the states of the US and is incorporated into EU member states\u2019 domestic laws as\nmandatedbyDirective85\/374[221,222].\nMost authorities believe that software, as such, does not fit within the various definitions of\n\u2019product\u2019applicableundersuchlaws.128 Evenso,undercurrently-existingproductliabilitylaw\na defect in a software component can be the source of a defect in a product into which it\nis installed. Liability of this sort arising from cyber security failures will probably increase\nas physical control devices are increasingly connected to remote data services, presenting\nmorecybersecurity-relatedriskstolifeandlimb.\nA cyberspace-connected product (e.g., an autonomous vehicle,129 an industrial control sys-\ntem, a pacemaker, a vehicle with fly-by-wire capability, a remotely operated home thermo-\nstat) that fails to deliver appropriate safety, is defective whether the safety is compromised\nthroughfailuresinelectrical,mechanical,software,orsecuritysystems.Thus,strictproduct\nliabilitycouldbeimplicatedincasesofpersonalinjuryorpropertydamagewhetherthesafety\noftheconnecteddeviceiscompromisedthrougherrorsinoperationaldecision-making(e.g.,\nan autonomous vehicle chooses to swerve into oncoming traffic after misinterpreting road\nmarkings)orerrorsincybersecurity(e.g.,aflawedorimproperlyimplementedauthentication\nschemepermitsaremotehackertocommandthesamevehicletodivertintooncomingtraf-\nfic,toopenthesluicegatesinadam,ortoalterahomethermostatsettingtoalife-threatening\ntemperature).\nInitscomprehensive2018evaluationofEuropeanproductliabilitylaw,theEuropeanCommis-\nsion referred extensively to the increased role of software and other so-called \u2019digital prod-\nucts\u2019 in modern commerce [223]. The Commission openly questioned the extent to which\ndigitalproducts(e.g.,softwareasaproduct,SaaS,PaaS,IaaS,dataservices,etc.)shouldbe\nredefined as \u2019products\u2019 under product liability law and thus subjected to strict liability analy-\nsis when defects cause death, personal injury, or property damage [224]. This is an area of\nlawthatcouldchangesignificantlyinthemedium-termfuture.\nKALaw&Regulation |October2019 Page98 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.7.3 Limiting the scope of liability: legal causation\nThe primary purpose of tort law is to compensate victims for harm suffered. A victim can\nnormallyonlybringalegalactionagainstatortfeasorifthevictimcanprovethattherelevant\ntortiousactionwasthecauseofalegallycognisableharmsufferedbythevictim.Putsimply,\npeoplemayactnegligentlywithouttortliability\u2013iftheirbehaviourcausesnoharm.\nCausation is one of the more difficult concepts to define in law. Different authorities take\ndifferentviewsaboutwhenitisappropriatetoholdatortfeasorresponsiblewhenitisclaimed\nthattortiousactionAhasproducedharmB.Thevictimisoftenrequiredtoprovecausation-\nin-fact as a first step. This concept is also expressed as \u2019but for\u2019 causation, because it can\nbe tested using the logical statement: \u2019But for tortious action A, harm B would not have\noccurred.\u2019 Liability can sometimes be eliminated by showing that a given harm would have\noccurredindependentlyofatortiousact[225,226].\nCausation-in-fact,however,isoftennotsufficientonitsowntoproveliability.Difficultiesarise\nwhen analysing more complex chains of causation where tortious action A causes result\nX , which in turn causes result X , ..., which in turn causes result X , which in turn causes\n1 2 n\nharmB.130AsthelinkbetweenAandB becomesincreasinglyattenuated,policymakersand\njudgesstruggletodefinethelimitsofresponsibilityofthepersoncommittingthetortiousact.\nSimilardifficultiesarisewhenthe\u2019lastcause\u2019inacombinationofnegligentactscausesharm\nthat is significantly disproportionate to the individual negligent last act, as a result of more\nseriouslapsesofjudgmentbyprioractors.Approachesadoptedtoresolvethisissueinclude\nlimitingtheresponsibilityofthetortfeasortoharmthatisreasonablyforeseeable[227].131\nThenarrowerdefinitionofcausationrequiredbytortlawmaybereferredtousingtermssuch\nas\u2019legalcausation\u2019or\u2019proximatecausation\u2019.\nProving that a specific harm was caused by a specific cyber security incident can be ex-\ntremelychallenging.Totakeacommonexample,anaturalpersonwhoseidentificationdata\nhasbeencompromisedmayfinditdifficultorimpossibletoprovethatthedatalostinagiven\ndatabreacheventarethesourceofthedatasubsequentlyusedbymaliciousactorstocarry\nout fraud through impersonation. Data breach notification laws help to redress the imbal-\nance of evidence available to victims in these cases, but even then, the victim must prove a\ncausallinkfromaspecificbreachtothefraudevent.Anotableexceptionisfinanciallossin-\ncurredfollowingabreachofpaymentcarddata,asthecausationofsubsequentfraudlosses\ncanbeeasilyinferredfromacontemporaneousdatabreachevent.Thesecasescreateother\nchallengesasdiscussedinSection3.7.4.\n3.7.4 Quantum of liability\nConsideration of the impact of tort law on cyber security related activity is incomplete with-\nout considering quantum of liability. (See Section 3.1.5.) Different states have different ap-\nproaches to defining what constitutes legally cognisable harm for purposes of tort law. A\nvictimisnormallyrequiredtoprovethefinancialvalueofharmcausedbyatortiousact.\nIn cases involving personal injury, the value of the harm is often calculated by reference to\neasilyunderstoodmeasuressuchas:lossofsalarysufferedbythevictimduetotheirinability\nto work, costs incurred by the victim for medical treatment, rehabilitation, or nursing care,\ncosts of installing accommodation facilitates for a permanently injured victim, etc. Some\nstates also allow compensation for harm in personal injury cases that is more difficult to\nquantifysuchaspainandsuffering,emotionaldistress,etc.\nKALaw&Regulation |October2019 Page99 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nA recurring issue in negligence cases concerns whether or not a victim can recover for so-\ncalledpureeconomicloss.Thereisadivergenceinthelawonthisquestion.Aleadingcase\ninEnglandconcernedtheeconomiclosscausedbyapoorlyconsideredcreditreferencepro-\nvided by a bank to its customer. Although the loss (the customer\u2019s subsequent inability to\ncollect a trade debt from its insolvent client) was purely economic in nature, the English\ncourt decided it should be recoverable because the bank professed special skill (financial\nawareness),andthevictimreliedontheflawedstatementtoitsdetriment[228].132\nAgrowingnumberofcaseshavebeenbroughtonthebasisofnegligentcybersecuritywhich\nclaimlossesotherthanpersonalinjuryorpropertydamage.Somecourtshavealreadyexhib-\nited a willingness to award damages under the law of negligence to victims whose losses\narepurelyeconomicinnature[216].133 Otherlegalactions(settledbythepartiesbeforetrial)\nhaveinvolvedsubstantialclaimsforeconomiclossesbasedonnegligentcybersecurity.134\nProving legally cognisable harm can be challenging for some victims who might otherwise\nwish to take legal action based on cyber security failures. One example concerns the loss\nofprivacy.Thereisalotofargumentabouthowtoquantify(financially)theharmcausedby\nbreach of privacy unless the victim has some business or economic interest that is directly\nharmedasaresult.135\nAnother common example concerns the loss of confidentiality of financial authentication\nmethods such as payment card details. Card holders would have difficulty proving harm to\nthe extent that fraudulent charges are refunded by the issuing bank. Of course, the issuing\nbank will then be able to demonstrate financial harm as a result of refunding these monies,\nplusaprorataportionofthecostsincurredissuingreplacementcardsearlierthanplanned.\nInresponsetothesetypesofdifficultiesinprovingharm,somestateshaveadoptedspecific\nlaws that provide a schedule of damages that can be claimed without the need to quantify\nharm. An example is found in the State of Illinois Biometric Information Privacy Act, which\nprovides that any party aggrieved by a violation of the act can take legal action and recover\nUS$1,000 per violation (for negligent violations) or US$5,000 per violation (for intentional\nviolations) of the law\u2019s mandates.136 Similarly, US copyright law allows some rights owners\ntorecoverminimumdamagesusingastatutorytariff.\nSomejurisdictions,notablymemberstatesoftheUnitedStates,arepreparedtoaward\u2019puni-\ntive damages\u2019 (known in some jurisdictions as \u2019exemplary damages\u2019) in some tort cases.\nThese awards are intended to punish and deter bad behaviour. These awards can be dis-\nproportionate compared to the underlying award for the harm suffered by the victim. Exam-\npleswhereacourtmightawardpunitivedamagesmostcommonlyincludecaseswherethe\ntortfeasor demonstrates a pattern of repeated poor behaviour, or the tortfeasor has made\nrelevantoperationaldecisionswithgrossindifferencetohumanlifeorhumansuffering.\nKALaw&Regulation |October2019 Page100 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.7.5 Attributing, apportioning and reducing tort liability\nThis section discusses a few miscellaneous legal doctrines that are important to consider\nwhenattemptingtoassessrisksoftortliability.\n3.7.5.1 Vicariousliability\nThere are circumstances when the liability of a tortfeasor can be attributed to a second per-\nson. The situation commonly encountered in cyber security is liability for the tortious act of\nanemployeeattributedtotheiremployer.Thistypeofvicariousliabilityapplieswhenthetort\niscommittedduringthecourseofanemploymentrelationship.\nVicarious liability is strict liability. Once a victim proves that the employee committed a tort\nwhich caused relevant harm and then proves that the tort was committed within the course\nof employment, the employer becomes strictly liable for that underlying tort. Pleas by the\nemployerabouttakingreasonableprecautions,mandatingreasonabletraining,duediligence\nwhenhiringortheemployee\u2019sdeviationfromemploymentstandards,aregenerallyineffective\nagainstclaimsofvicariousliability.\nThe Court of Appeal in England in 2018 affirmed a vicarious liability claim brought in a data\nprotectiontortaction.InWmMorrisonSupermarketsPLCvsVariousClaimants,thedatacon-\ntrollerMorrisonwassuedbyvariousdatasubjectsafteradisgruntledinternalauditemployee\npublished salary data of 100,000 employees in violation of data protection law.137 The se-\ncure handling of salary data fell within the field of operation with which the employee was\nentrustedandthereforethetortwascommittedbytheemployeewithinthescopeoftheem-\nploymentrelationship,thusleadingtovicariousliability[193].Attimeofwriting,thisdecision\nispendingappealinTheSupremeCourtoftheUnitedKingdom.138\nTheonlyreliablemethodtoavoidvicariousliabilityistoencourageemployeebehaviourthat\nlimits or avoids tortious activity. This is worthy of consideration by those who develop and\nenforceacceptableusepolicies,staffsecuritystandards,employmentpolicies,etc.\n3.7.5.2 Jointandseveralliability\nIncaseswheremorethanonetortfeasorcanbesaidtohavecausedharmtoasinglevictim,\ntort law often imposes joint and several liability. The doctrine is simple: any jointly responsi-\nble tortfeasor could be required to pay 100% of the damages awarded to a victim. Although\nthetortfeasorsatisfyingthevictim\u2019sfinancialclaimmayhavetherighttopursuecompensa-\ntion (a.k.a. \u2019contribution\u2019) from other tortfeasors, this becomes problematic when the joint\ntortfeasors have no financial resources or are resident in foreign states where there is no\neffectivemethodofenforcingsuchrights.\nPractitioners may wish to consider the impact of this rule when working with supply chain\npartnersorjointventurersthataresmall,donothavemuchcapital,orareresidentinaforeign\nstatewhereenforcementofdomesticjudgmentsmaybeproblematic.\nKALaw&Regulation |October2019 Page101 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.7.5.3 Affirmativedefences\nTortfeasors are sometimes able to take advantage of certain affirmative defences to tort\nclaims.Atortfeasorwhoisabletoprovetherelevantelementsofthesedefencescanreduce,\norsometimeseliminate,theirliability.\nIn the context of negligence, a common category of defences includes \u2019contributory negli-\ngence\u2019or\u2019comparativefault\u2019ofthevictim.Inthistypeofdefence,thetortfeasorattemptsto\nprovethatthevictim\u2019sownnegligencecontributedtotheirharm.Dependingonwhichstate\u2019s\ntort law is applicable to the claim, a successful defence can reduce or eliminate liability to\nthevictim.\nAnother category of defence that can be useful in various cyber security contexts include\n\u2019assumptionofrisk\u2019or\u2019consent\u2019.Inthistypeofdefence,thetortfeasoravoidsliabilitybyprov-\ningthatthevictimwasawareof,orknowinglyconsentedto,therisksthatultimatelycaused\nthe harm. This type of defence can be especially useful for those who supply cyber security\nservices that risk damage to client infrastructure, such as penetration testing. Practitioners\noften draft commercial engagement documents with a view to attempting to satisfy one of\nthesedefencesintheeventthatsomethinggoeswrongduringtheengagement.\nAs regards strict product liability, many states offer a so-called \u2019state of the art\u2019 defence.\nWhere this defence is allowed, a party can avoid strict liability by proving that a product, al-\nthough defective, was produced at a time when the technological state of the art would not\nhave enabled discovery of the defect. It is debatable how this defence might apply to prod-\nucts made defective as a result of cyber security flaws.139 Of greater significance, perhaps,\nis the affirmative defence against strict liability for a defective product available if the de-\nfendingpartycanprovethatthedefectispresentduetocompliancewithlawsorregulations\nconcerningproductdesign.140\n3.7.6 Conflict of law \u2013 torts\nDeciding which state\u2019s law applies to various aspects of a tort dispute is normally vested\nwithinthejuridicaljurisdictionoftheforumcourtdecidingthedispute.Therulesthatareused\ntodecidethisquestioncananddovaryfromstatetostate.WithintheEuropeanUnion,these\nruleshavebeenharmonisedformosttortsthroughthemechanismofthe\u2019RomeII\u2019Regulation\n[229]. Individual US states, by contrast, remain free to adopt their own individual choice of\nlawprincipleswhendecidingwhoselawshouldbeappliedtoaspectsoftortdisputes.Even\nwiththesevariationssomeusefulandgeneralisableprinciplescanbeidentified.\nBroadly speaking, courts that examine tort claims between persons in different states tend\nto adopt one of two methods most often used to decide whose law to apply: apply the law\nof the place where the tortious act originated or apply the law of the place where the injury\nwas suffered. Historically, it might have been difficult to find cases where these two events\noccurred in different states. Modern commerce, however, has produced a number of cases\nwherethetwoeventscanbewidelyseparatedbyspaceandtime.141\nIndisputesheardincourtsthroughouttheEuropeanUnion,theapplicablelawinatortaction\n(withsomeexceptions)isthelawoftheplacewherethedamagewassuffered.(RomeII,Art\n4(1).)Incasesofproductliability,therulesareslightlymorecomplexandtheapplicablelaw\nmightbetheplaceoftheinjuredparty\u2019shabitualresidence,theplacewheretheproductwas\nacquired,ortheplacewherethedamageoccurred.(RomeII,Art5.)\nThe above rules provide a reasonable indicator of the risk that cyber security failures occur-\nKALaw&Regulation |October2019 Page102 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nringduetoactionsperformedinStateA,andsubsequentlycausingharmtopersonsinState\nB, could easily become amenable to liability analysis under the tort law of State B. Thus\npractitioners (and their employers) might be held to a higher standard of care imposed by a\nforeign state where victims of negligent cyber security or defective IoT products are found.\n(See,forexample,thediscussionofliabilityinSection3.10.4.)\n3.8 INTELLECTUAL PROPERTY\n[107,108]\nThe complexity of intellectual property law prompted a nineteenth-century US jurist to com-\nment that this subject is closest to \u2019the metaphysics of law\u2019.142 Metaphysical or not, intel-\nlectual property can serve to constrain or encourage actions by cyber security practitioners.\nThissectionwillsummarisesomepointswherethetwofieldsintersect.\n3.8.1 Understanding intellectual property\nIntellectual property rights are negative rights \u2013 they convey the right to demand that other\npersons cease a prohibited activity. The nature of the activity to be prohibited is defined in\nthelawestablishingthatright.Ownershipofintellectualpropertynormallyconveysarightof\naction against others who transgress one or more acts prohibited by the relevant property\nright.\nIntellectual property rights do not give the affirmative right for the owner to take any action\nimaginablewiththesubjectmatter.Agivenaction(e.g.,combiningone\u2019sowncodewithoth-\ners, abusive intellectual property licensing practices) could infringe third-party intellectual\npropertyrightsortriggerliabilityundercompetitionlaw,amongothers.\nRegistered intellectual property rights (e.g., patents and registered trademarks) are granted\non a state-by-state basis following application to an appropriate state agency, often follow-\ning examination by state officials. Unregistered intellectual property rights (e.g., copyright)\nusuallyspringintoexistencewithoutanyneedforinterventionbystateofficials.\nTheterm\u2019publicdomain\u2019oftencausesconfusion.Inthefieldofintellectualpropertylaw,\u2019pub-\nlicdomain\u2019referstoaworkinwhichnocurrentintellectualpropertyrightsubsists.Bycontrast,\nthephrase\u2019publicdomain\u2019isalsousedcolloquiallytoindicatealack(orloss)ofconfidential-\nity.Todistinguishthesetwo,ifaconfidentialoriginalwrittenworkissubsequentlypublished\nthecontentsbecomepubliclyknown.Confidentialityhasbeenlost.Thiswork,however,may\nstill be protected by copyright unless these rights are expressly relinquished. In contrast, if\na person who writes software then declares that they are placing the code \u2019in the public do-\nmain\u2019thisstatementisoftentreatedasanirretrievablerelinquishmentofcopyright.Theterm\nshouldbeusedwithcare.\nKALaw&Regulation |October2019 Page103 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.8.2 Catalogue of intellectual property rights\nThis section will describe some of the intellectual property rights most likely to be encoun-\ntered by cyber security practitioners. Additional intellectual property rights that may be of\ninterest to practitioners, but which are not addressed in this section, include protections for\nsemiconductortopographies,theEUsuigenerisrighttopreventtheextractionorreutilisation\nofthecontentsofadatabase,andregisteredandunregistereddesignrights.\nIn many circumstances, contract rights (especially licensing agreements) supplement intel-\nlectual property rights and may be treated informally as a type of intellectual property. To\nmake matters more confusing, persons in business often use the phrase \u2019intellectual prop-\nerty\u2019inanexpansiveandcolloquialfashiontorefertoanyworkproductorprocessthatisthe\nresultofintellectualeffort-whetherornotitincorporateslegallyrecognisedandenforceable\nintellectualpropertyrights.Thissectiondealsonlywithlegalrights,assuch.\n3.8.2.1 Copyright\nCopyright143 is an unregistered right144 that springs into existence on the creation of a suffi-\ncientlyoriginalwork.Copyrightsubjectmatterincludesliteraryworks,whichforthispurpose\nincludessoftwarecode(bothsourceandexecutablecode).Thismakescopyrightespecially\nimportantforthedevelopersandusersofsecurityproductsembodiedinsoftware.\nThe scope of copyright is generally said to be limited to the expression of an idea rather\nthan the idea itself. Thus, copyright in software code normally protects only the code as\nwrittenandnotthefunctionalityoftheresultingsoftwareproduct.Protectionoffunctionality\nisusuallytheprovinceofpatentrights.\nThe term of copyright is, by ICT standards, extremely long. Literary works are normally pro-\ntectedforthelifeoftheauthorplus70yearsfollowingtheirdeath.Whilethetermofcopyright\nprotection granted to computer software may be less than this, it remains sufficiently long\nthattheexpirationofthecopyrighttermisunlikelytoapplytoanyrelevantsoftwareencoun-\nteredbyasecuritypractitionerwithintheirlifetime.\nInfringementofcopyrightnormallyconsistsofactssuchascopying,transmitting,displaying\nor translating a significant part of the protected work. Proving that one work infringes the\ncopyrightembodiedinasecondworkrequiresproofofcopying.Copyingcanbeinferredfrom\nsufficient points of similarity between the two works \u2013 there is no need to prove knowledge\nof copying by the accused. A plethora of forensic techniques have been developed over the\ncourseofdecadestoassessinfringementofsoftwaresourcecode.\nLiability for copyright infringement can sometimes be avoided through various \u2019fair use\u2019 or\n\u2019fairdealing\u2019limitations.Thesearedefineddifferentlyfromstatetostate.145\nThe scope of copyright protection was expanded at the turn of the twenty-first century to\nencompasstherighttotakelegalactionagainstpersonswhointerferewiththetechnological\nmeasures used to protect copyright works [230] at Art 11.146 This was intended to provide\nadditional legal rights of action against those who circumvent technologies such as digital\nrightsmanagementsystems(seethediscussioninSection3.8.4.)[231].\nKALaw&Regulation |October2019 Page104 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.8.2.2 Patents\nApatentisaregisteredintellectualpropertyright,grantedonastate-by-state147 basisfollow-\ningapplicationandexamination.Patentsaremeanttoprotectaninventionthatisnoveland\nthat also includes an additional distinguishing characteristic variously described by states\nas an \u2019inventive step\u2019, a \u2019non-obvious\u2019 character, or something similar. This inventive step re-\nquirementis a policydevice usedto limit patentprotectionto inventionsthat aresignificant\nin some fashion, rather than trivial.148 Novel inventions that would have been obvious to a\npersonskilledintherelevanttechnicalartarenormallydeniedpatentprotection.\nStates expressly define additional subject matter that may not be claimed as a patented\ninvention. Common exclusions of special interest to security practitioners are software, as\nsuch, and an idea or mathematical formula, as such.149 Inventions that embody these, how-\never,canbepatentablesubjectmatterinappropriatecircumstances.\nTheUSpatentsystemhaschangeditsapproachtosoftwarepatentsinthepastfewdecades\nand is increasingly receptive to them. Even states that notionally reject the concept of soft-\nware patents regularly grant patents on inventions that are embodied in software. In other\nwords,softwarepatents(crudelyspeaking)arearegularfeatureoftheICTdomain.\nCybersecurity-relatedinventionsthatappearontheirfacetobepurelymathematicaloralgo-\nrithmic (e.g., cryptographic methods) can be the subject of patent protection as embodied\nin various devices \u2013 including software-enabled devices. Aspects of historically significant\ncryptography inventions have been protected by patents, including DES, Diffie-Helman, and\nRSA [232]. Although the patents on these breakthrough cryptographic inventions have now\nexpired,thefieldofcybersecurityinnovationremainsawashwithpatentsandpendingpatent\napplications[233,234,235].\nThe price of a patent is paid in two forms: money and public disclosure. Applications are\nexpensive to prosecute and expensive to maintain. The process of navigating international\napplication and examination is sufficiently complex that (expensive) expert assistance is\nalways advisable, and often critical to success. In addition to application and examination\nfees paid to states, those who are granted a patent are then required to pay periodic fees to\nmaintainthepatentthroughoutitslife.\nBeyond the monetary cost, public disclosure is a core feature of the patent system. The\npatent application must disclose how the invention works in a manner that would enable a\nskilled technical practitioner to replicate it. The application and the granted patent, together\nwithexaminationcorrespondence,150 isnormallypublishedtoenablefuturestudy.151\nThe term of a patent is normally 20 years from the date of application. Patents are typically\nsubjected to an examination process which can take years to conclude. When a patent is\ngranted, the right holder is normally given the right to take legal action retrospectively for\ninfringements that took place after the application but before the grant, even if the infringe-\nment happened prior to the publication of the application.152 The validity of a patent can be\nchallengedpost-grantandthisisacommonmethodofdefendingagainstinfringementlegal\nactions.\nInfringement of a patent normally consists of acts such as manufacturing, distributing, im-\nporting, exporting or selling a product or service that embodies the claimed invention. Prov-\ning infringement involves a forensic comparison of the accused device or service with the\ninvention as claimed in the granted patent. There is no need for a right holder to prove that\nthe invention was copied from the patent or from any product. Many people who infringe\nKALaw&Regulation |October2019 Page105 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nICT-related patents do so initially without any awareness of third-party products or patent\nrights.153\n3.8.2.3 Trademarks\nTrademarks are usually registered154 intellectual property rights, granted on a state-by-state\nbasisfollowingapplication.155\nAtrademarkisasymbolorsignusedtodistinguishoneperson\u2019sbusinessorproductsfrom\nanother\u2019s. The most common trademarks consist either of words or figures.156 Trademarks\nare granted within defined use categories, meaning that it is possible for two different per-\nsons to have exclusive rights for the use of the same symbol in different lines of business.\nThe purpose of trademarks is to reduce the possibility of confusion for those who procure\ngoods or services, and to protect investment in the reputation of the enterprise supplying\nthosegoodsorservices.\nTrademarksarenormallyregisteredforaperiodof10years,althoughtheseregistrationscan\nberenewedindefinitely.157\nInfringement of a registered trademark normally consists of displaying an identical or con-\nfusinglysimilarmarkincombinationwithproductsorservicesthatfallwithintheregistered\nscope of exclusivity.158 Proving infringement involves comparing the accused sign with the\nregistered trademark and assessing whether the two are identical or confusingly similar.\nThere is no requirement to prove that the accused party has actual knowledge of the reg-\nisteredtrademark.159\nInfringementoftrademarkcanoccurthroughtheuseofadomainnameidenticalorconfus-\ninglysimilartoaregisteredmark.Thiscreateswell-knowntensions,asdomainnamesare(by\ndefinition)globallyunique,whiletrademarksarenot.Toprovethattheuseofadomainname\nconstitutesinfringementofaregisteredtrademark,arightsownersmustnormallyprovethat\nthe domain name is identical or confusingly similar to the mark, and that the domain name\nis used in the supply of goods or services within the scope of exclusive use defined in the\ntrademarkregistration.\nCertification marks are a type of trademark that is used to demonstrate conformity with\na given standard.160 These marks are registered by a standards body, which then grants li-\ncences to use the mark subject to compliance with the relevant standard. Any person who\nsuppliesrelevantgoodsorservicesbearingthemarkthatdoesnotconformwiththerelevant\nstandardriskslegalactionfortrademarkinfringement.\nAcollectivemarkisatrademarkthatisusedtoidentifythemembersofanassociation,such\nasaprofessionalsociety.Havingregisteredtherelevantcollectivemark,thesocietycantake\naction against those who use it without authorisation, and revoke authorisation from those\nwhosemembershiphasceased.\nKALaw&Regulation |October2019 Page106 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.8.2.4 Tradesecrets\nTrade secrets were traditionally protected under general tort law, giving persons who at-\ntempted to keep their secrets the right to take legal action against those who inappropri-\natelyobtained,usedordisclosedthesesecrets.Asthetwentiethcenturyprogressed,atrend\nemergedtoincreasethelegalprotectionoftradesecrets.ThepositionofindividualUSstates\nhasbeensignificantlyharmonisedsincethe1980s,andtheUSfederalgovernmentadopted\nthe Economic Espionage Act 1996 as a national trade secret law to deter trade secret theft\n[236, 237]. The European Union significantly harmonised its approach to trade secrets with\neffectfrom2018[238].\nThe subject matter of a trade secret is generally regarded as information that is secret, is\nvaluable because it is secret and remains secret due to the reasonable efforts of the secret\nkeeper.Subjectmattercanincludeinformationasdiverseasaningredientslist,amethodof\nmanufacture,acustomerlist,analgorithmordetailsofapatentableinventionpriortopatent\napplicationandpublication.ExamplesofcurrenttradesecretsinICTincludethefinerdetails\nofGoogle\u2019sPageRankalgorithmandvariousproprietarycryptographicalgorithms.\nMaintaining confidentiality is a core element of protecting a trade secret. Trade secrets can\nbe protected indefinitely so long as secrecy is maintained.161 Unfortunately, loss of trade se-\ncretsthroughactsofcyberindustrialespionageisbelievedtobewidespreadandshouldbe\na source of major concern for cyber security practitioners [239]. Loss of confidentiality of\npatentablesubjectmattercanbeespeciallydamaging,aspublicationofinventivedetailsby\nathirdpartypriortopatentapplicationnormallydestroyspatentability(astheinventionthen\nceasestobe\u2019novel\u2019).\nOwnersoftradesecretrightscannormallytakelegalactionagainstpersonswhomisappro-\npriate their secrets. In some circumstances, owners of a trade secret can also take legal\naction against third parties who receive a trade secret from a mis-appropriator (see the dis-\ncussioninSection3.8.4.2).\n3.8.3 Enforcement \u2013 remedies\nConsiderationoftheimpactofintellectualpropertylawisincompletewithoutalsoconsider-\ningremediesavailabletoasuccessfullitigant.(SeeSection3.1.5.)\n3.8.3.1 Criminalliability\nIn certain egregious circumstances, infringement of intellectual property \u2013 especially copy-\nright and trademark \u2013 can be prosecuted as a crime. These prosecutions usually require\nproof that the infringing party was aware of the infringement and are often based on a pat-\nternorpracticeofinfringingtheserights,enmasse.\nThosewhoviolatelegalprohibitionsagainstanti-circumventiontechnologiesforcommercial\nadvantageorfinancialgain,faceamaximumsentenceunderUScopyrightlawof5yearsfor\nafirstoffenceand10yearsforasecondoffence.162UnderBritishcopyrightlawapersonwho\nmanufactures, imports, distributes, etc., a device intended to circumvent these protections\nfacesamaximumsentenceof2years.163\nSome states classify the knowing misappropriation of a trade secret as a crime. The US\nadopted a national trade secret criminal law in 1996 [237]. These laws can serve as a basis\n(not necessarily the only one) for the criminal prosecution of industrial espionage activity.\nSomestatesdonotdefinemisappropriationoftradesecretsasacrime.164\nKALaw&Regulation |October2019 Page107 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.8.3.2 Civilliability\nArightsownerisnormallyabletotakelegalactionagainstapersonforinfringementofintel-\nlectualproperty.Remediesforinfringementnormallyincludemonetarydamages,whichmay\nbe calculated by reference to a so-called reasonable royalty, a statutory tariff or a demand\nthat the infringer make an account of any profits \u2013 a demand to pay to the rights owner the\neconomicbenefitgainedfromtheinfringement.\nCivil remedies may also include orders to seize, and perhaps destroy, products that infringe\nintellectual property rights. These orders are especially useful when interdicting shipments\nof\u2019knock-off\u2019goodsthatembodytrademarkorcopyrightinfringements.\nWith respect to trade secrets, persons in the US who suffered misappropriation of a trade\nsecret traditionally brought legal action under the relevant law of their individual state. In\n2016, the US national government adopted the \u2019Defend Trade Secrets Act 2016\u2019 amending\nthe Economic Espionage Act to authorise private rights of action under federal law for the\nmisappropriationoftradesecrets[240].\nAcommoncivilremedyfortheinfringementofintellectualpropertyisacourtorderaddressed\ntotherelevantinfringingpartytoceaseanyongoinginfringingactivity.Inthecontextofpatent\nenforcement, this can be especially devastating as an enterprise finds itself unable to con-\ntinuemanufacturingorsellinganinfringingproduct.Inthecontextoftradesecretmisappro-\npriation, this might include an order to cease manufacturing products employing the trade\nsecret or an order prohibiting the publication of the trade secret. (Imagine how these would\nincreasetheQvaluedescribedinSection3.1.5.)\nIn an online context, such orders might demand that content suppliers or server hosts take\ndown content that infringes copyright or a trademark. Parties who enforce patents have\nsought orders to force a service provider to stop the operation of infringing services deliv-\neredviaanonlineenvironment[241].\n3.8.4 Reverse engineering\nReverseengineering,\u2019theprocessofextractingknow-howorknowledgefromahumanmade\nartefact\u2019,hasgenerallybeenrecognisedasanacceptedpracticealthoughtreateddifferently\nwithinvariouscategoriesofintellectualpropertylaw[242,243].Reverseengineeringhashis-\ntoricallybeenviewedastheflip-sideoftradesecretmisappropriation.Whiletradesecretlaw\nprohibits the misappropriation of a trade secret (e.g., industrial espionage, bribery etc.), the\nscientificstudyofadevicesoldandpurchasedinapublicsaleinanefforttolearnitssecrets\nhasgenerallybeenviewedas\u2019fairgame\u2019.Ifatradesecretissuccessfullyreverseengineered\ninthisfashionandpublished,itceasestobeatradesecret.\nSincetheturnofthetwenty-firstcentury,however,thelegaltreatmentofreverseengineering\nseems to have shifted following the adoption of laws prohibiting interference with anticir-\ncumventiontechnologies,generallymakingtheseactivitiesmoredifficult[244,245].\nMost difficulties arise in the context of reverse engineering software products. Software li-\ncensesoftencontainonerousrestrictions,includingsomelimitationsonreverseengineering\ngenerallyand\/orreversecompilingspecifically.Europeanlawgenerallyprohibitsanyrestric-\ntionontheabilityofanauthorisedsoftwareusertoobserveandstudythefunctioningofthis\nsoftware,andalsograntstheseusersthelimitedrighttoreversecompilespecificallyforthe\npurposeofgaininginteroperabilityinformation[246].\nKALaw&Regulation |October2019 Page108 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nPamela Samuelson has produced a useful comparative summary of this confusing land-\nscape[247].\n3.8.4.1 Circumventingcopyrighttechnologicalprotectionmeasures\nFollowing the expansion of copyright law to prohibit the circumvention of technological pro-\ntection measures, those who wish to meddle with these measures do so at their peril. The\nimplementationoftheselawsprovidessomeexceptionstoliabilityforresearchinspecified\ncircumstances, although the precise circumstances vary. Each exception relied upon must\nbeexaminedwithcare.\nBritishcopyrightlaw,forexample,includesaspecificexemptiontoliabilityforcircumventing\nprotectionmeasuresincopyrightworksotherthanacomputerprogram,forpersonsconduct-\ning research into cryptography, \u2019unless in so doing, or in issuing information derived from\nthat research, he affects prejudicially the rights of the copyright owner\u2019 (CPDA s.296ZA(2)).\nInotherwords,oneoftheseresearchersmightfaceperilunderthelawiftheyweretopublish\ndetails that made it possible for others to circumvent the protection measures. There is no\nsuch general exception in British law for cryptography research involving the circumvention\nofmeasuresoncomputerprograms(CPDAs.296).\n3.8.4.2 Testingaproprietarycryptographicalgorithm\nSecurity researchers hoping to test the strength of a cryptographic system normally require\naccess to the relevant algorithm. This arises naturally from Kerckhoffs\u2019s Principle and is\nwell-known to cryptographers. A person who wishes to test the security capabilities of an\nalgorithm encounters practical difficulties when the manufacturer of the product employs a\nproprietaryalgorithmprotectedbytradesecretanddoesnotwishtodiscloseitfortesting.\nIn the Megamos Crypto case (Volkswagen v Garcia), the cryptographic product under ex-\namination (a special purpose processor chip used in automobile engine immobilisers and\nkeys) was manufactured under license by the algorithm\u2019s developer. The testers (academic\nresearchers) did not reverse engineer this product, which could have been accomplished\nusinganexpensivechipslicingtechnique.Theychoseinsteadtorecoverthealgorithmbyre-\nverseengineeringthird-partysoftware(TangoProgrammer)thatimplementedtheMegamos\nalgorithm[248].\nTheresearchersintendedtopublishtheresultsoftheiranalysis,whichwouldhavedisclosed\nthealgorithm.Partieswhohadaninterestinthetradesecretstatusofthealgorithmbrought\nlegalactionintheEnglishcourtstohaltpublication.TheEnglishHighCourtwasconfronted\nwith a request to prohibit publication of the research pending a full trial on the merits. The\ncourtseemedtoacceptthatiftheresearchershadrecoveredthealgorithmfromtheproduct\nitselfusingthechipslicingtechnique,therewouldbenocasetoanswer.Butthecourtfound\nthattherewasapossibilitythatthethird-partyTangoProgrammersoftwaremayhaveexisted\nonlyasaresultoftradesecretmisappropriation,andthattheresearchersshouldhavebeen\naware of this. The court issued a preliminary injunction prohibiting publication [249, 250].\nThe case was settled before trial commenced, and the researchers eventually published a\nversionoftheirpaperhavingredactedacomponentofthealgorithm[251].\nKALaw&Regulation |October2019 Page109 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.8.5 International treatment and conflict of law\nTheexistenceofintellectualpropertyrightsandassessmentoffirstownershiparenormally\nmeasuredbyreferencetotheplacewheretheserightscomeintoexistence[229].\nAftercreationinonestate,theexistenceofcopyrightisgenerallyrecognisedinmoststates\naroundtheworldbytheoperationofvariouscopyrighttreaties[252].Ifanauthorwritessome\nsoftware while resident in State A, the copyright laws of State A are normally viewed as the\nsource of authority for identifying the existence and first ownership of that copyright, while\ntreaties oblige most other states to enforce that copyright within their territories (subject to\nlimitationsorexclusionsgrantedbythosestates).\nGrantsofregisteredintellectualpropertyrights(e.g.,patentsandregisteredtrademarks)are\nmade on a state-by-state basis. When identical or confusingly similar trademarks are regis-\nteredindifferentstatestodifferentowners,therightsofeachownerareequallyvalidwithin\ntheirrespectiveregisteredterritory.Thiscancauseconfusionwhenatrademarkownerinone\nstate makes an accusation of infringement against the owner of a second, nearly identical,\ntrademarkinanotherstate[253].\nInfringement,anddefencestoinfringement,arenormallyassessedbyreferencetothelawof\nthe place where the intellectual property is infringed [229]. In cases of copyright, the courts\nshowapersistentwillingnesstoapplytherules(andlimitations)imposedbytheirdomestic\ncopyrightlawswithrespecttoworksthataredistributedordisplayedin-stateviatheInternet\n[95,131].Thecourtsarealsowillingtoenforcedomesticpatentsagainstdomesticinstantia-\ntionsofclaimedinventionsdeliveredaspartofaglobalserviceoffering[241].\n3.9 INTERNET INTERMEDIARIES - SHIELDS FROM\nLIABILITY AND TAKE-DOWN PROCEDURES\n[107,108]\nDuring the 1990s, policy makers around the world adopted special exceptions to shield cer-\ntain communication service providers from liability for online content in prescribed circum-\nstances.Thechangesweremadeinresponsetoearlycasesthatheldthesecommunication\nserviceprovidersliableunderthen-existinginterpretationsofcontentliabilitylawsincluding\ncopyright and defamation. These shields may be structured as affirmative defences, mean-\ningthattheuseoftheshieldrestsupontheabilityofanaccusedtoprovethattheyareentitled\ntobetreatedundertherelevantexception.\nIntheEuropeanUnion,theseexceptionstoliabilityweregenerallymandatedbyArticles12-15\nof the Ecommerce Directive. These provide generalised liability shields in respect of \u2019mere\nconduit\u2019,\u2019hosting\u2019and\u2019caching\u2019services[210].165 Theseprinciplesaretransposedintomem-\nberstatelawintheusualfashion.\nIn US law, various shields from liability arising under copyright, defamation etc., have been\nadoptedonasubject-by-subjectbasis.166\nThe widest scope of exemption from liability is normally afforded to those whose service\nconsists of acting as a mere conduit for data.167 These carriers are often exempted from\nliability without exception, although they may be ordered to filter traffic as part of a court-\norderedenforcementplan[131].\nKALaw&Regulation |October2019 Page110 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nThose who provide a service that consists of nothing more than hosting data are often ex-\nempted from content-related liability, unless and until they have reason to know that their\ninfrastructure is hosting illicit content.168 At this point, they often have an obligation to take\ndown offending content \u2019expeditiously\u2019. Confusion over how to implement this obligation re-\nsultedinchangestosomelawswhichnowspecifyindetailhowtake-downnoticesshouldbe\nsent to hosting organisations, and how hosting organisations are required to reply to these\nnotices.169\nThe topic of shielding service intermediaries from liability is not without controversy. Policy\nmakersre-examinetheseliabilityexceptionprovisionsfromtimetotime[254,255,256,257].\nIn2018,theUSCongressamendedthemainUScontentliabilityshieldsothatitnolongerpro-\ntectsanypersonincasesarisingfromclaimsofpromotingprostitutionoractinginreckless\ndisregardofsextrafficking.170\n3.10 DEMATERIALISATION OF DOCUMENTS AND\nELECTRONIC TRUST SERVICES\nAstheageofecommercedeveloped,concernsgrewabouthowtotransposetraditionalmeth-\nods for assuring information authenticity and integrity (e.g., signatures, seals, and indelible\nink)intoaformthatcouldbeusedinfullyelectronicandonlineenvironments.Securitytech-\nnology experts responded with an array of new technologies (often based on PKI) intended\ntoaddresstheseconcerns.\nThis, in turn, prompted a series of legal concerns which potentially interfere with the utility\nof such technologies. These broadly fit into three categories. The first relates to the admis-\nsibilityofelectronicdocumentsintoevidenceinlegalproceedings.Thesecondcategoryare\nlawsthatthreatenlegalenforceabilityofcommunicationsmadeinelectronicform.Thethird\ncategory relates to uncertainty about rights and responsibilities in the provision and use of\nidentificationtrustservices.\n3.10.1 Admission into evidence of electronic documents\nThe admissibility171 of electronic data as evidence into legal proceedings, once the subject\nof much suspicion by courts, has now become commonplace. Policy makers and judges\nhavebecomeincreasinglyconfidentaspractitionershavedevelopedforensictechniquesto\nassure the authenticity and integrity of this data. Occasionally, local rules mandate special\nprocedures for admitting electronic evidence. While forensic disputes about the weight to\nbe accorded to this evidence persist, this is conceptually no different from arguments that\nmightariseaboutanyothertypeofrecordedevidence.\nKALaw&Regulation |October2019 Page111 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.10.2 Requirements of form and the threat of unenforceability\nA requirement of form is any obligation imposed by applicable law that a given communica-\ntion will be enforceable if and only if it takes a prescribed form. A failure to comply with an\napplicablerequirementofformcreatestheriskthatthesubjectmatterofthecommunication\nwillbecomeunenforceableinwholeorinpart.\nDifferentstateshaveadopteddifferingrequirementsofformoverthecourseofcenturiesin\nresponsetowhateverpolicyissuewasascendantatthetime.Asaresult,theserequirements\nareremarkablydiverseandcanariseinawidevarietyofcircumstances.\nExamples of requirements of form adopted by various states include rules demanding that,\ninordertobeenforceable:\n\u2022 certainlegalnoticesmustbedelivered\u2019inwriting\u2019;\n\u2022 certaintypesofcommitmentmustbeinwritingand\u2019signed\u2019by(or\u2019executedunderthe\nhandof\u2019,etc.)thepartyagainstwhomenforcementissought;\n\u2022 certainsubmissionstoastateagencymustbemadeusingaspecifiedform;\n\u2022 certain contract clauses or notices that seek to restrict liability must be presented in\na prominent fashion (e.g., all in uppercase letters, bold or italic font, etc) to the party\nagainstwhomtheyaretobeenforced;\n\u2022 certain contract clauses that seek to restrict liability must be initialled by the party\nagainstwhomtheyaretobeenforced;\n\u2022 a last will and testament must be delivered in writing and signed by the testator in the\npresenceofaprescribednumberofwitnesses,whomustalsosignthedocument;and\n\u2022 adocumenttransferringtitletocertaintypesofpropertymustbesignedinthepresence\nofastatejudicialofficial,whomustthenaffixanofficialsealtothedocument.\nTheexamplesabovearemerelyintendedtoacquaintthepractitionerwithsomeofthemore\ncommontypesofrequirementadoptedwithindifferentlawsbydifferentstates.Somestates\nandsomelawsimposerelativelyfewrequirements,whileothersaggressivelyadoptavariety\nofsuchrequirements.\nElectronic trading systems developed as early as the 1960s (see Section 3.6.2.2) managed\nto work around many such problems. Requirements of form were overcome using a frame-\nwork contract. Participants enter into written agreements (with wet-ink-on-paper signatures\norfollowingwhateverotherrequirementofformmightbeimposedonthesecontracts)which\nconstitutethefoundationofthecontractualrelationshipsbetweenparticipants.172\nNewertradingplatformsbuiltonopenstandards,oftendirectedtobothbusinessesandcon-\nsumers,madeearlygainsbytradinginsubjectmatter(e.g.,thesaleofbooksandothersmall\nconsumergoods)wherecontractscouldbeconcluded,andpaymentssettled,withfewifany\nchallengesbasedonrequirementsofform.173\nThere is a broad international consensus that it should be possible to create and conduct\nbusinessrelationshipsinanonlineenvironment.In1996,theUnitedNationsformallyencour-\naged all states to enable online trading relationships [258]. Many states around the world\ncontemporaneously adopted a variety of laws and regulations designed to enable the on-\nline conduct of various types of transactions, trading relationships, administrative reporting,\nKALaw&Regulation |October2019 Page112 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ncourt filings, etc. Many were adopted in the specific context of enabling digital signatures\nandtrustservices,asdiscussedinSection3.10.3.\nThelegalenforceablityofcommunicationsrelatedtoothersubjectmatter,especiallytopics\nsuch as the disposition of a deceased\u2019s estate and the transfer of title to immovable prop-\nerty, have been slower to transition to electronic platforms. These often retain significant\nrequirements of form that make the electronic implementation of relevant communications\nimpracticableunlessanduntilstatesdecidetoamendtheirlaws.\n3.10.3 Electronic signatures and identity trust services\nThe emergence of modern ecommerce was contemporaneous with the emergence of iden-\ntity trust services, specifically those that issue digital certificates that bind the identity of a\npersonwithagivenpublickeyinaPKI.\nAsengineeringstandardsfortheseidentitytrustservicesbegantoemerge,tworelatedlegal\nquestionssurfacedforconsiderationbyanyonewhowishedtoprovideormakeuseofthese\nservices:\n\u2022 the extent to which a digital \u2019signature\u2019 produced using such a system would be ac-\ncordedlegalequivalencewithawet-ink-on-papersignature;and\n\u2022 thenatureofrightsandresponsibilitiesofvariouspersonsinvolvedinthemaintenance\nanduseofthesesystems.\nThe question of legal equivalence for signatures is merely a sub-set of the more general\nproblemofrequirementsofformdiscussedinSection3.10.2.Totheextentthatvariouslaws\nimposearequirementto\u2019sign\u2019acommunication,manystateshaveadoptedlawstoprovide\nlegalequivalencetoelectronicsignaturesinmost,butnotall,circumstances.\nThequestionofrightsandresponsibilitiesofpersonsinvolvedintrustservicearrangements\nissignificantlymorecomplex[259].\nConsider first the potential liabilities of a certificate issuer in a standard three-corner opera-\ntional model.174 The law of negligence (see Section 3.7.1) immediately creates a number of\nchallenges for any person operating as a certificate issuer, among them: what is the nature\nof the duty owed to a third party relying on a certificate; what are appropriate standards of\ncareinthisnewoperationalmodel;andwhatharmisforeseeablewhenerrorsoccur?Specific\nliabilityscenariosrangefromasystem-widedisastercausedbytheundetectedcompromise\nofarootcertificateortechnicalflawintheauthenticationmechanism,totheoccasional(al-\nthough recurring and perhaps inevitable) cases of improperly issuing a certificate following\nthemisidentificationofasignatory.\nConsider also the potential liabilities of a signatory or a third party who relies on a certifi-\ncate.Earlypolicydebatefocussedsignificantlyonthedegreetowhichsignaturesshouldbe\nbindingontherelevantsignatory\u2013especiallywhenthatpersonmayhavelostcontrolofthe\nsignaturecreationdevice.Thisisasurprisinglyoldissueinlaw,commonlyencounteredinthe\ncontextofcheque-signingmachines,signaturestamps,andthelike,adoptedbybusinesses,\nfinancial institutions, medical professionals, etc. Much of the policy debate over this issue\nappears now to be concentrated on the subject-matter laws governing specific use cases,\nsuchasthoseadoptedtoregulateelectronicpaymentservices[212,213].\nA lack of certainty over these issues has caused certificate issuers to seek out methods to\nlimit or otherwise rationalise their liability. A common strategy for limiting liability, entering\nKALaw&Regulation |October2019 Page113 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ninto contracts which include limitation clauses, faces a significant problem. Forming a con-\ntractbetweentheissuerandtherelyingpersonnormallyrequiresthecommunicationofoffer\nand acceptance between these persons (see Section 3.6). Most systems were designed to\nenable reliance without the constant intervention of presenting a user with new terms and\nconditions every time a relying party encountered a new certificate vendor. Similarly, certifi-\ncateissuersmightwishtowarnrelyingpartiesaboutthescopeofappropriatesubjectmatter\nforwhichthecertificatesmightbeused.\nThetechnologydevelopmentcommunityattemptedtoaddresstheseconcernsbyincorporat-\ninginthecertificatesspecificdatafieldsdesignedtocommunicatereliancelimitsandscope\nofuselimits.175 Thisstrategyfacedadifferentsetoflegalchallenges.Inpractice,thecertifi-\ncates tend to be buried in rarely-accessed segments of the user interface. Further, a vast\nnumberofenduserswhosemachinesmightberelyingonthesecertificateswouldlikelyfail\nto comprehend the data presented in them, as certificate data tends to be presented in a\nhighly technical fashion. In these circumstances, significant doubt has emerged about the\nability to create an enforceable limitation of liability between the certificate issuer and the\nrelyingthirdparty.176\nStates and legal experts intervened with a variety of recommendations, and then laws, at-\ntemptingtoaddresstheseissues[260,261,262,263].177Theselaws,oftenidentifiedwiththe\nterm \u2019digital signature\u2019 or \u2019electronic signature\u2019 in their titles, typically adopted some combi-\nnationofthefollowingpolicyinterventions:\n\u2022 mandatingtheacceptanceofelectronicsignaturesaslegalevidence;\n\u2022 mandating the legal equivalence of electronic signatures that meet certain minimum\ntechnicalcharacteristicstoassuremessageauthenticationandintegrity;\n\u2022 instructingjudgesthatelectronicsignatures(eventhosewhichprovidelittleornotech-\nnicalassuranceofauthenticationorintegrity)cannotberefusedlegalequivalencemerely\nbecausetheytakeanelectronicform,butleavingopenthepossibilityofdenyingequiv-\nalenceforotherreasons;\n\u2022 imposing on a certificate issuer a duty of care owed to third parties who rely on certifi-\ncates;\n\u2022 reversing the burden of proof for negligent operation of a certificate issuer enterprise,\nso that an injured third party is no longer required to prove negligence but instead the\ncertificateissuerisrequiredtoprovenon-negligentoperation;\n\u2022 establishingframeworksforregulationtoencouragehighertechnicalandnon-technical\nstandardsofcareintheoperationofacertificateissuancebusiness;\n\u2022 providing to certificate issuers the ability to limit their financial liability by presenting\nthelimitationinthecertificateitself,whetherornottherelyingthirdpartyactuallysees\nthislimitation;and\n\u2022 providing to certificate issuers the ability to exclude liability for certain subject matter\nbypresentingtheexclusioninthecertificateitself,whetherornotthethirdpartyactually\nreviewsthisexclusion.\nThereissomedegreeofvariancebetweenstatesonhowtheyhavechosentoaddressthese\nissues. Not all states have adopted all of these interventions. Many of these interventions\nare subject to a variety of additional conditions or limitations. A recurring theme concerns\nKALaw&Regulation |October2019 Page114 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntheunwillingnessoflawmakerstoreducerightsotherwiseaffordedbyconsumerprotection\nlaws.\nWhile some of these laws are general in nature, others are more narrowly drawn to address\nspecific subject matter. In some cases, the law delegates authority to a regulatory body to\nadopt specific secondary legislation and\/or technical standards on a subject-specific basis.\nAnypractitionerwhohopestodevelopaplatforminanareawhererequirementsofformare\ncommonplacemustresearchandreviewapplicablelawsandregulationstoreduceenforce-\nabilityrisk.\nWhilemuchdebateanddiscussionhasfocusedoncertificateissuers,signatories,andthird\nparties who rely on certificates, another actor in this domain is more often overlooked: the\nperson who selects which certificate issuers should be trusted by default. This \u2019certificate\nissuer selection\u2019 role is routinely undertaken, for example, by producers of consumer web\nbrowsers. This is perhaps inevitable, as the vast majority of end users would have no ratio-\nnalmethodofdiscriminatingbetweengood-qualityandpoor-qualitycertificateissuers.This\nraisesthequestionofdefiningwhatdutyofcarethesecertificateissuerselectorsmightowe\ntoendusers.178\n3.10.4 Conflict of law \u2013 electronic signatures and trust services\nThe nature of electronic signatures and trust services invariably implicates conflicts of law\nwhenrelevantpartiesareindifferentstates.ConsideracertificateissuerlocatedinStateA,a\nsignatorylocatedinStateBwhoprocuresacertificateandusesittocreatedigitalsignatures,\nandathirdpartyrelyingonthecertificatelocatedinStateC.\nAssessing the legal equivalence of the signature can become complicated depending on\nwhichlawimposesarelevantrequirementofformthatmandatesa\u2019signature\u2019.Inthecaseof\ndocumentsthatpurporttotransfertitletoimmovableproperty,thelegalequivalencequestion\nwill almost certainly be answered by reference to the law of the state where the immovable\nproperty is located without any regard to the location of certificate issuer, signatory, or third\nparty relying. (I.e., this could be a fourth State D.) The state where the immovable property\nis located is, in nearly all circumstances, the only one that can credibly assert enforcement\njurisdiction over a title dispute as it is the only sovereign that could seize the property. In\nmatters of a simple contract between a non-consumer signatory and non-consumer third\nparty, the European courts should be willing to find formal validity of the contract if it meets\ntherequirementsofvalidityappliedbythelawofthestatechosenbythepartiestogovernthe\ncontract, the law of State B, the law of State C, or possibly the law of either party\u2019s habitual\nresidenceifdifferentfromanyofthese(RomeI,Art11)[214].Whereconsumersareinvolved,\ntheEuropeancourtswouldonlyfindsuchacross-bordercontractvalidifitwasdeemedvalid\nunderthelawoftheconsumer\u2019shabitualresidence.\nDetermining the applicable law concerning limitations of liability is similarly complex. Con-\nsider, for example, the ability of a certificate issuer to rely on a limitation of liability granted\nunderthetrustservicesordigitalsignaturelawofStateA.IfthethirdpartyinStateC brings\nanegligenceactionagainstthecertificateissuer,theapplicabletortlawmaywellbethelaw\nof State C (see Section 3.7.6). The law of State C may not recognise the liability limitation\notherwise granted by State A law, especially in cases where injured persons are acting as\nconsumers. In other words, the value of any liability exclusion or limit granted by such laws\nbecomesquestionablewhenrelationshipscrossborders.\nKALaw&Regulation |October2019 Page115 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.11 OTHER REGULATORY MATTERS\nThis section will briefly address additional miscellaneous regulatory topics that a cyber se-\ncuritypractitionermightbeexpectedtoencounter.\n3.11.1 Industry-specific regulations and NIS Directive\nA wide variety of single-industry regulators have embraced cyber security within the frame-\nworkoftheirlargerroleregulatingsubjectindustries[264].Manyfinancialservicesregulators,\nfor example, in their role as regulators of operational risk in financial services, have always\nhad some degree of subject matter jurisdiction over cyber security operations. Details of\ncyber security risk management have increased in prominence within financial services reg-\nulationandcanbeexpectedtocontinuetofeatureprominently[265].\nSimilarly,withinprofessionsthatowelegallymandateddutiesofconfidentialitytoclientsor\nwhoseclientsenjoylegallymandatedprivilegesprohibitingdisclosureofclient-professional\ncommunications(e.g.,lawyersandphysicians)professionalregulatorshavebecomeincreas-\ninglyattunedtoproblemsofcybersecurity.\nManyofthesevariousregulationsincludeobligationstoreportordisclosesecuritybreaches.\nSuchdisclosurerequirementsoperateinadditiontoanyobligationsimposedbydataprotec-\ntionlaw(seeSection3.4.7).Thiscreatesapotentiallyconfusinglandscapewhenconsidering\ndisclosureobligations[266].\nAsstateshavebeguntofocusmoreheavilyoncybersecurityrisks,existingregulatorshave\nbeen encouraged to bring cyber security into their supervisory and regulatory frameworks\nespeciallyinthecontextofcriticalnationalinfrastructure.\nIn the European Union this has been accelerated by the adoption of the EU directive on net-\nworkandinformationsystems(NISDirective)[267].Article14oftheDirectiverequiresmem-\nberstatestoensurethat\u2019operatorsofessentialservices\u2019:\n\u2022 \u2019takeappropriateandproportionatetechnicalandorganisationalmeasurestomanage\nthe risks posed to the security of network and information systems which they use in\ntheiroperations\u2019;\n\u2022 \u2019take appropriate measures to prevent and minimise the impact of incidents affecting\nthe security of the network and information systems used for the provision of such\nessentialservices,withaviewtoensuringthecontinuityofthoseservices\u2019;and\n\u2022 \u2019notify,withoutunduedelay,thecompetentauthorityortheCSIRTofincidentshavinga\nsignificantimpactonthecontinuityoftheessentialservicestheyprovide\u2019.\nThe UK implementation devolves responsibility for regulatory oversight to relevant compe-\ntentauthorities-instructingexistingindustryregulatorstoadoptandenforcecybersecurity\nobligationssetoutintheDirective[268].\nEffortstouseregulationtoheightencybersecurityinsocietycontinuetotakemanydifferent\nforms.Debatecontinuesaboutwhichmodelsofregulationaremosteffective[269].\nKALaw&Regulation |October2019 Page116 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.11.2 Encouraging increased cyber security for products and services\nTheemergentInternetofThingsandtheaccompanyinggrowthofcloud-basedservicescre-\nate increased risks from cyber security breaches to both consumers and business enter-\nprises. Policy makers have begun to adopt legal frameworks for certification of compliance\nofproductsandserviceswithvariouscybersecuritystandards.\nIn the European Union, certification activity is expected to operate within the framework of\nthe EU Cyber Security Act [270]. (See also discussion of certification marks used by public\nandprivatestandardsbodiesinSection3.8.2.3.)\nRelevantsecuritystandardsmayemergefromavarietyofsources[271,272].\n3.11.3 Restrictions on exporting security technologies\nStates have long imposed restrictions on the export of goods intended for use in armed\nconflict. These laws grew significantly during the Cold War, as Western bloc states sought\nto restrict the flow of defence technologies to the Eastern bloc.179 These export limitation\nregimes also apply to \u2019dual use\u2019 goods: sensitive products that have legitimate uses in both\npeaceandwar.Althoughasurprisinglywidevarietyofdualuseproducts(andservices)have\nbeen caught under the terms of such restrictions, those that are caught because they em-\nbody certain cryptographic functions have been especially contentious in the field of cyber\nsecurity.\nPrior to the 1990s, the US (and other states) regulated the export of strong cryptographic\nproductswithanextremelybroadbrush.Exportprohibitionswereframedinsuchexpansive\nlanguage that almost any export required prior government licence. At the beginning of the\n1990s, the implementation of strong cryptography in software for general purpose comput-\ners, the growing body of non-governmental research work into cryptography, the availability\noftheInternetasameanstodistributeknow-howandsourcecode,andtheincreasingpres-\nsure for reliable standards-based cryptographic implementations in support of cyberspace\ninfrastructure,collidedwiththesesameexportrestrictions.\nIntheUS,aseriesoflegalactionsunderUSfreespeechlaw(i.e.,theFirstAmendmenttothe\nUSConstitution)werebroughtchallengingthevalidityofexportregulationsasappliedtocryp-\ntographic software. The argument presented proceeds, in essence, as follows: source code\nis expressive, expressive content is protected speech, therefore source code is speech, the\nexportregulationsarethereforeagovernmentalpriorrestraintonspeech,asapriorrestraint\ntheregulationsmustbeextremelynarrowlytailoredtoaddressacleardanger,buttheregula-\ntionsareinfactverybroadlydrawnandthereforedonotmeetconstitutionalmuster.TheUS\ncourtsstruggledwiththeconceptofwhethersourcecodewasprotected\u2019speech\u2019.Eventually,\nin Junger v Daley (2000), the US Court of Appeals for the 6th Circuit held that source code\nwas speech and found the US export regulations unconstitutionally over-broad [273].180 No\ndoubt in response to this and similar legal challenges in other US Circuits, combined with\nheavy lobbying by the ICT industry, the US government issued revised export regulations to\ncreatesignificantlymorelimitedrestrictionsoncryptographicexports[274].\nMany states including the US continue to maintain export restrictions on certain dual use\nproducts,includingsomeimplementationsofcryptographictechnology.Anyoneengagedin\nthe production of these products should review applicable laws carefully, as violations can\nbeprosecutedascrimes.\nKALaw&Regulation |October2019 Page117 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.11.4 Matters classified as secret by a state\nPractitionerswhoareemployedorengagedbystatesareroutinelysubjecttolawsthatman-\ndatesecrecyofcertaininformationclassifiedassecretbythosestates.Mostcommonly,this\narisesinanenvironmentwherethedisclosureofrelevantsecretscouldharmthedefenceof\nthestate,theintegrity ofapoliceinvestigation,thesafetyor efficacyofpersonsconducting\nstatesponsoredespionageactivity,etc.\nThese laws can sometimes be used to intervene and classify as secret the research and\ndevelopment work of third parties. Practitioners may also come within the remit of these\nlaws when state security officials choose to disclose certain classified information relating\ntocyberthreats.\nTheselawstendtoauthoriseextremelyseverecriminalpenaltiesforthosewhoviolatethem.\n3.12 PUBLIC INTERNATIONAL LAW\n[104]\nPublic international law181 is the body of law that regulates relationships among and be-\ntween states, which for this purpose includes international governmental organisations but\nexcludes constituent states of a federal state. Sources of public international law include\ntreaties, widely accepted international norms and customs, and decisions of international\ntribunals.\nOnly states are said to have \u2019standing\u2019 to enforce claims arising under public international\nlaw. Non-state persons are normally unable to take legal action against states for violation\nofpublicinternationallaw.Anon-statepersonmayholdtherighttotakelegalactionagainst\ntheir home state for failure to implement obligations imposed upon the state by public in-\nternational law, although states normally must affirmatively grant these rights to non-state\npersons[155].182\nSimilarly, international law normally seeks to regulate the behaviour of states rather than\nthe actions of their residents or nationals.183 Cyber operations undertaken by a non-state\nperson in State A against persons or infrastructure in State B normally do not constitute a\nviolationofinternationallaw,unlesstheactioncanbeattributedtoStateAortosomeother\nState C (see Section 3.12.1.) This action by a non-state person could, however, serve as a\nlegal justification under international law for State B to take some form of proportionate\ncountermeasure against such persons or equipment in State A as an act of self-defence\n([104]atR.4,cmt.2).\nIt has become widely accepted that principles of public international law should apply to\nactions taken with respect to cyberspace [102, 103, 104, 275]. Having said this, states can\nanddodivergein theiropinionsofhowtheseprinciplesshouldbeinterpreted inthecontext\nofspecifictypesofcyberoperation.Atthetimeofwriting,themostcomprehensiveandmost\nwidelyacceptedpublishedsourceofanalysisontheapplicationofinternationallawtocyber\noperationsistherestatementofinternationallawfoundintheTallinnManual2.0[104].184\nKALaw&Regulation |October2019 Page118 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.12.1 Attributing action to a state under international law\nAttribution is the process of determining if a state is legally responsible under international\nlawforagivenaction.Aseriesofinternationallawdoctrinesareusedtodefinewhenastate\nisresponsibleforagivenact([104]atR.14-19).185\nAgivenactionmightbelegallyattributedtoastateif,forexample:\n\u2022 the action is undertaken by an agent or officer of the state (such as an active on-duty\nmemberofthestate\u2019smilitaryorpolice);or\n\u2022 theactionisundertakenbyanon-stateperson(suchasatechnologyservicesprovider)\nunderthedirection,orwiththeactiveencouragement,ofstateofficials.\nIn extreme circumstances, if illicit activity is regularly initiated by non-state actors from cy-\nber infrastructure inside the territory of a state, and that state remains willfully blind to that\nactivityor otherwisefailstoexerciseappropriatedue diligenceinattemptingtoidentifyand\nrestrain the illicit activity, then it may be possible to attribute the illicit activity to that state.\nThistheoryisnotwithoutcontroversy([104]atR.6-7;R.14,cmt.3)[276].\n3.12.2 State cyber operations in general\nPublicinternationallawisfoundedontheprincipleofterritorialsovereignty.186Astateissaid\ntobesovereignwithinitsownterritory,andalsohastherighttoconductactivitiesoutsideof\nitsterritoryconsistentwithinternationallaw.\nInternationallawgenerallyprohibitsonestatefromviolatingthesovereigntyofanother([104]\nat R.4). States are, however, entitled to take appropriate countermeasures in response to a\nsecond state that has violated the obligations it owes under international law to the first\n([104] at R.20-26). Countermeasures are actions that would normally violate international\nlaw that are directed against the second state in an effort to encourage it to comply with its\nobligationsunderinternationallaw.\nCountermeasuresmustbeproportionaltothecomplained-ofviolationofinternationallawby\nthesecondstate.Countermeasuresinresponsetoanillegalcyberoperationmightconsistof\ncyberornon-cyberresponses.Thuscountermeasuresrespondingtoacyberoperationwhich\nviolated international law could legitimately consist of so-called \u2019kinetic\u2019 responses, cyber\noperational responses, or economic sanctions [277]. This raises a recurring challenge when\nattempting to understand how to assess the relevant \u2019proportionality\u2019 of non-cyber counter-\nmeasurestoacyberoperationthatviolatesinternationallaw[278].\nAcyberoperationofonestatedirectedagainstanotherstateisnormallycontrarytotheprin-\nciples of international law if it interferes in the affairs of the second state ([104] at R.66).\nA cyber offensive operation such as a DDoS operation, for example, would constitute inter-\nference if used to coerce the second state in a manner designed to influence outcomes in,\nor conduct with respect to, a matter reserved to the target state ([104] at R.66, cmt.8&19).\nTheoutcomesinquestionneednotbephysicalinnature,andcanincludedomesticpolitical\noutcomes([104]atR.66,cmt.20).\nA cyber operation of one state directed against another state is normally contrary to princi-\nplesofinternationallawifitconstitutesauseofforceorthreatofsame([104]atR.68-70).\nA state that is the victim of an \u2019armed attack\u2019 is entitled to take proportionate countermea-\nsures, including the use of force ([104] at R.71). Actions that constitute an armed attack are\nKALaw&Regulation |October2019 Page119 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\na sub-set of acts that constitute \u2019use of force\u2019 ([104] at R.71, cmt.6). Finding the dividing line\nbetweenthemischallengingandisgenerallymeasuredbyreferencetothescaleandeffects\nofthecomplained-ofact.InthecontextofdiscussingtheStuxnetoperation,forexample,the\nTallinnManual2.0expertsagreedthatifStuxnetweretobeattributedtoastateitwouldcon-\nstituteauseofforce;buttheyweredividedonwhetherthescaleandeffectsoftheoperation\nweresufficienttoconstitutean\u2019armedattack\u2019([104]atR.71,cmt.10).\nBecause of the uncertainty over when the scale and effects of a cyber operation are suffi-\nciently severe to constitute an armed attack, it has been suggested that some states have\nadopted a strategy using this uncertainty to conduct cyber operations in a \u2019grey zone\u2019 some-\nwherebetweenpeaceandarmedconflict[278].\n3.12.3 Cyber espionage in peacetime\nCyber espionage, per se, during peacetime is not generally considered a violation of interna-\ntionallaw([104]atR.32)[159,160,279].187\nCyber surveillance and evidence gathering activities conducted from within the territory of\nonestateagainstpersonsorequipmentinanotherstatewouldthereforenotnecessarilycon-\nstituteaviolationofinternationallaw.Espionagemethods,however,couldeasilyviolatethe\ndomestic criminal law of the second state (e.g., obtaining unauthorised access to comput-\ners).Furthermore,methodsthatsupportespionagebyharmingequipmentwithintheterritory\nofthesecondstatewouldconstituteaviolationofthatstate\u2019ssovereigntyand(ifsufficiently\ndamaging)couldamounttoauseofforce.188\nAspecificexampleofthisprincipleappliestostateeffortstotapsubmarinecommunication\ncables for the purpose of intercepting communications. If a state covertly taps cables in\ninternational waters without significantly interrupting their functionality, this very likely does\nnotconstituteaviolationofinternationallaw.Ifonestateplacesthetapwithintheterritorial\nwatersofasecondstate,however,theoperationconstitutesaviolationofthesecondstate\u2019s\nsovereignty([104]atR.54,cmt.17).\n3.12.4 Cross-border criminal investigation\nActionsbyonestatethatconstitutetheexerciseofpolicepowerwithintheterritoryofanother\n(unrelated)189 state normally constitute a violation of that state\u2019s sovereignty under interna-\ntionallaw.Thisiseasytoseeincaseswherepolicepowersinvolvetheuseofforceinperson,\nsuch as searching physical premises, or arresting or interrogating a suspect located in the\nsecondstate.\nActsofsurveillanceconductedfromwithintheterritoryofonestatethatdonotinvolvephys-\nical contact by that state\u2019s agents with the territory of another state are more complex to\nanalyse.Whilestateremotesurveillanceactionsontheirownmightnotconstituteviolations\nofinternationallaw(seeSection3.12.3),stateevidencegatheringmethods(suchascovertly\ntakingremotecommandofabotnetcontrollerorotherequipmentlocatedontheterritoryof\nanother state) can constitute a violation of the other state\u2019s sovereignty under international\nlaw([104]atR.4,cmt.18)andmayalsoconstitutethecommissionofacrimeundertheother\nstate\u2019sdomesticlaw.\nNonetheless, it is well documented that remote cyber surveillance and evidence gathering\nactivities are conducted by the law enforcement agencies of various states from time to\nKALaw&Regulation |October2019 Page120 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntimewiththeexpressorimpliedauthorisationoftheinvestigatingstate,anddirectedagainst\ncyberinfrastructurelocatedinanother,non-consenting,state[109].\n3.12.5 The law of armed conflict\nUpon commencement of armed conflict, the conduct of activity within the context of that\nconflictissaidtobegovernedbythe\u2019lawofarmedconflict\u2019(alsoknownvariouslyasthe\u2019law\nofwar\u2019and\u2019internationalhumanitarianlaw\u2019.)190 Statecyberoperationsconductedaspartof\nanarmedconflictareassessedbyreferencetothelawofarmedconflict.TheTallinnManual\n2.0addressesthistopicinsomedetail([104]atPartIV,R.80-154).\nThis field is the subject of extensive study and debate by the military leadership of many\nstates, which invest significant time and effort producing legal guidance for their military\ncommanders concerning that state\u2019s interpretation and implementation of the law. Some\nof these are published and available for public review [280, 281, 282]. The US DOD Manual\nspecificallyaddressescyberoperations[281].\nTheprecisemeaningof\u2019armedconflict\u2019issubjecttosomedisagreement,althoughitiswidely\nunderstoodthatarmedconflictcan(andoftendoes)existintheabsenceofanyformaldec-\nlarationofwar([104]atR.80,cmt.2).Duringthecourseofarmedconflict,someinternational\nlegal obligations (e.g., the 1944 Chicago Convention on civil aviation) are suspended or oth-\nerwisealteredasbetweenbelligerentstatesengagedinhostilities.\nKeyprinciplesthatunderpinthelawofarmedconflictinclude:\n\u2022 Military necessity: a state may use such force as is necessary to defeat an enemy\nquicklyandefficiently,providedthatsuchforcedoesnotviolateotherprinciplesofthe\nlawofarmedconflict.\n\u2022 Humanity:astatemaynotinflictsuffering,injuryordestructionthatisnotnecessaryto\naccomplishalegitimatemilitarypurpose.\n\u2022 Distinction(akaDiscrimination):astatemustendeavourtodistinguishmilitarypersons\nand objects from civilian persons and objects. This imposes an obligation upon a bel-\nligerent state to distinguish its own military person and objects from civilian persons\nandobjects,aswellasworkingtodistinguishenemystatemilitaryandcivilianpersons\nandobjects.\n\u2022 Proportionality:astatemaynotactinamannerthatisunreasonableorexcessive.\nA recurring issue of discussion among experts concerns what is required to treat a cyber\noperation, on its own, as an \u2019attack\u2019 under the law of armed conflict. The Tallinn Manual 2.0\nrefers to such an operation as a \u2019cyber attack\u2019, which the expert group defines as a cyber\noperation \u2019that is reasonably expected to cause injury or death to persons or damage or de-\nstruction to objects\u2019 ([104] at R.92).191 The characterisation of a cyber operation as a cyber\nattackunderinternationallawiscritical,asthelawofarmedconflictlimitshowstatescarry\noutsuchattacks.\nBelligerent states are to avoid targeting their attacks (which would include cyber attacks)\nagainst civilian persons or objects ([104] at R.93, 94 & 99). Exceptions arise with respect to\ncivilianswhoparticipateinarmedconflict([104]atR.96,97).\nAlthough the principles of the law of armed conflict are not significantly in dispute, how to\ninterpret and apply these in the context of specific cyber operations raises a series of re-\nKALaw&Regulation |October2019 Page121 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ncurring questions. For example, many legal experts take the view that the principle of not\ntargeting cyber attacks against civilian objects applies only to tangible objects and that in-\ntangible data, as such, does not fall within the legal definition of \u2019object\u2019 [283]. This was the\nviewofthemajorityoftheTallinnManual2.0expertgroup,althoughaminorityofthatgroup\nfeltthatintangiblessuchasdatashouldcountas\u2019objects\u2019iftheeffectofdamagingoralter-\ning such data was sufficiently significant ([104] at R.100, cmt.6). There is wider agreement,\nhowever,thatanoperationthattargetsandaltersdata,whichinturncausesinjurytopersons\nordamagetoproperty,doesrisetothelevelofcyberattack([104]atR.92,cmt.6).\nAnotherdifficultyinapplicationconcernstheinterminglingofmilitaryandciviliancyberinfra-\nstructure. Under the law of armed conflict, if an object is used for both military and non-\nmilitarypurposesitbecomesamilitaryobjective([104]atR.101).Thisleadstothepossibility\nthat significant components of public cyber infrastructure, including dual-use data network-\ning and cloud services infrastructure, could be characterised as a legitimate target of cyber\nattackintimeofarmedconflict(subjecttootherlegallimitationssuchastheneedtorespect\nthe principles of humanity and proportionality) ([104] at R.101, cmt.4-5). Some have argued\nthat such outcomes point to the need to reconsider how public international law should op-\nerateinthiscontext[283].\n3.13 ETHICS\nCybersecuritypractitionersoftenfindthemselvesoperatinginpositionsoftrust,wherespe-\ncialknowledgeandskillspotentiallygivethemasymmetricpowertoinfluenceordisruptthe\naffairs of their clients or other members of the public. Those who act outside of a specific\nclient relationship, such as product developers and academic researchers, exercise special\nskills in a manner that could cause harm to a wide variety of third parties. Practitioner activ-\nities often take place behind closed doors away from the glare of public scrutiny. This is a\nvolatile mix. Ethical norms might assist in curbing behaviours that abuse positions of trust\norotherwisepresentsignificantrisktothepublic.\nEarlycybersecurityethicsguidancefocusedsignificantlyonlegalriskmanagementsuchas\nliability arising under intellectual property, data protection and privacy laws [284]. Although\npractitioners should remain aware of laws that apply to their actions, compliance with the\nlaw,onitsown,maybeinsufficienttoguideapractitionertoethicalaction.192\nAs a practice that is generally conducted in the absence of formal state professional regu-\nlation, it is difficult to identify generalisable norms that are expected to apply to activities\nundertakenbysecuritypractitioners.193 Thissectionwillsurveysomeoftherecurringissues\nandpotentialsourcesofguidance.\n3.13.1 Obligations owed to a client\nA review of some obligations normally owed by regulated professionals to clients may be\nhelpfulassocieties(andvariousnascentprofessionalbodies)continuetodevelopapproaches\ntoobligationsthatshouldbeowedbycybersecuritypractitionerstotheirclients.\nAt the very least, one can identify various duties of care that arise under contract or tort law\nto conduct services and other activities that involve risk in a reasonable fashion and with\nappropriate expertise. Product designers similarly owe various legal obligations under the\nnormalrulesoftortlaw.\nKALaw&Regulation |October2019 Page122 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nRegulatedprofessionalsarenormallyexpectedtoactinthebestinterestsoftheirclients,to\navoid conflicts of interest and to maintain the confidentiality of client affairs. While affirma-\ntively adopting these types of obligation by contract is often non-controversial, difficulties\ncanarisewhenasecuritypractitionerandclientdisagreeaboutthemostappropriatecourse\nofactioninspecificcircumstances.\nChallengescanarisewithrespecttonon-mandatorydisclosureofevidencetointerestedthird\nparties.194 If a practitioner discovers evidence of wrong-doing and there is no supervening\nlegalobligationtoreportthatevidence,thepractitionerandclientmightdisagreeconcerning\nthedisclosureofsuchevidencetointerestedthirdpartiessuchasrelevantpoliceauthorities,\nCERTsortortvictims.\nThese cases can be difficult to navigate. In cases of evidence of economic crimes directed\nagainsttheclient(e.g.,pettytheft),theclientmayviewpublicdisclosureasmoredamaging\nthanhandlingthemattersolelyonaninternaldisciplinarybasis.Incaseswhereanemployee\nis found to have harmed a third party through tortious action such as negligence, disclos-\ning this evidence to the victim may work to the financial detriment of the client\u2019s company\nthroughvicariousliability.\nOtherdifficultcasesarisewhentheinterestsofthepractitionerandtheirclientarenotaligned.\nSome professional ethics systems, for example, allow a regulated professional to disclose\nsome parts of a client\u2019s confidential information as part of a legitimate bill collecting activ-\nity (e.g., by filing a legal action for breach of contract relating to the delivery of confidential\nservices).Suchdisclosuresmustnormallybelimitedtoinformationthatisnecessarytopur-\nsuecollectionandmaycomewithobligationstoseekappropriateprotectiveordersfromthe\ncourts.\nActions by a practitioner that interfere with the proper functioning of their client\u2019s infrastruc-\ntureinanefforttoexerciseundueinfluenceovertheclientareunsavouryatbest,andmight\ncrossalineintocriminalconductatworst.Anexpressorimpliedthreatofsuchactionseems\nnobetter.\nItremainstobeseenwhethercybersecuritypractitioner-clientrelationshipswillbecomethe\nsubjectofformalstateregulationorlicensureinduecourse.\n3.13.2 Codes of conduct\nVarious professional bodies have published codes of conduct and ethical guidelines for cy-\nbersecuritypractitioners.Manyoftheserefertohigh-levelethicalprincipleswithoutthemore\ndetailed guidance that is necessary to assist practitioners with interpretation of the princi-\nples.195\nExamplesoftwomorerecentandcarefullyconsideredcodesofconductarepresentedbelow\nfor consideration. One is framed as a code of general applicability and one is built around a\ndefinedbusinessprocess.\nThe Association for Computing Machinery can trace its history to the mid-twentieth century\nand maintains a global membership of more than 100,000 [285]. The ACM Code of Ethics\nand Professional Conduct was extensively revised in 2018 to take account of the impact of\ndataconnectivity[286].TherevisedACMCodeprovidesmultiplepointsofguidancerelevant\nto the field of cyber security. The ACM also provides supplementary materials to assist in\nunderstandingandapplyingtheCode[287].\nKALaw&Regulation |October2019 Page123 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nThe ACM Code clearly demonstrates the difficulties of balancing ethical imperatives. In its\nadmonition to avoid harm (Section 1.2), it states there is an \u2019additional obligation to report\nanysignsofsystemrisksthatmightresultinharm\u2019.WhiletheCodeaddressesthepossibility\nof \u2019whistle-blowing\u2019 as a reporting technique in appropriate circumstances, it also cautions\nthat \u2019capricious or misguided reporting of risks can itself be harmful. Before reporting risks,\nacomputingprofessionalshouldcarefullyassessrelevantaspectsofthesituation\u2019.\nBycontrast,CRESTwasestablishedintheUKintheearlytwenty-firstcenturyoriginallyasa\nmembershipbodyforfirmsthatsupplypenetrationtestingservices.196 Atthetimeofwriting,\nit has more than 180 accredited member firms [288]. Penetration testing typifies a service\nthatshouldbeofsignificantconcerntothepublic:informationasymmetrymeansclientsare\ngenerally unable to distinguish good practice from bad, services are supplied confidentially\nawayfrompublicscrutiny,andpractitionererrorscancausedisproportionateharmtoclients\nor third parties. The CREST Code of Conduct for CREST Qualified Individuals provides guid-\nanceonnumeroustopicsrelevanttodeliveringtheseservicesincludingservicemethodology,\nethical business practices, and obligations owed to clients [289]. The CREST Code also pro-\nvides a client complaint mechanism and the organisation reserves the right to expel from\nmembershipthosewhofailtoadheretotheCRESTCode.Totheextentthatclientsmandate\nthatsuppliersofrelevantservicesmaintainCRESTmembership,thesemandatesmayslowly\nmigrate CREST from a purely voluntary membership association into a de facto regulator of\nthosewhosupplytheseservices.\nBy historical standards, cyber security presents a relatively new set of methods and pro-\ncesses which are at best poorly understood by the public. Generalised codes like the ACM\nCode are helpful, as they guide a community of persons with relevant technical expertise\nwho may work in fields as diverse as research and development or security management.\nService-specificcodesliketheCRESTCodearehelpful,astheyfocusclearlyonspecifichigh-\nriskservices.Codesofconductwillundoubtedlycontinuetodevelopastheimpactofcyber\nsecuritypractitioneractivityonthepublicbecomesbetterunderstood.\n3.13.3 Vulnerability testing and disclosure\nThe process of searching for, finding, disclosing, and acting in response to, security vulnera-\nbilitiescausesrecurringethical(andlegal)issues[290,291].\n3.13.3.1 Testingforvulnerabilities\nPractitionerswhotestforsecurityvulnerabilitiesshouldconsidercarefullythenatureoftheir\nactivities. The mere act of studying and analysing objects such as tangible hardware prod-\nucts,locallyresidentlicensedsoftware,orpublishedcryptographicprimitivesandcommuni-\ncation protocols, is normally uncontroversial. It is difficult to draw a line of causation from\nthemereactofanalysistopublicharm.\nPractitionersshouldbecareful,however,toconsiderthesourceofthesecurityobjectunder\nstudy. There may be a distinction, for example, between reverse engineering a silicon chip\ntodiscoverthefunctionalityofatradesecretcryptographicschemeandreverseengineering\nthird-partysoftwareofsuspiciousprovenancethatembodiesthesamesecretmethodology.\nAlthough the first might be generally permissible, the second may constitute a violation of\ntradesecretrightsandresultinliabilityorrestrictionsonlimitingtheabilitytopublishresults\n[249,250](seethediscussioninSection3.8.4.2andNote201).\nWhen vulnerability testing is conducted remotely, the testing methods can raise additional\nKALaw&Regulation |October2019 Page124 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nissues.Practitionersmustfirstremaincognisantthatunauthorisedeffortstogainaccessto\nacomputersystemareoftendefinedasacrime(seeSection3.5).AsstatedintheACMCode\nSection2.8,\u2019Asystembeingpubliclyaccessibleisnotsufficientgroundsonitsowntoimply\nauthorization\u2019[286].197 Ifpractitionersaretestinginresponsetoa\u2019bugbounty\u2019program,they\nshould review carefully the terms of the program to assure that they are not exceeding the\nscopeofauthorisedtestingactivity.\nPractitioners should also consider the potential impact of their testing methods on the sta-\nbilityofpublicorprivateinfrastructures,includingthosethatarethetargetoftestingaswell\nasintermediaryandthird-partysystems.\n3.13.3.2 Disclosureofvulnerabilities\nThosewhofindsecurityvulnerabilitiesfaceachoiceofwhattodowiththeirnew-foundknowl-\nedge.Choicesexistonaspectrumfrommakingnodisclosure,topublishingeverydetailim-\nmediatelytotheworldatlarge.Inbetweenthesetwoextremeslieanarrayofpossibilities.\nThose who make no disclosure choose to do so for different reasons. Some wish to make\nno disclosure in an effort to avoid complicated problems of ethics and potential liability. It\nis difficult to reconcile this position with the ethical principle expressed in the ACM Code\nSection2.8\u2019toreportanysignsofsystemrisksthatmightresultinharm\u2019[286].\nSome who operate in support of state security agencies may wish maintain the secrecy of\navulnerabilityafterdecidingthattherisksandbenefitsofdisclosureoutweightherisksand\nbenefitsofmaintainingsecrecy[292,293,294,295].198 Theethicsofthis\u2019equities\u2019balancing\nprocessisatopicofcontinueddebate[294,296].\nFinders who choose to make an immediate full public disclosure of vulnerabilities without\nany prior warning to any effected person may do so for a variety of reasons. Some suggest\nthatthisistheonlycertainmethodofencouragingremediationeffortsbydevelopers.Some\ndonotwishtoinvestinthetime-consumingprocessofstagingtheprivateandpublicdisclo-\nsuresdescribedbelow.Somefearthatengagingwithdeveloperswillpromptalegalinterven-\ntion prohibiting disclosure.199 It is difficult to reconcile these arguments with the guidance\nfromtheACMCodetominimiseharm.\nMany practitioners follow a principle known as \u2019responsible disclosure\u2019. The idea is to dis-\nclosefirston aconfidentialbasisto apersonorgroupof personswhomaybeableto reme-\ndiateormitigatetheimpactofthevulnerability.Afteraperiodoftimehaselapsed,thefinder\nmightthenproceedtoasecondstageofpublicdisclosure.Second-stagepublicdisclosureis\noftenjustifiedbythepractitioneronthetheorythatpublicationwillenableotherpractitioners\ntostudyandavoidsimilarvulnerabilities,and\/orincentiviseproductandserviceprovidersto\nremediatethevulnerability.\nAtthetimeofwriting,thereappeartobenogenerallyagreedprinciplesontheproperconduct\nofresponsibledisclosure.Pointsofdivergenceinclude:\n\u2022 howtomanageprivatedisclosurewhenthevulnerabilityformspartofawidelyadopted\nindustrystandard;\n\u2022 how to manage private disclosure when the vulnerability is found in a product which\nformsacomponentorsub-componentindownstreamproducts;200\n\u2022 definingtheappropriatelengthoftimebetweenprivateandpublicdisclosures;\nKALaw&Regulation |October2019 Page125 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n\u2022 defining what circumstances, if any, mandate an indeterminate delay to public disclo-\nsure;and\n\u2022 defininghowtorespondiftherelevantvendorsorpurchasersofcompromisedproducts\ndisagreewiththefinderaboutthewisdomortimingofpublicdisclosure.\nPublic disclosure of vulnerabilities could also create tortious liability for a disclosing finder,\nespeciallyiftheprocessorsequenceofdisclosuresispoorlymanagedorthevulnerabilityis\nmisdescribed.\nPractitionerswhoseektojustifypublicationonthebasisthatitfitsgenerallywithintherubric\nof\u2019responsibledisclosure\u2019mayreceiveapoorreceptionfromstateauthorities[249,250].201\nVariouseffortstoobtainfinancialbenefitsfromdisclosingavulnerabilityalsoleadtodebate.\nAcceptingafinancialrewardfromavendorpursuanttoapublished\u2019bugbounty\u2019programme\nseems now to be widely accepted, especially as the vendor controls the terms of the pro-\ngramme[297].Othermorecontroversialtacticstomonetisefindingsinclude:\n\u2022 requestingafinancial\u2019bugbounty\u2019fromavendorasaconditionofdisclosurewhenthe\nvendorhasnoexistingbugbountyprogrammeinplace;\n\u2022 sellingknowledgeofthevulnerabilitytoathird-partybroker,whothenre-sellstheinfor-\nmation;and\n\u2022 engaginginmarkettradeactivity(e.g.,short-sellingpubliclytradedsharesofavendor)\nin an effort to profit financially from advance knowledge that a vulnerability will soon\nbepublished[298].\nPractitionerswhofindvulnerabilitiesduringthecourseoftheirworkassecurityresearchers\nmustfurtherconsidertheextenttowhichtheymaybeaccountabletotheiremployerorfunder\nforanyfinancialbenefitsobtained.\n3.13.3.3 Facilitatingandactingonvulnerabilitydisclosures\nProduct and service vendors should consider how they can facilitate and then act upon vul-\nnerabilitydisclosuresinamannerthatminimisesharmtocustomersandthirdpersons.202\nKey principles to facilitate proper vendor handling of vulnerability disclosures include: pub-\nlishing acceptable methods for finders to disclose vulnerabilities to the vendor, working dili-\ngently to verify the vulnerability once it is disclosed, developing remediation or mitigation\nstrategies, disseminating fixes, working with supply chain partners, and providing feedback\ntofinders.\nA framework to develop specific vendor policies and processes can be found in ISO\/IEC\n29147(theprocessofreceivingandhandlinginformationaboutvulnerabilities)andISO\/IEC\n30111 (the process of verifying and remediating vulnerabilities) [299, 300]. State agencies\nhave also published varying guidance on this topic, which is revised from time to time [301,\n302].203\nKALaw&Regulation |October2019 Page126 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n3.14 CONCLUSION: LEGAL RISK MANAGEMENT\nSection 3.1.5 introduced one way for a given Bob to think about the risk of legal action from\na given Alice. There were many points implicit in that introduction, however, including Bob\u2019s\nawarenessof:Alice,herrightofaction,aswellasdetailsofapplicablesubstantiveandproce-\ndurallaw.Onitsown,thefunctionpresentedismosthelpfulafter-the-fact-afterBobreceives\na threat of legal action from Alice. The purpose of this Section is to consider legal risk man-\nagementbefore-the-fact.\nAnyoneseekingtounderstandlegalriskoftenbeginswithaninformationdeficit.Simplylearn-\ningaboutthemanylawsandregulationsthatcanorshouldinfluencetheoperationofasingle\nenterprisecanbeprohibitivelytime-consumingandexpensive.\nThisproblemmultipliesaccordingtothenumberofjurisdictionswithwhichapersonmaybe\ndealing \u2013 a significant challenge if cyberspace truly enables contact with every jurisdiction\nintheworld.Inthemoderneraofmorethantwohundredsovereignstatesrecognisedunder\npublicinternationallaw,plushundredsofstatesthataremembersofafederalorsimilarstruc-\nture, plus untold tens (or hundreds) of thousands of additional municipal jurisdictions with\nvarying degrees of law making and enforcement authority, merely discovering the content\nof applicable laws and regulations and assessing enforcement risks can be a monumental\ntask. Private law obligations imposed by contract and (potentially voluntary) self-regulatory\nsystemscomplicatemattersfurther.Inafieldwheremultinationalcontactsandrelationships\narecommonplace,considerationsoftheeffectivelimitsofstatepowerarealsoappropriate.\nWhatfollowareafewsubjectsforconsiderationwhenconstructingalegalriskmanagement\nframework.\nIdentifysubjectmatterareasofgreatestrisk.Thenatureoftheactivitiesundertakenbyaper-\nson helps to identify which laws and regulations will be of most significance to that person.\nFor example, banks, telecommunications infrastructure providers, and providers of medical\nand legal services are always cognisant of their need to seek and maintain appropriate li-\ncenses for their activities. Providers of gaming (gambling) services are also very attuned to\nthe wide variation of laws that apply specifically to their operations. And all businesses are\nextremelyawareoftheneedtounderstandtaxreporting,collection,andpaymentobligations.\nConsidertheimpactonhumanlife.Astrictcost-benefitanalysismaybeusefulwhenmaking\noperationaldecisions,butbecomesproblematicwheremattersofhumanlifeandsafetyare\nconcerned.Lawsandregulationsadoptedtoprotecthumanlifeandcompensateforpersonal\ninjuryshouldbeaccordedspecialrespect.Ablatantdisregardofsuchrulesraisesignificant\nmoral and ethical concerns and can also result in exceptional or punitive measures when\ntheserulesareenforced.\nConductduediligencethatisalignedwithidentifiedrisks.Nobodyinstructsalawyerto\u2019Goand\nfindeverylawintheworldthatarguablymightapplytoanythingIdo.\u2019Atypicalduediligence\nstrategyinvolvesfirstidentifyingandinvestigatingthelawsthatcoulddestroyorbankruptan\nenterprise.Otherlawsandregulationsmaybecomeincreasinglysignificantasanenterprise\ngrowsorchangescharacter.Foreignlawsbecomeincreasinglysignificantastheenterprise\nmakesincreasingcontactwithnewjurisdictions.\nConsider the practical limits of territorial enforcement jurisdiction. In the era of online com-\nmerce, some enterprises become paralysed with fear about the potential legal obligations\ntohundredsofstateswhoseresidentsmightgainaccesstositecontent.Thosethatremain\nKALaw&Regulation |October2019 Page127 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nparalysedmaygooutofbusiness.Mostoftheotherstrytoadoptpragmaticapproachesthat\ninclude good faith efforts to filter content or otherwise block access to residents of states\nthatcharacteriseone\u2019sproductsorservicesasillicit.\nConsidertherelativecostofbreachinga(non-criminal)legalobligation.Committingacrimeis\ndifferentfromfailingtohonouracivilobligation.Therearetimeswhenthecostofanswering\nacivillegalactionislessthanthecostofcompliance.Mostcommonly,thisoccursinthecon-\ntextofacommercialcontractwhichhasbecomeuneconomictoperform,oracivilregulatory\nrequirementwithafixedfinancialpenalty.Inappropriatecircumstances,apersonmightrea-\nsonablyconcludethatrepudiatingitscivilobligation(andacceptingtheriskofalegalaction\nformoneydamages)islessexpensivethanfulfillingthecorrespondingobligation.\nConsider the risks to one\u2019s own personal reputation, safety and liberty. Cyber security practi-\ntioners are sometimes confronted with situations where they are tempted, or instructed, to\nviolatecriminallaw.Thosewhofacethiscircumstanceshouldrememberthattheymayper-\nsonallysuffertheconsequencesoftheiractions,irrespectiveofwhateverincentivehasbeen\nprovidedbyanemployerorclient.\nConsiderthelikelihoodofenforcement.Therearetimeswhenpersonswhohavelegalrights\nchoose not to enforce them. For example, the risk of legal action from an individual natural\npersonwhohassufferedademinimislossasaresultofaminorbusinesstortmaybedimin-\nishinglysmall.Iftherightsofthousandsormillionsofthesepersonscanbejoinedtogether\ninaclassactionlawsuit,however,theriskincreasessignificantly.\nConsiderthechallengesofcollecting,preserving,andpresentingevidence.Effortstoenforce\nlegalrightsandeffortstodefendagainstclaimsallhingeonone\u2019sabilitytoprove,ortorebut\nan adversary\u2019s efforts to prove, the underlying facts in dispute. Consider what issues will re-\nquireproofwhenanadversepartyseekstoenforcealegalright,andhowonecancollectand\npreserve evidence to an appropriate forensic standard in anticipation of the need to defend\nagainst this effort. Practitioners are also cautioned to explore the parameters of any appli-\ncable document or data retention policy, which involves the routine and regularly scheduled\ndestruction or deletion of documents. While the routine destruction of documents in accor-\ndance with a carefully defined governance policy is usually permissible, these procedures\nnormally must be suspended to the extent that documents may be relevant to any legal ac-\ntion that has commenced or been threatened. Any attempt to destroy evidence that might\nbe relevant to such a legal action often constitutes a violation of the law and can result in\nsevereconsequences.204\nConsider vicarious liability. The only certain way to reduce vicarious liability is to influence\nemployeebehaviourtoreducethenumberofactsthataretortiousorotherwiseviolateappli-\ncableregulations.Internalgovernancedocumentsintendedtoreduceliabilitytothirdparties\nshouldthereforebewrittenwiththegoalofinfluencingthisbehaviour.\nConsiderlocalisingriskyactivitiesinseparatelimitedliabilitylegalpersons.Lawyersroutinely\ncounsel business clients concerning the creation and structuring of separate legal persons\ninanefforttocontainliabilitieswithindefinedpoolsofinvestmentcapital.Thisisacomplex\nsubjectthatrequirescarefulnavigation.\nConsiderrisksthatareexternaltothelegalsystem,perse.Insomecircumstances,thegreat-\nest risk arising from a legal action or a threat of legal action has almost nothing to do with\nlawsorregulations,assuch.Consider,forexample,theimpactofapotentiallegalactionon\nthereputationofanorganisationortheimpactofanadversefindingonthemaintenanceof\nrelevantstatelicensestoconductbusiness.\nKALaw&Regulation |October2019 Page128 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nConsider changes to law or enforcement policy that are likely to arise. Societies and policy\nmakers are generally becoming more aware of the impact of cyber security. As this aware-\nnessincreases,statesandtheiragentsmayincreaseenforcementactivities,re-examineas-\nsumptionsaboutexistingpolicy,andintervenerapidlywithamendedornewlaws.\nKALaw&Regulation |October2019 Page129 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nCROSS-REFERENCE OF TOPICS VS REFERENCE MATERIAL\n3.2Jurisdiction X X X X X X\n3.4Dataprotection X X X X\n3.5ComputerCrime X X X\n3.6Contract X X\n3.8Intellectualproperty X X\n3.9Internetintermediaries X X\n3.12Publicinternationallaw X\nNOTES\n1Civil procedure governs process-related matters in non-criminal legal proceedings, such as the form of\npleadingssubmittedtothecourt(includingthesizeandshapeofpaperonwhichtheyarewritten),timeallowed\nfordefensivepleadingsandreplies,methodsofservingnoticeonparties,expandingorcontractingthenumber\nof parties in a law suit, the scope of mandatory disclosure of potential evidence, case management orders,\nmethodsofappealingadversedecisions,etc.Examplesoftheserulescanbefoundinthe[EnglandandWales]\nCivilProcedureRules,Title28oftheUnitedStatesCode,andthe[US]FederalRulesofCivilProcedure.\n2Criminal procedure governs process-related matters in criminal proceedings. Because criminal proceed-\ningsplaceatrisktheindividuallibertyoftheaccused,theserulesareheavilyinfluencedbyhumanrightslaw,\ncanbesignificantlydifferentfromcivilprocedure,andthusareoftenmaintainedseparatelyfromcivilprocedure\nrules.Examplesoftheserulesincludethe[UK]CriminalProcedureandInvestigationsAct1996,the[US]Federal\nRulesofCriminalProcedure,etc.\n3Rulesofevidencegovernthepresentationandexaminationofevidencebeforeatribunal.Thiscaninclude\nmatterssuchastheprohibitionofsomecategoriesofhearsayevidence,presentationofso-called\u2019computer\nevidence\u2019,introductionandexaminationofexperttestimony,permissibleexaminationandcross-examination\ntechniques,etc.\n4Cybersecuritypractitionersarenotaloneinthisrespect.Highlyexperiencedlawyersroutinelyrequireguid-\nancefrom\u2019localcounsel\u2019whoareretainedspecificallytoassurecompliancewiththeseruleswhenattempting\ntomanagemulti-statedisputes.\n5SeeNote13\n6AnecdotalevidencegatheredbytheauthorovermanyyearsofICT-focusedinternationalcommerciallegal\npractice,however,stronglysuggeststhatmanyofthenormsexpressedinthisknowledgeareaarealsoreflected\ninsystemsofcivillaw(seeNote14).Thereisnoclaimthatthenormspresentedherewouldnecessarilybefound\ninothersystemsofdomesticlawsuchasthosefoundedonreligiousdoctrineorsuigeneriscustomarylaw.\n7Practitionersmightwishtothinkofthemas\u2019ActualAlice\u2019and\u2019ActualBob\u2019asdistinguishedfrom\u2019Device\nAlice\u2019and\u2019DeviceBob\u2019.\n8ReadersignoretheNotesattheirperil.\n9While jurists and legal scholars tend to agree on the process of legislative amendment to law, the idea\nthatevolutioninsocietalvaluescanleadtochangesintheinterpretationofun-amendedlawisnotuniversally\naccepted. Depending upon the system of law in question, some jurists and legal scholars take the view that\nKANOTES |October2019 Page130\n]59[uW&htimsdloG\n]401[0.2launaMnnillaT\nlhoK\n,dnalwoR\nhtrowselrahC\n&\n]701[\n]801[yarruM ]901[nedlaW\n&\n,relssoB\n,tloH\n]011[rallepS-deirfgieS\n]111[hguolC\natad\nUE\nno\nkoobdnaH\n]071[walnoitcetorp\n]171[senilediuGRPDG TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nsomelawsrepresentunchanging(perhapsevenuniversal)valuesandrejectanyothernotionasinappropriate\norheretical.Thisdisagreementalsoexposesarecurringtensionindefiningandmaintainingthedivisionofleg-\nislativefromjudicialauthority.Forthesecuritypractitionerthisdebatecanbesimplifiedasfollows:bywhatever\nmechanism,lawchangesovertime.\n10ThenatureandchallengesoflegalscholarshiphavebeennicelysummarisedbyDavidFeldman,Q.C.[303].\n11The pace of change in various laws depends upon how deeply rooted they are in social values. Certain\nfoundationalprinciplesconcerningtheadministrationofjustice(e.g.,therighttonoticeandtherighttopresent\none\u2019scasetoatribunal),aresoslowtochangethattheyappearwithinthespanofasinglegenerationtobe\nimmutable.Othertypesoflaw(e.g.,taxlaw)areamendedcontinually.\n12Indeed,therelativeutilityofasystemoflawarguablydependsuponthischaracteristicofpredictabilityof\noutcome.Acontrary,evennihilistic,viewoflawandlegalanalysisisfoundintheacademicschoolofcritical\nlegalstudies.AgoodandaccessibleexampleisthescholarshipofGirardeauSpann[304].\n13CommonlawsystemsarethosederivedfromthelawofEngland.Thesearethefoundationoflegalsystems\nin states that had close historical connections with Great Britain, including England, Wales, Ireland, Australia,\nNew Zealand, Singapore, most of the constituent provinces of Canada, most of the constituent states of the\nUnitedStates,etc.Asaresult,thissystemoflawisnearlyubiquitousinanglophoneterritories.\n14Civil law systems are those derived from a mix of Germanic, Napoleonic, and\/or Nordic laws. These are\nthefoundationoflegalsystemsthroughoutEurope(withtheexceptionofafewcommonlawjurisdictions)and\nin states that had close historical connections with continental Europe. These include European states such\nasFrance,Germany,Italy,Sweden,andRussia,andnon-EuropeanstatessuchasArgentina,Brazil,Mexico,and\nJapan.(InthecaseofJapan,thelate19thcenturyMeijiStateselectedthecivillawofGermanyastheprimary\nbasisforitslegalmodernisationprogramme[305].)\n15Seediscussionof\u2019code\u2019inthetextaccompanyingNote20\n16Intheauthor\u2019sexperience,mistakinga\u2019bill\u2019(notlaw)fora\u2019statute\u2019(law)isnotanuncommonoccurrence\namong cyber security practitioners who are unaccustomed to legal research. This is especially easy for the\nunwary who stumble across the annual mountain of bills introduced by members of the US Congress which\nneverbecomelaw.\n17Asalimitednarrowexception,somestatesadoptthepracticeofexamininglegislativehistory(suchasthe\nseriesofdraftbillsastheywereamendedintheprocessofdebatetobecomelaw)asameansofhelpingto\ninterpretthelawasfinallyadopted.\n18ThestatusofEuropeanUnionlegislationintheUnitedKingdomafterBrexitiscomplex.TheUKhasadopted\nlegislationthatwillgenerallycontinuewithinthebodyofUKdomesticlawthosepre-BrexitEUlawsthataremost\nrelevanttocybersecurity(e.g.,dataprotectionregulation)unlessanduntiltheUKParliamentdecidestodiverge\nfromEUlegalprinciples.\n19Inthecontextofasystemoffederalstates,\u2019foreignstate\u2019canincludeanothermemberstateofthefedera-\ntion.Thus,courtsoftheStateofNewYorkwouldregardinterpretationsoflawissuedbycourtsoftheStateof\nCaliforniaasthedecisionsofaforeignstate.Assuch,theywouldnotconstitutebindingauthorityinNewYork\nStatecourts,althoughtheymighthavevalueasasourceofpersuasiveauthority.Thisdiscussionshouldnot\nbeconfusedwiththesubjectofenforcingforeignjudgments(seeSection3.2.4).\n20Forexample,theUnitedStatesCode(U.S.C.)(acollectionofotherwisedisparateActsoftheUSCongress\norganised into code form by editors who then revise the code as further legislation is adopted or amended),\nandtheB\u00fcrgerlichesGesetzbuch(BGB)(thecomprehensivecodeofGermancivillawadoptedenmasseatthe\nstartofthe20thcenturyandamendedfromtimetotime).\n21Forexample,theCodeofFederalRegulations(C.F.R.)(acodifiedformofUSsecondarylegislation).\n22For example, the Uniform Commercial Code (U.C.C.) (a set of model laws produced as a joint project of\ntheUniformLawCommissionandtheAmericanLawInstitute,whichhasinturnbeenadoptedwithsomelocal\nvariationsbymostconstituentstatesoftheUnitedStatesandhasthusbecomeextremelyinfluential).\n23Thislastcategorycansometimessuggestthefuturedevelopmentoflaw,asstatesmaydecidetomandate\ncompliancewithcodesthatbeganlifeassuggestedrules.Similarly,courtsmayuseadvisorycodesasaway\nofinterpretingresponsibilitiessuchastherequirementtoact\u2019reasonably\u2019inassessingnegligenceliability.\nKANOTES |October2019 Page131 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n24Forexample,TheTallinnManual(arestatementofpublicinternationallawapplicabletocyberoperations)\nandtheRestatement(Third)ofTorts:ProductsLiability[104,221].\n25Thiscanbesimplifiedwiththeobservation,\u2019There\u2019snosuch\"place\"ascyberspace\u2019.\n26Somecreativeargumentsagainstthisresultincludeattemptingtorecharacterisecyberspaceas\u2019territory\u2019\nthat exists separately from sovereign states, thus attempting to describe a universal and harmonised set of\nlegalprinciplesthatshouldbeapplicabletoallusesofcyberspaceglobally,andinsomecasesrejectingtheau-\nthorityofsovereignstatestointerveneincyberspace-relatedactivities.Thebestoftheseconstituteinteresting\nexperimentsinlegalphilosophy[306].\n27Therelativemeritsofdefininganartificialintelligenceasapersonforlegalpurposeshavebeenconsidered\nbylegalscholarsfromtimetotime[307,308].\n28A variety of other legal doctrines might create liability for persons as a result of actions directed by an\nartificialintelligence[309].\n29Variousfinancialfraudcrimesareoftendefinedinthisfashion,forexample,requiringproofthattheaccused\nhadaspecificintentiontodeceive(scienter).ManyofthecomputercrimesdiscussedinSection3.5.1maynot\nrequiresuchproof.\n30Criminalintent(oritslack)shouldbedistinguishedfromcircumstanceswherethelawexpresslyprovides\nadefencesuchas\u2019publicinterest\u2019,\u2019publicnecessity\u2019,or\u2019self-defence\u2019.\n31\u2019Civil law\u2019 in this context, meaning non-criminal law, should not be confused with the term \u2019civil law\u2019 as a\nmeansofclassifyingsystemsoflawsuchasarefoundinthestatesofcontinentalEurope.SeeNote14.\n32Principles of human rights law designed to guarantee a fair trial for Alice often force people like Bob to\ndelaytheircivilactionuntiltherelevantcriminalprosecutionisconcluded.Thedifferenceinstandardsofproof,\nitisentirelypossibleforAlicetobefound\u2019notguilty\u2019oftheallegedcrimeandstillbefoundliableforthealleged\ntort.\n33ThelawoftheUnitedKingdomexpresslyprohibitsintroducingthecontentofsuchinterceptedcommuni-\ncationsasevidenceincourtproceedings.\n34Thisdefinitionof\u2019proof\u2019standsinsharpcontrasttoa\u2019mathematicalproof\u2019.Inthefieldofmathematics,to\n\u2019prove\u2019somethingmeanstoestablishundeniabilityasalogicalnecessity\u2013toestablishthetruthofaproposition\nbeyondanydispute.(Forexample,proofofPythagoras\u2019theorem.)Bycontrast,theproofofareal-worldevent\ninacourtoflawneverresultsinabsolutecertainty.Afactfinderinalegalproceedingmustreachaconclusion\nonlessthantotalcertainty.Atechnologyjournalisteloquentlysummarisedthiswhenhestated,\u2019Thepurpose\noflawisnottoachievephilosophicalormathematicaltruth,buttotakeamessyrealityandachieveworkable\nresultsthatsocietycanlivewith\u2019[310].\n35An\u2019affirmativedefence\u2019iscontrastedwithothertypesofdefencewherethepartypursuingarightofaction\ncontinuestocarrytheburdenofproof.Forexample,inacriminalprosecutionformurderunderEnglishlawif\ntheaccusedclaims\u2019self-defence\u2019itremainstheresponsibilityofthestatetoprovebeyondreasonabledoubt\nthat the accused is NOT entitled to the defence. By contrast, a claim of \u2019insanity\u2019 is an affirmative defence\nunderEnglishcriminallaw.Theburdenofprovinginsanityfallsontheaccused,althoughthestandardofproof\nrequiredismerelythe\u2019balanceofprobabilities\u2019[311].\n36Therearemanypossiblecriticismsofthisapproachtoexplaininglegalriskanalysis,includingthefocuson\n\u2019cost\u2019asadeterminantofrisk.FactorsbeyondthemerefinancialareconsideredinSection3.14.\n37Althoughcourtsusethissamephrasetodescribethetwostandardsofproof,theyremainfreetodefine\nthemdifferentlyinthecontextofinterpretingtwodifferentlawsadoptedfortwodifferentpurposes.\n38Thistermcanalsobeusedtodescribesubjectmatterandterritorialauthorityoflegalpersonscreatedby\ntreaty between states, such as international governmental organisations (e.g., the ITU) and special purpose\nmulti-statemunicipalorganisations(e.g.,ThePortAuthorityofNewYorkandNewJersey,andtheWashington\n[DC]MetropolitanAreaTransitAuthority).\n39By contrast, \u2019subject matter jurisdiction\u2019 refers to the scope of the subject matter that can be addressed\nbyagivenentity.Forexample,asinglestatemightchoosetodivideitscourtsystemintotwoparts:onethat\naddressesonlycriminalcomplaintsandonethataddressesonlycivilmatters.Whiletheterritorialjurisdiction\nof both courts might be identical, the subject matter jurisdiction is clearly different. Similarly, the scope of\nKANOTES |October2019 Page132 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nauthoritydelegatedtoindividualregulatoryagencies,ministersofstate,etc.,constituteatypeofsubjectmatter\njurisdictionforthatagency.\n40AgoodintroductiontotheprinciplesofjuridicaljurisdictionforcivilcasesisfoundintherecastBrusselsI\nRegulation,whichpresentstherulesnormallyapplicabletocivilmattersincourtslocatedwithintheEuropean\nUnion[312].\n41TotakeanadmittedlywhimsicalfictionalexamplefromtheWildWest,inthefilmSilveradoSheriffLangston\n(portrayed by John Cleese) discontinues his hot pursuit of criminal suspects through the wilderness after a\nsniperopensfireonhisposse.Hejustifieshisactionexplainingwrylytohiscompanions,\u2019Todaymyjurisdiction\nendshere\u2019[313].SheriffLangston\u2019squandaryillustratestherelationshipbetweenstatepowerandenforcement\njurisdiction. Non-fictional examples that explore the territorial limits of state enforcement power are readily\navailable,albeitcontroversial,andinsomecasesarethesubjectofdiplomaticandinternationallegaldispute.\n42SeevariousUSstatutescriminalisingactsofhomicideagainstUSnationalswhileoverseascodifiedat18\nU.S.C.\u00a72332.\n43Reasons this activity might not be illegal under the law of the first state include, most obviously, where\nthefirststatehasnotadoptedanylawtocriminalisethecomplained-ofhackingactivity.Alternatively,thefirst\nstatemaycriminalisetheactivityinnormalcircumstancesbutofficiallywarrantsthecyberoperationpursuant\ntothelawfuldomesticauthorityofthefirststate.Inthissecondscenario,thepersonundertakingtheoperation\nwould normally be immune from criminal prosecution in the first state but subject to criminal prosecution in\nthesecond.Thisdiscussionfocusessolelyonliabilityoftherelevantnon-statepersonundertakingthecyber\noperation.Theliabilityofstatestooneanotherforsuchoperationsisaddressedinpublicinternationallaw(see\nSection3.12).\n44ThesubjectsofespionageandremoteevidencegatheringarediscussedinSections3.12.3&3.12.4\n45The1998disputeoverlegalcontrolofDNSrootservers,anditsinformalalbeitdramaticresolution,isre-\ncountedbyGoldsmithandWuandcriticisedbyFroomkinamongothers[95,314].\n46Abankinthissituationfacesthepracticalproblemoftwocompetingstatesmakingconflictingdemands:\noneorderingpayment,andasecondprohibitingpayment.Takingtheanalysisonestepfurther,imaginewhat\ncould happen if (in an effort to avoid adverse enforcement actions by the United States) the London branch\nof a US bank refused to comply with the judgment of an English court. This bank might jeopardise its ability\ntoconductregulatedbankingactivitiesinLondon.Presumably,thedepositorcouldalsoaskEnglishcourtsfor\nenforcement assistance by demanding the seizure and forfeiture of funds held by such defaulting US banks\nondepositwithotherbanksintheUK.Thedepositorcouldalsotakethejudgmentandrequestenforcement\nbythird-partystateswheretheUSbankalsoheldfundsondeposit.Thesearethetypesofanalysisthatarise\nwhenanon-statepersonconsiderstheriskofpotentiallyconflictingstatemandates.\n47InthecontextoftheUSfederalsystem,eachmemberstateoftheUSisnormallyrequiredtoenforcecivil\njudgments issued by courts of other member states under the Constitutional mandate to give \u2019full faith and\ncredit\u2019toactsofotherUSstates.(USConstitution,ArtIV,Sec1.)AsimilarruleappliesintheEuropeanUnionby\noperationofChapterIIIofthe(recast)BrusselsIRegulation[312].\n48To avoid a point of occasional confusion, if a suspect is travelling from State A to State C and they are\ntransitingStateB,thepoliceofStateB arenormallyabletoarrestthatsuspectuponarrivalinStateB.This\ncontinuestoholdtrueevenifthesuspectdoesnotrequestentrytoStateB.Criminalsuspectscanbe,andhave\nbeen,arrestedintheinternationaltransitareasofairports.\n49Lessig\u2019sphrase\u2019codeislaw\u2019hasbeenthesubjectofwidespreaddiscussionamongbothtechnologistsand\nlawyers[315].Lessighighlightsthecloseinterrelationshipbetweentechnologicalcontrols(computercode)and\nhumangovernancecontrols(legalcode).Botharemechanismsthatcanservetolimithowsystemsareused.\nEachmechanismhasdifferentutility.Andultimately,eachmechanismmayinfluencetheother.However,the\nphrasehasbeeninterpretedbysometomeanthat\u2019whoeverwritesthecomputercodeisessentiallymakingthe\nlaw\u2019.ThehistoryofhowlawsareenforcedwithrespecttoInternet-relatedactivitystronglysuggeststhatthis\ninterpretationis(atbest)terriblymisleadingand(atworst)misunderstandsthedirectionofcausalitybetween\ncomputerandlegalcode.\nWhiletechnologistscertainlyenjoyedfirst-moveradvantageinchoosingthedesignoftheunderlyingarchi-\ntectureoftheInternetandrelatedapplications,lawmakers-andthesocietiesforwhomtheyserveasaproxy\n- have responded strongly with their own opinions about how systems should work. As one author has wryly\nobserved,societalopinionseemstohavemoved\u2019from\"CodeisLaw\"to\"LawisLaw\"\u2019[160].Inotherwords,one\nKANOTES |October2019 Page133 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nshouldnotassumethatthepersonswhowritethe(computer)codearethesamepersonswhocreatethelegal\nnormstobeenforced.\n50The significant role undertaken by various platform operators in filtering content on a state-specific ba-\nsisandsupplyingsimilargeo-filteringtoolstotheircontentsupplyingcustomersisoftenoverlookedinpolicy\ndebate.\n51AnexampleofcollaborativefilteringisfoundintheworkoftheInternetWatchFoundation.Amongother\nthings,theIWFmaintainsaURLdatabaseofsitesknowntohostimagesofchildsexualabuse.Thisdatabase\nisusedbyvariousserviceproviderstorestrictaccesstothesesites[316].\n52TheopinionofJudgeLynch,concurring,isespeciallyinterestingashewrotetohighlightmanyofthemore\nunsettlingandcounter-intuitivepolicyaspectsthatwouldresultfromthejudgmentand\u2019toemphasizetheneed\nforcongressionalactiontoreviseabadlyoutdatedstatute\u2019.\n53AlthoughtheMicrosoftcasewasdismissedpriortojudgment,theextensivecollectionofbriefsfiledwith\ntheUSSupremeCourtbyavarietyofinterestedthirdpartiesconstitutesatreasuretroveofanalysisandadvo-\ncacyonthistopic.ItremainspossiblethatafuturedisputemightbebroughtintheUScourtstochallengethe\nauthorityoftheUSCongressunderthetermsoftheUSConstitutiontoextendjurisdictioninthisfashion.While\ntheoutcomeofanysuchfuturechallengeisdebatable,itseemsunlikelytosucceed.\n54The precise meaning of \u2019lawful and voluntary consent\u2019 in Article 32b of the Budapest Convention has\npromptedmuchdiscussion.Oneareaofrepeatedconcernistheacceptancebysomestatesofcriminalplea\nbargainingtechniquesasameansofobtainingconsentfromcriminalsuspects[139,317].\u2019Consent\u2019isachal-\nlengingsubjectinlaw,generally[318].SeealsoSection3.4.2.\n55Althoughpeoplemostoftendiscusstheissueofdatasovereigntyinthecontextofcompelleddisclosureof\ndata,otherstateinterventionsmayalsobepossiblesuchascompelleddataalterationordeletion,orcompelled\nserviceinterruption.\n56Methodsusedinanefforttomitigatethisriskusingcryptographictechnology,databaseshardingorrepli-\ncationoverserversinmultiplestates,etc.areoutsidethescopeofthisknowledgearea.\n57TheRegulation,ofcourse,doesnotinterferewithanydatalocalisationrulesimposedforreasonsofstate\nsecurityasthissubjectareafallsoutsidetheregulatorysubjectmatterjurisdictionoftheEuropeanUnion.\n58The discussion in the Section focuses primarily on the privacy rights of natural persons. States can and\ndoapplytheseorsimilarrightstolegalpersons,althoughtheprivacyrightsoflegalpersonsmaybelessthan\nthoseaccordedtonaturalpersonsinsomecircumstances.\n59Tounderstandthelegalcontextoftheinternationalinstrumentscited,seetheintroductorydiscussionof\npublicinternationallawinSection3.12.\n60TheconditionalnatureoftherightexpressedinArticle7isexplainedinanaccompanyingreport[319,320].\n61IntheUSlegalsystem,forexample,theFourthAmendmenttotheUSConstitutionprovidesasetofrights\nthatlimitonlystateactions,whiletheCaliforniaConstitutiongrantsageneralrightofprivacyeffectiveagainst\nstateandnon-stateactions.BoththeUSanditsconstituentstateshavepromulgatedalargenumberoflaws\nthatregulateintrusionsundervariousconditions.Thelandscapeiscomplicated.\n62Examples made possible by the emergent mobile app economy include processing data concerning per-\nsonal contacts, calendar and scheduling information, banking data and authentication credentials, personal\nnotesandcommunications,browsingandshoppinghistory,intimaterelationshipdata,andavarietyofhealth-\nrelateddatafromheartrateandexercisepatternstomenstruationdata.Eachnewdatasetpresentsaquestion\naboutthe\u2019normal\u2019expectationofprivacywhenusingtheseservices,andthepermissiblescopeofintrusionby\nstateandnon-statepersons.\n63InthereferencedcaseofSmithvMaryland,theUSSupremeCourtdecidedin1979thatcompelleddisclo-\nsureofcustomerdiallingrecordsdidnotconstitutea\u2019search\u2019forpurposesoftheFourthAmendmenttotheUS\nConstitutionasthecustomerhadnoexpectationofprivacyinthelistofnumbersdialled[158].\n64Comparetheinformationthatcanbeinferredafterdiscoveringthatatargetofinvestigationhasnavigated\ntoaURLstringsuchas\u2019web.example.com\/politicalpartyname\/how-to-renew-my-membership.htm\u2019withthedis-\ncoverythatthesamepersondialledaphonenumbersuchas\u20191-202-555-7730\u2019.Inthisexample,theURLmeta-\nKANOTES |October2019 Page134 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ndata leads to a strong inference of communication content and the probable ability to reconstruct accessed\ncontentprecisely.\n65TheUSSupremeCourt,forexample,decidedin2018thatacellphonecustomerhasareasonableexpecta-\ntionofprivacyinlocationdataandthereforethestate-compelleddisclosureofthisdataconstitutesa\u2019search\u2019\nforFourthAmendmentpurposes[321].InEurope,customerlocationdatahasbeenexpresslyprotectedunder\nprivacyanddataprotectionlawsforsometime.\n66Consider,forexample,thecapabilityofvariousde-anonymisationtechniquesthatcanbeappliedtometa-\ndataaswellasthereportedgrowthofmetadataanalysisinthefieldofsignalsintelligence.\n67There are, of course, risks associated with the implementation of these facilities and examples of how\ntheyhavebeenabusedinviolationofapplicablelaw.Anti-abusemeasurescanandshouldbefoundedonboth\ntechnologicalandorganisationalcontrols.\n68Thecomplexityfacingamultinationalservicesproviderincomplyingwithlawfulinterceptionobligationsis\nwellillustratedinVodafone\u2019spublishedtransparencyreport,whichincludesalengthysummaryoftherelevant\nlawstheyfacein28states[322].\n69Inanefforttonavigatepotentialrestrictionsonreportingnewtypesofinterception,someserviceproviders\nadoptedthepracticeofpublishingso-called\u2019WarrantCanaries\u2019\u2013astatementpublishedonarecurringbasis\nthat no interception warrants of a given type had been received. The theory behind this practice was that a\nsubsequent failure to re-publish the Canary statement would allow the public to infer (without the communi-\ncation provider expressly stating) that state-warranted interception had commenced. This practice seems to\nhave fallen into disfavour, probably aided by the sometimes-debatable legal status of the practice plus addi-\ntionalstatelegalinterventionsthatmadethisstrategymoredifficultorimpossibletocarryoutwithintheterms\nofapplicablelaw.See,e.g.,50U.S.C.\u00a71874(a)[323].\n70In the US, some courts have held that efforts to compel disclosure of passwords triggers scrutiny under\nhuman rights law as it forces a suspect to give testimony against himself, while mandatory presentation of\na fingerprint to unlock a device does not trigger this same legal objection [165]. This is an area where legal\nstandardsremainmurkyandthetopicisripeforfurtherdisputeanddevelopment[166].\n71Anexampleiss.49ofthe(UK)RegulationofInvestigatoryPowersAct2000.\n72Practitioners should be careful to distinguish between activities such as developing a communications\nprotocol, writing software that implements a protocol, supplying such software to the public, and supplying\naservicethatimplementsaprotocol.Aquicktestthatmayassistinclarifyingaperson\u2019sstatusistoaskthis\nquestion:\u2019Wouldtherelevantcommunicationsservicecontinuetooperateiftheprocessesadministeredbythis\npersonceasedtofunction?\u2019Thus,apersonwhosuppliesIMAPservices,SMTPservices,orakeydistribution\nservicetosupportend-to-endencryptionforacommunicationsappismorelikelytobeclassifiedasacommu-\nnicationsserviceproviderunderrelevantlegislationthanapersonwhomerelywritessoftwarethatimplements\naprotocol.Detailsofapplicablelawsdivergesignificantlyandmustbeinvestigatedonastate-by-statebasis.\n73Forexample,BradyvMaryland[324].Thisislesslikelytooccurtotheextentthatthelawofastate(such\nastheUK)prohibitsuseofinterceptedcommunicationsasevidenceinlegalactions[167]ats.56.\n74TheUSexclusionaryrulehasbeenhotlydebatedformorethanhalfacentury.\n75Activitiesundertakenbystatesindefenceofstatesecuritygenerallyfalloutsidetheprescriptivejurisdiction\noftheEU.Memberstatesmaychooseindividuallytoapplysimilarprinciplesinthestatesecuritycontext[187],\nPart4.\n76Practitionersmustnotlosesightofthisregulatorypurpose.Whenassessingrisksofvariousprocessing\nactivitiesandsecurityarrangementsinthecontextofdataprotectionlawcompliance,therisktobeassessed\nisnormallytheriskofharmtodatasubjects-livinghumanbeings.Risksfacedbytheprocessingenterprise(in-\ncludingrisksofnon-compliancewithdataprotectionlaw)shouldbeevaluatedseparately.Asimilarobservation\ncanbefoundinthecontextoftheCarrollTowingcasediscussedinSection3.7.1.2andNote123.\n77The attempt to delineate \u2019pseudonymous\u2019 from \u2019anonymous\u2019 data is a subject of significant discussion\n[325].Whiledetailsofde-anonymisationmethodsarebeyondthescopeofthisknowledgearea,examplesseem\nreadilyavailable[326].\n78Forexample,theterm\u2019personallyidentifiableinformation\u2019isdefinedforthepurposesofUSbankruptcylaw\nat 11 U.S.C. \u00a7101(41A) and defined differently for the purposes of a federal law prohibiting the disclosure of\nKANOTES |October2019 Page135 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nvideorentalhistoriesat18U.S.C.\u00a72710(a)(3).\n79ThisisanaturalresultoftheUSapproachtothissubject,whichistoadoptnarrowlydrawnsuigenerislaws\nthatspecificallyfocusonindividualusecases.TheciteddecisionsaredrawnfromexamplesoftheUScourts\ninterpretinga1988laworiginallyadoptedtorestrictthedisclosureofvideorentalrecordsastheywerekeptin\nthe1980s.Thecourtswerecalledupontointerpretthisageingstatuteinthecontextofonlinestreamingservice\nrecords in 2015. Practitioners may be interested to note that as US courts are charged with responsibility to\ninterpretthewilloftheUSCongresswhenresolvingthesecases,theyseemunawareof(orperhapsuninterested\nin)thetechnicaldefinitionsofPIIofferedbytheISOandNISTpublications[179,180].\n80In practice, there may be a strong temptation, and corresponding pressure, to assume that the absence\nof obvious personal identifiers in a data set means that no personal data are present. A better approach is\nto appreciate that data protection law tends to measure obligations in proportion to the risks presented by\nany given processing activity. Data sets containing personal data without obvious personal identifiers might\nthereforepresentalowerriskwhenprocessed,thusmakingcompliancelessonerousinsuchcases.\n81Consent is perhaps one of the least well understood, and hotly debated, terms in data protection law. In\nadditiontomanysourcesofguidancepublishedbypublicauthoritiesonthistopic,practitionerswhowishto\nexplorethisconceptindepthmighttakeinspirationfromoutsidethebodyofdataprotectionlaw[318].\n82Thenotificationsdiscussedinthissectionaredistinguishedfromseparaterequirements,ifany,toshare\nsecuritybreachinformationwithrelevantindustry-specificregulatorsorsecuritycoordinationauthorities(see\nSection3.11.1).\n83By2010,46USstateshadadoptedlegislationmandatingsomeformofpersonaldatabreachnotification\ntoeffectedpersons[327].\n84Mandatoryobligationstocommunicatepersonaldatabreachestodatasubjectsirrespectiveoftheriskof\nharmhasbeencriticisedonanumberofgrounds,including:datasubjectsbecomeoverwhelmedbycommuni-\ncationsandareunabletodistinguishthedegreeofriskpresentedbyanyindividualbreach,communicatingtoa\nlargesetofdatasubjectsisextremelyresource-intensive,andcommunicatingtodatasubjectscouldinterfere\nwiththeabilityofpoliceauthoritiestoinvestigatethebreach.\n85 The UKICO explained the proposed finein its Statement of July8, 2019: \u2019The proposed fine relates to a\ncyberincidentnotifiedtotheICObyBritishAirwaysinSeptember2018.Thisincidentinpartinvolvedusertraffic\nto the British Airways website being diverted to a fraudulent site. Through this false site, customer details\nwere harvested by the attackers. Personal data of approximately 500,000 customers were compromised in\nthisincident,whichisbelievedtohavebeguninJune2018.TheICO\u2019sinvestigationhasfoundthatavarietyof\ninformationwascompromisedbypoorsecurityarrangementsatthecompany,includinglogin,paymentcard,\nandtravelbookingdetailsaswellnameandaddressinformation.\u2019\n86 TheUK ICOexplainedtheproposedfineinits StatementofJuly9, 2019:\u2019The proposedfinerelatesto a\ncyberincidentwhichwasnotifiedtotheICObyMarriottinNovember2018.Avarietyofpersonaldatacontained\ninapproximately339millionguestrecordsgloballywereexposedbytheincident,ofwhicharound30million\nrelatedtoresidentsof31countriesintheEuropeanEconomicArea(EEA).SevenmillionrelatedtoUKresidents.\nIt is believed the vulnerability began when the systems of the Starwood hotels group were compromised in\n2014. Marriott subsequently acquired Starwood in 2016, but the exposure of customer information was not\ndiscovereduntil2018.TheICO\u2019sinvestigationfoundthatMarriottfailedtoundertakesufficientduediligence\nwhenitboughtStarwoodandshouldalsohavedonemoretosecureitssystems.\u2019\n87As Ian Walden notes, \u2019classifying certain subject matter as criminally illegal can be a highly contentious\nmatter, raising complex definitional issues, questions of causation, and human rights concerns, specifically\nrightstoprivacy,freedomofexpression,assembly,andassociation\u2019[109]atpara3.95.\n88Theproblemispresentedinthewell-knowncaseofRvGoldandSchifreen[328].Theaccusedwerearrested\nintheUKin1985aftertheyhadobtainedasystempasswordforanearlyemailsystemandusedittoaccessan\nemailaccountassignedtoamemberoftheBritishRoyalFamily.Althoughtheaccusedwereoriginallyconvicted\nfollowingtrialin1986forviolatingtheForgeryandCounterfeitingAct1981,theHouseofLords(atthattimethe\ncourtoflastresortintheUK)quashedtheconvictionin1988holdingthatthecomplained-ofactionwasnota\nviolationofthe1981statute.\n89BruceSterlingprovidesaninterestinghistoryofearlycomputercrimeinvestigationandprosecutionefforts\ninthe1980sbytheUSauthorities,andcolourfullydescribeshowtheysometimesmissedtheirintendedtarget\nKANOTES |October2019 Page136 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n[329]. Clifford Stoll also describes the contemporaneous challenges he encountered as a private citizen at-\ntemptingtoinvestigatecomputerintrusion,complainingthatheoftencouldnotfindlawenforcementofficials\nabletoassisthim[330].\n90AcatalogueofUSstatecomputercrimestatutesismaintainedbytheNationalConferenceofStateLegis-\nlatures[331].Averyusefulandoft-citedsurveyofUSstatelawswascompiledbySusanBrenner[332].\n91BoththeBudapestConventionandDirective2013\/40allowstatesacertaindegreeofflexibilityinthedetail\noftheirdomesticlaws,andmanycontractingstateshavedeclaredreservationsagainstcertainprovisionsof\ntheBudapestConvention.\n92Confusingly,theverb\u2019tohack\u2019isalsousedtodescribenon-criminal,ofteninformal,ICTresearchanddevel-\nopment activities that are pleasingly clever or demonstrate a previously unknown characteristic of an object.\nThispositiveconnotationofthetermnowextendsbeyondtherealmofICTdevelopment,ascanbefoundin\nemergingphrasessuchas\u2019lifehack\u2019and\u2019hackathon\u2019.\n93Theroleofprosecutorialdiscretionisonepossibleexplanationforthelackofademinimisexceptioninthe\ndefinitionofcomputercrimes.SeethediscussioninSections3.5.3and3.5.5.\n94ThiswasdiscussedaftertheClicktelevisionprogramme\u2019s\u2019Botnetexperiment\u2019wasbroadcastontheBBC\nin March 2009, in which the show\u2019s producers procured and then commanded the actions of such a botnet,\nalbeitwithanavowedlybenignintention[333,334,335,336].\n95Insomerareinstances,non-statepersonsaregrantedtherighttobringacriminalprosecutionwhenstate\nofficialshavechosennottodoso.\n96USFederalCourtsundertakeanalgorithmicapproachincalculatingrecommendedcriminalsentencespur-\nsuanttheUSFederalSentencingGuidelines[337].Undertheseguidelines,crimesagainstinformationsystems\nareclassifiedas\u2019economic\u2019crimesandsentencesmaybesignificantlyenhancedbaseduponvalueofdamage\ncaused by the criminal activity [197]. (Details of the calculation are set out in [337] at \u00a72B1.1, taking note of\nthevariousinterpretiverulesapplicabletoviolationsof18U.S.C.\u00a71030,etseq.)Althoughfederaljudgesare\nrequired to take this calculation into account when passing sentence, they may deviate from the sentencing\nguidelinessubjecttowhateverlimitsmaybemandatedbyCongressinthesubstantivecriminalstatute.\n97Thisbecomesmoreobviouswhenconsideringintrusioneffortsagainstindustrialcontrolsystemssuchas\nthosethatoperatedamsluicegates,nationalelectricitypowergrids,steelmillsandfoundries,automobiles,oil\ntankers,pipelines,andnuclearpowergenerationfacilities.\n98Historically,theComputerMisuseAct1990didnotcontemplatetheideaofstate-warrantedintrusioninto\ninformationsystems.Thisexpressexceptiontocriminalliabilityunderthe1990ActfirstappearedintheRegu-\nlationofInvestigatoryPowersAct2000,thepredecessoroftheInvestigatoryPowersAct2016.\n99Such proof would most likely consist of asking the fact finder to draw reasonable inferences from the\ncircumstancessurroundinganygivenactofproductionordistribution.\n100Somehavearguedthatconducting\u2019legitimate\u2019securityresearchactivitiesshouldbeshieldedfromcriminal\n(andperhapscivil)liabilityifappropriateconditionsaremet[338,339].Similarargumentshavebeenadvanced\ninthecauseofsecurity-relatedjournalism.Thesepolicyargumentshavenotyetfoundoverwhelmingsupport\nfromvariousstatelawmakers,althoughthedebateisnotwelladvanced.\n101Ithasbeensuggestedthatpersonswhoengageinsecurityresearchanddevelopmentactivitythatmight\notherwiseconstituteademinimisviolationofcomputercrimelawsmightenterintoformalorinformalagree-\nments with law enforcement or state security officials to receive an assurance of non-prosecution. Risks to\nthe practitioner include potential misunderstanding with state officials, potential inability to enforce the non-\nprosecutionagreement,orcollaterallegalrisksuchastortliability[206].Riskstoastatepursuingthisstrategy\nincludethepossibilitythatsuchanagreementmightbeusedtoattributeresponsibilitytothestateunderpublic\ninternationallawfortheactionsofsuchresearchersordevelopers(seeSection3.12.1).\n102Insomesystemsofcontractlaw,however,aserviceprovidermayberequiredtogivecustomersadditional\ntimetopayorspecialnoticesbeforeservicescanbesuspended.Suspensionofservicesincircumstancesthat\nwouldcauseathreattohumanlifeandwelfare(e.g.,energyservicessuppliedinafreezingcoldclimate)are\noftenseparatelyregulatedandcanbesuspendedonlyinaccordancewithstrictrules.\n103Orin Kerr\u2019s US casebook contains a helpful collection of citations and arguments on this topic ([197] at\nch.2G).\nKANOTES |October2019 Page137 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n104Indiciaofenforceabilityaregenerallybeyondthescopeofthiswork.Itisbothdifficulttodescribegeneral-\nisablemultinationallegalnormsaboutthese,andthistopicisoflesserconcerntocybersecuritypractitioners.\n105Theterm\u2019offer\u2019mustbeconsideredwithcareanddistinguishedfromlesssignificantformsofcommunica-\ntionsuchasan\u2019invitationtotreat\u2019or\u2019invitationtotender\u2019.Whilesomeecommercesystemsmakecontractual\noffers to a wide range of potential customers, the most common design is for the vendor to publish invita-\ntionstotreat\u2013essentiallyaskingcustomerstomakeanofferwhenplacinganorder.Thisgenerallyshiftswho\nhascontroloverthetimeofcontractcreationbackintothehandsoftheonlinevendor\u2013anoften-usefulrisk\nmanagementdevice.\n106PractitionersskilledincomputersciencemightwishtodrawinspirationfromtheTwoGeneralsProblem.\n107Inthiscontext,\u2019order\u2019referstoacommunicationbyapotentialcustomertoasupplierseekingacontract.In\npractice,anorderusuallyconstituteseitheranofferoranacceptancedependingonthetermsandconditions\napplicabletotherelevantonlineplatform.InthefieldofB2Conlinecommerce,ithasbecomecommonpractice\nforanordertobedefinedasacontractualoffer\u2013capableofbeingacceptedorrejectedbytheonlinesupplier.\n108The rule embodied in Article 11 is a rather muted result of a European debate in the 1990s concerning\nwhethertoharmonisethetimeofthecontractualtriggerinonlinecommerce.Lawmakers,facingawidevariety\nofcontractruleswhicharebeyondscopeofthisknowledgearea,ultimatelychosenottoharmonisethisaspect\noflaw.TheresultingversionofArticle11islimitedtothisquestionofdefiningthetimeofreceiptofelectronic\nordersandacknowledgments.\n109Forexample,financialtransactionsystemssuchasSWIFT,airlinereservationsystemssuchasAmadeus,\nGalileo,etc.\n110Codifiedin15U.S.C.\u00a71681c(g).\n111Thisknowledgeareawillnotseektodifferentiatebetweenacontractualwarrantyandacontractualcondi-\ntion.Althoughthesecreatedifferentrightsinthehandsofapartysufferingabreach,thetopicisbeyondscope\nofthisknowledgearea.\n112UnderEnglishlaw,thisisnormallystyledastheconditionof\u2019satisfactoryquality\u2019andwasformerlyknown\nas the condition of \u2019merchantable quality.\u2019 Under the law of most US states is it styled the warranty of \u2019mer-\nchantability\u2019.Civillawsystemsadoptasimilarconcept.\n113InthelawofEnglandandmostUSstatesthisisstyled\u2019fitnessforpurpose\u2019.Onceagain,inEnglandthisis\nsaidtobeacontractualconditionandinUSstatesitisgenerallyawarranty.\n114Examplesoftypicallanguagefoundincontractsforthesupplyofsoftwareinclude,\u2019Vendorwarrantsthat\nthesoftwarewillcomplywiththeDocumentationforaperiodof60daysfollowingdelivery.\u2019\n115Thesearenotlegaltermsofart,butmerelyusedtoillustratethevariabledegreeofbreachseverity.\n116Thenamesoftheremediesaredrawnfromcommonlawpractice.Otherlegalsystemsmayemploydifferent\ntermsand\/orgrantalternativeremedies.\n117Thosewhodealregularlywithprocurementagreementsmightfindthisconceptexpressedinclausesthat\nspecify the right to terminate a contract following \u2019material breach\u2019, \u2019material breach that causes significant\nharm\u2019, \u2019a series of minor breaches that collectively create material harm\u2019, etc. The definition of the trigger is\nlimitedonlybytheimaginationofthedrafter,althoughsomelegalsystemsimposelimitsontheeffectiveness\noftheseclauses.\n118The leading case on this issue in England in the early twentieth Century concerned the duty of a person\nwhobottlesbeveragesowedtothosepersonswhoeventuallydrinkthem.Theadventofthemoderneconomy\ncreatedsupplychainsinwhichtheproducerandconsumerhadnodirectbusinessrelationship,whereproducts\nchangehandsmultipletimesbeforebeingconsumed.Applyinganearlierversionoftheruledescribedabove,\ntheEnglishcourt(actinginitscapacityasacommonlawpolicymaker)statedthatthebottledbeveragewas\nitself the proximate link between producer and consumer, and that a producer of such a drink could readily\nforeseetheharmcausedbytheadulterationofthebottle\u2019scontents.\n119Awell-known,borderingoncomic,examplecanbefoundinthe1928Palsgrafcase[340].(Seealsodiscus-\nsionofcausationinSection3.7.3.)\n120Thislastcategoryismentionedbecauseoftheoccasionallyencounteredpracticewhereapersonattempts\ntoavoidliabilitybypurposefullyavoidingknowledgeofrisk.Thisstrategyisunlikelytodefeataclaimofneg-\nKANOTES |October2019 Page138 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nligenceandmayevenexacerbateliabilityinjurisdictionsthatawardpunitivedamages.(Seethediscussionin\nSection3.7.4.)\n121Inthecited2018Dittmancase,thePennsylvaniaSupremeCourtannouncedthatthecommonlawofPenn-\nsylvania imposes a duty of care on employers to safeguard the electronic storage of employee data. A mid-\nranking appellate court in the State of Illinois reached the opposite conclusion in 2010 when interpreting the\ncommonlawofIllinois[341].IntheUS,negligencelawmayplayanincreasingroleindefiningresponsibilities\ntosafeguardpersonaldata.\n122SeediscussioninSection3.10.3.\n123JudgeHandsurprisedlegalpractitionersofthedaybyexpressingthisconceptusingamathematicalfor-\nmula, stating that if B < PL then the failure to adopt a given precaution constitutes negligence, where B is\ntheburden(cost)ofthemethod,P istheprobabilityoflossintheabsenceofthemethod,andListheamount\noflosstobeavoided.Thesetwocasesandoneformulahavebeenthesubjectofextensivecomment,debate\nandanalysisbygenerationsofUSlawyersandlawstudentsanditremainsausefulframeworktodiscussrisk\nandresponsibility[218,220].Practitionersmaywishtoconsiderhowchangesinthecybersecurityenvironment\novertime(includingthefallingcostsofsomedefensivetechnologies(B),aswellaschangingprobabilitiesof\nharmtothirdparties(P)andtheamountoflossestheymightsuffer(L)asaresultofchangesinthesurround-\ningenvironmentsuchasmigrationtodifferentinfrastructures,ever-largeraggregationsof\u2019bigdata\u2019,etc.)may\ninfluenceliability.Thespeedatwhichthesevariableschangemayhelptoplanthefrequencyforreassessing\ndecisionstorejectproposedprecautions.Yesterday\u2019s\u2019impractical\u2019precautionmaybecometomorrow\u2019s\u2019must\nhave\u2019solution.\n124AsimilarobservationinthecontextofdataprotectionregulationcanbefoundinSection3.4.1.\n125In the referenced case, the negligence per se claim was based on an allegation that Target had failed to\ncomplywithaMinnesotalawconcerningtheproperstorageofcreditcarddetails[215].(Seealsothediscussion\nofthiscaseatSection3.7.4)\n126TheMorriswormmightbeanearlyexampleofthistypeofincident[330].\n127This section is addressed primarily to \u2019design defects\u2019 and does not discuss \u2019manufacturing defects\u2019, in\nwhich individual products from a production run deviate from their specification due to sporadic intermittent\nerrorsinthemanufacturingprocess.\n128Evenifaproducerofsoftwareisnotamenabletoaclaimfoundedonatheoryofstrictliability,itcouldstill\nfaceaclaimfoundedonatheoryofnegligence.Avictimtakinglegalactionagainstasoftwareproducerbased\nonatheoryofnegligencewouldneedtoproveunreasonableconductbythesoftwareproducer.\n129Self-driving automobiles in particular have prompted a significant amount of discussion as lawyers and\nlaw-makersconsiderbothcurrentliabilityrules,andpotentialamendmentstotheserulestoenablethishighly-\nanticipatedtechnology[342,343,344].\n130Such attenuated chains of causation are a familiar meme in science fiction stories about time travel. A\nnon-fictionbutentertainingexplorationofhighlyattenuatedchainsofcausationfromscientifichistoryisfound\nintheworkofjournalistJamesBurkeinvariousiterationsofhisBBCtelevisionprogramme,\u2019Connections\u2019.\n131SeealsodiscussionofforeseeabilityinSection3.7.1.1.\n132Such\u2019negligentmis-statement\u2019casesarewatchedcloselybyprofessionalsandotherserviceprovidersin\nthebusinessofsupplyingcriticalinformation-relatedservicessuchaspublicaccountants.Thistypeofnegli-\ngence theory is also of special interest to providers of trust services, as it potentially defines their liability to\nthirdpartieswhorelyupontheaccuracyofissuedcertificates.(SeeSection3.10.3)\n133InthecitedDittmancasetheSupremeCourtofPennsylvania,actinginitsroleasinterpreterofthecommon\nlawofPennsylvania,heldinNovember2018thatemployersoweadutyofcaretotheiremployeestomaintain\nreasonablecybersecuritytosafeguardemployeedatafromloss[216].InanysimilarincidentintheEU,atort\nactioncouldbefashionedeasilyunderatheoryofbreachofdataprotectionrights.\n134AnobviousexampleisthevariouslegalactionsbroughtbyfinancialinstitutionsagainstTargetfollowing\nitswell-known2013lossofcarddataincident.Plaintiffbanksinatleastoneoftheactionsbasedtheirclaimon\nvariouslegaltheoriesincludingnegligenceandnegligenceperse[215].Settlementsofthislawsuitandothers\nbroughtbyfinancialinstitutionsagainstTargetexceededUS$100million[345,346].\nKANOTES |October2019 Page139 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n135Compareeasilyquantifiablelossesresultingfrombreachofprivacysuchaslossofrevenuefromanexclu-\nsiveagreementtopublishthevictim\u2019sweddingphotographsinaspecificnewspaper,lossofsalaryasaresult\nofvictim\u2019sdismissalfromemploymentetc.,withmoredifficult-to-quantifyharmsuchasthevictim\u2019sembarrass-\nmentorshame.\n136ThisprovisioniscodifiedinIllinoislawat740ILCS14\/20.\n137Theinternalauditorwasarrestedandchargedwithcriminalviolationofdataprotectionlaw,computercrime,\nandfraud.Hewasconvictedandsentencedtoeightyearsimprisonment.\n138The Supreme Court of the United Kingdom granted leave to appeal on 15 April 2019. Hearing has been\nscheduledforlate2019,whichsuggeststhepotentialforadecisionsometimein2020.\n139Comparepotentialapplicationofthestate-of-the-artdefenceinthecontextofmaterialssciencewhere(for\nargument\u2019ssake)atthetimeofproductiontherewasnoknownscientifictestforthelater-discovereddefect\nin the material, with the context of a software-induced product defect due to a previously unknown zero day\nexploit. The former might be said to have been undiscoverable, while the latter was merely undiscovered. It\nis debatable when a given exploit could be truly classified as having been \u2019undiscoverable\u2019. This topic merits\nfurtherstudy[347].\n140Ithasbeensuggestedanecdotallythatsomeregulationofsafety-criticalsystemscanleadtoweaknesses\nin that system\u2019s cyber security by limiting or foreclosing the possibility of adopting state-of-the-art security\nmeasures.Aspecificinstancerelatedtotheauthorconcernsaregulatoryrequirementthatcertainsafety-critical\ncontrolsystemsmustbeexhaustivelytestedbyexaminingeverypossiblestateofthecontroldevicepriortouse.\nSomedefensivecybersecuritymethods,especiallythosethatadoptartificialintelligenceormachinelearning,\narebytheirnatureimpossibletotesttoexhaustioninthisfashion.Thistopicmeritsfurtherstudy.\n141Afavouriteexamplebelovedoflawprofessorsinvolvesthehypotheticalcaseofthebadlyloadedrailcar.\nThe car may have been improperly overloaded in State A, but only produces injury after the train begins to\ndescendasteepgrademanyhourslaterinStateB.\n142ThisisattributedtoUSSupremeCourtJusticeJosephStory,whoapparentlyusedthephrasemorethan\nonce [348]. A darker shadow was cast over the practice of intellectual property law by Lord Esher, MR, when\nin1892heobserved,\u2019amanhadbetterhavehispatentinfringed,orhaveanythinghappentohiminthisworld,\nshortoflosingallhisfamilybyinfluenza,thanhaveadisputeaboutapatent.Hispatentisswallowedup,and\nheisruined.Whosefaultisit?Itisreallynotthefaultofthelaw:itisthefaultofthemodeofconductingthe\nlawinapatentcase\u2019[349].Littlehaschangedintheinterveningcentury[350].\n143Moral rights arising under an author\u2019s rights (droit d\u2019auteur) infrequently present challenges for security\npractitionersandisbeyondthescopeofthiswork.\n144In United States law, copyright comes into existence automatically but must be registered prior to com-\nmencementofanyUSinfringementproceedings.\n145LimitationstoUKcopyrightarecodifiedinChapter3oftheCopyrightsDesignsandPatentsAct1988,ss.28,\netseq.TheUSfairuseexceptionandotherlimitationsarecodifiedin17U.S.C.\u00a7107,etseq.\n146Theimplementationofthisprotectionhasbeenbothinconsistentandcontroversial[231,351].Itiscodified\ninUScopyrightlawat17U.S.C.\u00a71201,etseq.,andinUKcopyrightlawinPartVIIoftheCopyrightsDesignsand\nPatentsAct1988atss.296,etseq.\n147The European Union is in the process of adopting the Unitary Patent, a single patent right that applies\nthroughoutmuch,butnotyetall,oftheterritoryoftheEU.Thestatusanduseofthisnewpatentrightcontinues\ntoevolve.\n148Inventorsshouldnotconfusethisconceptfrompatentlawwithvariousscientificoracademicdefinitions\nofsignificantortrivial.Ascientificallytrivialstepcanstillbe\u2019inventive\u2019inpatentlaw[352].\n149Thephrase\u2019assuch\u2019shouldserveasawarningthatloopholesareabouttoappear,asifbymagic.Theyare.\n150Whilecopiesofpatentsandpublishedapplicationsfrommanystatesarenoweasytofindonline,correspon-\ndencewiththepatentexaminersandtheprosecutionhistoryisoftenmoredifficulttoobtainandmayrequire\nassistancefromalegalpractitioner.Onceobtained,however,thiscanbeveryenlighteningtoanypersonwho\nwishestochallengepost-factothevalidityofagrantedpatent.\nKANOTES |October2019 Page140 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n151Averylimitedsubsetofpatentapplicationsforinventionsaresubjecttoastatesecrecyclassificationand\nareonlypublishedinaregisterofsecretinventions.\n152Anyone innovating in the ICT field faces a series of related challenges. The pace of ICT innovation is so\nfast, the intermingling of parallel innovative ideas so commonplace, the number of patent applications filed\nso large, and the prior art cataloguing ICT innovation so untidy, that it is difficult to produce any innovative\nICT product that does not infringe some extant third-party patent, or published or unpublished application. A\ntypical strategy adopted by large ICT developers is to file large numbers of patent applications on their own\ninventions,movetomarketasquicklyaspossiblewithnewproducts,andthenwaittoreceivesuggestionsof\npatent infringement from third parties in the hope of eventually defending against some of these threats or\nnegotiatinganacceptablecross-licensearrangement.\n153IntheUSpatentsystem,awarenessbytheinfringingpartyofpatentrightstriggersaspecial\u2019trebledam-\nages\u2019rule:monetarydamagesawardedtotherightsholderaremultipliedbythreewitheffectfromthedateof\ntheinfringer\u2019sawareness.ThisiswhyrightsholderstypicallybeginaUSpatentenforcementprocessbysending\ncopiesoftheirpatentstogetherwitha\u2019wewishtomakeyouaware\u2019coverletterthatdoesnotexpresslyaccuse\ntherecipientofinfringement.This,combinedwiththefactorssetoutinNote152,iswhymanyICTinnovators\nassiduouslyavoidresearchingthird-partypatentsandpatentapplications.\n154Somestatesdefine\u2019unregistered\u2019trademarkrightswhicharesimilarincharactertotheEnglishlawtortof\npassingoff.\n155ACommunityTrademarkisasingletrademarkthatextendsthroughouttheterritoryoftheEU.\n156Inmoderntrademarkpractice,therelevantsigncanconsistofsoundsorsmells.Asoundtrademarklikely\ntobefamiliartocybersecuritypractitionersisthe\u2019IntelInside\u2019musicalchime(US75332744,UK00002403603).\n157TrademarkUK00000000001hasbeenregisteredcontinuouslyintheUKfrom1876todate.\n158Courtsaredividedonthequestionofwhethermeta-tags,notnormallyvisibletoendusers,canconstitute\nan infringement of registered trademarks. Even where meta-tags cannot be used to prove infringement, they\ncanserveasusefulevidenceforotherpurposessuchasdemonstratingtheknowledgeorawarenessofthetag\nauthorinrelatedtortactionssuchaspassingoff.\n159By contrast, in actions based on theories of passing off or unregistered trademark rights the complain-\ning party is usually required to prove that the accused party has knowledge of the unregistered mark and is\npurposefullytakingadvantageofthereputationconnectedtothatmark.\n160AnexamplethatshouldbefamiliartopractitionersistheWi-Filogo(US75799630,UK00002209133)regis-\nteredbyWi-FiAlliance.\n161Acommonly-citedexampleofalong-standingtradesecretistheformulaforCoca-Cola,whichremainsthe\nsubjectofmuchspeculation.\n16217U.S.C.\u00a71204(a).\n163CopyrightsDesignsandPatentsAct1988,s.296ZB.\n164TheEuropeanUnionDirectivedoesnotmandatethecriminalisationoftradesecretmisappropriation[238]\n165NotethattheEcommerceDirectivedoesnotapplytodataprotectionlaw[210]atArt5(b).\n166Forexample,17U.S.C.\u00a7512(shieldingfromcopyrightinfringement),47U.S.C.\u00a7230(shieldingfromliability\nthosewhoblockorscreenoffensivematerial,althoughnotapplicableasashieldagainstliabilityarisingunder\nobscenity,intellectualpropertyorprivacylaws.)Section230inparticularhascomeunderincreasingscrutiny\nbyUScourtsasmorelegalactionshavebeentakenagainstsocialmediaserviceproviders.\n167Althoughtheselegaldefinitionsarenotspecificallylinkedtotechnicaldefinitions,thisconceptisapprox-\nimately equivalent to providing services that consist of nothing more than carrying and routing traffic at the\nphysical,datalinkand\/ornetworklayersoftheTCP\/IPprotocolsuite.Agooddefinitionoftheconceptisfound\ninArticle12oftheEcommerceDirective[210].\n168SeeArticle14oftheEcommerceDirective[210].\n169Thebest-knownprocedurecodifiedinlawisprobablyfoundinUScopyrightlawat17U.S.C.\u00a7512(c).\nKANOTES |October2019 Page141 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n170The\u2019AllowStatesandVictimstoFightOnlineSexTraffickingActof2017\u2019istheresultoftheFOSTA-SESTA\nbillsproposedinCongress.Thenarrowingoftheliabilityshieldiscodifiedin47U.S.C.\u00a7230(e)(5).Alegalaction\nchallengingthislawasaviolationofUSfreedomofspeechprincipleswaslaunchedshortlyafteritspassage\nandremainspendingatthetimeofwriting[353,354].\n171Theabilitytoadmit(topresent)evidencetoacourtisathresholdquestiongovernedbytherulesofevidence\nusedbythatcourt.Admissibilityaskssimplywhethersuchevidencewillbeconsideredatall.Ifadmittedinto\nevidence,afactfindermustthenassesstherelativevalueor\u2019weight\u2019ofthatevidence.Masonsummarisesthe\nEnglishlawpositiononelectronicdocumentsin[355].\n172The framework contract, in turn, would refer to a series of electronic trading rules (often called \u2019the rule\nbook\u2019)thatspecifiedhowelectroniccommunicationsmappedontolegalobligations.Such\u2019EDI\u2019systemswere\ndevelopedatatimewhentelecommunicationsbandwidthconstraintsmeantthattradinginstructionsweretypi-\ncallytransmittedinextremelysmallpayloadsusingtext-based(e.g.,ascii)highlystructuredmessages.Therule\nbookwasusedtotranslatebetweenstructuredmessagesandlegallysignificantcommunication,andserved\nasthespecificationforsoftwareusedtoaccessthesystem.\n173Byunderwritingtheriskofmanysuchtransactions,thepositiveimpactofthepaymentcardindustrytothe\ngrowthandsuccessoftheseplatformsshouldnotbeunderestimated.\n174The \u2019three-corner\u2019 model for this purpose comprises only three persons: the certificate issuer who both\nidentifiesthesignatoryandissuesthecertificate,thesignatorywhoseidentifyisboundtothecertificateand\nthethirdpartywhoreliesonthecertificatetoidentifythesignatory.Aseachoftheserolesbecomesdivided\namongmorepersons,analysingtherelationshipsandresponsibilitiesbecomesmorecomplex.\n175See,forexample,X.509.\n176Thesedoubtsarisefromavarietyoflegaldoctrines.Forexample,theremaybefailuretoformacontract\nwitharelyingpartybecauseoffailuretocommunicatethetermsofcontract.Courtsmightrefusetoenforce\nlimitationsofliabilitypresentedincertificatesorelsewhereduetopublicpolicyconcernssuchasthereasonabil-\nityofthelimitation.Notethattheseconcernsaremoreeasilyaddressedintheso-called\u2019two-corner\u2019issuance\nmodel, where a signatory self-certifies its identity and serves as its own certificate issuer. In the two-corner\nmodelthereisno\u2019thirdparty\u2019andthesignatorymayhaveadirectrelationshipwiththerelyingpartymoreeasily\nenablingtheimpositionofliabilitylimits.\n177StephenMason\u2019sworkinparticularincludesanextensiveinternationalcatalogueoftheselaws[260].\n178Asimilaranalysiscouldapplyincircumstanceswhereenterprisesordertheirmembersofstafftoadoptand\ninstalltrustcertificatesissuedbytheenterprisespecificallytosupportSSL\/TLSinspection.Suchenterprises\nshouldconsiderthevarioustypesofliabilitythatmightariseasaresult.\n179Statesmayalsoapplyembargoesonmostoralltradewithspecificstatesaspartofamoregeneralpro-\ngrammeofsanctions.\n180TheprecisestatusofsoftwareasspeechforpurposesofUSfreespeechlawremainssomewhatmurky.\nWhileUSFederalcourtsseemwillingtoclassifysourcecodeasprotectableexpression,theyalsoappeartotake\nitsinherentfunctionalityintoaccountwhenassessingfreespeechrights.Thisinturnsuggeststhatgovernment\ninterventiontorestrictactsofdistributingsourcecodearemoreeasilyjustifiedthanrestrictionsonclassicnon-\nfunctionalspeech[274,356,357].\n181Theterm\u2019pubicinternationallaw\u2019isoftenreferredtomoresimplyas\u2019internationallaw\u2019.Bycontrast,thefield\nof\u2019privateinternationallaw\u2019describestheprocessofdeterminingwhichdomesticstatelaw(s)willbeapplied\ntovariousaspectsofprivatelawdisputessuchastortandcontractactions.Aspectsofprivateinternational\nlaw, or conflicts of law, are considered in this knowledge areas in the context of individual substantive legal\nsubjects.\n182In the referenced Halford case the complaining party successfully argued that the United Kingdom had\nfailed to provide her with privacy rights required by the European Convention on Human Rights as regards\ninterception of communications by state authorities [155]. This case precipitated the adoption by the UK of\ncomprehensivelegislationregulatingtheinterceptionofcommunications.\n183Anotableexceptioninvolvesprosecutionaccordingtotheprinciplesofinternationalcriminallawsuchas\ncrimesagainsthumanity.\nKANOTES |October2019 Page142 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n184The process of creating the Tallinn Manual was not without controversy, and even the conclusions ex-\npressedinthe\u2019Rules\u2019(whichrepresentunanimousconsensusamongthelargeexpertgroup)arenotuniversally\nagreed [104, 358]. The Tallinn Manual itself helpfully provides extensive commentary that highlights circum-\nstanceswheresomestatesdisagreewiththeunanimousviewsoftheexpertgroup,andotherissueswherethe\nexpertgroupitselfdidnotachieveconsensus.ItisthereforenotsurprisingthattheTallinnManual2.0doesnot\nrepresenttheofficialpolicyoftheproject\u2019ssponsors(NATOanditsmemberstates)orthevariousadditionalor-\nganisationswhoseexpertsparticipatedinitscreationandrevision.Nonetheless,anecdotalevidencesuggests\nthatexpertswhoadviseallofthesepersonskeepacopyoftheTallinnManualcloseathandandconsultthe\nworkroutinely.\n185Theterm\u2019attribution\u2019isoftenusedinmorethanonesense.Practitionersshouldbecarefultodistinguish\nthelegaldoctrinesusedtoanalyseattributionfromtheprocessofcollectingandpresentingevidenceintended\ntoproveattribution.Thissectiondiscussesonlytheformer.Thelatterismoreproperlyaddressedinthefield\nofforensics.\n186The principle of territoriality and the exercise of state power is explored in the context of jurisdiction in\nSection3.2\n187Espionage during armed conflict is treated separately under the law of armed conflict. See, for example,\n([104]atR.89.)\n188See, for example, the discussion in Tallinn 2.0 of \u2019herding\u2019 target state communications to less secure\ninfrastructurebyinterferingwithmoresecureinfrastructure([104]atR.32,cmt.12).\n189Thequalifier\u2019unrelated\u2019stateismeanttodistinguishcircumstanceswheremorethanonesovereignstate\nmaintainsconcurrentjurisdictionoverasingleterritory,asfoundinfederalstates.\n190Theterm\u2019lawofwar\u2019significantlypredatestheterm\u2019lawofarmedconflict\u2019,butisnowusedlessfrequently\nespeciallyasarmedconflictoftentakesplaceintheabsenceofanyformaldeclarationofwar.\u2019International\nhumanitarianlaw\u2019(IHL)isamorerecentterm[282]atp.8,fn.5.Theadoptionanduseof\u2019IHL\u2019todescribethis\nfieldisnotwithoutcontroversy[359].\n191Although this should be obvious, the concept of \u2019cyber attack\u2019 used to discuss obligations under interna-\ntionallawissignificantlymorenarrowthantheterm\u2019attack\u2019whichisbroadlydefinedformostotherpurposes\nincybersecurity.Cybersecuritypractitionerstendtousetheterm\u2019attack\u2019todescribeanyefforttoobtainunau-\nthorised access to a system, resources, or information, or any malicious activity intended to collect, disrupt,\ndeny,degrade,ordestroyinformationsystemresources[360].\n192Inthecaseofoffensivecyberoperationsundertakenatthedirectionofastate,compliancewith\u2019allapplica-\nblelaws\u2019mayindeedbeimpossibleastheactionstakenatthedirectionofasponsoringstatemayconstitute\ncrimesunderthedomesticlawofthetargetstate.Similarly,insomecircumstancesapractitionermightcom-\nplainthatcompliancewithalegalobligationis,itself,ethicallychallenging[361].Thissectiondoesnotattempt\ntoresolvetheseissues.\n193Practitionersshouldbemindfulthatiftheyareemployedorengagedbyaregulatedprofessionalfirm(e.g.,\nalegal,medical,orpublicaccountancyfirm)thepractitionermaybeobligedbyapplicablelawtoconformwith\ntherulesoftherelevantregulatedprofession\u2013especiallyonmatterssuchclientconfidentialityorclient\u2019slegal\nprivilegetoprohibitthedisclosureofsensitiveinformation.Thesepractitionersmustbecomefamiliarwiththe\nobligationsimposedbytheregulationsthatapplytothatfirm.\n194This discussion does not address circumstances where applicable law mandates disclosure of this evi-\ndencetoidentifiedthirdparties,suchasthedatabreachdisclosurerequirementsimposedbyGDPR.Insuch\ncases,apractitionershouldbecarefultotakeappropriateadviceconcerningtheirindividuallegalreportingobli-\ngationsasdistinctfromobligationsimposedupontheirclient,andtourgetheirclienttoinvestigatetheclient\u2019s\nownpotentiallegalreportingobligations.\n195Manyearlyexamplesincludemandatesto \u2019comply\u2019withthelaw,whileothersdemandthatapractitioner\nshould \u2019be aware\u2019 of the law. Some include the concept of avoiding harm to others without discussing the\nsubtletiesofthisproscription.Somespeakofageneralaffirmativeobligationtoprotect\u2019society\u2019,withoutiden-\ntifyingthenatureoftheobligationinpractice,identifyingtherelevantsocietyincaseswheretwosocietiesare\nin conflict, or discussing the possible conflict between protecting society generally and a client individually.\nSomespeakofobligationstoprotect\u2019infrastructure\u2019,withoutclarifyingwhoseinfrastructureistobeprotected:\npublic,private,first-party,third-party,domestic,orforeign.Manyofthesecodesfailentirelytodiscussspecific\nobligationsowedtoaclientandhowtomanagepotentialconflicts.\nKANOTES |October2019 Page143 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n196CRESThassubsequentlyaddedadditionalservicestoitscertificationprocess.\n197SeealsoOrinKerr\u2019sextensivediscussionsof\u2019authorization\u2019inthecontextofUScomputercrimestatutes\n[199,200].\n198Somerisksofdisclosuremightincludetheimpracticabilityofpatchingorfixingthevulnerability.Theben-\nefitsofsecrecymightincludeastatesecurityagency\u2019sabilitytoexploitthegivenvulnerability.\n199Thisisaspecialthreatforfindersengagedinacademicsecurityresearchwhofacenormalacademicpres-\nsuretopublishresearchresults[338].\n200Whiledisclosingauniquevulnerabilityinasingleonlineservicetoasingleeffectedfirmissimple,disclosing\navulnerabilityinacomplexsupplychainpresentsspecialproblems.Disclosingfirsttodownstreamproducers\noffinishedgoodsorservicesfocusesthedisclosureonthosewhoappeartohavethemostatriskfromsecu-\nrityfailure,butwhomaynothavethetoolsnecessarytomitigatethethreat.Thisdownstreamdisclosurealso\ncreatesariskofalienatingtheupstreamdeveloperofthecomponent\u2013especiallyifthevulnerabilityismisde-\nscribed.Inthefieldofacademicsecurityresearchinparticular,researchersoftendependongoodcontinuing\nrelationshipswiththedevelopercommunity.Disclosingfirsttotheupstreamdevelopercreatesachallengeif\nthatdeveloperisdilatoryinremediatingthevulnerability.Findersinthissituationmightconsiderthepotential\nforamulti-stepprivatedisclosureprocessstarting(perhaps)withtheupstreampartymostlikelytobeableto\nunderstandandremediatethethreat.Havingdisclosedandthenprovidedanopportunityforthatpartytoanal-\nyseorrebuttheclaimofvulnerability,thefindermightbeginadditionalprivatedisclosuresonestepatatime\ndownthesupplychaintothosewhomighttakeactiontomitigatethethreat.Second-stagepublicdisclosure\nwouldthenbecomealaststepofmany.\n201Commentingonadecisionbyacademicstopublishvulnerabilitydetailsmorethanninemonthsafterprivate\ndisclosuretoanupstreamsecuritycomponentvendor,butinthefaceofstrongobjectionsbyadownstream\npurchaserwhoincorporatedthecompromisedsecurityproductintotheirmass-producedautomobiles,anEn-\nglishHighCourtJudgenoted,\u2019Ithinkthedefendants\u2019mantraof\"responsibledisclosure\"isnosuchthing.Itisa\nself-justificationbydefendantsfortheconducttheyhavealreadydecidedtoundertakeanditisnottheactionof\nresponsibleacademics.\u2019MegamosCrypto(VolkswagenvGarcia),Para42[249,250].Notethattheacademics\nintheMegamosCryptocaseclaimedthattheywereadheringtothen-currentresponsibledisclosureprocedures\npublishedbytheNationalCyberSecurityCentreoftheNetherlands,thestateinwhichtheyconductedthebulk\noftheirresearch.\n202Whilethemerepresenceofavulnerabilityinaproductorservicedoesnotnecessarilyconstitutevendor\nnegligence, vendors who receive a vulnerability report should consider that a failure to act in a reasonable\nfashionfollowingreceiptofsuchareportcouldconstituteanindependentactofnegligence.\n203Somehaveattemptedtoaddressthisissuebyadoptinglegislationthatwouldregulatethedisclosurepro-\ncess.One(asyet)unsuccessfulattemptinLatviaishelpfullydescribedin[339].\n204AnexamplelikelytobefamiliartopractitionerswasthefateoftheArthurAndersenaccountingfirminthe\nearly21stcentury.ThefirmwasanadvisertotheEnronCorporation,andwasaccusedbytheUSgovernment\nofimproperlydestroyingevidencerelatedtotheEnroninvestigation.Afederaljuryreturnedaguiltyverdictin\nthe firm\u2019s 2002 criminal trial [362]. Upon conviction, the firm was debarred from conducting public company\nauditworkeffectivelyendingitsabilitytooperateasagoingconcern.Thecriminalconvictionultimatelywas\noverturnedbytheUSSupremeCourtin2005[363].Thiscametoolateforthefirm,whichhadceasedongoing\noperations.\nKANOTES |October2019 Page144 Chapter 4\nHuman Factors\nM. Angela Sasse Ruhr Universit\u00e4t Bochum &\nUniversity College London\nAwais Rashid University of Bristol\n145 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n4.1 INTRODUCTION: UNDERSTANDING HUMAN\nBEHAVIOUR IN SECURITY\nIntheirfoundational1975paper,TheProtectionofInformationinComputerSystems,Jerome\nSaltzerandMichaelSchroederestablishedtenprinciplesfordesigningsecurity[8].Threeof\nthoseprinciplesarerootedintheknowledgeofbehaviouralsciences:\n\u2022 Psychology: the security mechanism must be \u2018psychologically acceptable\u2019 to the hu-\nmanswhohavetoapplyit;\n\u2022 Human Factors and Economics: each individual user, and the organisation as a whole,\nshouldhavetodealwithasfewdistinctsecuritymechanismsaspossible;\n\u2022 Crime Science and Economics: the effort required to beat a security measure should\nexceedtheresourcesandpotentialrewardsfortheattacker.\nNearly 100 years before Schroeder & Saltzer, the founding father of cryptography, Auguste\nKerckhoffs formulated six principles for operating a secure communication system, with a\nkey focus on human factors: Three of those were \u201cit must be easy to use and must neither\nrequirestressofmindnortheknowledgeofalongseriesofrules\u201d.\nBoth of these foundational texts recognised that security measures cannot be effective if\nhumans are neither willing nor able to use them. A good example is email encryption. We\nhavehadtoolsforencryptingemailforover20years.Yettoday,lessthan0.1%ofemailssent\nareend-to-endencrypted.ThisoutcomewaspredictablesinceWhitten&Tygarfoundin1999\nthat even well-motivated and trained people could not use email encryption correctly [364].\nThis situation has not yet changed substantially\u2014although recent research offers insights\nintothemeanstodoso[365,366,367].\nOverthepast20years,therehasbeenagrowingbodyofresearchintotheunderlyingcauses\nofsecurityfailuresandtheroleofhumanfactors.Theinsightthathasemergedisthatsecu-\nritymeasuresarenotadoptedbecausehumansaretreatedascomponentswhosebehaviour\ncanbespecifiedthroughsecuritypolicies,andcontrolledthroughsecuritymechanismsand\nsanctions. But the fault does not lie primarily with the users, as suggested by the oft-used\nphrase that humans are the \u2018weakest link\u2019, but in ignoring the requirements that Kerckhoffs\nandSchroeder&Saltzersoclearlyidentified:thatsecurityneedstobeusableandacceptable\ntobeeffective.Anexampleofthisisthecaseofpasswordpolicies.Adams&Sasseshowed\nthatpasswordpoliciesandmechanismsagreeduponbysecurityexpertsdidnotworkatall\ninpracticeand,consequently,wereroutinelybypassedbyemployees[368].Naiakshinaetal.\nshowed that not only end-users have trouble with passwords but developers do as well. De-\nvelopersneedtobeexplicitlypromptedtoincludesecurityand,evenwhenthisisdone,they\noftenincludeoutdatedandfaultysecuritymechanisms[369,370].\nTheaimofthisCyBOKKnowledgeAreaistoprovideafoundationalunderstandingoftherole\nof human factors in cyber security. One key aspect of this is how to design security that is\nusable and acceptable to a range of human actors, for instance, end-users, administrators\nand developers. This knowledge area also introduces a broader organisational and societal\nperspectiveonsecuritythathasemergedoverthepastdecade:theimportanceoftrustand\ncollaborationforeffectivecybersecurity,whichcanonlybeachievedbyengagingstakehold-\nersandnegotiatingsecuritysolutionsthatmeettheirneeds[371].Thisrequiresasetofskills\nthat have traditionally not been part of the training provided for security experts and practi-\ntioners.Thisknowledgeareaaimstocapturetheknowledgetochangethat.\nKAHumanFactors |October2019 Page146 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nFigure 4.1: Human behaviour in context, showing internal factors and contextual ones that\ninfluencebehaviour.\nThis knowledge area is organised (Figure 4.1) in a starting on the inside, working outwards\nmanner:startingwiththeindividualandinternalfactorsthatdrivehumanbehaviour(capabil-\nities and limitations, mental models), moving onto aspects of the broader context in which\ninteractionwithsecuritytakesplace.Wewillthenconsidertheotherimmediatefactorsthat\nhave an impact: the behaviour of others around us, and especially how they handle security\nrisks, users\u2019 emotional stances towards the organisation and how security behaviour can\nbe successfully managed through design and a range of group and organisational factors.\nNote that human factors and usability in a security context can be distinguished from other\ncontextsbythepresenceofadversariesorrisk.AsshowninFigure4.1,theadversarymayac-\ntivelyworktoalterusers\u2019perceptionsofthesystem\u2019scapabilitiesandboundariesaswellas\nexploitingthespecificsofsocialandorganisationalcontexts(e.g.,securitypolicies,working\npractices,decision-makinghierarchies)toimpactsecurity.Studyingusablesecuritythrough\nan active attacker model [372, 373] and raising users\u2019 awareness about security issues by\nincorporating such models, e.g. anti-phishing simulations [374, 375], is an on-going area of\nstudy.Thesemechanismsoffersomeprotection,butrequireusertimeandeffort.Therefore,\nKAHumanFactors |October2019 Page147 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nas we discuss later, the total security workload needs to be monitored so that productivity\nis not reduced and workarounds induced. Furthermore, they have implications in terms of\nusers\u2019 trust in the organisation and completion of the primary (non-security) task at hand\n\u2013 the design of any such interventions or campaigns needs to consider and address these\nrisks[375].\nNotethatwedonotdiscussthespecificsofadversarialbehaviours,asthesearethesubject\noftheMalware&AttackTechnologyKnowledgeArea(Chapter7).However,wewilltouchon\nanyrelevantelementswheretheyrelatetousabilityandhumanfactors,forexample,security\nawareness, training and anti-phishing. Usability considerations are equally important with\nregardstoprivacycontrolsandtechnologies.ThisdiscussionformulatespartofthePrivacy\n&OnlineRightsKnowledgeArea(Chapter5)andhenceisnotconsideredhereanyfurther.\n4.2 USABLE SECURITY \u2013 THE BASICS\n[376,377]\nWhenusersdonotbehaveasspecifiedbysecuritypolicies,mostsecuritypractitionersthink\nthat the users are at fault: that they \u2018just don\u2019t understand the risks\u2019 or \u2018are just too lazy\u2019. But\nresearchhasshownthatnon-compliance,whichwenowrefertoas\u2018rule-bending\u2019,iscaused\nby people facing a stark choice between doing what is right by security, and reducing their\nproductivity. Most choose productivity over security, because that is what the organisation\nalsodoes.\nA typical response to such rule-bending is security awareness and education, that is, \u2018fitting\nthe human to the task\u2019. But Human Factors research established decades ago that, when\nwe take all of the costs and the resulting performance into account, \u2018fitting the task to the\nhuman\u2019 ismoreefficient.Thereisaroleforsecurityawarenessandtraining(Section4.4)but\nit should be thought of as one of the options but not the first resort. It cannot help humans\nto cope with security tasks that are impossible, error-inducing, or drain too many individual\nandorganisationalresources[378].AstheUK\u2019sNationalCyberSecurityCentre(NCSC)policy\nputsit:\n\u2018The way to make security that works is to make security that works for peo-\nple1\u2019\nInotherwords,securityhastobeusable.TheISOdefinesusability(ISO9241\u201311:2018)as\n\u2018Theeffectiveness,efficiencyandsatisfactionwithwhichspecifiedusersachieve\nspecifiedgoalsinparticularenvironments.\u2019\nAndthecriteriabywhichusabilityisassessedare:\n1. effectiveness: the accuracy and completeness with which specified users can achieve\nspecifiedgoalsinparticularenvironments;\n2. efficiency:theresourcesexpendedinrelationtotheaccuracyandcompletenessofthe\ngoalsachieved;\n3. satisfaction: the comfort and acceptability of the work system to its users and other\npeopleaffectedbyitsuse.\n1https:\/\/www.ncsc.gov.uk\/information\/people-strongest-link\nKAHumanFactors |October2019 Page148 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nWecanimmediatelyobservethatthesecriteriaalignwiththeprinciplesarticulatedbyKerck-\nhoffsandSaltzer&Schroeder\u2019s.Buthowtodeliverthisinpractice?\n4.2.1 Fitting the task to the human\nFrom a practical point of view, making security tasks fit or usable means establishing a fit\nwithfourkeyelements[377]:\n1. thecapabilitiesandlimitationsofthetargetusers;\n2. thegoalsthoseusershave,andthetaskstheycarryouttoachievethem;\n3. thephysicalandsocialcontextofuse;and\n4. thecapabilitiesandlimitationsofthedeviceonwhichthesecuritymechanismisused.\nWe now examine each of these in turn, and how they apply to designing a usable security\nmechanism.\n4.2.1.1 Generalhumancapabilitiesandlimitations\nThere are general capabilities and limitations \u2013 physical and mental \u2013 that apply to most\nhumans. Giving humans a task that exceeds their capabilities means we set them up to fail.\nWhen the demand they face is borderline, most humans make an effort to meet it. But this\nwillcomeatasignificantcost,whichmayultimatelyprovetobeunsustainable.\nWithgeneralcomputingdevicestoday,thephysicalcapabilitythatcanbeexceededbysecu-\nrity tasks is most likely the ability to detect signals: many security systems provide status\nmessages, reminders or warnings. Humans can only focus their attention primarily on one\ntask at any one time. That focus will be on their main activities, and many security mecha-\nnismsdemandmoretimeandattentionthanuserscanafford[376].Thismeansthatchanges\nin passive security indicators are often not noticed, in particular if they are on the edges of\nthe screen. Asking users to check these indicators is setting them up to fail\u2014even if they\nconsciouslytrytodoit,theirfocuswillbedrawnbacktothemaintask.Ifsecurityindicators\nneed to be attended to, they should to be put in front of the person, and require a response.\nThiswillwork,butonlyforinfrequentandreliableindicators(seeAlarmfatigue).\nKAHumanFactors |October2019 Page149 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nAlarm fatigue Thebrainstopspayingattentiontosignalsithasclassifiedasirrelevant.They\nare filtered out before they reach the conscious processing level (Section 4.2.1.2). It means hu-\nmansdonotperformwellontaskswheretheyhavetoscreenforrareanomalies(e.g.,inbaggage\nscreeningandsomeformsofClosedCircuitTelevision(CCTV)monitoring).Weneedtechnology\nsupportandprocessessuchasjobrotationtogetgoodperformance.Alarmfatigueisarelated\nphenomenon. Once alarms have been classified as unreliable, people stop paying attention to\nthem. How high a false alarm rate (with which people can work) depends on the risk, the fre-\nquencyatwhichfalsealarmsoccur,andthedemandsoftheothertaskstheyhavetocomplete.\nButevenwitha10%falsealarmrate,onecanexpectalarmfatigue.Oncepeoplestarttodismiss\nalarms,itishardtogetthemtotakethemseriouslyagain.Moreover,oncetheydismissonetype\nofsecuritywarningasfalse,similar-lookingorsoundingoneswillalsobedismissed.Manysecu-\nrity warnings today have far too high a false alarm rate and are thus dismissed. SSL certificate\nwarnings,forinstance,haveafalse-positiverateof50%ormore.So,itisnotsurprisingthatpeo-\npleignorethem,particularlyifnosecurealternativeforcompletingthetaskisofferedatthesame\ntime.RobReeder,whenworkingatMicrosoft,coinedthehandyacronymNEAT:warningsshould\nbeNecessary,Explained,Actionable,andTested[379].Addtothat\u2018andhaveafalsealarmrateof\n10%orless\u2019andonemayhaveachanceofsecuritywarningsbeingeffective.\nA key mental capability is memory. There are several types of memory. The first distinction\nis between Short Term Memory (STM) and Long Term Memory (LTM). When one tries to\nmemoriseanitem,itneedstogoroundtheSTMloopafewtimesbeforeitistransferredinto\ntheLTM.STMiswhatis,forinstance,usedforone-timepasswords,suchasnumericcodes\ndisplayedbytokensordisplayedonanotherdevice.\nSTM and One Time Passwords (OTPs) The use of one-time PINs or passwords (OTPs) in\nsecurity has increased as Two Factor Authentication (2FA) has become more common. We fo-\ncusourattentiononthenumberdisplayedandrepeatittoourselves(mentallyoraloud).Thenwe\nturnourattentiontotheentryfield,retrievetheitemfromtheSTMloop,andrepeatittoourselves\nwhileenteringit.Whatisimportanttonoteisthatthisworksformostpeopleforstringsofupto6\ncharacters,thatis,a6-digitnumber,becausewecanbreaktheminto2bitsof3characterseach.\nCodes that are longer overload the STM loop. People have to start looking forwards and back-\nwardsbetweenthedisplaytoreadthecharactersandenterthem.Thisincreasesboththeentry\ntimeandthelikelihoodoferror.Andmixingalpha-numericcharactersalsoimpactsperformance.\nWhether a user will be able to recall what is stored in LTM depends on how embedded it is:\nitems retrieved frequently are well embedded, those that are not will fade over time. That\nmeans we can expect problems with infrequently used items that require unaided recall\n(aidedrecall,e.g.,recognisingone\u2019sownimagesinasetofimages,iseasier).LTMisdivided\nintotwodistinctareas:generalknowledgeisstoredinSemanticMemory(LTM-SM),whereas\nitemsconnectedtoone\u2019spersonalhistoryarestoredinEpisodicMemory(LTM-EM):autobio-\ngraphicalmemory.ItemsstoredinLTM-SMfadefasterthanthoseinLTM-EMbecause,inthe\nlattercase,onestoresnotjusttheitem,buttheimagesandemotionsconnectedtothem.\nKAHumanFactors |October2019 Page150 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nLTM and passwords LTM-SM is divided into areas in which similar items are stored. When\none tries to retrieve an item, the section in which it is stored is activated, and the items in the\nsection compete to be retrieved \u2013 with those that have been retrieved most frequently \u2018coming\ntomind\u2019first.Thisinterferenceeffectisquitepowerfulanddisruptive,particularlybecauseitems\nonedoesnotneedanymore(suchasoldpasswords)keeplingeringandcompetewiththosethat\nneed to be recalled. Thus, managing a multitude of the same type of credentials is impossible,\nespecially if several of them are used infrequently. People need coping strategies, be it writing\nthem down, using a password manager or one-time credentials. We can agree that 123456 or\nP@SSwordarenotsecure.But,sincemostusersnowhavedozensofpasswords,theinsistence\nonstrongpasswordshascreatedahumanlyimpossibletask.Mostpeoplestruggleiftheyhave\nmore than 2\u20133 passwords or PINs \u2013 and the longer and stronger they are, the more they will\nstruggle.\nThe NCSC Password Guidance a, therefore, recommends several ways of supporting people in\nmanaginglargenumbersofuniquepasswords:switchingto2FAsolutionsand\/orpasswordman-\nagers,andifitisnotpossibletodoeither,notexpiringstrongpasswordsonaregularbasis.Ifa\npasswordhastobeexpired(e.g.,becauseithasbeencompromised),alittletimeinvestmentdur-\ningthedaythepasswordhasbeenchangedcanhelp.Peoplecanbrute-forcetheoldpassword\nout by repeating the new password around ten times immediately, and repeating that process\nthreeorfourtimesathourlyintervals.\nahttps:\/\/www.ncsc.gov.uk\/guidance\/password-guidance-simplifying-your-approach\nOneimportantsecuritycriterionforknowledge-basedauthenticationisthatacredentialshould\nbedifficulttoguess.Duetohumanphysicalandmentalcharacteristics,theselectionofcre-\ndentials is, however, often biased towards the familiar, or those that can be more easily dis-\ntinguishedfromothers.\n1. With passwords, people try to pick ones that are easier to recall, e.g., those that have\nmeaningforthemsuchasmemorablenamesordates.\n2. Whenusershavetochooseimagesascredentials,theypreferstrongcoloursandshapes\novermorediffuseones[380].\n3. When these are pictures of humans, they will pick pictures of \u2018more attractive\u2019 people\nandthosefromtheirownethnicbackground[381].\n4. Whenthecredentialisaparticularlocationwithinapicture,peoplepreferfeaturesthat\nstandout[382].\n5. With location-based systems, people pick memorable locations, for example, when\nchoosing locations for a 4-digit PIN on a 5 \u00d7 5 number grid, they go for connected\nlocations,anchoredonanedgeorcornerofthegrid[383].\n6. The order of the elements of a credential is predictable, because there is a strong cul-\ntural preference, e.g., people who speak languages that read left-to-right will choose\nthatorder[383].\n7. With finger swipe passwords on Android phones, people pick from a very limited num-\nberofshapes[384].\nThese human biases reduce the diversity (number of different passwords) in a password\ndatabase,andincreasethelikelihoodofanattackerguessingapassword.Tocounteractthis,\nsecurity policies have barred too obvious choices. Whilst not allowing very obvious choices\nsuchas\u2018password\u2019asapasswordand\u20180000\u2019asaPINisprudent,havingtoomanyrestrictions\nKAHumanFactors |October2019 Page151 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nincreasestheworkloadassociatedwiththepasswordcreationtask(seeSection4.2.1.2).For\ninstance, a password checker that rejects 5+passwords in a row as too weak will put users\nunderconsiderablestressandmostlikelytowardsre-usingapassword.\nSimilarly, password strength meters are often used to guide and influence the user\u2019s pass-\nword choices. For instance, Ur et al. [385] discussed the impact of various password meter\ndesigns on users\u2019 choice of passwords, as well as highlighting the increased workload for\nusersandthefrustrationfacedbythemwhenfacedwithmorestringentpasswordmeters.A\nrecent work by Golla and D\u00fcrmuth [386] investigated the accuracy of 45 password strength\nmeters including several deployed in practice, as well as academic proposals. Their work\nshows a degree of variation in terms of accuracy and, more critically, that this has not sig-\nnificantly improved over five years. So, even if we are to disregard the additional workload\non users (not that we should), these approaches do not always have the level of accuracy\nrequiredtoeffectivelyimplementpasswordpolicies.Theseconsiderationsmustbebornein\nmindwhendeployingsolutionstoenforcesecuritypolicies.\nSometimes, the question is raised as to whether there is training to help users cope with\nrecalling security credentials. Memory athletes use specific exercises to enhance memory\nperformance.ThewriterJoshuaFoerdetailsinhisbestsellerMoonwalkingwithEinstein[387]\nthatitrequiresaseriousinitialtimeinvestment(severalmonthsfull-time)butalsocontinuing\ntraining(atleast30minutesaday),plusthetimerequiredtorecallandenterthepasswords\n(whichinitselfpeoplefindtoomuch[388]).\nWe have, so far, discussed the capabilities and limitations that apply to most people. But,\nspecificusergroupswillhaveadditionalneedsthatshouldinformtheselectionorconfigura-\ntion of security mechanism or processes. For instance, children and older citizens can have\ncapabilities and limitations (e.g., motor skills) that differ from working age adults. People\nwith larger fingers struggle to hit small targets accurately, such as the small keys on a soft\nkeyboard.Culturalvaluesandnormsneedtobeconsidered.Thephysicalandmentalcondi-\ntionsofusersalsoneedtobetakenintoaccount.Notallusersareabletooperateequipment\nwiththeirhands,readfromscreens,orhearaudio.Conditionssuchascolourblindnessaffect\nsizeablenumbersofpeople,soimagesusedforgraphicalauthenticationneedtobechecked.\nCertainaudioorvideoeffectscanharmuserswithconditionssuchasautismorepilepsy.\nCAPTCHAs Some work on Completely Automated Public Turing test to tell Computers and\nHumans Aparts (CAPTCHAs) has investigated supporting users with sensory impairments,\ne.g., [389]. However, one needs to bear in mind that CAPTCHAs add more effort for the legiti-\nmateuser,impedingtheachievementoftheintendedgoal,i.e.,access.Theusabilitylimitations\nofthesemechanismsthataimto\u2018verify\u2019legitimatehumanusers\u2013andtheircontributiontosecu-\nrityfatigue\u2013mustbeconsidered[390,391].\nKAHumanFactors |October2019 Page152 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n4.2.1.2 Goalsandtasks\nHuman behaviour is essentially goal-driven. People perform tasks to achieve goals, at work:\n\u2018Iwanttogetthisquotationtoourcustomertoday\u2019,orintheirpersonallife:\u2018Iwanttogetthe\nbestutilitydealforus\u2019.Toachievethesegoals,peoplecompleteaseriesoftasks.Toprepare\naquotation,thesewouldincludeworkingoutthematerialsrequiredandtheircost,theperson-\nhoursrequiredandtheircost,therelevantfees,taxesetc.Ifataskhasseveralstepsorunits,\nit can be decomposed into sub-tasks. For instance, working out the person-hours required\nonajobcanbebrokendownintothefollowingtasks:\n1. identifyalltheworkstepsthatneedtobecompleted,\n2. workoutwhattypeofemployeeisrequiredtocompleteeachtask,\n3. howlongeachspecifictypeofemployeeneedstospendonwhichtask,\n4. whatpreparationseachtypeofemployeemayneedtomake.\nThesetasksarecalledprimaryorproductiontasksinhumanfactorsterminology,anddesign-\ningthetechnologytoolssopeoplecancompletethesetaskseffectivelyandefficientlyisthe\nmostfundamentalaspectofusability.Toensurepeoplecancompletetaskseffectively,tech-\nnology(andsecurity)designersneedtoknowtherequirementsforthetaskstheyperform:\nProductionandenablingtasks Productiontasksarewhatpeopleconsider\u2018theirjob\u2019,andin\nmany jobs, they may have spent years studying or training for them. At an organisational level,\nthe production tasks performed by many individuals in an organisation add up to business pro-\ncessesthatproducethegoodsorservices.Anythingthatstopstheseprocessesorslowsthem\ndown will cause the organisation significant problems. When we talk about \u2018resilience\u2019 of an or-\nganisation,itisabouttheabilitytokeepthosebusinessprocessesgoingtoproducetheoutput.\nAswellasproductiontasks,anorganisationhastasksthatdonotdirectlycontributetobusiness\nprocesses, but have been added to protect its ability to keep going in the long term: safety and,\nindeed,securityarekeyenablingtasks.Someorganisationsgetawaywithnotsupportingthese\nenablingactivitiesforaperiodoftimeandthisexplainsthegrudgewithwhichsomeindividuals\nand organisations view security. The fact that safety or security measures do not immediately\ncontribute to the output and the bottom line explains why it is a grudge sale, particularly when\nindividualsororganisationsfeelunderpressure.\n1. Whatoutputhastobeproducedsothegoalisachieved?Thetaskhastobecompleted\neffectively, e.g., if the quotation is not correct or not sent to the customer in time, the\ntaskisnotcompletedeffectively.\n2. Are there constraints on time and resources? Business processes may set an upper\nlimitonthetimetaskscantake,ortheresourcestheycandrawupon,suchas,access\ntoinformationorservicesforwhichtheorganisationhastopay.\n3. Is the task performed frequently (several times a day) or infrequently (once a month)?\nThe execution of tasks people perform frequently becomes \u2018automatic\u2019, whereas new\nor infrequently performed tasks are completed in a conscious, step-by-step manner\n(see Section 4.2.1.4). For frequently performed tasks, the design should optimise for\nspeed and reduce physical effort (which could lead to fatigue). For infrequent tasks,\nthedesignshouldtrytoreducementaleffortbyguidingtheusersandminimisinghow\nmuchtheyhavetoremember.\nPeoplefocusontheproductiontask,andenablingtasksareoftenexperiencedasanunwel-\nKAHumanFactors |October2019 Page153 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ncomeinterruptionordistraction.Tostaywithourauthenticationexample2:anemployeehas\nto authenticate with a password to a database to find out the hourly rate of a particular spe-\ncialistthatthebusinesscharges.Ifshedoesthisfrequently,andcanrememberthepassword,\nitmayonlytakeafewsecondsforhertorecallandenterit.Butifshehasjustreturnedfrom\navacation,cannotrememberitandittakes20minutestogetthroughtoahelpdesktohave\nitreset,andthenshehastothinkupandmemoriseanewpassword\u2013allbeforeshecanget\ntothedatabase\u2013thesecuritytaskhassuddenlybecomeamassivedisruption,andperhaps\ntheeffectivecompletionoftheproductiontaskisnowunderthreat.\nAndnotehowoneseeminglyquicktaskof\u2018authenticate\u2019(with2subtasksof\u2018recallpassword\u2019\nand\u2018typepassword\u2019)hasnowspawnedtwofurtherauthenticationtasks:\u2018recoverpassword\u2019\nand\u2018createpassword\u2019,bothwithmultiplestepseach.\nMost workarounds to security mechanisms, such as, writing passwords down or sharing\nthem,happenbecausepeopletrytoensureeffectiveproductiontaskcompletion(toprotect\nbusiness productivity). For instance, people often keep their own copies of documents that\nshould be in an access-controlled repository, or clear-text copies of documents that should\nbe encrypted, because they fear not being able to access them when they need them. Or\nwhentherepeatedeffortanddisruptionresultingfromhavingtoenterapasswordtounlock\na screen gets too much, they install mouse-jiggling software to stop the screen locking and\nhavingtoentertheirpassword[388].Evenifauserknowsthepasswordwell,thesecondsit\ntakesaddupifitneedstobedonedozensoftimesaday.\nTherefore, to avoid security tasks being bypassed, we must design them to fit into primary\ntasks.Wecanachieveagoodfitinanumberofways:\n\u2022 Automatingsecurity,forinstance,usingimplicitauthenticationtorecogniseauthorised\nusers,insteadofrequiringthemtoenterpasswordsmanytimesover.\n\u2022 If explicit human action is necessary in a security task, we should minimise the work-\nloadandthedisruptiontotheprimarytask.\n\u2022 Designingprocessesthattriggersecuritymechanismssuchasauthenticationonlywhen\nnecessary(see,forexample,[392]).\n\u2022 Designsystemsthataresecurebydefault3 sothattheydonotpushtheloadofsecurity\nconfigurationsandmanagementontotheusers.\nWorkload can be physical (typing a password) or cognitive (remembering a password). Hu-\nmansgenerallytrytobeefficientandkeepboththeirphysicalandmentalworkloadaslowas\npossible.But,givenachoice,mostpeoplewilltakeanextraphysicaloverextramentalwork-\nload,especiallyifthephysicaltaskisroutineandcanbedone\u2018onautopilot\u2019(SeeSection4.3).\nMental workload quickly becomes too much, especially if adjacent tasks require the same\nmentalcapability,suchasmemory.\nTherefore, in order to design a security task that fits well, we need to know the production\ntasks, and consider the mental and physical workload. Before selecting a security measure,\nsecurityspecialistsmustcarryoutaworkloadaudit:\n1. Whatistheworkloadassociatedwiththeprimaryandsecondary(security)task?\n2We could equally consider other examples, for instance, access control where the user perspective is: \u2018I\nneed to share information X with person Y\u2019 whereas access control policies take the approach: \u2018deny all and\nthenenablespecificaccess\u2019.\n3https:\/\/www.ncsc.gov.uk\/information\/secure-default\nKAHumanFactors |October2019 Page154 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n2. Are there performance constraints in the primary task (e.g., the time in which it has to\nbecompleted)?\n3. Are there resource constraints (mental or physical capability, or external ones such as\nlimitedaccesstopaidservices)?\n4. Whatistheimpactoffailingtocompletethesecuritytask?\nWorkloadmeasurement Howcanwemeasuretheworkloadassociatedwithasecuritytask?\nAsimpleproxyisthetime:howlongdoesittaketocompletethesecuritytask?Consideringthis\nbefore implementing a new policy or security measure would be an improvement on the status\nquo, whereby the impact of a policy or measure is only considered once it is causing problems.\nOnce we know how long it takes, we need to determine if and where it disrupts primary activity.\nTheassessmentofwhethertheimpactontheprimarytaskisacceptablecanbecarriedoutinfor-\nmally,forinstance,withexperiencedstaffandlinemanagerswhoknowtheproductiontaskwell.\nA more formal assessment can be carried out analytically using the Goals, Operators, Methods\n(GOMS)methodorempiricallyusingtheNASATaskLoadIndex(TLX).\nAs we have already discussed, people are hardwired to protect their productivity. They have\nabuilt-inawarenessofhowmuchtimeandefforttheyarespendingonnon-productivetasks,\nand an idea of how much non-productive activity is reasonable. They have what Beaute-\nmentetal.calledaComplianceBudget[393].Asthedayprogressesandenablingtasksadd\nup,thelikelihoodthattheywillseemtoomuchandbebypassedincreases.Furnell&Thomp-\nsoncoinedthetermsecurityfatigue[394]andtheuphillbattletoturnsecurityfromagrudge\nsaleintoapositivequality(Section4.2.1.3)canbeattributedtothis.\nSecurityisnottheonlyenablingtaskemployeesface.Othersinclude:safety,sustainability,di-\nversitytraining,variousregulatoryregimesandsoon,leadingtoComplianceFatigue.Beaute-\nment et al. [393], recommend that security specialists have an open and honest discussion\nwith line managers and business leaders about the time and budget available for enabling\nactivities,andhowmuchofitisavailableforsecurityversusotherenablingfunctions.Once\nthat is known, the workload of the security tasks can be calculated and priorities identified\n\u2013 which security behaviours really matter for the key risks a particular group of employees\nface \u2013 and security tasks streamlined. Making security mechanisms smarter and less \u2018all\nor nothing\u2019 can also help reduce compliance fatigue. For instance, allowing authentication\nwithanoldpassword,orhaving\u2018breaktheglass\u2019policiesthatallowbutflagaccessbyusers\nwhodonothavepermissionreducesthelikelihoodoftaskdisruption.Andifusersknowthey\nhave access to efficient security recovery and support services, it will reduce the need for\nworkarounds.\nKAHumanFactors |October2019 Page155 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n4.2.1.3 InteractionContext\nContextual Inquiry Inmodernworkorganisations,staffcanworkinmanypartsoftheworld,\nandinmanydifferentphysicalandsocialenvironments.Itcanbequiteachallengeforasecurity\nexpert to identify all the factors that could impact security and usability. Many usability profes-\nsionalsfollowanapproachcalledContextualInquiry[395]:\n\u2018ThecorepremiseofContextualInquiryisverysimple:gototheuser,watchthem\ndo the activities you care about, and talk with them about what they\u2019re doing right\nthen.\u2019\nContextualInquiryusesamixtureofobservationandinterviewtoidentifytheprimarytaskspeo-\nplearecarryingout,andwhatmakesthemdothiswell.\nBoththephysicalsurroundingsandthesocialenvironmentinwhichpeoplehavetoperform\nsecurity tasks affect performance and security. Most working age people now interact with\ntechnology on the move more frequently than at the desk traditional working environments.\nThis change in the context of use affects a number of security mechanisms, not least of\nbeingoverheardwhenonthephone\u2013thecaseofformerCIADirectorMichaelHaydenbeing\noverheardgivinganoff-the-recordinterviewonboardatrainbeingaparticularlyspectacular\none4. The risk of being overheard is now addressed in many corporate training packages,\nbut several security mechanisms are still in use that are vulnerable to being overheard, e.g.,\nsecurity questions such as date of birth, mother\u2019s maiden name. Using partial credentials\nonly and entry via keypad increases security but also accentuates the mental and physical\nworkload at the same time. Some attackers can also try to glean credentials via shoulder-\nsurfing or hidden cameras. Overall, the use of a One Time Password (OTP) as part of a 2FA\nsolutioncouldofferprotectionand betterusability.\nThe usability of security mechanisms can be affected by the following physical characteris-\ntics:\n1. Light: In bright light, displays can be hard to see, which can affect graphical authenti-\ncation in particular. Biometric systems such as iris and face recognition rely on input\nfromcameras.Brightlightcanleadtoglare,whichmeanstheimagescapturedarenot\ngoodenoughtoprocess.\n2. Noisewillmostobviouslyinterferewiththeperformanceofvoicerecognitionsystems.\nBut high levels of noise also impact human performance in general due to increased\nstress and, in turn, increased likelihood of error. Unexpected loud noises trigger a hu-\nmanstartleresponse,whichdivertsattentionawayfromthetask.\n3. Ambienttemperature can affect the performance of both technology and humans. Fin-\ngerprint sensors can stop working when it is cold, and humans are slower at pointing\nandselecting.Theymayalsoneedtowearprotectiveclothingsuchasglovesthatmake\nphysical operations of touchscreens impossible or difficult. Similarly, too hot an envi-\nronmentcanleadtodiscomfortandsweatcaninterferewithsensors.\n4. Pollution can impact equipment operated outdoors. This is a particularly concern for\nfingerprintsensorsandtouchscreens.Thelipidsleftbehindcombinewiththeparticles\nand the resulting dark grease can clog sensors or leave a clearly visible pattern on the\ntouchscreen.\n4https:\/\/www.theguardian.com\/world\/2013\/oct\/24\/former-spy-chief-overheard-acela-twitter\nKAHumanFactors |October2019 Page156 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nThesocialcontextinwhichpeoplefindthemselvesstronglyinfluencesbehaviourthoughval-\nues: shared beliefs about what is important and worthwhile, and norms: rules and expecta-\ntionsaboutactualbehaviour.Iftheexpectedsecuritybehaviourisinconflictwithday-to-day\nbehaviouralnorms,wecanexpectproblems.Forinstance,ifanorganisationvaluescustomer\nsatisfaction,andemployeesaretoldtobefriendlytowardscustomersatalltimes,asecurity\npolicy that requires staff to treat any customer enquiry as a potential attempt to extract in-\nformationwillnotfit.Understandingthereasonsunderpinningnon-compliancewithsecurity\npolicies can shed light on these conflicts between security requirements and the primary\ntask[396].Trustisanotherkeynorm.Humansdonotliketofeeldistrusted\u2013andithasbeen\nshownthatcommunicatingdistrusttoemployeesencouragesbadbehaviour,ratherthanpre-\nventit[397].\nOtheraspectsneedtobeconsideredinordertounderstandhowsecuritybeliefs,normsand\ncopingstrategiesareshaped.Forinstance,usersoftengettheirknowledgefromtheirwider\nsocial networks and these are also a source of support and help when they face usability\nchallenges[398,399].\n4.2.1.4 Capabilitiesandlimitationsofthedevice\nWe have already discussed that the physical characteristics of a device may make interac-\ntion with security mechanisms difficult in certain circumstances. Some characteristics of\nthedevicecanresultinsecuritymechanismsbecomingdifficulttouseinanycircumstance.\nEnteringlongandcomplexpasswordsonsoftkeyboardsonamobilephonetakesfarlonger\nand is more error-prone than on a regular keyboard [400]. And while with frequent use on a\nkeyboard,mostpeoplecanbecomequiteproficientatenteringacomplexpassword,perfor-\nmance does not improve when humans hit a basic limitation. What is particularly worrying\nfromasecuritypointofviewisthat(withoutcolluding)auserpopulationstartstoconverge\non a small number of passwords that are easiest to enter with the minimum amount of tog-\ngles,whichmakesguessingavalidpasswordeasierforattackers[401].\nWhilst2FAhassecuritybenefitsandreducestheneedforstrongpasswords,notall2FAsolu-\ntionsareusablebydefault.Manyusersfindwidelyused2FAtokenssuchasDigipassdifficult.\nTheyappreciatethefactitfitsintotheirwallet,butitisultimately\u2018toofiddly\u2019[402].Also,over\nhalf of online banking users have accounts with more than one financial services provider.\nThe fact that even those that use 2FA implement it differently (which token is used when it\nhastobeused,andhowthedifferentelementsofauthenticationarereferredto(passphrase,\npasscode, key phrase) causes confusion for the users. Similarly, different implementations\nofChipandPINcreateslightlydifferentvariationsinthetaskthatcatchesusersout,leading\ntohumanerror(Section4.3).\nWith increasing numbers of new devices appearing, from smart watches to home devices,\nand even smaller screen sizes and implicit interactions between users and devices through\navarietyofsensorsandactuators,consideringtheergonomicsofsecurityinteractions[403]\nis ever more important. The risks arising from Bring Your Own Device (BYOD) cultures are\ndiscussedintheRiskManagement&GovernanceKnowledgeArea(Chapter2).\nKAHumanFactors |October2019 Page157 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n4.3 HUMAN ERROR\n[11,404]\nInover30yearsofresearchintoaccidentsandsafety,thepsychologistJamesReasonworked\nout that virtually all mistakes people make are predictable [11]. They occur as a result of la-\ntentfailures(organisationandlocalworkplaceconditions)andactivefailures(errorsandvio-\nlationsbyhumans)incombinationtoallowtheaccidenttooccur.Figure4.2showsReason\u2019s\n\u2018Swiss Cheese\u2019 model adapted for security. A security incident occurs because the threat\nfindsitswaythroughaseriesofvulnerabilitiesintheorganisation\u2019sdefences.Apersonmay\nbetheonewhopushedthewrongbuttonorclickedonthelinkandcausedtheincident.How-\never,severalotherfailuresprecededthis,leadingtothatpersonbeingputinapositionwhere\nmakingwhatappearedtherightchoiceturnedouttobethewrongone.\nLatentusabilityfailuresinsystems-of-systems Onecanalsonotassumethatallsystems\naredesignedfromscratchwithusablesecurityconsiderationsinmind.Mostoftensystemsare,\ninfact,systems-of-systems(SoS),derivedfromcomposingotherwiseindependentsystemsthat\ncometogethertoorchestrateaparticularserviceortask.IntegrationproblemsinSoShavebeen\nstudied,e.g.,[405]andonemustconsiderthelatentfailuresthatariseduetothedecisionsmade\nduring integration. Poor usability and task fatigue represents a sufficient risk to the security of\ntheSoStowarrantupfrontinvestmentinordertoavoidlatentfailures.\nThe work of Reason and his fellow safety researchers [406, 407] led to organisations being\nheld responsible for fixing upstream safety issues as they are discovered, rather than wait-\ningforanaccidenttohappen.Theconceptofanearmissdescribesasituationwheresafety\nissues become apparent, but an accident is avoided at the last minute. In most industries\nthat are subject to safety regulations, there is an obligation to report near-misses and inves-\ntigateanyfailureassoonasitisdiscovered\u2013witharequirementtoaddresstherootcauses\nidentifiedthroughtheinvestigationsothatfuturefailuresaremitigated.\nApplied to security, an employee not following a security procedure constitutes an active\nfailure and should be investigated and fixed. If the investigation shows that the conflicting\ndemands of production task and security lead the employee to disregard security, the con-\nflictisanunderlyinglatentfailurethattheorganisationneedstoaddress.Oftensecuritynon-\ncompliance is ignored until an incident occurs. Unlike security, safety does not have active\nadversarieswithwhomtocontend.Butmanyimprovementscouldbemadetocurrentsecu-\nritypracticesbyapplyingsafetyconcepts(asdiscussedinSection4.2.1.2).\nAs already mentioned in Section 4.2.1.2, tasks that people carry out frequently become au-\ntomatic, whereas tasks they are doing for the first time or very infrequently are carried out\nin a conscious, step-by-step manner. The psychologist Daniel Kahneman, 2002 Nobel prize\nlaureate in economics for his work on human biases in decision-making, described the two\nareas, System 1 and 2, and the way they work as, Thinking Fast and Slow [408]. One very im-\nportant insight is that the majority of activities people undertake are carried out in System\n1 mode, and this is what makes us efficient. If people carried out most of their activities in\nSystem 2 mode, they would not get much done. Exhortations to \u2018Take Five\u20195 every time be-\nforeclickingonalinkareunrealisticwhenpeoplegetdozensofworkemailswithembedded\nlinks. Furthermore, if without clicking on that link or giving personal information, there is no\nway of completing the primary task, productivity comes under serious threat. Unspecific ad-\n5https:\/\/takefive-stopfraud.org.uk\/\nKAHumanFactors |October2019 Page158 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nFigure 4.2: Security Version of Reason\u2019s \u2018Swiss Cheese\u2019 model. Holes are latent & active fail-\nures. When a threat finds one in successive layers then the threat succeeds. \u2018Cheese slices\u2019\naredefencesprovidedbysecuritypolicies&mechanisms.\nvice such as \u2018just stop and think\u2019 rarely works because just stopping people in their tracks\nand without supporting them achieving their goals securely is not helpful. In addition, con-\nsidering the workload of security measures, security experts need to consider the further\nimpact that following their advice has on people\u2019s ability to complete their primary tasks, as\nwellastheimpactontheeffectivenessofgeneralcommunicationbetweenorganisationand\nemployees.TheuseofDomain-basedMessageAuthenticationReportingandConformance\n(DMARC),forinstance,shouldenableemployeestodistinguishgenuineinternalcommunica-\ntionsfrompotentialphishingattempts.TheuseofDMARCtoprovideareliableindicationof\n\u2018safe\u2019senderscanreducethenumberofemailsaboutwhichusershavetobecautious.Even\nbetter,theprovisionofultra-securebrowsingtechnology,whichisnowavailable,meansthat\nclickingonlinkshasnoadversetechnicalconsequences,sousereducationandtrainingcan\nfocusonexplainingsocialengineeringandmanipulationtechniques.\nWhen tackling complex problems, humans often have to combine both fast and slow pro-\ncesses,andthereisanin-betweenmixed-mode,wheretaskexecutionisnotfullyautomatic:\nsomeofthebehavioursareautomatic,butoneneedstostopandconsciouslyworkoutwhich\nbehaviourtoselect.Productivitycostsaside,securityexpertssuggestingpeopleshould\u2018stop\nand think\u2019 assume that \u2018slow mode\u2019 equals \u2018safe mode\u2019. For instance, using slow mode can\nalso lead to overthinking, to rationalising or explaining away evidence, to bringing irrelevant\nconcernstobear,focusing onthewronggoals(e.g.,production goals),andtowastinglarge\namounts of time and energy. In fact, each of these modes of operation comes with its own\ntypeofhumanerror(Table4.1).\nKAHumanFactors |October2019 Page159 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nMode Typeoferror Cause SecurityExample\nAutomatic mode Slips and Recognitionfailure \u201cI forgot to check for the\n(fast) lapses Memoryfailure padlock before I entered\nAttentionfailure mycreditcarddetails.\u201d\nMixedmode MistakeI Human chooses incor- \u201cIdidnotcheckforthepad-\nrectresponse lock because websites on\nmyiPhonearesafe.\u201d\nConsciousmode MistakeII Human does not know \u201cIdidnotknowtocheckfor\n(slow) correctresponse the padlock before enter-\ningmycreditcarddetails.\u201d\nTable4.1:Automatic,mixedmodeandconsciousworkspace(basedon[11])\nEveninconsciousmode,peopletrytobeefficient,resortingto\u2018theclosestthingtheyknow\u2019,\nthatis,theyaremostlikelytochoosebehaviourstheyusefrequently,orthosethatseemmost\nsimilartothesituationtheyencounter.Attackersexploitthisbycreatingverysimilar-looking\nwebsites,orincorporatingsecuritymessagesintotheirphishingemails.\nReason identifies four types of latent failures that are more likely to cause people to make\nerrors.\n1. Individual factors include fatigue (as discussed in Section 4.2.1.2), but also inexperi-\nenceandarisk-takingattitude.\n2. HumanFactorsincludethelimitationsofmemory(asdiscussedinSection4.2.1.1)but\nalsocommonhabitsandwidelysharedassumptions.\n3. Taskfactorsincludetimepressure,highworkloadandmultipletasks,butmonotonyand\nboredom are equally error-inducing because people shift their attention to diversions.\nUncertaintyaboutroles,responsibilitiesandrulesalsoleadtoincorrectchoices.\n4. Workenvironmentfactorsincludeinterruptionstotasks(asdiscussedinSection4.2.1.2)\nand poor equipment and information. People are also particularly prone to error when\nrulesandprocedureschange.\nTask and work environment factors are clearly the responsibility of the organisation. There\nshouldberegularreviewsofhowwellpoliciesarefollowed.Iftheyarenot,theunderpinning\ncauses must be identified and addressed. The causes of near misses, mistakes that hap-\npened but did not lead to an incident, should be similarly used to identify and change the\nunderlyingcauses.Wealsoneedtodevelopabetterunderstandingofhowhumansrespond\nwhenunderstressconditions,e.g.,inreal-timewhenfacedwithanunfoldingattack.\nKAHumanFactors |October2019 Page160 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n\u2018Neverissueasecuritypolicythatcan\u2019tbefollowed\u2019\n(Or:GeneralMacArthur,shadowsecurityandsecu-\nrity hygiene) The famous WWII military leader Gen-\neral Douglas MacArthur coined the phrase \u2018never give\nan order that can\u2019t be obeyed.\u2019 He recognised the cor-\nrosive impact of a single order that cannot be followed\nin reality\u2014it undermines the credibility of all orders and\nthesuperiorswhoissuethemandseedsuncertaintyand\ndoubt.Itisthesamewithsecuritypolicies:whenemploy-\nees encounter security policies that are impossible to\nfollow or are clearly not effective, it provides a justifica-\ntion for doubting all security policies. That is why secu-\nrityhygieneisessential.Whenpoliciesarenotbeingfol-\nlowed,securityprofessionalsmustinvestigate,inanon-\nconfrontational manner, why and if it is because they\nare impossible or too onerous to follow and re-design\nthe solution. Kirlappos et al. pointed out that in most\ncases,employeesdonotshowblatantdisregardforse-\ncurity,buttrytomanagetherisktheyunderstandinthe\nbestwayknowhow,whattheycallshadowsecurity[396].\nTheir \u2018amateur\u2019 security solutions may not be entirely effective from a security perspective, but\nsince they are \u2018workable\u2019, asking \u2018how could we make that secure\u2019 is a good starting point for\nfindinganeffectivesolutionthatfitsinwithhowpeoplework.\n4.4 CYBER SECURITY AWARENESS AND EDUCATION\n[409,410]\nSecurity practitioners often respond with security awareness, education and training mea-\nsures when people do not follow security policies. But, in Section 4.3 we established that\nsecurity hygiene must come first: if people keep being told that the risk is really serious and\ntheymustfollowpolicy,butcannotdosoinpractice,theydevelopresentmentandanegative\nattitudetowardssecurityandtheorganisation(whichiscounter-productive).\nIn practice, the three terms: awareness, education and training, are often used interchange-\nablybutaredifferentelementsthatbuildoneachother:\nSecurityAwareness. The purpose of security awareness is to catch people\u2019s attention and\nconvince them security is worth the engagement. Given that many organisations face\ncomplianceandsecurityfatigue,toquoteCormacHerley:MoreIsNotTheAnswer[376]:\naimingalotofcommunicationswillbackfire.Weneedtocapturepeople\u2019sattention,and\nget them to realise that (a) cyber security is relevant to them, that is, the risks are real\nandcouldaffectthem,and(b)therearestepstheycantaketoreducetheriskandthat\nthey are capable of taking those steps. Crafting effective awareness messages is not\nan easy task for security professionals. Working with the communications specialists\ninanorganisationcan,therefore,help.Theynotonlyknowhowtocraftmessagesthat\ncatch people\u2019s attention, but know how to reach different audiences via the different\nchannelsavailabletothem,andintegratethemintotheoverallsetofcommunications\ntoavoidmessagefatigue.\nSecurityeducation. Once people are willing to learn more about cyber security, we can pro-\nKAHumanFactors |October2019 Page161 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nvideinformationaboutrisksandwhattheycandotoprotectthemselvesagainstthem.\nMost people currently have very incomplete and often incorrect mental models (see\nSection 4.4.2) on cyber risks. Transforming them into more accurate ones provides a\nbasis on which to build cyber security skills. However, it is hard to ascertain whether\nthe education leads to more accurate mental models or at least the ones that security\nprofessionals expect people to possess. This divergence must be borne in mind. For\ninstance, Nicholson et al. [411] introduce the Cybersurvival task as a means to under-\nstandsuch divergence betweensecurity experts andemployeesin order to informthe\ndesignofsecurityeducationprogrammes.\nSecurityTraining. Training helps people to acquire skills, e.g., how to use a particular secu-\nritymechanismcorrectly,howtorecogniseandrespondtoasocialengineeringattack.\nInadditiontoshowingpeoplehowtodosomething,weneedtosupporttheacquisition\nofskillsbylettingthempractisetheskillsinasettingwheretheycan\u2018experiment\u2019with\nsecuritydecision-makingandreflectontheirperceptionsandbiases[412].Partsofskill\nacquisition can be supported online, but, like all learning, it is much more likely to be\nsuccessfulwhentakingplaceinthecontextofasocialcommunity[413].\nAcommonmisunderstandingisthatifpeoplecompletethethreestepsaboveandknowwhat\ntodo,theywillchangetheirbehaviour.Butknowingwhattodoandhowtodoitisnotenough.\nAswediscussedinSection4.3,humanactivityis90%automatic,drivenbyroutinesorhabits\nstoredinthelong-termworkspace.Thenewsecuritybehaviourneedstobeembeddedthere\nbut its place is occupied by an existing behaviour (similar to an old password). The adage\nthat \u2018old habits die hard\u2019 accurately describes the fact that until we manage to push the old\nbehaviouroutandthenewbehaviourbecomesautomatic,allourawareness,educationand\ntrainingeffortsmaynotyieldthechangesinbehaviourweareseeking.Thisisachallenging\nundertaking.Sinceproductiveactivityneedstocarryonwhilewechangesecuritybehaviour\n(Section4.2),wecanonlytarget1\u20132behavioursatatime,andembarkonchangingthenext\n1\u20132 only once these have become genuinely embedded. Nor should one conflate security\nawareness and education with security culture (cf. Risk Management & Governance Knowl-\nedge Area (Chapter 2)). These can be one element in developing a security culture but are\nnotinthemselvesrepresentativesofaneffectivesecurityculture.\nThe RISCS White Paper \u2018Awareness is only the first step\u2019 [409], presents a model of support\n(Figure 4.3 that organisations need to provide to achieve security behavioural change. It\nshows that the three steps we have discussed so far are only the first steps, and that a fur-\ntherfourstepsarerequiredtoachievebehaviouralchange.Tosupporttheseadditionalsteps,\nwe can draw on a new generation of learning resources that have evolved. And such steps\nrequireinvestmentfromorganisations-intermsofstrategy,time,planningandresources.\n4.4.1 Newapproachestosupportsecurityawarenessandbehaviourchange\nSimulationsandgamesareincreasinglybeingused,bothtomakesecurityawarenessmore\nattractive,andtohelpwithmorecomplexeducationalmeasuresandbehaviouralchange.\nAnti-phishing simulations designed to teach employees not to click on suspicious links are\nprobably the most widely used in organisations today. Their popularity stems from the fact\nthattheyprovidetheabilitytomeasuretheimpactofinterventions,andtheytendtoshowa\ndecreaseinclickratesintheshortterm.Theargumentisthattheexperienceofhavingbeen\nphishedisa\u2018teachablemoment\u2019thatcapturestheemployees\u2019attentionandpersuadesthem\nKAHumanFactors |October2019 Page162 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nFigure4.3:BehaviourchangemodelfromRISCSWhitePaper[409]\nto work their way through the education being offered. However, Fogg, who first introduced\ntheconceptof\u2018triggermoments\u2019(referredtoasPromptsinthemostrecentFoggBehaviour\nModel, cf. Figure 4.4) is very clear that they will only lead to behaviour change if the person\nhas a sufficient level of motivation to engage with the training provided, and the ability to\napply the skills being taught. Joinson argues that certain emotional and contextual triggers\nemployed by social engineering attackers are so targeted and powerful (for instance, a no-\ntification purporting to have information about traffic or public transport disruptions shortly\nbeforetheendoftheworkingday)thattheycannotbepreventedbytraining[414].\nFrom a human factor perspective, anti-phishing simulations can be problematic: 1) because\nemployees may perceive this as being attacked by their own organisation, which reduces\ntrust [404] and 2) they may lead employees to become so reluctant to click on links that\ntheydonotactongenuineemailsthatmaybeimportant.Thesefactorsneedtobecarefully\nconsideredinthedesignofanysuchsimulations[375].Furthermore,aswediscussedabove,\nthe use of mechanisms such as DMARC can reduce the number of suspicious emails on\nwhichusersneedtofocus,enablingeducationandtrainingtobegearedtowardsexplaining\nsocialengineeringandmanipulationtechniques.\nKAHumanFactors |October2019 Page163 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nFigure 4.4: Fogg Behaviour Model has three factors: motivation, ability and triggers (https:\n\/\/behaviormodel.org)\nSecurity awareness games CaptureTheFlag(CTF)gamesaredesignedtoraiseawareness\nofvulnerabilities,andhowtheycanbeexploited.Theideaisthatbyseeinghowtheycanusethe\nvulnerabilitiestoattackasystem,defenderslearntonotincorporatethemintheirownsystems.\nHowever,thefocusisontrainingthosechargedwithsecuringtheorganisationandnotthewider\nsetofusersandemployees.\nTherearetabletopcardgamesaimedatprovidingsecurityawarenesstoawideruserbasewithin\norganisations, e.g., Ctrl-Alt-Hack [415], dox3d!a and others are specifically targeted towards ICT\nspecialistsanddevelopers,e.g.,Microsoft\u2019sElevationofPrivilegeb.Therearealsoboardgames\ndesignedtobeplayedbyworkgroupstoraiseawarenessofcybersecuritythreatsandthecom-\nplexity of cyber risk decision-making, e.g., Decisions and Disruptions [412]. All of these games\nhavethepotentialadvantageofofferingasociallearningexperienceifplayedinagroupcontext.\nBut,iftheyareprovidedasone-offexercises,theyareunlikelytohavealastingeffect.\nOverall, games and simulations have the potential to offer engaging new elements that can be\ndeployedatdifferentstagesofthebehaviourchangemodel(seeFigure4.3)buttheyneedtobe\npartofaplannedbehaviourtransformationprogramme,notone-shotinterventions.\nahttps:\/\/d0x3d.com\/d0x3d\/about.html\nbhttps:\/\/www.microsoft.com\/en-us\/SDL\/adopt\/eop.aspx\n4.4.2 Mental models of cyber risks and defences\nMuch of the knowledge in the long-term workspace is organised in the form of mental mod-\nels, mental analogues of devices with which people interact. They can range in detail from\nstructural models (like blueprints) that experts have, to task-action models that enable non-\nexpertstooperateadevicecompetently.Apersonwithatask-actionmodelofoperationcan\ndrive a car, but only an expert with a structural model can diagnose faults and repair them.\nClearly,wecannotexpectnon-securityexpertstounderstandallcyberrisksindetail.\nWasharguesthatinadequatementalmodelsofsecuritymakeusersvulnerableagainstintel-\nligentadversaries:\nKAHumanFactors |October2019 Page164 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n\u2018These users believe that their current behavior doesn\u2019t really make them vul-\nnerable,sotheydon\u2019tneedtogotoanyextraeffort.\u2019[410]\nUnderstanding users\u2019 mental models can provide insights into how users perceive particu-\nlar security information, e.g. alerts [416] or specific tasks they have to undertake, e.g. dele-\ntion [398]. The question is: which models would be helpful? There are example mental mod-\nels in the literature, for instance, physical security models, medical models, criminal mod-\nels, warfare models and market models [417], which may provide a basis to communicate\ncomplex security issues to users. Perceptions of risk are also relevant in this regard. These,\nalongwithresponsibility,arecoveredintheRiskManagement&GovernanceKnowledgeArea\n(Chapter2)soarenotdiscussedfurtherhere.\n4.5 POSITIVE SECURITY\n[418]\nWhat is the goal of cyber security? When asked, most people\u2019s first response is along the\nlinesofpreventingcyberattacksoratleastreducingtheriskofattackssucceeding,orlosses\nbeingtoohigh.AsFlorencioetal.pointedout,vendorsandthosewhowantorganisationsto\ntake security more seriously resort to a \u2018Fear Uncertainty and Doubt (FUD) sale\u2019 \u2013 creating\nfearsofattacksandtheirconsequences,UncertaintyaboutconsequencesandDoubtabout\norganisations\u2019 ability to defend themselves \u2013 thus boosting the cyber security market and\nthesaleofproducts[418].\n\u2018FUDprovidesasteadystreamoffactoids(e.g.,rawnumberofmalwaresam-\nples,activityonundergroundmarkets,orthenumberofuserswhowillhandover\ntheir password for a bar of chocolate) the effect of which is to persuade us that\nthingsarebadandconstantlygettingworse.\u2019\nSecuritypractitionerstodaycomplainthatmostindividualsandbusinessesdonottakecyber\nrisks seriously. The problem is that fear sales are not a good basis for security decision-\nmaking: when the resulting investment in security turns out not to be effective, decision-\nmakers become skeptical about the benefits of cyber security. This, in turn, encourages the\nothersidetorampuptheFUD,leadingtoaspiraloffearandgrudginginvestmentinsecurity.\nIn order to defend from novel threats, companies need more than passive adherence \u2013 em-\nployees wanting to defend the organisation, and understanding and agreeing with the re-\nsponsibilities they have been assigned in the defence. To achieve that, we must make se-\ncurityapropositionthatiscredible,sothatpeoplewanttobuyintoit.Positivesecurityoffers\nmore than protecting things we care about from negative consequences (\u2018freedom from\u2019).\nIt enables us to engage in activities we value, and have experiences we cherish (\u2018freedom\nto\u2019) [419, 420]. Roe argues that a positive conception of security will open ideas for new pol-\nicyoptionsandinterventions,andencourageindividualsorgroupstobecomemoreinvolved\nindecision-makingaboutsecurity,andbeingpartofdeliveringit[420].\nAnotherkeyaspectofpositivesecurityisthelanguageweuseinconnectionwithit.Asafirst\nstep, we must stop the practice of demonising people who are unwilling or unable to follow\nsecurityadvice:callingthesepeople\u2018TheWeakestLink\u2019implicitlyblamesthemfornotbeing\nabletomakesenseof,orcomplywith,security.\nKAHumanFactors |October2019 Page165 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n4.6 STAKEHOLDER ENGAGEMENT\n[393,421,422]\n4.6.1 Employees\nFromtheresearchonhumanbehaviourincybersecurityoverthepastdecade,oneveryclear\ntheme has emerged: the importance of engaging in finding ways of making security work\nfor employees. Communication and leadership are important in this regard. However, these\naspects and others pertaining to organisational cultures are discussed in the Risk Manage-\nment & Governance Knowledge Area (Chapter 2). Here, we focus on employees rather than\norganisational leadership and aspects, such as strategic board-level leadership of cyber se-\ncurity.\nLizzieColes-Kempandcolleagueshavedevelopedanapproachthattakesemployeeinvolve-\nmentinimprovingsecurityastepfurther.Theyuseprojectivetechniques(e.g.,drawingsand\ncollages) to build representations of daily activity, and ground the discussion of security in\nthese. Case studies [371, 396] show how this helps to identify the root causes of insecure\nbehaviourthatthe organisation seesas undesirable,in manycasesbadly designedsecurity\n(echoing the results of Beautement et al. [393]), but also more fundamental failings of the\norganisationtosupportthebusinessanditsindividualtasks.\nCreative security engagements (first mentioned by Dunphy et al. [423]) encourage partici-\npants(employeesinthecompanycontextorconsumersorcitizensinwiderengagement)to\nreflecton:\n\u2022 theirenvironment,\n\u2022 theemotionstheyfeel,\n\u2022 theconstraintstheyexperience,\n\u2022 thepressurestheyareunder,\n\u2022 theactionsandtaskstheyperformwhengeneratingandsharinginformation.\nOneparticulartechniqueforcreativeengagementsusingLegoforthephysicalmodellingof\ninformationsecuritythreatswasdevelopedbytheEUTrespassProject6.Thistypeofphysical\nmodelling bridges the gap between the typical diagrams (flow-charts and Unified Modelling\nLanguage (UML) diagrams, for example) with which security practitioners commonly work,\nandtheeverydaypracticesoftheconsumerswhoareaffectedbysecuritydesign.Heath,Hall\n& Coles-Kemp [424] reported a successful case study of this method to model security for\na home banking application, which identified areas where human intervention and support\nneededtobeprovidedtomakesecurityworkoverall.\nThese studies provide examples of different ways of engaging with employees, consumers\nandcitizensonsecurity.Theyarepartofagrowingtrendinresearch(cf.workonProductive\nSecurity [425]), moving away from the mechanistic approach of looking for traits within in-\ndividualsthatareconducivetothedesiredsecuritybehaviour,ortryingtochangebehaviour\nbyaddressingortweakingthosetraits.Thefundamentalfocusoftheseapproachesisabout\nchanging the design of security to align with user and organisational tasks to reduce work-\n6https:\/\/www.trespass-project.eu\/\nKAHumanFactors |October2019 Page166 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nloadandincreaseproductivityforanorganisation.Thefactthatitalsoleadstoamoreposi-\ntiveperceptionofsecurityisavaluableside-effect.\n4.6.2 Software developers and usable security\nZurko & Simon pointed out that unusable security affects not only general employees who\nmay not have specific computing or security education but also those who have significant\ntechnicalskills,suchasdevelopersandsystemadministrators[426].Theyalsofaceincreas-\ningworkloadsandcomplexity,andmakemistakesbecausethelibrariesandapplicationpro-\ngramminginterfaces(APIs)theydrawonarenotusable.Arguably,errorsthatthesetechnical\nusersmakegenerallyhaveamoresignificantimpactthanmistakesmadebygeneralemploy-\nees,e.g.,theHeartbleedvulnerability.\nDevelopers and password security We noted above the usability issues of password and\notherauthenticationsystemsthathavebeenstudiedextensivelyforend-users,highlightingprob-\nlemsandinformingdesigndecisionsforbetterpoliciesandmotivatingresearchintoalternatives.\nHowever,end-usersarenottheonlyoneswhohaveusabilityproblemswithpasswords.Thede-\nveloperswhoaretaskedwithwritingthecodethroughwhichthepasswordsarestoredmustdo\nso securely. Yet, history has shown that this complex task often fails due to human error with\ncatastrophicresults.Ifdevelopersforgetto\u2018hashandsalt\u2019apassworddatabase,thiscanleadto\nmillionsofend-userpasswordsbeingcompromised.Naiakshinaetal.[369,370]conductedaran-\ndomisedcontroltrialwithcomputersciencestudents,aswellasfreelancedevelopers,andfound\nthat,similartoend-users,developersalsosufferfromtask-focusandtheyseesecurityasasec-\nondarytask.Noneofthestudentparticipants,andonlyasmallnumberoffreelancedevelopers,\nimplementedanykindofsecurityunlessexplicitlypromptedtodoso.Interestingly,ofthosepar-\nticipantswhodidimplementsomesecuritymeasures,thestudentsdidbetterthanthefreelance\ndevelopers, who on the whole used more outdated and incorrect cryptographic mechanisms to\nstoretheirpasswords.\nAnumberofstudies,e.g.,Encketal.[427]andFahletal.[421]havehighlightedtheextentto\nwhich vulnerabilities manifest in modern eco-systems centred on app development. It was\nnotable that, of the 96 developers who were contacted by Fahl et al., a large number were\nwillingtoprovideinformation,butonly13wereinterviewedbecausetheircompaniesrefused\npermissionforthemtodoso.Fromtheinterviews,Fahletal.foundthatdevelopershadlittle\nto no security training and were under extreme pressure to complete the app quickly\u2014and\nthatwasthereasonforthemistakesthatledtovulnerabilities.\nAcaretal.[428]havestudiedtheimpactofonlinesocialnetworks,suchasStackOverflow,on\nthe security of code that developers produce. Two thirds of the developers who used Stack-\nOverflow or a textbook managed to produce a functionally correct solution within the allo-\ncatedtime,whereasonly40%ofthoseusingofficialdocumentationdid.Intermsofthesecu-\nritytasks,theresultswerereversed.Thoseusingofficialdocumentationproducedthemost\nsecure code and those using the StackOverflow the least. A traditional security response to\nthis result would be \u2018use of StackOverflow should be forbidden.\u2019 But clearly, the productivity\nprice developers and their organisations would pay would be a hefty one. For instance, re-\ncentwork[429]hasshownthatdevelopersutilisesuchforumstoexchangeinformationand\noffer mutual support for security problem-solving. That is not to say that such advice is al-\nwayseffective(asnotedabove)buttheforumsdoprovideacommunityofpracticeinwhich\ndeveloperscansharetheirproblemsandseekhelp.Banningsuchforumsoutrightwithoutre-\nplacingthemwithrelevantsupportwould,therefore,notaddressthecruxofwhydevelopers\nseeksuchsupport.\nKAHumanFactors |October2019 Page167 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nTheusabilitychallengesofcryptographicAPIsandtheirdocumentationhavebeenhighlighted\nbyArztetal.[430]andNadietal.[431],andtoolsproposedtosupportdevelopersintheirus-\nage[432].Recently,toolshavealsobeenproposedtoimprovetheusabilityofstaticanalysis,\ne.g.[433].GreenandSmithhavesynthesisedinsightsfromtheexistingbodyofresearchinto\nasetoftenprinciplestomakeapplicationprogramminginterfacesforsecurityandcryptog-\nraphy libraries more usable for developers [422]. Patnaik et al. [434] identify four usability\nsmells that indicate that cryptographic APIs may not be fully addressing such principles, of-\nfering insights to library developers on the key areas on which to focus in order to improve\ntheusabilityoftheirlibraries.\nThedisconnectbetweendevelopersandusersalsoneedstobeconsidered.Caputoetal.[435]\nhighlighted that developers did not understand the impact of the lack of usability on individ-\nual performance and wellbeing, organisational productivity, or the effectiveness of security.\nThey recommend that management must ensure that developers experience the results of\nthelackofsecurityandusabilitydirectly\u2013byhavingtodealwithhelpdeskcalls,theimpact\nof losses \u2013 and engage more. Recent work has provided insights into the role of strong or-\nganisationalsecurityculturesondevelopers\u2019mindsetswithregardstosecurity[436]andhow\nexpertsimprovetheirsecuritypractices[437].\n4.7 CONCLUSION\nHumansandtechnologiesdonotexistinisolation.Humansconceivenewtechnologies,de-\nsign and implement them, and are also their users and maintainers. Cyber security is no dif-\nferent.Humanbehavioursshapecybersecurity(e.g.,responsestophishingcampaignslead\ntoanti-phishingfiltersornewsecuritytraining).Equally,thedesignofcybersecurity(humans\ndesignthosefiltersortrainingmechanisms)impactspeople\u2019sinteractionswithsystemsand\nthe security mechanisms designed into those systems (e.g., impedence to primary tasks or\nincreased workload arising from security tasks). We must consider this symbiotic relation-\nship throughout the conception, design, implementation, maintenance, evolution \u2013 and let\u2019s\nnot forget, decommissioning \u2013 of cyber security mechanisms. Human factors must play a\ncentralroleas,afterall,thepurposeofcybersecurityistoprotectpeople,theirdata,informa-\ntionandsafety.Wemust\u2013asfaraspossible\u2013fitthetasktothehumanandnotthehuman\ntothetask.\nKAHumanFactors |October2019 Page168 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nCROSS-REFERENCE OF TOPICS VS REFERENCE MATERIAL\n4.2Usablesecurity\u2013the\nc4.2 c4.2\nbasics\n4.2.1Fittingthetasktothe\nhuman\n4.3HumanError c4.3 c4.3\n4.4Cybersecurity\nc4.4 c4.4\nawarenessandeducation\n4.5PositiveSecurity c4.5\n4.6Stakeholder\nc4.6 c4.6 c4.6\nEngagement\nKAHumanFactors |October2019 Page169\n]673[erom4102yelreh\n]773[gnimrofsnart1002essas\n]11[namuh8002nosaer\n]404[ytiruces2102soppalrik ]904[ssenerawa5102reyeb\n]014[klof0102hsaw\n]814[duf4102oicnerofl\n]393[ecnailpmoc9002tnemetuaeb\n]124[2102:lhaF\n]224[srepoleved6102neerg TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nKAHumanFactors |October2019 Page170 Chapter 5\nPrivacy & Online Rights\nCarmela Troncoso \u00c9cole Polytechnique\nF\u00e9d\u00e9rale de Lausanne\n171 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nINTRODUCTION\nThe pervasiveness of data collection, processing, and dissemination raises severe privacy\nconcerns regarding individual and societal harms. Information leaks may cause physical or\npsychologicaldamagetoindividuals,e.g.,whenpublishedinformationcanbeusedbythieves\nto infer when users are not home, by enemies to find out weak points to launch attacks on\nusers or by advertising companies to build profiles and influence users. On a large scale,\nthe use of this information can be used to influence society as a whole, causing irreversible\nharmtodemocracy.Theextentoftheharmsthatprivacylosscauseshighlightsthatprivacy\ncannotsimplybetackledasaconfidentialityissue.Beyondkeepinginformationprivate,itis\nimportant to ensure that the systems we build support freedom of speech and individuals\u2019\nautonomyofdecisionandself-determination.\nThe goal of this knowledge area is to introduce system designers to the concepts and tech-\nnologies that are used to engineer systems that inherently protect users\u2019 privacy. We aim\nto provide designers with the ability to identify privacy problems, to describe them from a\ntechnicalperspective,andtoselectadequatetechnologiestoeliminate,oratleast,mitigate\ntheseproblems.\nPrivacy is recognised as a fundamental human right [438]: \u201cNo one shall be subjected to ar-\nbitraryinterferencewithhisprivacy,family,homeorcorrespondence,nortoattacksuponhis\nhonour and reputation\u201d. As such, it has been studied for many years from a socio-legal per-\nspective with two goals. First, to better understand what privacy means for society and indi-\nviduals.Second,toensurethatthelegalframeworksthatunderpinourdemocraciessupport\nprivacy as a right. The former studies proposed definitions such as privacy being \u2018the right\ntobeletalone\u2019[439],\u2018therighttoinformationalself-determination\u2019[440,441]or\u2018thefreedom\nfromunreasonableconstraintsontheconstructionofone\u2019sownidentity\u2019[442].Probablyone\nof the best examples of the latter are the principles and rules associated with the European\nData Protection Legislation [443] covered in the Law & Regulation Knowledge Area (Chap-\nter 3). All of these conceptualisations are of great importance to define and understand the\nboundariesofprivacyanditsroleforsociety.However,theirabstractandcontext-freenature\noften makes them not actionable for system designers who need to select technologies to\nensurethatprivacyissupportedintheirsystems.\nTo address this gap, in this knowledge area, we conceptualise privacy in a similar way as\nsecurity engineering conceptualises security problems [444, 445]. We consider that privacy\nconcerns,andthesolutionsthatcanaddressthem,aredefinedbytheadversarialmodelcon-\nsidered by the designer, the nature of the information to be protected, and the nature of the\nprotectionmechanismitself.Typicalexamplesofadversarialmodelscanbe:third-partyser-\nviceswithwhomdataaresharedarenottrusted,theserviceprovideritselfisnottrustedwith\nprivatedataoftheusers,orusersofaserviceshouldnotlearnprivatedatafromotherusers.\nTypical examples of private data to be protected from these adversaries can be: the con-\ntent of users\u2019 communications, their service usage patterns, or the mere existence of users\nand\/ortheiractions.Finally,typicalexamplesofprotectionmeanscanbetechniquesthaten-\nableinformationavailabilitytobecontrolled,suchasaccesscontrolsettings,ortechniques\ntohideinformation,suchasEncryption.\nThis knowledge area is structured as follows. The first part, comprising three sections, con-\nsiders three different privacy paradigms that have given rise to different classes of privacy\ntechnologies. The first is privacy as confidentiality (Section 5.1), in which the privacy goal\nis to hide information from the adversary. We revise technological approaches to hide both\nKAPrivacy&OnlineRights |October2019 Page172 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ndata and Metadata, and approaches to hinder the adversary\u2019s ability to perform inferences\nusing the data that cannot be hidden. The second is privacy as informational control (Sec-\ntion 5.2), in which the goal is to provide users with the means to decide what information\ntheywillexposetotheadversary.Werevisetechnologiesthatsupportusersintheirprivacy-\norienteddecisionsandtechniquesthathelpthemexpresstheirpreferenceswheninteracting\nwithdigitalservices.Finally,weintroduceprivacyastransparency(Section5.3),inwhichthe\ngoal is to inform the user about what data she has exposed and who has accessed or pro-\ncessed these data. We revise solutions that show users their digital footprint, and solutions\nthatsupportaccountabilitythroughsecurelogging.\nThe privacy requirements that define the privacy goals in the paradigms mentioned above\nare often context dependent. That is, revealing a particular piece of information may be ac-\nceptable in some environments but not in others. For instance, disclosing a rare disease is\nnot considered a privacy concern in an interaction with a doctor but would be considered a\nprivacy violation in a commercial interaction. Nissembaum formalizes this concept as con-\ntextual integrity [446], which explicitly addresses an information flow may present different\nprivacy needs depending on the entities exchanging this information or the environment in\nwhich it is exchanged. We note that once the requirement for a flow are clear (including the\nadversarialmodel),adesignercandirectlyapplythetechnologiesdescribedinthischapter.\nThe second part of the knowledge area is devoted to illustrating how privacy technologies\ncan be used to support democracy and civil liberties (Section 5.4). We consider two core\nexamples: systems for secure voting and to circumvent censorship. For the former, privacy\nofthevotesisimperativeforthefunctionalityitself.Forthelatter,privacyofcommunication\npartnersisnecessarytoensurethatcontentcannotbeblockedbyacensor.\nWeacknowledgethatprivacytechnologiescanbeusedintosupportillicit(e.g.,distributionof\nchildpornography)oranti-socialbehaviors(e.g.,cyberbullying),asdescribedintheAdversar-\nial Behaviours Knowledge Area (Chapter 7). While there exist solutions to selectively revoke\nthe protection provided by privacy technologies, these are strongly discouraged by privacy\nresearchers and privacy advocates. The reason is that adding backdoors or escrow possi-\nbilities to ease law enforcement, inherently weakens the security of the privacy-preserving\nsystemsastheycanalsobeexploitedbymaliciousactorstoundermineuser\u2019srights.There-\nfore,wedonotconsiderthesetechniqueswithinthisdocument.\nWeconcludetheknowledgeareabyoutliningthestepsinvolvedintheengineeringofprivacy-\npreserving systems (5.5). We provide guidelines for engineers to make informed choices\nabout architectural and privacy technologies. These guidelines can help system designers\ntobuildsystemsinwhichtheusers\u2019privacydoesnotdependonacentralisedentitythatmay\nbecomeasinglepointoffailure.\nWe note that many of the privacy technologies we revise in this knowledge area rely on\nthe cryptographic concepts introduced in the Cryptography Knowledge Area (Chapter 10).\nThroughout this knowledge area, we assume that the reader is familiar with these basic\nconcepts and avoid repeating cryptographic definitions and reiterating on the explanation\nofcommonprimitives.\nKAPrivacy&OnlineRights |October2019 Page173 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nCONTENT\n5.1 PRIVACY AS CONFIDENTIALITY\n[447][448][449][450][451][452][453][454]\nInatechnicalre-interpretationofthe\u2018righttobeletalone\u2019[439]privacydefinition,acommon\nconceptualisationofprivacyistoavoidmakingpersonalinformationaccessibletoanyentity,\ninparticulartoawiderpublic[444].Underthisdefinition,theobjectiveofprivacytechnologies\nis to enable the use of services while minimising the amount of exposed information. Here,\ninformation refers to both data exchanged explicitly with the service, as well as information\nmade implicitly available in the Metadata associated with these exchanges (e.g., identity of\ntheusersorfrequencyofusage).\n5.1.1 Data Confidentiality\nWe now describe two approaches to minimise the amount of exposed information. We first\npresent methods that provably prevent unauthorised access to information, typically based\nontheuseofadvancedcryptographicprimitivestoensurethatnodatacanbeinferred.Sec-\nond, we present disclosure control methods, which relax the Confidentiality definition to en-\nsure that the information leaked to the adversary is limited to a certain amount, or is not\nlinkabletoanindividualperson.\n5.1.1.1 Cryptography-basedaccesscontrol\nA first flavour of Confidentiality-oriented privacy technologies focus on protecting the data\nthroughtheuseofcryptography.Thesetechnologiesmainlyconsidertwoadversarymodels:\none where the recipient is considered trusted and the data have to be protected while in\ntransit, and one in which the recipient is not trusted and the data must be kept private even\nwhenitisprocessed.\nProtecting data in transit. The protection of data in transit is typically known as end-to-end\nencryption (E2EE). Here, an end refers to the origin and destination of the communication.\nFor instance, the sender and receiver of an email, or the client and server of a service. E2EE\nensuresthattheConfidentialityofdataisensuredbetweenbothends.Thatis,nothirdparty,\nfrom the routers in the communication infrastructure, to the application (e.g., email, mes-\nsaging) servers that enable the communication, can access the communication. Addition-\nally,E2EEtypicallyprovidesIntegrity,impedinganyintermediaryfrommodifyingthedataex-\nchanged, and Authentication, ensuring that the communication parties can be sure of each\nothers\u2019identity.\nFromatechnicalperspective,inE2EEthedevicesattheendofthecommunicationholdthe\nEncryption key used to protect the data. Usually, these are symmetric encryption keys and\ncan be agreed using key transport, or can be established using any modality of the Diffie-\nHellman exchange. The use of Diffie-Hellman to agree one key per session additionally pro-\nvidesforwardsecrecy,butonemustbecarefulwhenimplementingtheexchange[455].Typi-\ncally,DigitalSignaturesandMessageAuthenticationCodesareusedtoprovideIntegrityand\nauthentication. Canonical examples of E2EE encryption are the TLS protocol [456], widely\nused in client-server scenarios; or the PGP protocol, a common encryption mechanism for\nemailcommunications[457].\nKAPrivacy&OnlineRights |October2019 Page174 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nAspecialtypeofE2EEisOff-the-RecordMessaging(OTR)[448].1OTRseekstoprovidestronger\nprivacy properties than the above protocols. It considers an adversary that can not only ob-\nserve the communication, but also eventually compromise one of the devices participating\ninthecommunication.Thiscompromisegivestheadversarythechancetogetthelong-term\nkeysoftheparticipants.InsuchademandingscenariothetwomaingoalsofOTRaretopro-\nvidei)perfectforwardsecrecyandii)repudiableAuthentication,whichpermitsausertodeny\nhavingsentamessageinthepast.Theprotocolderivesthecryptographickeysusedforthe\nconversation using an unauthenticated Diffie-Hellman key exchange. Then, the participants\ncarry out a mutual authentication inside the protected channel, which guarantees the future\nrepudiability.Encryptionkeysarerotated,andoldkeysaredeleted,soastomaintainforward\nsecrecy. Current OTR protocols also include strong protection against man-in-the-middle at-\ntacks,eveniftheparticipantsdonotpre-sharesecrets[458,459].\nFinally, we can remark that E2EE is nowadays prevalent in instant messaging applications\nsuchasSignal,WhatsApp,FacebookMessenger,orViber.Alloftheseapplicationsarebased\nontheso-calledSignalProtocol(previouslyknownasAxolotlorTextSecure)[460].Similarto\nOTR, this protocol provides authenticated messaging between users with end-to-end Confi-\ndentiality, and messages are kept secret even if the messaging server is compromised, and\neveniftheuser\u2019slong-termkeysarecompromised.Thesepropertiesrelyonanauthenticated\nkey exchange protocol that mixes multiple Diffie-Hellman shared secrets, and on a protocol\nto refresh the keys called double ratcheting [452]. Cohn-Gordon et al. provided in [461] a de-\ntaileddescriptionofthisprotocol,includingaformalanalysis.\nNotethatalloftheaboveprotocolsonlyofferstrongguaranteesaslongasthemechanisms\ntoauthenticatethecommunicationpartiesworkasexpected.Forinstance,theConfidential-\nityprovidedbyTLSreliesonserviceskeepingtheirkeyssecretandthePublicKeyInfrastruc-\nture operating reliably, so that the communication parties can be authenticated. Similarly,\nWhatsApp\u2019sConfidentialityreliesonthefactthatphonenumbersarehardtospoofand,thus,\nusersaresurethattherecipientoftheirmessageistheirintendedinterlocutor.\nProtection of data during processing. The previous protocols focus on protecting data in\ntransit from third parties other than the communication participants. We now consider situ-\nations in which the recipient needs to perform some computation on the data, even though\nshe is considered adversarial. We distinguish two scenarios: one in which computation is\ncompletelyoutsourcedandoneinwhichthesenderparticipatesinthecomputation.\nIn the first scenario, commonly known as outsourcing, the data belong to the sender and\nthe recipient acts as the data processor. Typical examples are the use of cloud services to\ncomputeonbigdata,e.g.,privacy-preservingtrainingandclassificationusingmachinelearn-\ning [462], or to hold a database in which the sender wants to perform searches [463]. The\nsolutionstothisproblemarebasedonadvancedcryptographicprotocols.Wenowillustrate\ntheuseoftheseprotocolsinacoupleofexamples,andwereferthereadertotheCryptogra-\nphy Knowledge Area (Chapter 10) for more details on the technical details of the underlying\nprimitives.\nA common problem when outsourcing services is that accessing particular pieces of out-\nsourced data may reveal information about the user to the entity holding the data. For in-\nstance, accessing a given entry on a patent database reveals business intentions; and ac-\ncessingaparticularentryinamessagingdirectoryrevealsrelationshipsbetweenusers.This\nproblemcanbemitigatedbyusingPrivateInformationRetrieval(seetheCryptographyKnowl-\n1https:\/\/otr.cypherpunks.ca\/\nKAPrivacy&OnlineRights |October2019 Page175 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nedge Area (Section 10.9.2)), which allows a database to be queried without revealing which\nrecord is being accessed. An example use case for information retrieval is the creation of\nprivacy-preservingdirectoriesforsocialnetworks[464,465,466].\nAnotherexamplewhereremoteprocessingisneededcomprisesdigitalshopsordigitalbank-\ning, where a server returns information to a user depending on the inputs. The shop needs\ntoprocesspaymentsandthenshipthedigitalitem;andthebankprovidesmoney,ormakes\na payment, upon authentication. Users\u2019 shopping patterns, however, may reveal a lot about\ntheir profiles. In this case, Oblivious Transfer (see the Cryptography Knowledge Area (Sec-\ntion 10.9.1)), in which a service can transfer an item without knowing which item is being\ntransferred,canbeusedtosupportprivacy-preservinginteractions[467,468].\nThe previous techniques are useful for particular operations: search an item on a database,\ntransfer that item. Ideally, we would like to be able to perform any operation on outsourced\ndata.AveryrelevanttechnologyforthisisHomomorphicencryptionencryption(seetheCryp-\ntography Knowledge Area (Section 10.11)). This type of encryption allows any operation on\nencrypted data to be performed. Such flexibility, however, comes at a high cost in terms of\ncomputation time, and for some implementations also in terms of bandwidth, thus making\nit far from practical at this point. Less general versions such as somewhat homomorphic\nencryptionorpartiallyhomomorphicencryption,whichonlypermitlimitedoperations(sums,\nmultiplications or evaluating a given function) provide better trade-offs and can already be\nusedforsimpleconcretetasks.\nWenotethatinrecentyears,theprivacy-preservingcryptographicprimitivesabovehavebeen\ncombined with new secure hardware [469, 470] in order to improve performance. While this\ncombinationindeedbringstheperformanceofprivacy-preservingcryptographyclosertothe\nbenchmarks needed for deployment, it is important to highlight that such an improvement\ncomes at the expense of trusting the manufacturer of the secure hardware not to leak the\ninformation(orthekey)tounintendedparties.\nIn the case of database outsourcing, it is worth mentioning tailored solutions that combine\ndifferenttypesofprivacy-preservingcryptographyinordertoincreaseefficiency[471].These\ndatabases rely on techniques such as homomorphic encryption, order-preserving encryp-\ntion [472, 473], or deterministic encryption, among others. These schemes indeed provide\ngreatperformance.However,ithasbeendemonstratedthatchoosingweakercryptographic\nprimitives to favour efficiency may have a significant impact on privacy [474, 475, 476, 477].\nTherefore, they are only recommended to support compliance, and should only be deployed\nin a trusted environment where attacks are unlikely. It is not recommended to use them in\nscenarioswheredataprivacyisofcriticalimportanceandtheentitythatholdsthedatabase\nisnottrusted.\nThe second scenario is collaborative computation, i.e., the entities involved in the commu-\nnication collaborate to perform the computation. The result of this computation may be of\ninterestforthesender,forthereceiver,forboth,orforthirdparties.Yet,iftheparticipantsdo\nnot trust each other, i.e., for a given entity, any of the other participants may be considered\nan adversary. Typical applications are comparing databases or computing statistics across\ndatasets [478, 479]. Such applications can be supported by Multi Party Computation (see\nthe Cryptography Knowledge Area (Section 10.9.4)), as described by Archer et al. in [480].\nWhen the goal of the application is to find similarities between two databases (e.g., con-\ntacts [481, 482], malicious activities [483], or genetic information [484]), one can also use\nlighterprotocolssuchasPrivateSetIntersection[485,486,487].Theseprotocolsallowtwo\nparties to compute the intersection of datasets without revealing anything except the inter-\nKAPrivacy&OnlineRights |October2019 Page176 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nsection,orthecardinalityoftheintersection.\nVerification in the encrypted domain. When data are processed in the encrypted domain,\nit is hard for the entities performing the computation to run any check on the adequacy of\nthe inputs. To solve this problem, many primitives build on Zero-Knowledge Proofs (see the\nCryptography Knowledge Area (Section 10.9.1)) to prove to the entity performing the com-\nputation that the inputs comply with a certain format or with certain constraints. We now\ndescribethreecasesinwhichverificationintheencrypteddomainiskeytoenablingtheuse\nofprivacy-preservingcryptographicprotocols.\nPrivate computation - input verification. Zero knowledge proofs are very well suited to en-\nsuring that the input to a privacy-preserving protocol is of a particular form or is not mali-\ncious. For instance, they have been used, among others, to prove the adequacy of inputs in\nbillingapplications,e.g.,thattheybelongtoasetofvalidinputs[488],orarewithinparticular\nranges [489], to prove that there are no malicious inputs when requesting information from\namessagingsystem[490],orwhenrunningaprivateintersectionprotocol[491].\nPrivate authentication. To maintain Confidentiality, entities participating in protocols may\nwanttoauthenticatetheircommunicationpartners.However,typicalAuthenticationsystems\narebasedonrevealingtheidentityoftheauthenticatingparty.Revealingone\u2019sidentity,inand\nof itself, may result in a privacy breach (e.g., when the authentication is against a sensitive\nservice,suchasamedicalservice).AsolutiontoavoidthisproblemistheuseofAnonymous\nCredentials,alsoknownasAttribute-BasedCredentials(ABCs)[449,492,493].\nInsteadof authenticatinganentitywith respect toanidentity inordertograntauthorisation,\nABCsenabletheentitytoprovepossessionofacombinationofdifferentattributestoobtain\nthesameauthorisation.Thisproofdoesnotrevealanyadditionalinformationabouttheentity\nauthenticating, nor does it reveal the concrete values of the attributes. Furthermore, ABCs\nare unlinkable between contexts. In other words, credentials look different every time they\nareshown,suchthatdifferentshowingscannotbelinkedtoeachother.\nWhile from the point of view of privacy, ABCs bring many advantages, they also introduce\nnew challenges. Anonymity may open the door to misbehaviour. Unfortunately, the strong\nAnonymity and Unlinkability properties provided by original ABCs do not allow an authority\nto limit or revoke authorisation for misbehaving users. In response, several schemes have\nappearedthatprovidecapabilitiestolimittheamountoftimesthatacredentialcanbeused\nbefore the user is identifiable [494]; capabilities to blacklist credentials so that access can\nbetemporarilyrevoked[495,496];orcapabilitiestocompletelyrevokethecredentials[497].\nThere exist several implementations of ABCs [498, 499] available under diverse licenses.\nTheseimplementationsofferdifferentsubsetsofthefunctionalitiesmentionedabove.\nPrivate payments. Verification of encrypted data is also key to enabling privacy-preserving\npayments,inwhichthepayermayhavetoprovetothebuyer,forinstance,thathehasenough\nfunds without revealing the exact amount. Early digital cash systems relied on Blind Sig-\nnatures (see the Cryptography Knowledge Area (Section 10.10)) to enable banks to sign e-\ncoins [450]. In a nutshell, to extend an e-coin to a client, a bank would blindly sign a random\nvalue.Tospendthee-coin,theclientwouldgivethisnumbertotheseller,whocouldredeem\nit at the bank. By storing the random number, banks can detect double spending, but not\nidentifythedoublespender.\nMorerecentprivacy-preservingpaymentschemes,liketheblockchain-basedZerocash[500,\nKAPrivacy&OnlineRights |October2019 Page177 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n501] system, include more information in the transactions to provide better guarantees. In\neach transaction, the user proves, in zero knowledge, that she owns the e-coins input to the\ntransaction;thateachoneoftheinpute-coinswaseitherrecentlymined(mintedinZerocash\nterms)orwastheoutputofaprevioustransaction;andthattheinputandoutputvaluesofthe\ntransaction are the same, i.e., no money would be lost. For the sake of efficiency, Zerocash\nrelies on particularly efficient zero-knowledge proofs called zero-knowledge Succinct Non-\ninteractive ARguments of Knowledge (ZK-SNARK) systems [502]. These proofs are shorter\n(intheorderofhundredsofbytes)andrelativelyfasttoverify.\n5.1.1.2 Obfuscation-basedinferencecontrol\nThe protocols discussed in the previous section provide strong (cryptographic) guarantees\nregarding the Confidentiality of data. Such strong protection, however, comes at the cost of\nefficiencyandflexibility.Ononehand,privacy-preservingcryptographicprimitivesrequiresig-\nnificantresourcesintermsofcomputationand\/orbandwidth.Ontheotherhand,theynarrow\ndownthetypeofprocessingthatcanbedoneondata.Thisisinherenttocryptographiccon-\nstructions that fix inputs and outputs, and strictly define what information will be available\naftertheprotocolisexecuted.\nInthissection,wedescribeapproachestoprotectdataConfidentialitybasedonobfuscating\nthedataexposedtoanadversary.ThesetechniquesprovideamorerelaxeddefinitionofCon-\nfidentialitythancryptography,inthesensethattheycannotcompletelyconcealinformation.\nInstead, their goal is to provide a way to control the extent to which an adversary can make\ninferencesaboutusers\u2019sensitiveinformation.Infact,formostofthesetechniques,thelevel\nofprotectiondependsontheconcretedataandadversarialknowledge.Thus,itisimportant\nto run an ad-hoc analysis for the inference capability, as explained in Section 5.5. Also, we\nnotethattheprivacygainedfromthesetechniquesisbasedonlimitingtheinformationavail-\nable to one\u2019s adversary. Consequently, these techniques reduce the amount of information\navailable for anyone and, hence, may have an impact on utility if the purpose of the applica-\ntionisbasedonsensitiveinformation,e.g.,findingmatchesondatingapplications.However,\nwe note that when the sensitive information is not crucial for the purpose of the application\nthese techniques may be deployed without affecting utility, e.g., a weather application that\ncanoperateusingveryrudimentarylocationdata.\nObfuscation-based inference control techniques are not suitable for protecting data in tran-\nsit, but can be used to support privacy-preserving outsourcing, privacy-preserving collabo-\nrative computations, and privacy-preserving publishing. There are four main techniques to\nobfuscate data, as described below. We note that these techniques are mostly oriented to\nobfuscate numerical or categorical fields. Obfuscating more complex content, such as free\ntext,isamuchmoredifficulttaskduetocorrelationsthatarehardtoremoveinasystematic\nmanner. To date, there are no known techniques that can reliably anonymise free text. How-\never,thesetechniquesarequiteeffectiveatreducingtheinformationleakedbyMetadata,as\nwediscussinSection5.1.2.\nForthesakeofillustration,letustakethefollowingmicrodatafileasacurrentexample.This\nisaverysimpleexample,andwestressthatthetechniquesintroducedbelowcanbeapplied\ntomanytypesofdataformatsanddomains.\nKAPrivacy&OnlineRights |October2019 Page178 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nName Age Gender ZIP Salary\nAlice 21 Female 21345 51300\nBob 32 Male 25669 67400\nCarla 25 Female 18934 51500\nDiana 64 Female 21223 60200\nEve 34 Female 18022 73400\nFrank 37 Male 25321 55800\nGerald 19 Female 18235 68900\nTable5.1:Anexampledatabase\nAnonymisation.Acommontechniqueusedtopermitdataprocessingwithoutriskforindivid-\nualsisdataanonymisation.Anonymisation,asitsnameindicates,seekstodecoupleidentity\nfrominformation.Theideaisthatremovingidentifyinginformationfromdatapointsmakes\nthemunlinkable(i.e.,theycannotbegroupedasbelongingtothesameentity),thushindering\ntheabilityoftheadversarytoperforminferencesfromthedata.\nHowever, achieving full Anonymity is extremely difficult. In fact, when a dataset can be de-\nclaredanonymousremainsunclear.Datainandonthemselvescontainsenoughinformation\ntocorrelatedifferentattributesand\/orrecordsonadatabase.Giventhesegroups,thereare\nmany techniques to re-identify individuals behind the data release. A key insight into under-\nstandingthedifficultyofanonymisationistheuniquenessofindividual\u2019sdatapatterns[503,\n504]. There may be many combinations of the information released in a dataset that are\nunique to an individual. These are called quasi-identifiers. Finding quasi-identifiers enables\nthere-identifieddatabymappingthemtoidentifyinginformationinotherdatasources[453,\n505].Thus,anonymisationiscommonlycombinedwiththeobfuscationtechniquesdescribed\nbelowtolimittheriskofre-identification.\nAt this point in the knowledge area, it is worth referring to the notion of k-anonymity, which\nadvocates combining generalisation and suppression in order to ensure that records on a\ndatabase are anonymous among (i.e., indistinguishable from) at least other k entries in the\nsame dataset [506]. For instance, in the example above, one can generalise the ZIP code to\nachievetwo-anonymity:\nName Age Gender ZIP Salary\n* 21 Female 21* 51300\n* 32 Male 25* 67400\n* 25 Female 18* 51500\n* 64 Female 21* 60200\n* 34 Female 18* 73400\n* 37 Male 25* 55800\n* 19 Female 18* 68900\nTable5.2:Anonymization:Atwo-anonymousdatabasethroughgeneralisation\nWhile this notion is promising, there are several factors that make it unappealing and hard\ntouseinpractice.First,duetotheuniquenessoftheproblemmentionedabove,obtainingk-\nanonymity may require an unacceptable amount of generalisation in the database. Second,\ndepending on the application, k-anonymity may not actually prevent inference of sensitive\nattributes. This is illustrated in our running example in the Gender column. Even though the\nKAPrivacy&OnlineRights |October2019 Page179 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ngeneralisationintheZIPcodeensurestwo-anonymity,theadversaryknowswitha100%prob-\nabilitythegenderoftheusersineachZIParea,e.g.,alluserslivingin21*arewomen.Similarly,\ntheadversarylearnsthatfemalesintheir20searnapproximately51000.\nToaddressthisissue,researchersarguethatprivacynotonlyrequiresk-anonymity,butalso\nl-diversity, which ensures that for each k anonymous individual, there are at least l possible\nvalues for the sensitive attribute [507]. Researchers have also shown that l-diversity can be\nbrokenandso-calledt-closeness,wherethesetofsensitiveattributesisnotonlydiversebut\nfollowsthegeneraldistributionforthisattributeacrossapopulation,isneeded[508].\nThe k-anonymity notion is very popular in health-related applications [509]. It has also been\nadaptedtofieldsotherthandatabases[510,511].\nGeneralisation.Thistechniqueconsistsinreducingtheprecisionwithwhichdataareshared,\nwith the goal of reducing the accuracy of the adversary\u2019s inferences. Generalisation can\nbe achieved via a direct precision reduction of the shared values, or a bucketisation (i.e.,\namappingfromvaluestoranges)beforedataarereleased.Thistechniquehasbeenapplied,\namongothers,fordatabaseanonymisation[506],reducingtheprecisionofthevaluesinthe\ndifferentcells;orinprivatewebsearches[512],wherewordsaremappedtotheclosestword\nofapre-definedset.\nName Age Gender ZIP Salary\nAlice 10\u201330 Female 21*** 51300\nBob 30\u201340 Male 25*** 67400\nCarla 20\u201330 Female 18*** 51500\nDiana 60\u201370 Female 21*** 60200\nEve 30\u201340 Female 18*** 73400\nFrank 30\u201340 Male 25*** 55800\nGerald 10\u201320 Female 18*** 68900\nTable 5.3: Generalisation: Reducing the precision of the ZIP code to the first two digits; re-\nducingtheprecisionoftheAgecolumnviabucketisation.\nSuppression.Thistechniqueconsistsinsuppressingpartoftheinformationbeforeitismade\navailable to the adversary. The rationale behind suppression is that the fewer the data are\nprovided to the adversary, the more difficult is for her to make inferences. The suppression\nstrategy, which decides which information to hide, is key for the level of privacy protection\nthatsuchaschememayprovide.Forinstance,suppressinginformationatrandomisunlikely\ntodestroythepatternsinthedatathatallowforinferences.Thus,unlessmostofthedataare\ndeleted, this strategy seldom provides good protection. A common strategy is small count\nsuppression, where aggregated values below a threshold are not reported. The level of pro-\ntection of this strategy depends on the type of access to the data and the knowledge of the\nadversary[513].Othersuppressionstrategies,tailoredtothenatureofthedataunderconsid-\neration and their characteristics [514, 515] provide better privacy results. This technique has\nbeenapplied,amongothers,fordatabaseanonymisation[506],tohidesomeofthevaluesin\nthe different cells; or in location data publishing [514], to hide location samples that provide\ntoomuchinformation.\nKAPrivacy&OnlineRights |October2019 Page180 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nName Age Gender ZIP Salary\nAlice 21 Female 21345 51300\nBob 32 Male 25669 67400\nCarla 25 * 18934 51500\nDiana 64 * 21223 60200\nEve 34 Female 18022 73400\nFrank 37 * 25321 55800\nGerald 19 Female 18235 68900\nTable5.4:Suppression:SuppressionoftheGenderattributefor50%oftherecords.\nDummy addition. This technique consists in adding fake data points, so-called dummies, to\nthe data made available to the adversary in order to hide which are the real samples. The\nidea is that, as the adversary considers fake points when running the attack, her inference\nwillhaveerrors.Forthisdefensetobeeffective,fakepointshavetobeindistinguishablefrom\nreal points. Ideally, from the point of the view of the adversary, any sample should look like\narealordummyone withequalprobability.However,creating suchindistinguishablepoints\ntendstobedifficult[516],andtheadversarycaneasilyfilterthemout.Thus,thistechniqueis\nusefulinveryfewdomains.Dummyadditiontechniqueshavebeenusedtoincreaseprivacy\ninwebsearches[512,517]ortoprotectdatabasesfrominferences[518].\nName Age Gender ZIP Salary\nAlice 21 Female 21345 51300\nBob 32 Male 25669 67400\nCarla 25 Female 18934 51500\nDonald 54 Male 25669 53500\nDiana 64 Female 21223 60200\nEve 34 Female 18022 73400\nFrank 37 Male 25321 55800\nGoofy 61 Male 21346 41500\nGerald 19 Female 18235 68900\nMinnie 23 Female 18456 62900\nTable5.5:Dummyaddition:Adding50%offakerecords(inred).\nPerturbation.Perturbationtechniquesinjectnoiseintothedatamadeavailabletotheadver-\nsary. The noise is aimed at reducing the adversary\u2019s inference performance. Similar to sup-\npressiontechniques,thestrategyusedtointroducenoiseplaysacrucialroleinthelevelofpri-\nvacyprovided.Initialschemesdrewnoisefrommanykindsofrandomdistributions[519,520]\nand added them to the data. This approach was not really effective, as an adversary with\nknowledge of the noise distribution could infer the original data values with reasonable ac-\ncuracyandthusriskedleakingmoreinformationthanintended.\nKAPrivacy&OnlineRights |October2019 Page181 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nName Age Gender ZIP Salary\nAlice 21 Female 21345 51345\nBob 32 Male 25669 67863\nCarla 25 Female 18934 51053\nDiana 64 Female 21223 60302\nEve 34 Female 18022 74558\nFrank 37 Male 25321 55005\nGerald 19 Female 18235 69425\nTable 5.6: Perturbation: Obfuscating salary with noise drawn from a normal distribution\nN(0,1000).\nCurrently, the gold standard in perturbation-based techniques is to add noise to achieve so-\ncalled differential privacy. The main goal of this technique is to address the limitations of\ndataanonymisationtechniquesforpublishingsuchastheaforementionedk-anonymity.\nDifferentialprivacy,introducedbyDwork[521],isaprivacydefinitionoriginallyintendedtoen-\nable the design of techniques that permit maximising accuracy when querying statistical in-\nformation(mean,variance,medianetc.)aboutusersonadatabasewhileminimisingtherisk\nofunintendedinferences.Ratherthanapropertyofadataset(likethetechniquesabove),dif-\nferentialprivacyisapropertyofamechanismusedtooutputtheanswerstoqueriesagainst\na dataset. An algorithm is differentially private if, by looking at the result of the query, the\nadversary cannot distinguish whether an individual\u2019s data were included in the analysis or\nnot. More formally, an algorithm A provides (cid:15)-differential privacy if, for all datasets D and\n1\nD thatdifferonasingleelement(i.e.,thedataofoneindividual),andallpossibleoutputsS\n2\nofthealgorithm:\nPr[A(D ) \u2208 S] \u2264 e(cid:15) \u00d7Pr[A(D ) \u2208 S],.\n1 2\nDifferentialprivacyensuresthat,givenaperturbeddatasample,theadversarygainsanegli-\ngibleamountofnewinformationabouttheoriginaldatasamplewithrespecttotheherprior\nknowledge,regardlessofwhatthispriorknowledgewas.Thereexistanumberofalgorithms\ntoensurethatdifferentialprivacyismetforavarietyofqueries[451].\nDifferential privacy is an extremely useful definition because it gives a formal framework to\nreason about the amount of information a powerful adversary might be able to infer about\nindividuals in the data, regardless of the adversary\u2019s prior knowledge. However, it must be\nnotedthat:\n\u2022 Differential privacy provides a relative guarantee, as opposed to an absolute privacy\nprotection. This means that the protection provided is regarding the prior knowledge\nof the adversary. If the adversary already has full knowledge, differential privacy will\nnotimproveprivacy.Inotherwords,differentialprivacyensuresthatthereleaseofdata\ndoes not worsen the privacy loss of a user or population by more than a set threshold.\nHowever, this does not automatically ensure that a user\u2019s privacy is preserved overall.\nTherefore, to claim privacy, it is important to not only ensure that a scheme provides\na given guarantee, but also computes the adversarial error on the inferences so as to\nensurethatusers\u2019sensitiveinformationisactuallyprotected(seeSection5.5).\n\u2022 One of the current practical challenges of differential privacy is to determine what val-\nues of (cid:15) provide an acceptable level of privacy. The level of protection of crucially de-\nKAPrivacy&OnlineRights |October2019 Page182 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\npends on the value of this parameter. This means that merely fulfilling the differential\nprivacy definition with arbitrary parameter values does not directly guarantee that the\nadversary does not learn too much new information from the data. It is important to\nensure that the value of (cid:15) is such that the probabilities for different inferences are ac-\ntually indistinguishable. For example, if (cid:15) = 3, this only ensures that the ratio between\nthe probability of observing a result when an individual is, or is not, in the dataset is:\nPr[A(D ) \u2208 S]\/Pr[A(D ) \u2208 S] \u2264 e3 = 20.08. This probabilistic difference can typ-\n1 2\nically be detected by classical statistical detectors, or any modern machine-learning\nclassifier. In general, (cid:15) values greater than one deserve a closer look to verify that the\nalgorithmsprovidethesoughtlevelofprotection.\n\u2022 Theamountofnoiserequiredtohinderinferencesonthedatadependsontheso-called\nsensitivity of the algorithm. Sensitivity measures how much a change in the input will\nchange the output of the algorithm A. When the input is a database and the output a\nstatistical function,small inputchanges have little influenceon theoutput and, thus,a\nsmall amount of noise is enough to make the algorithm differentially private. We note,\nhowever,thatwhendifferentiallyprivatealgorithmsareappliedtoprotecttheprivacyof\nasinglesampleinsteadoftotheresultofastatisticalqueryonadatabase,thesensitiv-\nitymaybemuchhigher.Thus,onlyalargeamountofnoisemayensureprotection.For\ninstance,whendifferentialprivacyisappliedtoobfuscateauser\u2019sreportedpositionto\nobtainlocationprivacy,protectionmaybelessthanexpectediftheparametersarenot\ncarefullychosen[522].\n\u2022 Differential privacy provides a worst-case guarantee, which means that the amount\nof noise introduced is tailored to bound the leakage given by the data point in the\ndataset that provides the most information to the adversary with the best knowledge.\nThismeansthatinanaveragecasetheamountofnoiseislargerthanneeded.Recent\nstudies have been working towards tighter bounds that permit reduction in the noise\nrequiredtoprovideadesiredprotectionlevel[523].\nThedifferentialprivacynotionhasbeenextendedtoaccountformetricsotherthantheHam-\nmingdistance(i.e.,distinguishingwhetheroneindividualisinadatabaseornot)[524].Pertur-\nbationswithdifferentialprivacyguaranteeshavebeenusedtoprotect,amongothers,privacy\nin collaborative learning [525], or locations when querying location-based services [526]. It\nhasalsobeenrecentlyadoptedbytheUStoprotectcensusdata[527].\nFinally, it is important to remark that for many real cases, one of these inference controls\ncannotprovideenoughprivacyonitsown.Therefore,typicallyoneneedstocombineseveral\nofthesetechniquestolimitthenumbersofinferencesthatcanbemade.\n5.1.2 Metadata Confidentiality\nIn the previous section, we discussed means to protect the Confidentiality of the contents\nofmessages,databases,queries,etc.Thesetechniquesareessentialtoensureprivacy.Yet,\ntheydonotprotectagainstanadversarythatusestheMetadatatoinfersensitiveinformation\naboutindividuals.Concretely,therearethreetypesofmetadatathathavebeendemonstrated\nto be extremely vulnerable to privacy attacks: traffic metadata, associated to the communi-\ncationinfrastructure;devicemetadata,associatedwiththeplatformgeneratingthedata,and\nlocationmetadata,associatedwiththephysicallocationfromwhichdataisgenerated.\nInthissection,wediscusstheprivacyrisksassociatedwiththesetypesofmetadataandthe\nrelevantcontrolstoaddresstheserisks.\nKAPrivacy&OnlineRights |October2019 Page183 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nTrafficMetadata.Network-layerinformation,suchastheidentitiesoftheparticipantsinthe\ncommunication(IPaddresses),theamountandtimingofthedatatransferred,ortheduration\nof the connection, is accessible to observers even if communications are encrypted or ob-\nfuscated. This information, commonly known as traffic data, can be exploited to deduce po-\ntentiallysensitiveprivateinformationaboutthecommunication.Forinstance,inane-health\ncontext, messages are generally encrypted to preserve patients\u2019 privacy. However, the mere\nfact that a patient is seen communicating with a specialised doctor can reveal highly sen-\nsitive information even when the messages themselves cannot be decrypted. Confidential\ncommunicationsarenotonlydesirableforpersonalreasons,buttheyalsoplayanimportant\nroleincorporateenvironments.Thebrowsinghabitsofacompany\u2019semployees(e.g.,access-\ning a given patent from a patent database) can be used to infer the company\u2019s future lines\nof investment, thus giving an advantage to their competitors. Finally, even if the identity of\nthe communicating parties is innocuous, encrypted flows can reveal search keywords [528]\norevenconversations[529].\nAtechniquetoprotecttrafficdataistheuseofanonymouscommunicationsnetworks.These\nnetworks are typically formed by a series of relays such that communications do not travel\ndirectlyfrom origin todestination, but are sent fromrelaytorelay. These relays alsochange\nthe appearance of a message through means of Encryption to provide bitwise Unlinkability,\ni.e.,toensurethatpacketscannotbelinkedjustbylookingattheirbitcontent;theycanalso\nchangetrafficpatternsbyintroducingdelays,re-packagingmessages,orintroducingdummy\ntraffic.\nAnonymouscommunicationsnetworksfollowdifferentdesignsregardinghowtheinfrastruc-\nture is built (by users or dedicated relays), how they consider communications (message-\nbased vs. flow-based), or how they reroute messages (deciding a route at the source, or\nletting relays decide on routing), among others. In the following, we focus on the two most\nknown anonymous communications network types which have real-world deployment. We\nrefer readers to the surveys by Danezis et al. [530] for a historical overview of anonymous\ncommunications and by Shirazi et al. [454] for a comprehensive overview of more recent\nanonymouscommunicationsystems.\nThemostpopularanonymouscommunicationnetworkisTor2 [531].Thecoreelementofthe\nTor Network are Onion Routers (ORs), which are essentially routers that forward encrypted\ndata. ORs encrypt, respectively, decrypt packets along the way to achieve bitwise unlinkabil-\nity, as detailed below. When a user who wants to anonymously access an Internet service\nthrough the Tor network, she installs a Tor client in her device. This software builds a cir-\ncuitofconnectionsoverthreeORs,calledentry,middleandexitnodes,andtheclientroutes\nencryptedtraffictothedestinationserverthroughthiscircuit.\nTor uses so-called onion encryption, in which the client establishes a secret key with each\nof the ORs in the circuit using an adapted version of authenticated Diffie-Helmann (see the\nCryptography Knowledge Area (Chapter 10)). Every packet routed through the circuit gets\nencrypted with these three keys, first with the exit OR\u2019s key, then the middle OR\u2019s key, and\nfinally that of the entry OR. When the message travels through the circuit, the nodes \u2018peel\u2019\neachlayerofencryptionuntiltheoriginalpacketissenttothedestination.Theserversends\ndatatotheclientusingthesamecircuit,butintheinverseorder;i.e.,theserverencryptsthe\nmessage in layers that are decrypted by exit, middle, and entry ORs. In order to support low-\nlatencyapplications,OnionRoutersdonotimposedelaysonthemessagestheyreceiveand\nresend. Thus, traffic patterns are conserved while packets travel through the network. This\n2https:\/\/www.torproject.org\/\nKAPrivacy&OnlineRights |October2019 Page184 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nenablesanadversarywiththecapabilitytoobservebothendsofthecommunication(i.e.,the\nentryandexitnodes)tocorrelateincomingandoutgoingflowsinordertolinktheoriginand\ndestinationofcommunications[532].\nAt this point it is important to highlight the difference between using Tor and using a Virtual\nPrivate Network (VPN). Both technologies give the protection against an adversary that ob-\nservesonlyonesideofthecommunication,andbothfailtoprotectagainstanadversarythat\ncan see both extremes. However, while in Tor no single relay can on itself learn the link be-\ntweensenderandreceiver(i.e.,thetrustmodelisdecentralized),inaP3Ptheprovideractually\nknowsthiscorrespondenceandthusisasinglepointoffailure.\nInordertodestroytrafficpatternsandprotectcorrelationattackrelaysinananonymouscom-\nmunication,networksneedtodelaypacketsoraddnewones.Thisistheprinciplebehindthe\ndesignofmixnetworks[533].Asopposedtoonionrouting,whereallthepacketsfromacom-\nmunication are routed through a circuit, in mix-based communications routes are selected\nforeverymessage.Then,whenamixrelayreceivesapacket,insteadofimmediatelydecrypt-\ningandsendittothenexthoponthepath,themessageisdelayed.Howmanymessagesare\ndelayedisdeterminedbyafiringcondition,whichisaneventsuchasthearrivalofamessage\nor the expiration of a timeout that causes the mix to forward some of the messages it has\nstored. Which messages are fired depends on the batching strategy, which can select all of\nthe messages or a fraction according to a probabilistic function. Both mixes and users can\nsenddummytraffic,whichmaybeabsorbedbyothermixesorbytherecipient.\nA mix network designed to provide low latency is Loopix3 [534]. As opposed to Tor, where\nusers\u2019clientscommunicatedirectlywiththeTornodes,Loopixassumesthatuserscommuni-\ncatewithprovidersthatinturnsendmessagestoeachotherthroughtheLoopixanonymous\ncommunicationnetwork.ProviderschoosearandomroutecomposedofLoopixroutersand\nsend the message to the first node. Similar to Tor, messages get encrypted with the keys of\neachoftheseroutersusingtheSphinxpacketformat[535].InadditiontotheEncryption,mes-\nsagesareassignedadelayforeveryrelaytheyvisitaccordingtoanexponentialdistribution.\nFinally, providers inject dummy traffic into the network by sending packets to themselves\nvia a Loopix path, so as to provide cover for real messages. The combination of providers\nthat hide mix messages from users sending (respectively receiving) messages at the same\ntime, delays and cover traffic enable Loopix to provide provable guarantees regarding the\nUnlinkabilityofthesendersandreceiversofmessages.\nDeviceMetadata.Intoday\u2019soptimisedInternetservices,theconcretecharacteristicsofusers\u2019\ndevices are frequently sent along with their data requests in order to optimise the service\nproviders\u2019 responses. Even if users are anonymous on the network layer, these characteris-\ntics may become a quasi-identifier that enables service providers to track users across the\nweb[536,537].ThisisbecausecombinationsoffeaturessuchastheUserAgent(thebrowser\nsoftware vendor, software revision, etc.), its Language, or the Plugins it has installed, or the\nplatformaremostlyunique.4.\nDevice or browser fingerprinting is the systematic collection of this information for identifi-\ncation and tracking purposes. A large number of attributes, such as browser and operating\nsystemtypeandversion,screenresolution,architecturetype,andinstalledfonts,canbecol-\nlected directly, using client-side scripting and result in unique fingerprints. When this infor-\nmation is not directly available, other techniques can be used to learn this information, as\n3https:\/\/katzenpost.mixnetworks.org\/\n4https:\/\/amiunique.org\/,https:\/\/panopticlick.eff.org\/\nKAPrivacy&OnlineRights |October2019 Page185 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nexplainedbelow.\nAsanillustrativeexample,letusconsiderthelistoffontsinstalledonaparticularuser\u2019sweb\nbrowserasanidentifierthatenablestracking.Therearetwotechniquestoobtainthelistofin-\nstalledfonts,whichisknowntoprovideagoodlevelofuniqueness.Thisisbecausebrowsers\ninstall fonts on demand depending on the sites visited. Since users have different browsing\npatters,theirlistsofinstalledfontsbecomedifferentaswell.Fontfingerprintingtechniques\nexploitthefactthatifafontisinstalled,browserswillrenderit,butifnot.browserswillrevert\nto monospace font. Thus, depending on whether a font is installed or not, sentences will be\nrendereddifferently.Inthefirsttechnique,thetrackingwebsendsasentencetothebrowser\nto be printed with a series of fonts. Then, the client-side script checks the size of each sen-\ntence. When the size is equal to the sentence printed in monospace, the tracker learns that\nthe font is not installed. A similar technique is called canvas fingerprinting. In this case, the\ntrackerexploitstheHTML5Canvasfeature,whichrenderspixelsonthefly.Asbefore,differ-\nentfontsizeresultindifferentpixelfootprints.Measuringtheresultofthecanvasrendering\nthetrackercanascertainwhichfontsareinstalledinabrowser.\nDefendingagainstdeviceMetadataattackswhileretainingutilityisextremelydifficult.Onthe\nhand,hidingthesemetadatafromserviceprovidershasanimpactontheperformanceofthe\nservices,sinceitlimitspersonalisationanddeterioratestherenderingofinformation.Onthe\nother hand, it is hard to establish which combination of features would actually make users\nindistinguishablefromotherusers.Thisisbecausewehavenoknowledgeofthedistribution\nof fingerprints in order to imitate one of them, and trying combinations at random runs the\nrisk of being as unique as the original fingerprint [538]. Therefore, mechanisms need to be\ncarefullycraftedandevaluated[539].\nWe note that besides tracking based on metadata, trackers also use a series of techniques\nbased on the use of cookies. For instance, web pages can include cookies from third par-\nties, which allows these parties to detect when users revisit a page [540]. Third parties can\nalso use cookie syncing, whereby, besides adding their own tracking, webs redirect cookies\ntoothertrackerstoinformthemofwheretheusersaregoing[541].Finally,thereexistperva-\nsive mechanisms to install cookie-like information that cannot be removed by cleaning the\nbrowser\u2019scache[447].\nLocationmetadata.Finally,auser\u2019sgeographicallocationrevealedtoonlineservicescanbe\nused to infer sensitive information. This information can be revealed explicitly, for example,\nwhen the user makes queries to location-based services to find nearby points of interest\nor friends; or implicitly, for example, when GPS coordinates are associated with photos or\ncontent published on social networks, or inferred from the access point used to access the\nInternet.\nClustering techniques to find groups of nearby points where the user spends not significant\namountsoftimecanbeusedtoinferusers\u2019pointsofinterestsuchaswheretheylive,where\nthey work or their favourite leisure places. In many cases, points of interest can be used\nas quasi-identifiers for users. For instance, the three most commonly visited locations are\nunique to a user in a majority of cases, even when the locations are provided on a more\ngeneral level (e.g., US counties) [542]. Similarly, the types and patterns of locations visited\ncanbeusedtoinferdemographicdataaboutuserssuchasageorgender[543].Furthermore,\nonce movement patterns have been characterised, they can be used to predict individuals\u2019\nfuturemovements[544].\nThere are two kinds of defence for protecting location Metadata in the literature. The first\nKAPrivacy&OnlineRights |October2019 Page186 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nrelies on cryptographic techniques to process location-based services\u2019 queries (see Sec-\ntion 5.1.1.1). For instance, users can privately learn whether a friend is nearby. This service\ncan be realised by Homomorphic encryption encryption [545], private equality testing [546]\nor private threshold set intersection [547]. The second kind of defence is based on the ob-\nfuscation techniques described in Section 5.1.1.2 in order to control the inferences that an\nadversary draws from the location data. For instance, user\u2019s location can be hidden [548],\ni.e., not reported to the provider; perturbed [549], i.e., reporting a location different from the\nuser\u2019sactualposition;generalised[550],i.e.,reportedwithlessprecision;oraccompaniedby\ndummylocationssothattheuser\u2019srealmovementpatternscannotbeidentified[551].\n5.2 PRIVACY AS CONTROL\n[552][553][554]\nIn the previous section, we discussed privacy technologies that keep data confidential, by\nminimising the collection of data and\/or minimising the amount of information that can be\ninferred from any released data. A wider notion of privacy, which is usually referenced in\nregulations, broadens privacy from the notion of concealment of personal information, to\ntheabilitytocontrolwhathappenswiththeinformationthatisrevealed[441,443].\nThe idea behind the shift from technologies that minimise disclosure to technologies that\nprovide the means to control information use, is that in many cases, revealing data may be\nunavoidable or perceived as beneficial to the data subject. Thus, it is advisable to consider\nthe use of technologies that address two major concerns: i) enable users to express how\ntheyexpectthatdatadisclosedtotheserviceproviderareused,soastopreventundesirable\nprocessing of these data; and ii) enable organisations to define and enforce policies that\npreventthemisuseofinformation,asdefinedbytheusers.\nIn this section, we revise techniques that have been designed under the privacy as control\nparadigm.Wefocusontechniquesforthecreationandconfigurationofgoodprivacysettings\nthat help users express their preferences with respect to data disclosure and processing;\nand techniques that support the automated negotiation of privacy policies across services.\nBecause much of the protection relies on trust, privacy technologies that enhance privacy\nin a system through improved control are less numerous and varied than those designed to\nachieveConfidentiality.\nIt is important to highlight that these techniques inherently trust the service provider that\ncollects the data to correctly enforce the policies established by the user with respect to\nthird parties, as well as not to abuse the collected data itself. Also, as noted by Acquisti et\nal. [552], providing users with tools to control information flows can reduce risk perception\nandincreaserisk-taking,effectivelyreducingtheoverallprivacyofusers.\nKAPrivacy&OnlineRights |October2019 Page187 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n5.2.1 Support for privacy settings configuration\nPrivacy settings are those controls in a web service that allow users to express their prefer-\nences regarding how data should be revealed to other users, shared with third parties, and\nprocessedbytheserviceproviders.Madejskietal.haveshownthatthecomplexityofthese\nprivacysettingsmakesthembarelyusablebyindividuals[553].Thislackofusabilitycauses\nusers to misconfigure their privacy settings, i.e., establish configurations that do not match\ntheir expectations. This in turn results in unintended disclosure of data. We refer readers to\nthe Human Factors Knowledge Area (Chapter 4) for further information about the impact of\nusabilityofsystemsonsecurityandprivacy.\nTo counter this problem, researchers have proposed a number of techniques whose goal\nis to identify groups of individuals that share certain characteristics, and then establish the\nmost adequate settings for each user group. One area of research suggests letting security\nand privacy experts define what are the best policies are. [555]. This approach, however, is\ndifficulttogeneralisefromtargetedgroupstothegeneralpopulation,andinmanycasesmay\nresultinstrategiesthatoverestimatetheneedforprotection.Thisinturnlimitstoomuchthe\nsharingandprocessingofdata,thusrenderingsystemsunusable.Otherproposalsadvocate\nfor using machine-learning techniques to infer adequate settings for a user based on the\nsocial graph of a user\u2019s friends and acquaintances [535]. This technique, however, requires\nusers,oracentralisedrecommendersystem,toknowauser\u2019ssocialgraphinordertoperform\nthe inferences, which raises privacy concerns in itself. A third approach does not require\nknowledgeofauser\u2019ssocialgraph,buttriestofindadequateprivacysettingsbylookingata\nlargersetofusers.[556].Asopposedtotheprevioustechnique,auser\u2019ssuggestedsettings\npreference is derived from generic data. These techniques have been shown to be prone\nto produce policies that are valid for the majority of users, but often discriminate against\nusergroupswithspecificprivacyrequirementssuchasactivistsorpersonsofpublicinterest.\nFurthermore,ML-basedtechniquesoftenaugmentandperpetuatebiasespresentinthedata\nfromwhichtheinitialpoliciesareinferred.Afinalresearchareassuggestscrowdsourcingthe\noptimumcompositionofthesepolicies[557].Thesetechniquesaremoreflexibleinthesense\nthat users have more leeway to influence the policies. However, they are still influenced by\nmajorityvotesandmaynotbeidealforuserswhodonotfollowmainstreampractices.\n5.2.2 Support for privacy policy negotiation\nThe previous technologies support users at the time of configuring their privacy settings in\nanonlineservice.Anorthogonallineofworkisdedicatedtoautomatingthecommunication\nofuserpreferencestotheservice,orbetweenservices.\nTechnologiessuchastheW3C\u2019sPlatformforPrivacyPreferencesProject(P3P)[558],which\nfacilitatethecommunicationofsettingpreferencesbetweenuserandserviceprovider.P3P\nis an industry standard that allows websites to encode their privacy policies (what informa-\ntioniscollected,howitisusedetc.)inapre-definedformat.Thesepoliciescanbereadand\ninterpreted by browsers equipped to do so. The browser can then compare the site\u2019s policy\nwith a user\u2019s specified privacy preferences written in a machine readable language such as\nP3PPreferenceExchangeLanguage(APPEL)[559].P3P,however,doesnothaveanymeans\ntoenforcethattheserviceprovideractuallyfollowsthepracticesdescribedinthepolicy.\nOther technologies such as purpose-based access control [560] or sticky policies [561] pro-\nvide the means to specify allowed uses of collected information, and to verify that the pur-\nposeofadataaccessiscompliantwiththepolicy.Thesetechnologiescanbesupportedby\nKAPrivacy&OnlineRights |October2019 Page188 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ncryptographic mechanisms that guarantee that the service providers must comply with the\npreferencesestablishedbyusers.\n5.2.3 Support for privacy policy interpretability\nInordertoconfiguretheprivacysettingsaccordingtotheirexpectationsofhowdatashould\nbe handled, users need to understand the privacy policies that describe the meanings of\nthese settings. These policies are often long, verbose, and contain a lot of legal terms; and\ntheyoftenevolveovertime.Thus,usersfindthemdifficulttounderstand.Researchershave\ndevelopedtechnologiesthatenhanceusers\u2019abilitytointerpretprivacypolicies.\nCurrently, there exist two approaches to improve users\u2019 understanding of privacy policies.\nOneistotrustexpertstolabel,analyseandprovidereasonsforexistingprivacypolicies[562].\nAnother avenue is to completely automate the interpretation process. Polisis5 [554] is a\nmachine-learning-based framework that enables users to ask questions about natural lan-\nguage privacy policies. This tool offers a visual representation of the policy specifying the\ntypesofdatacollected,thepurposeofthiscollection,andthesharingpractices,amongoth-\ners.\n5.3 PRIVACY AS TRANSPARENCY\n[563][564][565]\nThelastprivacydesignparadigmweconsiderisprivacyastransparency.Asopposedtotech-\nnologies that limit data disclosure or the use of disclosed data, transparency mechanisms\nanalyseusers\u2019onlineactivitiesinordertoeitherprovidethemwithfeedbackabouttheimpli-\ncationsoftheiractions,orrunauditstocheckthattherehasbeennoviolationofprivacy.\nAswithcontrol-orientedtechnologies,transparency-basedprivacycannotpreventprivacyvi-\nolationsinandofthemselves.Infact,feedbackorauditshappenaftertheusershavealready\ndisclosed data to the provider. Thus, providers are again trusted with making sure that the\ncollecteddataarenotprocessedorsharedinwaysnotauthorisedbytheusers.\n5.3.1 Feedback-based transparency\nWe first describe mechanisms that make transparent the way in which information is col-\nlected, aggregated, analysed and used for decision making. The common factor between\nthese technologies is that they provide users with feedback about how their information is\nprocessedorperceivedbyothers.\nAnearlyeffortinthisdirectionistheconceptofprivacymirrors[563],whichshowuserstheir\n\u2018digitalselves\u2019;i.e.,howothersseetheirdataonline.Thisconceptwasadoptedbypopularon-\nlinesocialnetworkssuchasFacebook,whichallowsuserstocheckhowdifferentaudiences\n(e.g., friends, friends of friends, others), or even individual users, see their profiles whenever\nthey make changes to their privacy controls. A similar line of work provides other means of\nvisualisinghowprivacysettingsaffectdatasharinginordertoimproveusers\u2019understanding\nofthesetofpermissionstheyhaveselected.Thissolutionprovidesvisualcuestousersthat\nindicate the access permissions associated with the data they shared [566]. For instance,\nit can highlight fields in a social network profile with a different colour depending on who\n5https:\/\/pribot.org\/polisis\nKAPrivacy&OnlineRights |October2019 Page189 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nhas access to that particular information. Both solutions help users understand their prac-\ntices and modify their actions. However, they can only do so after the information has been\nrevealedtotheprovider(andpossiblytootherusers).\nA different type of user feedback comprises so-called privacy nudges [564]. Nudges assist\nusersinmakingchoicesabouttheirprivacyandsecuritysettings.Theygiveusersimmediate\nfeedbackwhenevertheuserperformsanonlineactioninawaythattheactioncouldbecan-\ncelledormodified.Forinstance,thenudgecaninformtheuserthatthepostsheiscurrently\nwriting is public so that the user is careful about the words she chooses to use. Nudging\ntools can be even more sophisticated and use modern machine learning algorithms to anal-\nysephotosortextastheyarebeinguploaded,andprovideuserswithmoreconcretefeedback\nsuchas\u2018thepostcanbeperceivedasnegative\u2019or\u2018thephotoisveryexplicit\u2019.Whileimmediate\nfeedback presents evident benefits compared to mirrors, since actions can be modified be-\nfore information is sent to the provider, it also has drawbacks. Experiments with users have\nshown that immediate feedback results in an uncomfortable feeling for users as they feel\nmonitored,anduserssometimesperceivetheadviceaspaternalisticandoutofplace[565].\n5.3.2 Audit-based transparency\nAsmentionedbefore,evenwithprivacypoliciesandaccesscontrolinplace,thereisnoguar-\nantee that user preferences will be respected. Additional measures can be put in place to\nenableuserstoverifythatnoabusehastakenplace.Torealisetheseaudits,thesystemisre-\nquiredtologalldataaccessandprocessingoperations.Thisloggingmayrevealwhenusers\nlogintothesystem,andwhenandhowtheirdataaretransmittedtoothers.Thus,depending\non the amount and granularity of the information, logging may introduce additional privacy\nrisks.\nTherefore,loggingpoliciesmustbecarefullycrafted.Oneapproachtodothisistoderivethe\nauditing specifications from the policies using formal methods [567]. This guarantees that\nthe generated logs, while being minimal, still contain enough information to audit whether\nthe policies are being respected. The solutions, however, are limited in their expressiveness\nand cannot handle privacy policies in modern systems where the amount of data collected\nandthenumberofentitiesinvolvedmakeaformalanalysisextremelycumbersome.\nTheuseofformalmethodsassumesthatdatasharingismanagedbyacentralisedauthority\nthatmustbetrusted.Thisisproblematicbecausethecentralisedauthoritybecomesasingle\npointoffailure.Recentadvancesincryptographyanddistributedledgerspermitthedesignof\nsolutionsthatprovidethemeanstocreatehighlysecurelogs,whileensuringthatnoprivate\ninformationissharedwithunauthorisedparties.Whenloggingismadeinsuchadistributed\nmanner, no individual party can modify the log on its own, reducing the need for trust and\neliminatinganysinglepointoffailure.Forinstance,systemslikeUnLynx[568]permitentities\nto share sensitive data, and perform computations on them, without entrusting any entity\nwith protecting the data. All actions are logged in a distributed ledger for auditing, and the\ncorrectnessoftheoperationsisensuredbyusingverifiablecryptographicprimitivesandzero-\nknowledge proofs. Therefore, it is not necessary to publish or log the sensitive data or the\noperationsdoneonthem.\nKAPrivacy&OnlineRights |October2019 Page190 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n5.4 PRIVACY TECHNOLOGIES AND DEMOCRATIC VALUES\n[569][570][571]\nPrivacy technologies are of paramount importance to ensure that our fundamental right to\nprivacy is respected in the digital world. Privacy protection is crucial for underpinning the\nvalues that support our democratic societies. Citing Daniel Solove: \u2018Part of what makes a\nsociety a good place in which to live is the extent to which it allows people freedom from\nthe intrusiveness of others. A society without privacy protection would be suffocation\u2019 [571].\nWhilesuchasocietyseemedsciencefictionnotsolongago,episodessuchastheFacebook\nCambridgeAnalyticacasehighlighttheimportanceofsecuringdatafrombeingaccessedby\nunintendedparties(e.g.,usingConfidentialityorcontroltechniques)toprotectcitizensfrom\ninterferenceandmanipulation.\nIn this section, we provide two examples that highlight the importance of privacy technolo-\ngies in supporting democracy. On one hand, we consider electronic voting systems that en-\nable fair elections to take place using electronic infrastructure in adversarial conditions. On\nthe other hand, we give an overview of censorship resistance technologies. These systems\nensure that in a digital world, where communication infrastructure is dominated by a small\nnumberofcompaniesandstateactorscanobserveallcommunications,individualshavethe\nmeanstocommunicatefreely.\n5.4.1 Privacy technologies as support for democratic political systems\nThegrowinguseofelectronicapplicationstointeractwithgovernmentalbodiesbringsgreat\nadvantages to society. Providing citizens with easy means to express their opinions, com-\nmentongovernmentinitiatives,orvoteinelections,increasestheirinvolvementinpublicde-\ncision processes. This in turn improves the power balance between those who can execute\ndecisionsandthosewhoareaffectedbytheoutcomeofthedecisionprocess.\nFortheseimprovementstobeeffective,citizensmustbeabletofreelyexpresstheiropinions\nandmustbesurethattheirinputscannotbemodifiedorlostduringtheprocess.Theuseof\ncommon infrastructures (e.g., cloud services or unprotected communication networks) to\nimplement these democracy-oriented applications, however, raises concerns about surveil-\nlance and manipulation. Therefore, it is important that these applications are supported by\nstrong privacy technologies that can protect users\u2019 identities, as well as their sensitive data\nandinputstothesystem.Wedescribetwoexampleapplications,electronicvotingandelec-\ntronicpetitions,wherebythetechnologiesintroducedintheprevioussectionsarecombined\nto enable citizens and governments to enjoy technological progress without compromising\nourdemocraticvalues.\nElectronicvoting(eVoting).Electronicvotingsystemshavethegoalofenablingfairelections\nto be conducted via electronic infrastructure in adversarial conditions. In particular, eVoting\nschemesprovide:\n\u2022 Ballotsecrecy:anadversarycannotdeterminewhichcandidateauservotedfor.\n\u2022 Universalverifiability:anexternalobservercanverifythatallthevotescastarecounted\nandthatthetallyiscorrect.Someprotocolsprovideaweakerproperty,individualverifi-\nability,whereeachvotercanverifythathis\/hervotehasbeencorrectlytallied.Benaloh\netal. provideacomprehensiveoverviewoftheaspectstoassesstoobtainend-to-end\nverifiability[572].\nKAPrivacy&OnlineRights |October2019 Page191 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n\u2022 Eligibility verifiability: an external observer can verify that all the votes cast were made\nbyauniqueeligiblevoter.\nInordertoguaranteethefirstaspect,itiskeytobreakthelinksbetweenthevotesputtingtheir\nballots into the system, and the ballots that come out. In traditional pen-and-paper physical\nelections, this is done by mixing the ballots all of which have exactly the same appearance\nin an urn. In eVoting, Unlinkability is typically achieved using mix networks [573, 574]. the\nvotes are passed through a series of mixes, which must not belong to the same authority.\nOtherwise,thisauthoritycouldtracethevotesandlinkthevoterstotheirvotingchoices.The\nresults are published on a public bulletin board which anybody can read and verify that the\nelectionwascarriedoutinahonestmanner.\nVoting mix networks are designed in a slightly different way than those mentioned in Sec-\ntion.5.1.2.InthecaseofeVoting,themixesfirewhenallvotesarein,andthebatchingstrategy\nistotakeallthevotes.Insimpleterms,itensuresthatallvotesaremixedtogether,obtaining\nthemaximumAnonymityset.Thisfulfillstheballotsecrecycriterionasanyvotecouldhave\nbeencastbyanyvoter.Furthermore,toensureuniversalverifiability,ineVotingmixnetworks\neverynodedoesverifiableshuffles[569].Thismeansthatthemixesprove,inzeroknowledge,\nthat they mix all the votes (all the votes at the input appear at the output) and the mixing is\nrandom.Eligibilityverifiabilitycanbeobtainedbyrequiringvoterstoproveinzero-knowledge\nthattheyareeligibletovote.\nOther voting protocols provide ballot secrecy through the use of blind signatures: an autho-\nrised entity verifies the eligibility of a user and blindly signs her vote (i.e., without seeing the\nvote content) [575]. The user provides a zero-knowledge proof along with the vote that the\nvote has been correctly constructed. Then, users submit the signed votes to the tally server\nusingananonymouscommunicationchannel.Thiswaynoentityinthesystemcanlinkvoter\ntovotes.\nAthirdstrategyisbasedonHomomorphicencryptionencryption.Intheseschemes,thetally\nserver creates a bulletin board with encrypted zero entries for every candidate [576, 577].\nThen, every user adds his vote to the desired candidate, and randomises the rest of the en-\ncryptions (so that encryptions of the same number never look the same). As before, zero-\nknowledgeproofscanbeusedtoensurethatsumsandrandomisationhavebeenperformed\ninthecorrectway.\nBesides the above three properties, some voting protocols additionally aim to provide coer-\ncionresistance,wherebyausercannotbeforcedtovoteforaparticularcandidateagainsther\nwill.Onestrategytoimplementsuchasystemistoprovideuserswithfakecredentials[578].\nThen, when users are under coercion they follow the instructions of the coercer, but provide\ntheir fake credentials to the system. This enables the tally server to ignore any votes pro-\nduced under coercion. Related approaches prevent coercion via re-voting, i.e., the schemes\npermit users to recast a vote so as to cancel their coerced choice [579]. These schemes de-\nfinepoliciestoestablishhowtocountvoteswheneveragivencredentialhascastmorethan\nonevote.(e.g.,countthelastone,oraddapointertothecancelledvote).\nAnonymouspetitions.Wedefineapetitionasaformalrequesttoahigherauthority,e.g.,par-\nliamentoranotherauthority,signedbyoneormorecitizens.Signingapetitionpublicly,how-\never,mightraiseconcernsorconflictsintermsofrelationshipsbetweenfriends,colleagues,\nand neighbours, discouraging citizens from participation [580]. Privacy technologies, in par-\nticular, anonymous credentials, can help in creating secure and privacy-preserving petition\nsystems.\nKAPrivacy&OnlineRights |October2019 Page192 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nInpetitionsystemsbasedonanonymouscredentials,citizenscanregisterwiththeauthority\nmanaging the petition system to obtain an anonymous signing key associated with some\nattributesrelevantforthepetitions.Then,atthetimeofsigningaparticularpetition,theycan\nprove they are eligible (e.g., they are inhabitants of the municipality referred to) but do not\nneedtorevealtheiridentity.Advancedcredentialpropertiessuchasdoublesigningdetection\nenablethecreationofthissystemwhileavoidingabusefrommisbehavingcitizens[581].\nMoremodernapproachesrelyonadvancedcryptographicprimitivestoremovetheneedfor\nacentraltrustedpartythatregistersusers.Forinstance,Sonninoetal.[582]enablethreshold\nissuanceandverificationofcredentialstosignthepetition,i.e.,severalauthoritiesparticipate\nin the issuance. This scheme improves Confidentiality, authenticity, and availability through\nthe use of distributed ledgers. This approach increases the level of privacy in the system,\nwhileatthesametimereducingtheneedtotrustonesingleparty.\n5.4.2 Censorship resistance and freedom of speech\nCensorshipsystemsattempttoimposeaparticulardistributionofcontentacrossasystem.\nTheymaypreventusersfrompublishingparticularcontentthatisconsideredcontroversialor\ndangerousforthecensorshipregime;ortheymaypreventusersfromaccessingcontentthat\nmayunderminethesocietalequilibriumthatthecensorwishestoimposeontheirsociety.\nIn this section, we show how privacy-preserving technologies can act as a cornerstone to\nsupportfreedomofspeechandfreedomofaccesstoinformation.Wewillelaborateonsome\nexamplesforeachofthesegoalsinordertoillustratethefundamentalprinciplesthatmake\ncensorship resistance possible. We refer the interested reader to the surveys by Khattak et\nal. [570] and Tschantz et al. [583] for a comprehensive revision of censorship resistance\nsystems.\nDatapublishingcensorshipresistance.Motivatedbythe\u2018ChurchofScientology\u2019courtorder,\nwhich caused the closure of the Penet remailer at the end of the 1990s [584], Anderson pro-\nposed the Eternity Service. This was the first system to use privacy technologies to protect\nthe publishing of content on the Internet [585]. Anderson\u2019s scheme proposed to distribute\ncopies of files across servers in different jurisdictions, so that those servers cannot be sub-\npoenaed at the same time. In this scheme, privacy technologies have fundamental roles for\nresistance:Encryptionnotonlyprovidesprivacyforusers,butalsopreventsselectivedenial\nof service at retrieval time; and anonymous Authentication not only protects users from the\nservice, it also protects the service from being coerced into revealing the identities of users,\ne.g.,bylawenforcement,sinceitcannotknowtheseusers\u2019identities.\nAnderson\u2019s proposal inspired later designs such as Freenet, a peer-to-peer system to pub-\nlish,replicate,andretrievedatawhileprotectingtheAnonymityofboththeauthorsandread-\ners[586].Additionally,thesystemprovidesdeniabilityfortheentitiesstoringtheinformation;\ni.e., the servers cannot know the content of the files they store and thus, can always claim\nto be unaware of what they are serving. In Freenet, files are located according to a key that\nis typically the hash of the file, but can also include a file description, or be a simple string.\nTo retrieve a file, a user obtains or computes the keys and asks Freenet nodes to find it. If a\nnodedoesnotcontainthefile,itasksaneighbour.Whenthefileisfound,itissentbackalong\nthe same path that the request followed in the network. This ensures that the node holding\nthe data does not know the recipient. To store a file, if the key does not already exist, the\npublisher sends the file along a path and every node on the path stores the file. To protect\nthe anonymity of the publisher, nodes that store the file also decide at random whether to\nKAPrivacy&OnlineRights |October2019 Page193 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nalso claim ownership. Such random claims also provide nodes with deniability as to which\nofthefilestheyarestoringareactuallytheirs.\nThe design of Freenet is based on strong cryptography, which protects the content of mes-\nsages. However, in the early days, the routes and timing of messages allowed attacks to\nbreakthesystem\u2019sanonymity.Tianetal.[587]showthatapassiveattackerdeployinganum-\nberofnodesinthenetworkthatcanmonitorrequestscanre-identifytherequesterbyrecur-\nsivelyaskingothernodesiftheyhaveseentherequest.Freenetalsoallowsforthecollection\nof privacy-preserving statistics. However, the statistic obfuscation method is vulnerable to\ninference attacks where the adversarial node combines several queries in order to learn in-\nformation about other Freenet nodes\u2019 properties (e.g., bandwidth) [588]. These issues are\nnowaddressedbyFreenet,butothersremainsuchastheattackbyLevineetal.[589],which\nenables a single node to distinguish whether a neighbouring peer is the actual requester of\na file or just forwarding the requests for other peers. The attack only requires passive ob-\nservation of traffic, and exploits the fact that the Freenet protocol determines the average\nnumber of requests for a file observable by a node depending on how far this node is from\nthe requester. Thus, a simple Bayesian inference suffices to detect whether a neighbour is\ntherequestinitiator.\nA different approach to censorship is followed in Tangler [590]. The system also provides\npublisher and reader anonymity, but achieves censorship resistance in a different way. In-\nsteadofsimplystoringthefilereplicatedinmanynodesinananonymousway,Tanglerfiles\nare split into small blocks that are stored on different servers. In order to recover a file, one\nmust thus contact a number of servers to retrieve enough of these blocks. In order to avoid\naserverbeingcompelledtodeleteablockbelongingtoafile,Tanglerbuildsblocksinsucha\nwaythatblockscontainpartsofmanydocuments.To\u2018tangle\u2019filesintoblocks,Tangleruses\nsecretsharing(SeetheCryptographyKnowledgeArea(Chapter10)).Tanglingimprovesavail-\nability in two ways. First, a censor can only delete a target file by causing collateral damage\nto other files that may be allowed. Second, whenever one wants to replicate a file, the files\nentangledinthereplicatedfileblocksarealsoreplicated.\nDataaccesscensorshipresistance.Toenablecensorship-freeaccesstodata,systemsmust\nbe able to conceal that users are accessing these data. This can be done in a number of\nways [570]. A first approach is mimicking, where censorship resistance is obtained by at-\ntempting to make accessing to censored data look like accessing allowed data (e.g., as a\nSkype call [591] or as a visit to an innocuous web page [592]). These approaches are effec-\ntive, but have been shown to be vulnerable to active attacks in which the adversary probes\nthesuspiciousconnectiontofindoutifanyoftheexpectedfunctionsoftheapplicationbeing\nmimickedaremissing[593].\nA second approach is tunnelling. In this case, the censored communication is directly tun-\nnelled through an uncensored service, instead of pretending to be that service. In particular,\nthese systems use widely used services as tunnels, e.g., cloud services [594, 595], so that\nblocking communications imposes a high cost for the censor. A third approach is to em-\nbed the communication inside some content (e.g., hidden in a photo or video [596]). This\napproach not only makes communications unobservable, but also deniable for all senders,\nrecipientsandapplicationshostingthecontent.\nFinally, some censorship resistance systems rely on hiding the destination of the communi-\ncation to prevent censors from blocking connections. This is achieved by relaying censored\ntrafficthroughoneormoreintermediatenodes.Thesenodescanbeproxies,suchasbridges\nKAPrivacy&OnlineRights |October2019 Page194 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nin the Tor network [531]. These bridges are Tor relays whose IPs are not public so that they\ncannotbeidentifiedasmembersofacensorshipresistancesystem.Toavoidthecensoriden-\ntifying connections to bridges due to their appearance, these are disguised using so-called\npluggabletransports[597],whichtransformthetrafficflowfollowingoneoftheapproaches\nreferencedinthissection.\nAnother option to hide the destination is the use of decoy routing, also known as refraction\nnetworking[598,599].Indecoyrouting,clientsdirecttheircensoredtraffictoabenigndesti-\nnation. This traffic includes an undetectable signal that can only be interpreted by a cooper-\nating Internet router. This router deflects the client\u2019s traffic to the censored site and returns\ntheresponsestotheclient.Obviously,thecooperatingroutermustbeoutsideofthecensor\u2019s\ndomain, but, depending on the scheme, it can be on the forward path from the client to the\nuncensoreddestination[598,599],oronthedownstreampath[600,601].\n5.5 PRIVACY ENGINEERING\n[602][603]\nThe growing privacy concerns in society have made the concept of \u2018privacy by design\u2019 very\npopular among policy makers. This concept advocates for the design and development of\nsystems that integrate privacy values to address users\u2019 concerns. However, the literature\naround this concept rarely addresses the actual processes behind the design, implementa-\ntion,andintegrationofprivacyprotectionsintoproductsandservices.\nIn this knowledge area, we first gave an overview of the landscape of privacy technologies,\nand subsequently provided a series of examples in which these technologies are combined\nto support the use of electronic systems while maintaining core democratic values. In this\nsection, we elaborated on the design principles behind these, and other, privacy-preserving\nsystems. We briefly discussed how these principles can be used to generally approach the\nengineering of systems that embed strong privacy protections. We refered the reader to the\nwork by G\u00fcrses et al. [602] for a more comprehensive explanation of these principles and\ntheir role in the design of privacy-preserving systems. A relevant paper to help the reader\nunderstandingtheseprinciplesistheworkHoepmanonprivacystrategies[604]\nThetwoprimarygoalswhendesigningprivacy-preservingsystemsareto:\n\u2022 Minimise trust: limit the need to rely on other entities to behave as expected with re-\nspecttosensitivedata.Forinstance,inmix-basedeVoting,trustisnotonlydistributed\nacross the entities managing the mixes, but verifiable shuffles are put in place to limit\ntoamaximumtheamountofrelianceonthegoodbehaviourofeachmix.Similarly,the\ncryptographic primitives used to implement privacy-preserving electronic petitions do\nnotrequiretrustontheregistrationauthoritytoprotecttheidentitiesofthesigners.\n\u2022 Minimise risk: limit the likelihood and impact of a privacy breach. For instance, in Tor,\ncompromisingonerelaydoesnotprovideanysensitiveinformationaboutusers\u2019brows-\ninghabits.Ifonecompromisestheentrynode,onecannotlearnthedestinationsofthe\ncommunications,onlythemiddlenodesofthecircuits;andifonecompromisestheexit\nnode,onecannotlearntheoriginofthecommunication.\nTominimisebothtrustandrisk,privacyexpertstypicallydesignsystemsinaccordancewith\nthefollowingstrategies:\nKAPrivacy&OnlineRights |October2019 Page195 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n\u2022 Minimise Collection: whenever possible, limit the capture and storage of data in the\nsystem.\n\u2022 Minimise Disclosure: whenever possible, constrain the flow of information to parties\notherthantheentitytowhomthedatarelates.Thisrefersbothtodirectflowsbetween\nsendersandreceivers,andtoindirectflows,e.g.,useofcontroltechniquestolimitthe\ninformationavailablewhenpublishingorqueryingadataset.\n\u2022 Minimise Replication: whenever possible, limit the number of entities where data are\nstoredorprocessedintheclear.\n\u2022 MinimiseCentralization:wheneverpossible,avoidasinglepointoffailureregardingthe\nprivacypropertiesinthesystem.\n\u2022 MinimiseLinkability:wheneverpossible,limitthecapabilityoftheadversarytolinkdata.\n\u2022 MinimiseRetention:wheneverpossible,limittheamountoftimeinformationisstored.\nImplementingthesestrategiesatfirstmayseemincompatiblewithmaintainingtheIntegrity\nof the system. For instance, if no information is disclosed or collected, how can one make\nsurethatnoentityisabusingthesystem?Ifthereisnocentralauthority,howcanonemake\nsurethatAuthenticationandauthorisationworkasexpected?Thisiswhereprivacytechnolo-\ngiescomeintoplay.Theyenablethedesignofsystemswhereaslittleinformationaspossi-\nble is revealed to parties other than the ones to which the information relates, and in which\nthere is a minimum need to trust providers or other users in order to preserve the privacy of\nsensitiveinformationwhilestillpertainingIntegrityandallowinginformationexchange.\nIn order to decide which privacy technology is most adequate to build a system, a first step\nis to identify the data flows that should be minimised; i.e., those that move data to entities\nto whom the data do not relate. The second step is to identify the minimal set of data that\nneeds to be transferred to those entities. To identify the minimum required information that\nneeds to be transferred, the designer should attempt to keep as much data as possible out\nofreachofthoseentitieswithoutharmingthefunctionalityofthesystem.Strategiestomin-\nimise unnecessary information flow (based mainly on the technologies introduced through-\noutSection.5.1)are:\n\u2022 Keep the data local: perform any computation on sensitive data on the user side, and\nonlytransmittheresultoftheoperation.Additionalinformation,suchaszero-knowledge\nproofsorcommitments,maybeneededtoguaranteethecorrectnessoftheoperations.\n\u2022 Encrypt the data: encrypt the data locally and send only the encrypted version to other\nentities.Ifanyoperationsonthedataareneeded,seethenextpoint.\n\u2022 Useprivacy-preservingcryptographicprotocols:processdatalocallytoobtaininputsto\naprotocolinwhich,byinteractingwiththeuntrustedentitiesusingoneoftheprotocols\nintroducedintheprevioussections,theusercanobtainorproveinformationwhilelim-\niting the information made available to those entities. For instance, using anonymous\ncredentials for Authentication without revealing the identity or even the value of an at-\ntribute,orusingprivateinformationretrievaltoperformasearchonadatabasewithout\nrevealingthequerytothedatabaseholder.\n\u2022 Obfuscatethedata:usetechniquestocontrolinferencetoprocessthedatalocallyand\nonlysendtheperturbedversiontotheuntrustedentity.\nKAPrivacy&OnlineRights |October2019 Page196 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n\u2022 Anonymise the data: process the data locally to remove identifiable information and\nsendittotheuntrustedpartyviaananonymouschannel.\nBy seeking minimisation of trust and using the above techniques, system designers are\nbound to collect, process and retain fewer data than with other strategies based on com-\npliance with regulation. We recognise that many systems and applications cannot be built\nwithoutcollectingsomeuser-relateddata.Forthesecases,designersmusttakeintoaccount\nthe privacy technologies outlined in Section. 5.2 and Section. 5.3. These techniques, while\nrequiring trust, help minimise the risk of a breach and, if the breach happens, minimise the\nimpactthatthedisclosureofdatamayhavefortheusers.\nPrivacyevaluation.Onceprivacytechnologiesorend-to-endsystemshavebeendesigned,it\nisimportant toconductaprivacyevaluation.Thisevaluationhasthegoalofquantifyingthe\nlevelofprivacythatthetechnology,andrespectivelythesystem,canprovide.\nForprivacytechnologiesbasedoncryptographicprimitives,theprivacyevaluationistypically\ncovers the cryptographic proofs that ensure that only the intended information is leaked by\ntheoperations.Onthecontrary,forprivacytechniquesbasedonobfuscation,itisnecessary\nto carry out an analysis to validate that the combination of techniques provides the desired\nlevelofprivacy.\nAsystematicprivacyevaluationtypicallyconsistsofthefollowingsteps.First,oneneedsto\nmodeltheprivacy-preservingmechanismasaprobabilistictransformation.Thisestablishes\nthe probability that, given an input, the privacy mechanism returns a given output. Second,\none needs to establish the threat model, i.e., what the adversary can see and what is her\npriorknowledge.Third,assumingthattheadversaryknowsthemechanism,considerhowhe\nwouldannultheeffectoftheprivacymechanism.Thisusuallyentailseitherdoingananalysis\nof the probability distributions, or using inference techniques such as machine learning to\ncomputewhattheadversarycanlearn.\nAt the end of the process, one usually has a distribution describing the probability that the\nadversaryinferseachofthepossibleinputs.Thisprobabilitydistributionisthenusedasinput\ntoaprivacymetricthatcapturestheinferencecapabilityoftheadversary.Wereferthereader\nto the survey by Wagner and Eckhoff for a comprehensive description of privacy metrics in\ntheliterature[603].\n5.6 CONCLUSIONS\nProtecting privacy, as we have described in this knowledge area, is not limited to guaran-\nteeing the Confidentiality of information. It also requires means to help users understand\ntheextenttowhichtheirinformationisavailableonline,andmechanismstoenableusersto\nexercise control over this information. We have described techniques to realise these three\nprivacyconceptions,emphasisingtheadversarialmodelinwhichtheyoperate,aswellaspro-\nvidingguidelinestocombinethesetechniquesinordertobuildend-to-endprivacy-preserving\nsystems.\nPreserving privacy and online rights is not only important for individuals, it is essential to\nsupport democratic societies.Thedeployment ofprivacytechnologiesis keyto allowusers\nfree access to content, and freedom of speech. Of equal importance is to avoid that any\nentitygainingadisproportionateamountofinformationaboutindividualsorgroups,inorder\ntopreventmanipulationandabusethatcoulddamagedemocraticvalues.\nKAPrivacy&OnlineRights |October2019 Page197 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nCROSS-REFERENCE OF TOPICS VS REFERENCE MATERIAL\nTopic Cite\n5.1PrivacyasConfidentiality\n5.1.1DataConfidentiality [448,449,450,451,452]\n5.1.2MetadataConfidentiality [447,453,454]\n5.2PrivacyasControl\n5.2.1Supportforprivacysettingsconfiguration [552]\n5.2.2Supportforprivacypolicynegotiation [553]\n5.2.3Supportforprivacypolicyinterpretability [554]\n5.3PrivacyasTransparency\n5.3.1Feedback-basedtransparency [563,564,565]\n5.3.2Audit-basedtransparency [567]\n5.4PrivacyTechnologiesandDemocraticValues\n5.4.1Privacytechnologiesassupportfordemocraticpoliticalsystems [569,571]\n5.4.2Censorshipresistanceandfreedomofspeech [570]\n5.5PrivacyEngineering [602,603]\nKAPrivacy&OnlineRights |October2019 Page198 II Attacks & Defences\n199  Chapter 6\nMalware & Attack\nTechnologies\nWenke Lee Georgia Institute of Technology\n201 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nINTRODUCTION\nMalwareisshortfor\u2019malicioussoftware\u2019,thatis,anyprogramthatperformsmaliciousactivi-\nties.Weusethetermsmalwareandmaliciouscodeinterchangeably.Malwarecomeswitha\nwide range of shapes and forms, and with different classifications accordingly, e.g., viruses,\nTrojans,worms,spyware,botnetmalware,ransomware,etc.\nMalware carries out many of the cyberattacks on the Internet, including nation-state cyber-\nwar, cybercrime, fraud and scams. For example, Trojans can introduce a backdoor access\ntoagovernmentnetworktoallownation-stateattackerstostealclassifiedinformation.Ran-\nsomwarecanencryptdataonauser\u2019scomputerandthusmakingitunaccessibletotheuser,\nandonlydecryptthedataaftertheuserpaysasumofmoney.Botnetmalwareisresponsible\nfor many of the Distributed Denial-of-Service (DDoS) attacks as well as spam and phishing\nactivities.Weneedtostudythetechniquesbehindmalwaredevelopmentanddeploymentin\nordertobetterunderstandcyberattacksanddeveloptheappropriatecountermeasures.\nAs the political and financial stakes become higher, the sophistication and robustness of\nboth the cyber defence mechanisms and the malware technologies and operation models\nhave also increased. For example, attackers now use various obfuscation techniques such\nas packing and polymorphism as well as metamorphism to evade malware detection sys-\ntems [605], and they set up adaptive network infrastructures on the Internet to support mal-\nware updates, command-and-control, and other logistics such as transits of stolen data. In\nshort,itisbecomingmoreimportantbutalsomorechallengingtostudymalware.\nTherestofthischapterisorganisedasfollows.Wewillprovideataxonomyofmalwareand\ndiscuss their typical malicious activities as well as their eco-system and support infrastruc-\ntures. We will then describe the tools and techniques to analyse malware behaviours, and\nnetwork- and host- based detection methods to identify malware activities, as well as pro-\ncesses and techniques including forensic analysis and attribution to respond to malware\nattacks.\nCONTENT\n6.1 A TAXONOMY OF MALWARE\n[606,c6]\nThere are many types of malware [606]. It is instructive to create a taxonomy to systemati-\ncallycategorisethewidespectrumofmalwaretypes.Thistaxonomydescribesthecommon\ncharacteristicsofeachtypeofmalwareandthuscanguidethedevelopmentofcountermea-\nsures applicable to an entire category of malware (rather than a specific malware). Since\ntheremanyfacetsofmalwaretechnologiesandattackoperations,basedonwhichmalware\ncan be categorised and named, our taxonomy can include many dimensions. We discuss a\nfewimportantonesbelow.Itshouldbeborneinmindthatother,morespecialised,attributes\ncouldalsobeusedsuchastargetprocessorarchitectureoroperatingsystem.\nThe first dimension of our taxonomy is whether malware is a standalone (or, independent)\nprogramorjustasequenceofinstructionstobeembeddedinanotherprogram.Standalone\nmalwareisacompleteprogramthatcanrunonitsownonceitisinstalledonacompromised\nmachine and executed. For example, worms and botnet malware belong to this type. The\nKAMalware&AttackTechnologies |October2019 Page202 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nsecond type requires a host program to run, that is, it must infect a program on a computer\nby inserting its instructions into the program so that when the program is run, the malware\ninstructionsarealsoexecuted.Forexample,documentmacrovirusesandmaliciousbrowser\nplug-insbelongtothistype.Ingeneral,itiseasiertodetectstandalonemalwarebecauseitis\naprogramorarunningprocessinitsownrightanditspresencecanbedetectedbyoperating\nsystemorsecuritytools.\nThe second dimension is whether malware is persistent or transient. Most malware is in-\nstalled in persistent storage (typically, a file system) as either standalone malware or an\ninfection of another program that already resides in persistent storage. Other malware is\nmemory-resident such that if the computer is rebooted or the infected running program ter-\nminates, it no longer exists anywhere on the system. Memory-resident malware can evade\ndetectionbymanyanti-virussystemsthatrelyonfilescanning.Suchtransientmalwarealso\nhas the advantage of being easy to clean up (or, cover-up) its attack operations. The tradi-\ntionalwayformalwaretobecomememory-residentistoremovethemalwareprogram(that\nwas downloaded and installed previously) from the file system as soon as it gets executed.\nNewer approaches exploit system administrative and security tools such as PowerShell to\ninject malware directly into memory [607]. For example, according to one report [608], after\naninitialexploitthatledtotheunauthorisedexecutionofPowerShell,meterpretercodewas\ndownloaded and injected into memory using PowerShell commands and it harvested pass-\nwordsontheinfectedcomputer.\nThe third dimension generally applies to only persistent malware and categorises malware\nbased on the layer of the system stack the malware is installed and run on. These layers,\nin the ascending order, include firmware, boot-sector, operating system kernel, drivers and\nApplication Programing Interfaces (APIs), and user applications. Typically, malware in the\nlower layers is harder to detect and remove, and wreaks greater havoc because it has more\ncontrol of the compromised computer. On the other hand, it is also harder to write malware\nthatcanbeinstalledatalowerlayerbecausetherearegreaterconstraints,e.g.,amorelimited\nprogrammingenvironmentintermsofboththetypesandamountofcodeallowed.\nThefourthdimensioniswhethermalwareisrunandspreadautomaticallyvs.activatedbya\nuseraction.Whenanauto-spreadingmalwareruns,itlooksforothervulnerablemachineson\ntheInternet,compromisesthesemachinesandinstallsitselfonthem;thecopiesofmalware\non these newly infected machines immediately do the same \u2013 run and spread. Obviously,\nauto-spreading malware can spread on the Internet very quickly, often being able to expo-\nnentiallyincreasethenumberofcompromisedcomputers.Ontheotherhand,user-activated\nmalware is run on a computer only because a user accidentally downloads and executes it,\ne.g., by clicking on an attachment or URL in a received email. More importantly, when this\nmalware runs, although it can \u2018spread\u2019, e.g., by sending email with itself as the attachment\nto contacts in the user\u2019s address book, this spreading is not successful unless a user who\nreceivesthisemailactivatesthemalware.\nThe fifth dimension is whether malware is static or one-time vs. dynamically updated. Most\nmodern malware is supported by an infrastructure such that a compromised computer can\nreceiveasoftwareupdatefromamalwareserver,thatis,anewversionofthemalwareisin-\nstalledonthecompromisedcomputer.Fromanattacker\u2019spoint-of-view,therearemanyben-\nefits of updating malware. For example, updated malware can evade detection techniques\nthatarebasedonthecharacteristicsofoldermalwareinstances.\nThesixthdimensioniswhethermalwareactsaloneorispartofacoordinatednetwork(i.e.,a\nbotnet).WhilebotnetsareresponsibleformanycyberattackssuchasDDoS,spam,phishing,\nKAMalware&AttackTechnologies |October2019 Page203 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\netc., isolated malware has become increasingly common in the forms of targeted attack.\nThat is, malware can be specifically designed to infect a target organisation and perform\nmaliciousactivitiesaccordingtothoseassetsoftheorganisationvaluabletotheattacker.\nMostmodernmalwareusessomeformofobfuscationinordertoavoiddetection(andhence\nwe do not explicitly include obfuscation in this taxonomy). There is a range of obfuscation\ntechniques and there are tools freely available on the Internet for a malware author to use.\nForexample,polymorphismcanbeusedtodefeatdetectionmethodsthatarebasedon\u2018sig-\nnatures\u2019orpatternsofmalwarecode.Thatis,theidentifiablemalwarefeaturesarechanged\nto be unique to each instance of the malware. Therefore, malware instances look different\nfrom each other, but they all maintain the same malware functionality. Some common poly-\nmorphic malware techniques include packing, which involves compressing and encrypting\npart of the malware, and rewriting identifiable malicious instructions into other equivalent\ninstructions.\nviruses host-program persistent firmwareandup Y Y N\nmalicious\nhost-program persistent application N Y Y\nbrowserextensions\nbotnetmalware both persistent kernelandup Y Y Y\nmemory-resident\nstandalone transient kernelandup Y Y Y\nmalware\nTable6.1:UseoftheTaxonomytoClassifyRepresentativeMalware\nAsanillustration,wecanapplythistaxonomytoseveraltypes(ornames)ofmalware.SeeTa-\nble6.1.Inparticular,avirusneedsahost-programtorunbecauseitinfectsthehost-program\nby inserting a malicious code sequence into the program. When the host-program runs, the\nmalicious code executes and, in addition to performing the intended malicious activities, it\ncan look for other programs to infect. A virus is typically persistent and can reside in all lay-\nersofthesystemstackexcepthardware.Itcanspreadonitsownbecauseitcaninjectitself\ninto programs automatically. A virus can also be dynamically updated provided that it can\nconnect to a malware update server. A polymorphic malware virus can mutate itself so that\nnew copies look different, although the algorithm of this mutation is embedded into its own\ncode. A virus is typically not part of a coordinated network because while the infection can\naffectmanycomputers,theviruscodetypicallydoesnotperformcoordinatedactivities.\nOther malware that requires a host-program includes malicious browser plug-ins and exten-\nsions, scripts (e.g., JavaScript on a web page), and document macros (e.g., macro viruses\nandPDFmalware).Thesetypesofmalwarecanbeupdateddynamically,formacoordinated\nnetwork,andcanbeobfuscated.\nBotnet malware refers to any malware that is part of a coordinated network with a botnet\ninfrastructurethatprovidescommand-and-control.Abotnetinfrastructuretypicallyalsopro-\nvidesmalwareupdate,andotherlogisticsupport.Botnetmalwareispersistentandtypically\nobfuscated, and usually resides in the kernel, driver, or application layers. Some botnet mal-\nware requires a host-program, e.g., malicious browser plug-ins and extensions, and needs\nKAMalware&AttackTechnologies |October2019 Page204\nroenoladnats margorp-tsoh rotnetsisrep\ntneisnart fosreyal\nkcatsmetsys\n?gnidaerps-otua\nyllacimanyd\n?elbatadpu\n?detanidrooc TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nuser activation to spread (e.g., malicious JavaScript). Other botnet malware is standalone,\nand can spread automatically by exploiting vulnerable computers or users on the Internet.\nTheseincludetrojans,key-loggers,ransomware,clickbots,spambots,mobilemalware,etc.\n6.1.1 Potentially Unwanted Programs (PUPs)\nA potentially unwanted program (PUP) is typically a piece of code that is part of a useful\nprogram downloaded by a user. For example, when a user downloads the free version of a\nmobilegameapp,itmayincludeadware,aformofPUPthatdisplaysadbannersonthegame\nwindow. Often, the adware also collects user data (such as geo-location, time spent on the\ngame,friends,etc.)withouttheuser\u2019sknowledgeandconsent,inordertoservemoretargeted\nadstotheusertoimprovetheeffectivenessoftheadvertising.Inthiscase,theadwareisalso\nconsideredspyware, which isdefinedas unwantedprogram thatstealsinformation abouta\ncomputer and its users. PUPs are in a grey area because, while the download agreement\noften contains information on these questionable behaviours, most users tend not to read\nthefinerdetailsandthusfailtounderstandexactlywhattheyaredownloading.\nFromthepointofviewofcybersecurity,itisprudenttoclassifyPUPstowardsmalware,and\nthis is the approach taken by many security products. The simple reason is that a PUP has\nallthepotentialtobecomefull-fledgedmalware;onceitisinstalled,theuserisatthemercy\nofthePUPoperator.Forexample,aspywarethatispartofaspellcheckerbrowserextension\ncangatherinformationonwhichwebsitestheusertendstovisit.Butitcanalsoharvestuser\naccount information including logins and passwords. In this case, the spyware has become\namalwarefromjustaPUP.\n6.2 MALICIOUS ACTIVITIES BY MALWARE\n[606,c6][605,c11-12]\nMalware essentially codifies the malicious activities intended by an attacker. Cyberattacks\ncan be analysed using the Cyber Kill Chain Model [609], which, as shown in Table 6.2, repre-\nsents(iterationsof)stepstypicallyinvolvedinacyberattack.ThefirststepisReconnaissance\nwhere an attacker identifies or attracts the potential targets. This can be accomplished, for\nexample,byscanningtheInternetforvulnerablecomputers(i.e.,computersthatrunnetwork\nservices, such as sendmail, that have known vulnerabilities), or sending phishing emails to\na group of users. The next phase is to gain access to the targets, for example, by sending\ncraftedinputtotriggeravulnerabilitysuchasabufferoverflowinthevulnerablenetworkser-\nvice program or embedding malware in a web page that will compromise a user\u2019s browser\nand gain control of his computer. This corresponds to the Weaponization and Delivery (of\nexploits) steps in the Cyber Kill Chain Model. Once the target is compromised, typically an-\nother piece of malware is downloaded and installed; this corresponds to the Installation (of\nmalware)stepintheCyberKillChainModel.Thislattermalwareistherealworkhorseforthe\nattackerandcancarryoutawiderangeofactivities,whichamounttoattackson:\n\u2022 confidentiality \u2013 it can steal valuable data, e.g., user\u2019s authentication information, and\nfinancialandhealthdata;\n\u2022 integrity \u2013 it can inject falsified information (e.g., send spam and phish emails, create\nfraudulentclicks,etc.)ormodifydata;\n\u2022 availability\u2013itcansendtrafficaspartofadistributeddenial-of-service(DDoS)attack,\nKAMalware&AttackTechnologies |October2019 Page205 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nuseupalargeamountofcompute-resources(e.g.,tominecryptocurrencies),orencrypt\nvaluabledataanddemandaransompayment.\nStep Activities\n1 Reconnaissance Harvestingemailaddresses,\nidentifyingvulnerablecomputersandaccounts,etc.\n2 Weaponization Designingexploitsintoadeliverablepayload.\n3 Delivery Deliveringtheexploitpayloadtoavictimviaemail,\nWebdownload,etc.\n4 Exploitation Exploitingavulnerabilityand\nexecutingmaliciouscodeonthevictim\u2019ssystem.\n5 Installation Installing(additional)malwareonthevictim\u2019ssystem.\n6 Command&Control Establishingacommandandcontrolchannelforattackers\ntoremotelycommandeerthevictim\u2019ssystem.\n7 ActionsonObjectives Carryingoutmaliciousactivitiesonthevictim\u2019ssystemandnetwork.\nTable6.2:TheCyberKillChainModel\nMost modern malware performs a combination of these attack actions because there are\ntoolkits (e.g., a key-logger) freely available for carrying out many \u2018standard\u2019 activities (e.g.,\nrecording user passwords) [605], and malware can be dynamically updated to include or ac-\ntivatenewactivitiesandtakepartinalongerorlarger\u2018campaign\u2019ratherthanjustperforming\nisolated,one-offactions.ThesearetheActionsonObjectivesintheCyberKillChainModel.\nBotnets exemplify long-running and coordinated malware. A botnet is a network of bots (or,\ncompromisedcomputers)underthecontrolofanattacker.Botnetmalwarerunsoneachbot\nand communicates with the botnet command-and-control (C&C) server regularly to receive\ninstructions on specific malicious activities or updates to the malware. For example, every\ndaytheC&Cserverofaspammingbotnetsendseachbotaspamtemplateandalistofemail\naddressessothatcollectivelythebotnetsendsaverylargenumberofspammessages.Ifthe\nbotnetisdisruptedbecauseofdetectionandresponseactions,e.g.,thecurrentC&Cserveris\ntakendown,thebotnetmalwareisalreadyprogrammedtocontactanalternativeserverand\ncanreceiveupdatestochangetoabotnetthatusespeer-to-peerforC&C.Ingeneral,botnets\narequitenoisy,i.e.,relativelyeasytodetect,becausetherearemanybotsinmanynetworks.\nBotnetC&CisanexampleoftheCommand&ControlstepintheCyberKillChainModel.\nIncontrasttobotnets,malwarebehindtheso-calledadvancedpersistentthreats(APTs)typ-\nically targets a specific organisation rather than aiming to launch large-scale attacks. For\nexample,itmaylookforaparticulartypeofcontrollerintheorganisationtoinfectandcause\nit to send the wrong control signals that lead to eventual failures in machineries. APT mal-\nware is typically designed to be long-lived (hence the term \u2018persistent\u2019). This means it not\nonly receives regular updates. but also evades detection by limiting its activity volume and\nintensity(i.e.,\u2018lowandslow\u2019),movingaroundtheorganisation(i.e.,\u2018lateralmovements\u2019)and\ncoveringitstracks.Forexample,ratherthansendingthestolendataouttoa\u2018dropsite\u2019allat\nonce, it can send a small piece at a time and only when the server is already sending legiti-\nmatetraffic;afterithasfinishedstealingfromaserveritmovestoanother(e.g.,byexploiting\nthe trust relations between the two) and removes logs and even patches the vulnerabilities\ninthefirstserver.\nWhenweusetheCyberKillChainModeltoanalyzeacyberattack,weneedtoexamineitsac-\ntivitiesineachstep.Thisrequiresknowledgeoftheattacktechniquesinvolved.TheATT&CK\nKnowledge Base [610] documents the up-to-date attack tactics and techniques based on\nreal-worldobservations,andisavaluablereferenceforanalysts.\nKAMalware&AttackTechnologies |October2019 Page206 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n6.2.1 The Underground Eco-System\nThe early-day malware activities were largely nuisance attacks (such as defacing or putting\ngraffitionanorganisation\u2019swebpage).Present-daymalwareattacksarebecomingfull-blown\ncyberwars(e.g.,attacksoncriticalinfrastructures)andsophisticatedcrimes(e.g.,ransomware,\nfake-AntiVirustools,etc.).Anundergroundeco-systemhasalsoemergedtosupportthefull\nmalware lifecycle that includes development, deployment, operations and monetisation. In\nthis eco-system, there are actors specialising in key parts of the malware lifecycle, and by\nproviding their services to others they also get a share of the (financial) gains and rewards.\nSuch specialisation improves the quality of malware. For example, an attacker can hire the\nbestexploitresearchertowritethepartofthemalwareresponsibleforremotelycompromis-\ningavulnerablecomputer.Specialisationcanalsoprovideplausibledeniabilityorattheleast\nlimit liability. Forexample, a spammeronly \u2018rents\u2019a botnet tosend spam andis not guiltyof\ncompromisingcomputersandturningthemintobots;likewise,theexploit\u2018researcher\u2019isjust\nexperimenting and not responsible for creating the botnet as long as he did not release the\nmalwarehimself.Thatis,whiletheyareallliableforthedamagebymalware,theyeachbear\nonlyaportionofthefullresponsibility.\n6.3 MALWARE ANALYSIS\n[605,c1-10][611,612,613,614,615,616,617,618,619,620,621,622]\nThere are many benefits in analysing malware. First, we can understand the intended mali-\nciousactivitiestobecarriedoutbythemalware.Thiswillallowustoupdateournetworkand\nendpoint sensors to detect and block such activities, and identify which machines have the\nmalwareandtakecorrectiveactionssuchasremovingitorevencompletelywipingthecom-\nputercleanandreinstallingeverything.Second,byanalysingthemalwarestructure(e.g.,the\nlibraries and toolkits that it includes) and coding styles, we may be able to gain information\nthat is potentially useful to attribution, which means being able to identify the likely author\nandoperator.Third,bycomparingitwithhistoricalaswellasgeo-locationdata,wecanbetter\nunderstandandpredictthescopeandtrendofmalwareattacks,e.g.,whatkindsofactivities\n(e.g.,miningcryptocurrencies)areontheriseandifacybercrimeismovingfromoneregion\nto another. In short, malware analysis is the basis for detecting and responding to cyberat-\ntacks.\nMalware analysis typically involves running a malware instance in an analysis environment.\nThere are ways to \u2018capture\u2019 malware instances on the infection sites. A network sensor can\nexamine traffic (e.g., web traffic, email attachment) to identify possible malware (e.g., pay-\nloadthatcontainsbinaryorprogram-likedatafromawebsitewithalowreputation)andrun\nit in a sandbox to confirm. If a network sensor is able to detect outgoing malicious traffic\nfromaninternalhost,ahost-basedsensorcanfurtheridentifytheprogram,i.e.,themalware,\nresponsible for such traffic. There are also malware collection and sharing efforts where\ntrustedorganisationscanuploadmalwaresamplesfoundintheirnetworksandalsoreceive\nsamplescontributedbyotherorganisations.Academicresearcherscantypicallyjustobtain\nmalwaresampleswithoutneedingtocontribute.Whenacquiringandsharingmalwaresam-\nples,wemustconsiderourlegalandethicalresponsibilitiescarefully[623].Forexample,we\nmustprotecttheidentitiesoftheinfectionsitesfromwhichthemalwaresampleswerecap-\ntured,andwemustnotsharethemalwaresampleswithanyorganisationthatisanunknown\nentity or that does not have the commitment or technical capabilities to analyse malware\nsafely.\nKAMalware&AttackTechnologies |October2019 Page207 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nThemalwareanalysispipelinetypicallyincludesthefollowingsteps:1)identifyingtheformat\nof a malware sample (e.g., binary or source code, Windows or Linux, etc.), 2) static analysis\nusingdisassembly(ifthemalwareisinbinaryformat),programanalysis,statisticalanalysis\nofthefilecontents,etc.,and3)dynamicanalysisusingananalysisenvironment.Steps2and\n3canbecombinedanditerated.\n6.3.1 Analysis Techniques\nMalware analysis is the process of learning malware behaviours. Due to the large volume\nand increasing complexity of malware, we need to be able to rapidly analyse samples in a\ncomplete,reliableandscalableway.Toachievethis,weneedtoemploytechniquessuchas\nstatic analysis, dynamic analysis, symbolic execution and concolic execution [605]. These\nprogramanalysistechniqueshavebeendevelopedtosupportthesoftwaredevelopmentcy-\ncle, and they often need to be customized or extended for malware analysis because mali-\nciousprogramstypicallyincludecodeconstructedspecificallytoresistanalysis.Thatis,the\nmainchallengeinmalwareanalysisistodetectandbypassanti-analysismechanisms.\n6.3.1.1 StaticAnalysis\nStatic analysis involves examining the code (source, intermediate, or binary) to assess the\nbehavioursofaprogramwithoutactuallyexecutingit[605].Awiderangeofmalwareanalysis\ntechniquesfallintothecategoryofstaticanalysis.Onelimitationisthattheanalysisoutput\nmay not be consistent with the actual malware behaviours (at runtime). This is because in\nmany cases it is not possible to precisely determine a program\u2019s behaviours statically (i.e.,\nwithouttheactualrun-timeinputdata).Amoreseriousproblemisthatmalwareauthorsare\nwellawareofthelimitationsofstaticanalysisandtheyleveragecodeobfuscationandpack-\ning to thwart static-analysis altogether. For example, the packed code cannot be statically\nanalysedbecauseitisencryptedandcompresseddatauntilunpackedintoexecutablecode\natrun-time.\n6.3.1.2 Dynamicanalysis\nDynamic analysis monitors the behaviours of malware execution in order to identify mali-\ncious behaviours [605]. Static analysis can provide more comprehensive coverage of pro-\ngram behaviours but may include unfeasible ones. Dynamic analysis identifies the precise\nprogrambehavioursperthetestinputcasesbutmissesbehavioursthatarenottriggeredby\ntheinput.Additionally,dynamicalanalysiscandefeatcodeobfuscationtechniquesdesigned\nto evade static analysis. For example, when malware at run-time unpacks and executes its\npacked code, dynamic analysis is able to identify the (run-time) malicious behaviours in the\noriginally packed code. When performing dynamic analysis, the main questions to consider\nare:whattypesofmaliciousbehavioursneedtobeidentifiedandcorrespondingly,whatrun-\ntime features need to be collected and when to collect (or sample), and how to isolate the\neffects on the malware from those of benign system components. Typically, the run-time\nfeatures to be collected need to be from a layer lower than the malware itself in the system\nstacksothatthemalwarecannotchangethecollectedinformation.Forexample,instruction\ntracescertainlycoverallthedetailsofmaliciousbehavioursbutthedatavolumeistoolarge\nforefficientanalysis[624].Ontheotherhand,systemcall(orAPIcall)tracesarecoarserbut\nsummarise how malware interacts with the run-time system, including file I\/O and network-\ning activities [625]. Another advantage of dynamic analysis is that it is independent of the\nKAMalware&AttackTechnologies |October2019 Page208 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nmalware format, e.g., binary, script, macro, or exploit, because all malware is executed and\nanalysedinasimilarfashion.\n6.3.1.3 Fuzzing\nFuzzing is a method for discovering vulnerabilities, bugs and crashes in software by feed-\ningrandomisedinputstoprograms.Fuzzingtools[626]canalsobeusedtotriggermalware\nbehaviours. Fuzzing can explore the input space, but it is limited due to code-coverage is-\nsues [611], especially for inputs that drive the program down complex branch conditions. In\ncontrast, concolic execution (see 6.3.1.5 Concolic Execution) is good at finding complex in-\nputs by formulating constraints, but is also expensive and slow. To take advantage of both\napproaches,ahybridapproach[627]calledhybridfuzzingcanbeused.\n6.3.1.4 SymbolicExecution\nSymbolic execution [611, 614, 628, 629, 630] has been used for vulnerability analysis of le-\ngitimate programs as well as malware analysis [612]. It treats variables and equations as\nsymbols and formulas that can potentially express all possible program paths. A limitation\nof concrete execution (i.e., testing on particular inputs), including fuzzing, for malware anal-\nysis is that the program has to be executed end-to-end, one run at a time. Unlike concrete\nexecution,symbolicexecutioncanexploremultiplebranchessimultaneously.Toexploreun-\nseen code sections and unfold behaviours, symbolic execution generalises the input space\ntorepresentallpossibleinputsthatcouldleadtopointsofinterest.\n6.3.1.5 ConcolicExecution\nWhilesymbolicexecutioncantraverseallpathsintheory,ithasmajorlimitations[628],e.g.,it\nmaynotconvergequickly(ifatall)whendealingwithlargesymbolspaceandcomplexformu-\nlasandpredicates.Concolicexecution,whichcombinesCONCreteandsymbOLICexecution,\ncanreducethesymbolicspacebutkeepthegeneralinputspace.\nOffline Concolic Execution is a technique that uses concrete traces to drive symbolic execu-\ntion; it is also known as a Trace Based Executor [613]. The execution trace obtained by con-\ncreteexecutionisusedtogeneratethepathformulasandconstraints.Thepathformulasfor\nthe corresponding branch is negated and Satisfiability Modulo Theories (SMT) solvers are\nused to find a valid input that can satisfy the not-taken branches. Generated inputs are fed\nintotheprogramandre-runfromthebeginning.Thistechniqueiterativelyexploresthefeasi-\nblenot-takenbranchesencounteredduringexecutions.Itrequirestherepetitiveexecutionof\nalltheinstructionsfromthebeginningandknowledgeoftheinputformat.\nOnline Concolic Execution is a technique that generates constraints along with the concrete\nexecution[614].Whenevertheconcreteexecutionhitsabranch,ifbothdirectionsarefeasible,\nexecution is forked to work on both branches. Unlike the offline executor, this approach can\nexploremultiplepaths.\nHybrid Execution: This approach switches automatically between online and offline modes\ntoavoidthedrawbacksofnon-hybridapproaches[615].\nConcolicExecutioncanusewhole-systememulators[614,631]ordynamicbinaryinstrumen-\ntation tools [615, 629]. Another approach is to interpret Intermediate Representation (IR) to\nimitate the effects of execution [612, 616]. This technique allows context-free concolic exe-\ncution,whichanalysesanypartofthebinaryatfunctionandbasicblocklevels.\nKAMalware&AttackTechnologies |October2019 Page209 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nPath Exploration is a systematical approach to examine program paths. Path explosion is\nalso inevitable in concolic execution due to the nature of symbolic space. There are a va-\nriety of algorithms used to prioritise the directions of concolic execution, e.g., Depth-First\nSearch(DFS)ordistancecomputation[632].Anotherapproachistoprioritisethedirections\nfavouringnewlyexploredcodeblocksorsymbolicmemorydependence[615].Otherpopular\ntechniques include path pruning, state merging [614, 633, 634], under-constrained symbolic\nexecution [616]andfuzzingsupport[611,613].\n6.3.2 Analysis Environments\nMalware analysis typically requires a dedicated environment to run the dynamic analysis\ntools[605].Thedesignchoiceoftheenvironmentdeterminestheanalysismethodsthatcan\nbe utilised and, therefore, the results and limitations of analysis. Creating an environment\nrequires balancing the cost it takes to analyse a malware sample against the richness of\nthe resulting report. In this context, cost is commonly measured in terms of time and man-\nual human effort. For example, having an expert human analyst study a sample manually\ncan produce a very in-depth and thorough report, but at great cost. Safety is a critical de-\nsignconsiderationbecauseoftheconcernthatmalwarebeingexecutedandanalysedinthe\nenvironment can break out of its containment and cause damage to the analysis system\nand its connected network including the Internet (see 6.3.2.1 Safety and Live-Environment\nRequirements). An example is running a sample of a botnet malware that performs a DDoS\nattack,andthusiftheanalysisenvironmentisnotsafe,itwillcontributetothatattack.\nMachineEmulator Type2Hypervisor Type1Hypervisor Bare-metalmachine\nRunsinhostOS,\nCode-based Runsdirectlyon\nprovidesvirtualisation Novirtualisation\narchitectureemulation systemhardware\nserviceforhardware\nEasytouse, Easytouse, Mediumtransparency,\nFine-grained Fine-grained Fine-grained Hightransparency,No\nintrospection, introspection, introspection,Low virtualenvironment\nPowerfulcontrolover Powerfulcontrolover overheadforhardware artifacts\nthesystemstate thesystemstate interaction\nLackoffine-grained\nLowtransparency, Lowtransparency, introspection,\nLesscontroloverthe\nUnreliabilitysupportof Artifactsfrom Scalabilityandcost\nsystemstate\narchitecturesemantics para-virtualisation issues,Slowerto\nrestoretocleanstate\nUnicorn[635], VirtualBox[638], VMwareESX[641],\nNVMTrace[644],\nQEMU[636], KVM[639], Hyper-V[642],\nBareCloud[620]\nBochs[637] VMware[640] Xen[643]\nTable6.3:ComparisonofMalwareAnalysisEnvironments\nTable 6.3 highlights the advantages and disadvantages of common environments used for\nrun-time (i.e., dynamic) analysis of malware. We can see that some architectures are eas-\nier to set up and give finer control over the malware\u2019s execution, but come at the cost of\ntransparency(thatis,theyareeasierforthemalwaretodetect)comparedtotheothers.For\nexample,bare-metalsystemsareveryhardformalwaretodetect,butbecausetheyhaveno\ninstrumentation, the data that can be extracted are typically limited to network and disk I\/O.\nKAMalware&AttackTechnologies |October2019 Page210\nerutcetihcrA\nsegatnavdA\nsegatnavdasiD\nselpmaxE TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nBy contrast, emulators like QEMU can record every executed instruction and freely inspect\nmemory. However, QEMU also has errors that do not exist in real hardware, which can be\nexploited to detect its presence [645]. A very large percentage of modern malware detect\nemulated and virtualised environments and if they do, then they do not perform their mali-\nciousactionsinordertoavoidanalysis.\n6.3.2.1 SafetyandLive-EnvironmentRequirements\nClearly, safety is very important when designing a malware analysis environment because\nwe cannot allow malware to cause unintended damage to the Internet (e.g., via mounting a\ndenial-of-service attack from inside the analysis environment) and the analysis system and\nitsconnectednetwork.Unfortunately,althoughpurestatictechniques,i.e.,codeanalysiswith-\noutprogramexecution,arethesafest,theyalsohaveseverelimitations.Inparticular,malware\nauthors know their code may be captured and analysed, and they employ code obfuscation\ntechniques so that code analysis alone (i.e., without actually running the malware) will yield\naslittleinformationaspossible.\nMalware typically requires communication with one or more C&C servers on the Internet,\ne.g., to receive commands and decrypt and execute its \u2018payload\u2019 (or the code that performs\nthe intended malicious activities). This is just one example that highlights how the design\nof a live-environment is important for the malware to be alive and thus exhibit its intended\nfunctionality. Other examples of live-environment requirements include specific run-time li-\nbraries [646], real user activities on the infected machine [647], and network connectivity to\nmalwareupdateservers[648].\n6.3.2.2 VirtualisedNetworkEnvironments\nGiven the safety and live-environment requirements, most malware analysis environments\nare constructed using virtualisation technologies. Virtualisation enables operating systems\ntoautomaticallyandefficientlymanageentirenetworksofnodes(e.g.,hosts,switches),even\nwithin a single physical machine. In addition, containment policies can be applied on top of\nthevirtualenvironmentstobalancethelive-environmentandsafetyrequirementsto1)allow\nmalware to interact with the Internet to provide the necessary realism, and 2) contain any\nmaliciousactivitiesthatwouldcauseundesiredharmorside-effects.\nExample architectures [617] include: 1) the GQ system, which is designed based on multiple\ncontainmentserversandacentralgatewaythatconnectsthemwiththeInternetallowingfor\nfilteringorredirectionofthenetworktrafficonaper-flowbasis,and2)thePotemkinsystem,\nwhichisaprototypehoneyfarmthatusesaggressivememorysharinganddynamicallybinds\nphysicalresourcestoexternalrequests.Sucharchitecturesareusedtonotonlymonitor,but\nalsoreplaynetwork-levelbehaviours.Towardsthisend,wefirstneedtoreverse-engineerthe\nC&C protocol used by malware. There are several approaches based on network level data\n(e.g., Roleplay [649], which uses bytestream alignment algorithms), or dynamic analysis of\nmalwareexecution(e.g.,PolyglotandDispatcher[650]),oracombinationofthetwo.\nKAMalware&AttackTechnologies |October2019 Page211 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n6.3.3 Anti-Analysis and Evasion Techniques\nMalware authors are well aware that security analysts use program analysis to identify mal-\nware behaviours. As a result, malware authors employ several techniques to make malware\nhardtoanalyse[605].\n6.3.3.1 EvadingtheAnalysisMethods\nThesourcecodeofmalwareisoftennotavailableand,therefore,thefirststepofstaticanaly-\nsisistodisassemblemalwarebinaryintoassemblycode.Malwareauthorscanapplyarange\nofanti-disassemblytechniques(e.g.,reusingabyte)tocausedisassemblyanalysistoolsto\nproduceanincorrectcodelisting[605].\nThe most general and commonly used code obfuscation technique is packing, that is, com-\npressingandencryptingpartofthemalware.Sometriviallypackedbinariescanbeunpacked\nwith simple tools and analysed statically [651], but for most modern malware the packed\ncodeisunpackedonlywhenitisneededduringmalwareexecution.Therefore,anunpacking\ntool needs to analyse malware execution and consider the trade-offs of robustness, perfor-\nmance, and transparency. For example, unpackers based on virtual machine introspection\n(VMI)[618]aremoretransparentandrobustbutalsoslower.Bycontrast,unpackersbuilton\ndynamic binary instrumentation (DBI) [622] are faster, but also easier to detect because the\nDBIcoderunsatthesameprivilegelevelasthemalware.\nManytechniquesaimatobfuscatingtheintendedcontrol-flowsofamalware,e.g.,byadding\nmorebasicblocksandedgestoitscontrol-flowgraph[605,652,653].Acountermeasureisto\nanalyzemalwaresamplesbytheirdynamicfeatures(i.e.,whatamalwaredoes).Thereason\nis that static analysiscan be made impossible via advanced obfuscation using opaque con-\nstants[654],whichallowstheattackertohidewhatvalueswillbeloadedintoregistersduring\nruntime.Thisinturnmakesitveryhardforstaticmalwareanalysistoextractthecontrol-flow\ngraph and variables from the binary. A more effective approach is to combine static and dy-\nnamic analysis. For example, such an approach has been shown to be able to disassemble\nthehighlyobfuscatedbinarycode[655].\nAlesscommonbutmuchmorepotentobfuscationtechniqueiscodeemulation.Borrowing\ntechniques originally designed to provide software copyright protection [656], malware au-\nthors convert native malware binaries into bytecode programs using a randomly generated\ninstruction set, paired with a native binary emulator that interprets the instruction set. That\nis, with this approach, the malware \u2018binary\u2019 is the emulator, and the original malware code\nbecomes\u2018data\u2019usedbytheemulatorprogram.Notethat,forthesameoriginalmalware,the\nmalware author can turn it into many instances of emulated malware instances, each with\nitsownrandombytecodeinstructionsetandacorrespondingemulatorbinary.Itisextremely\nhardtoanalyseemulatedmalware.Firstly,staticanalysisoftheemulatorcodeyieldsnoinfor-\nmationaboutthespecificmalwarebehavioursbecausetheemulatorprocessesallpossible\nprogramsinthebytecodeinstructionset.Staticanalysisofthemalwarebytecodeentailsfirst\nunderstandingtheinstructionsetformat(e.g.,bystaticanalysingtheemulatorfirst),andde-\nvelopingtoolsfortheinstructionset;butthisprocessneedstoberepeatedforeveryinstance\nof emulated malware. Secondly, standard dynamic analysis is not directly useful because it\nobservestherun-timeinstructionsandbehavioursofanemulatorandnotofthemalware.\nAspecialiseddynamicanalysisapproachisneededtoanalyseemulatedmalware[621].The\nmain idea is to execute the malware emulator and record the entire instruction traces. Ap-\nplyingdynamicdataflowandtaintanalysistechniquestothesetraces,wethenidentifydata\nKAMalware&AttackTechnologies |October2019 Page212 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nregions containing the bytecode, syntactic information showing how bytecodes are parsed\ninto opcodes and operands, and semantic information about control transfer instructions.\nThe output of this approach is data structures, such as a control-flow graph (CFG) of the\nmalware,whichprovidesthefoundationforsubsequentmalwareanalysis.\nMalware often uses fingerprinting techniques to detect the presence of an analysis environ-\nmentandevadedynamicanalysis(e.g.,itstopsexecutingtheintendedmalwarecode).More\ngenerally, malware behaviours can be \u2018trigger-based\u2019 where a trigger is a run-time condition\nthatmustbetrue.Examplesofconditionsincludethecorrectdateandtime,thepresenceof\ncertain files or directories, an established connection to the Internet, the absence of a spe-\ncific mutex object etc. If a condition is not true, the malware does not execute the intended\nmalicious logic. When using standard dynamic analysis, the test inputs are not guaranteed\nto trigger some of these conditions and, as a result, the corresponding malware behaviours\nmay be missed. To uncover trigger-based behaviours a multi-path analysis approach [619]\nexplores multiple execution paths of a malware. The analyser monitors how the malware\ncode uses condition-like inputs to make control-flow decisions. For each decision point, the\nanalyser makes a snapshot of the current malware execution state and allows the malware\nto execute the correct malware path for the given input value; for example, the input value\nsuggeststhatthetriggeringconditionisnotmetandthemalwarepathdoesnotincludethe\nintended malicious logic. The analyser then comes back to the snapshot and rewrites the\ninput value so that the other branch is taken; for example, now the triggering condition is\nrewrittentobetrue,andthemalwarebranchistheintendedmaliciouslogic.\n6.3.3.2 IdentifyingtheAnalysisEnvironments\nMalware often uses system and network artifacts that suggest that it is running in an anal-\nysis environment rather than a real, infected system [605]. These artifacts are primarily cat-\negorised into four classes: virtualisation, environment, process introspection, and user. In\nvirtualisation fingerprinting, evasive malware tries to detect that it is running in a virtualised\nenvironment. For example, it can use red pill testing [657], which entails executing specific\nCPU instruction sequences that cause overhead, unique timing skews, and discrepancies\nwhencomparedwithexecutionsonabare-metal(i.e.,non-virtualised)system.Regardingen-\nvironmentartifacts,virtualmachinesandemulatorshaveuniquehardwareandsoftwarepa-\nrameters including device models, registry values, and processes. In process introspection,\nmalware can check for the presence of specific programs on operating systems, including\nmonitoringtoolsprovidedbyanti-viruscompaniesandvirtualmachinevendors.Lastly,user\nartifactsincludespecificapplicationssuchawebbrowser(orlackthereof),webbrowsinghis-\ntory, recently used files, interactive user prompts, mouse and keyboard activities etc. These\naresignalsforwhetherarealhumanusestheenvironmentformeaningfultasks.\nAnanalysisenvironmentisnottransparentifitcanbedetectedbymalware.Therearemitiga-\ntiontechniques,someaddressspecifictypesofevasionwhileothersmorebroadlyincrease\ntransparency. Binary modifications can be performed by dynamically removing or rewriting\ninstructionstopreventdetection[658],andenvironmentalartifactscanbehiddenfrommal-\nware by hooking operating system functions [659]. Path-exploration approaches [619, 660]\nforcemalwareexecutiondownmultipleconditionalbranchestobypassevasion.Hypervisor-\nbased approaches [618, 661] use introspection tools with greater privilege than malware so\nthat they can be hidden from malware and provide the expected answers to the malware\nwhen it checks the system and network artifacts. In order to provide the greatest level of\ntransparency, several approaches [620, 644] perform malware analysis on real machines to\navoidintroducingartifacts.\nKAMalware&AttackTechnologies |October2019 Page213 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n6.4 MALWARE DETECTION\n[605,c11,c14-16,c18][662,663,664,665,666,667,668,669,670,671,672]\n6.4.1 Identifying the Presence of Malware\nTheprocessoflocatingamaliciousprogramresidingwithinahostinvolvesidentifyingclues\nthat are indicative of the malware\u2019s presence on a computer system. We call these clues\n\u2018indicatorofcompromise\u2019,andtheyarethe\u2018features\u2019or\u2018artifacts\u2019ofmalware.\n6.4.1.1 FindingMalwareinaHaystack\nIn order to identify malware, we must first have an understanding of how malware is dis-\ntributed to their victims\u2019 hosts. Malware is commonly distributed via an Internet down-\nload [673]. A vulnerable Internet-facing program running on a computer can be exploited to\ndownload malware onto the computer. A user on the computer can be socially engineered\nto open an email attachment or visit a web page, both may lead to an exploit and malware\ndownload.\nWhilst being downloaded onto a host, the malware\u2019s contents can be seen in the payload\nsectionofthenetworktraffic(i.e.,networkpacket)[605].Asadefense,anAntivirus(AV)so-\nlution, or Intrusion Detection System (IDS), can analyse each network packet transported to\nan end-host for known malicious content, and block (prevent) the download. On the other\nhand, traffic content encrypted as HTTPS is widely and increasingly adopted by websites.\nUsing domain reputation systems [674], network traffic coming from domains and IP ad-\ndressesknowntobeassociatedwithmaliciousactivitiescanbeautomaticallyblockedwith-\noutanalysingthetraffic\u2019spayload.\nAfterbeinginstalledonacomputer,malwarecanresidewithinthehost\u2019sfilesystemormem-\nory(orboth).Atthispoint,themalwarecansleep(wheretheexecutabledoesnothingtothe\nsystem)untilalaterpointintime[675]asspecifiedbythemalwareauthor.AnAVorIDScan\nperiodicallyscanthehost\u2019sfilesystemandmemoryforknownmaliciousprograms[605].As\nafirstlayerofdefence,malwaredetectorscananalysestaticfeaturesthatsuggestmalicious\nexecutable contents. These include characteristics of instructions, control-flow graphs, call\ngraphs,byte-valuepatterns[676]etc.\nIf malware is not detected during its distribution state, i.e., a detection system misses its\npresence in the payloads of network traffic or the filesystem and memory of the end-host,\nit can still be detected when it executes and, for example, begins contacting its command-\nand-control(C&C)serverandperformingmaliciousactionsovertheInternetoronthevictim\ncomputer system. An AV or IDS on the network perimeter continuously monitors network\npacketstravellingoutofanend-host.IftheAVorIDSseesthatthehostiscontactingknown\nmalicious domain names or IP addresses it can surmise that the host has been infected by\nmalware. In addition, an AV or IDS on the end-host can look for behaviour patterns that are\nassociatedwithknownmalwareactivities,suchassystemorAPIcallsthatrevealthespecific\nfilesreadorwritten.\nKAMalware&AttackTechnologies |October2019 Page214 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nEvasion and Countermeasures Since Antivirus and IDS solutions can generate signatures\nformalwareexecutables,malwareauthorsoftenmorphthecontentsoftheirmalware.They\ncanchangethecontentsoftheexecutableswhilegeneratingidenticallyfunctionalcopiesof\ntheir malware (i.e., the malware will perform the same dynamic behaviours when executed).\nSince its static contents have been changed, the malware can evade an AV or IDS that uses\nthese static features. On the other hand, the malware can still be detected by an AV or IDS\nthatusesthedynamicfeatures(i.e.,whatthemalwaredoes).\nHeuristics, e.g., signatures of a packing tool, or high entropy due to encryption, can be used\ntodetectandblockcontentsthatsuggestthepresenceofpackedmalware,butthismaylead\ntofalsealarmsbecausepackingcanalsobeusedbybenignsoftwareandservices,suchas\nvideogames,toprotectproprietaryinformation.Themostreliablewaytodetectpackedmal-\nwareistosimplymonitoritsrun-timebehavioursbecausethepackedcodewillbeunpacked\nandexecuted,andthecorrespondingmaliciousbehaviourscanthenbeidentified[662].\nInadditiontochangingthemalwareexecutable,anattackercanalsochangethecontentsof\nitsmaliciousnetworktrafficbyusingpolymorphismtomodifypayloadssothatthesameat-\ntackslookdifferentacrossmultipletrafficcaptures.However,classicpolymorphicmalware\ntechniques [677] make the payloads look so different that even a naive IDS can easily differ-\nentiate them from benign payloads. On the other hand, with polymorphic malware blending\nattacks[663]maliciouspayloadscanbemadetolookstatisticallysimilartobenignpayloads.\nMalware authors often implement updating routines, similar to updates for operating sys-\ntemsandapplicationssuchaswebbrowsersandofficetools.Thisallowsmalwareauthors\nthe flexibility to make changes to the malware to not only include new malicious activities\nbutalsoevadedetectionbyAVsandIDSthathavestartedusingpatternsoftheoldmalware\nanditsoldbehaviours.\n6.4.2 Detection of Malware Attacks\nWe have discussed ways to identify static and behaviour patterns of malware, which can\nthen be used to detect instances of the same, or similar malware. Although many popular\nvariants of malware families have existed at one time or another (e.g., Zeus [678, 679], Spy-\neye[680,681],Mirai[682]),therewillalwaysbenewmalwarefamiliesthatcannotbedetected\nbymalwaredetectionmodels(suchasAVsignatures).Therefore,weneedtogobeyondiden-\ntifyingspecificmalwareinstances:weneedtodetectmaliciousactivitiesingeneral.\n6.4.2.1 Host-basedandNetwork-BasedMonitoring\nThe most general approach to detect malicious activities is anomaly detection [664, 665,\n683].Ananomalyinsystemornetworkbehaviourisanactivitythatdeviatesfromnormal(or\nseen) behaviour. Anomaly detection can identify both old and new attacks. It is important\nto note that an anomalous behaviour is not the same as a malicious behaviour. Anomalous\nbehaviours describe behaviours that deviate from the norm, and of course it is possible to\nhaveabnormalbenignactivitiesoccurringonasystemornetwork.\nOn the other hand, a more efficient and arguably more accurate approach to detect an old\nattack is to find the patterns or signatures of the known attack activities [605]. This is often\ncalled the misuse detection approach. Examples of signatures include: unauthorised write\ntosystemfiles(e.g.,WindowsRegistry),connectiontoknownbotnetC&Cservers,etc.\nTwo different, but complementary approaches to deploy attack detection systems are: 1)\nKAMalware&AttackTechnologies |October2019 Page215 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nhost-basedmonitoringofsystemactivities,and2)network-basedmonitoringoftraffic.Host-\nbasedmonitoringsystemsmonitoractivitiesthattakeplaceinahost,todetermineifthehost\nis compromised. These systems typically collect and monitor activities related to the file\nsystem,processes,andsystemcalls[605,666].Network-basedmonitoringsystemsanalyse\nactivitiesthatarenetwork-wide,e.g.,temporalcharacteristicsofaccesspatternsofnetwork\ntraffic flows, the domain names the network hosts reach out to, the characteristics of the\nnetworkpacketpayloadsthatcrossthenetworkperimeter,etc.[605,667].\nLet us look at several examples of malicious activities and the corresponding detection ap-\nproaches.Thefirst-generationspamdetectionsystemsfocusedonanalysingtheemailcon-\ntentstodistinguishlegitimatemessagesfromspam.Lattersystemsincludednetwork-level\nbehaviours indicative of spam traffic [684], e.g., spikes in email traffic volumes due to large\namountofspammessagesbeingsent.\nFor DDoS detection, the main idea is to analyse the statistical properties of traffic, e.g., the\nnumber of requests within a short time window sent to a network server. Once a host is\nidentifiedtobesendingsuchtraffic,itisconsideredtobeparticipatinginaDDoSattackand\nits traffic is blocked. Attackers have evolved their techniques to DDoS attacks, in particular,\nbyemployingmultiplecompromisedhosts,orbots,tosendtrafficinasynchronisedmanner,\ne.g., by using DDoS-as-a-service malware kits [685]. That is, each bot no longer needs to\nsend a large amount of traffic. Correspondingly, DDoS detection involves correlating hosts\nthatsendverysimilartraffictothevictimatthesametime.\nFor ransomware detection, the main approaches include monitoring host activities involved\nin encryption. If there is a process making a large number of significant modifications to a\nlarge number of files, this is indicative of a ransomware attack [686]. The \u2018significant\u2019 modi-\nfications reflect the fact that encrypting a file will result in its contents changing drastically\nfromitsoriginalcontents.\nHost-based and network-based monitoring approaches can be beneficially combined. For\nexample,ifweseecontentsfromvarioussensitivefilesonoursystem(e.g.,financialrecords,\npassword-relatedfiles,etc.)beingtransmittedinnetworktraffic,itisindicativethatdataare\nbeingexfiltrated(withouttheknowledgeandconsentoftheuser)toanattacker\u2019sserver.We\ncan then apply host-based analysis tools to further determine the attack provenance and\neffectsonavictimhost[687].\nSince many malicious activities are carried out by botnets, it is important to include botnet\ndetectionmethods.Bydefinition,botsofthesamebotnetarecontrolledbythesameattacker\nand perform coordinated malicious activities [668, 688]. Therefore, a general approach to\nbotnet detection is to look for synchronised activities both in C&C like traffic and malicious\ntraffic(e.g.,scan,spam,DDoS,etc.)acrossthehostsofanetwork.\nKAMalware&AttackTechnologies |October2019 Page216 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n6.4.2.2 MachineLearning-BasedSecurityAnalytics\nSince the late 1990s, machine learning (ML) has been applied to automate the process of\nbuilding models for detecting malware and attacks. The benefit of machine learning is its\nability to generalise over a population of samples, given various features (descriptions) of\nthose samples. For example, after providing an ML algorithm samples of different malware\nfamiliesfor\u2018training\u2019,theresultantmodelisabletoclassifynew,unseenmalwareasbelong-\ningtooneofthosefamilies[669].\nBoth static and dynamic features of malware and attacks can be employed by ML-based\ndetection models. Examples of static features include: instructions, control-flow graphs,\ncall graphs, etc. Examples of dynamic features include: system call sequences and other\nstatistics (e.g., frequency and existence of system calls), system call parameters, data-flow\ngraphs[689],networkpayloadfeatures,etc.\nAnexampleofsuccessstoriesinapplyingmachinelearningtodetectmalwareandattacksis\nbotnet detection [690]. ML techniques were developed to efficiently classify domain names\nas ones produced by Domain Generation Algorithm (DGA), C&C domains, or legitimate do-\nmains using features extracted from DNS traffic. ML techniques have also been developed\nto identify C&C servers as well as bots in an enterprise network based on features derived\nfromnetworktrafficdata[668].\nA major obstacle in applying (classical) machine learning to security is that we must select\nor even engineer features that are useful in classifying benign and malicious activities. Fea-\nture engineering is very knowledge- and labour- intensive and is the bottleneck in applying\nMLtoanyproblemdomain.Deeplearninghasshownsomepromiseinlearningfromalarge\namountofdatawithoutmuchfeatureengineering,andalreadyhasgreatsuccessinapplica-\ntionssuchasimageclassification[691].However,unlikemanyclassicalMLmodels(suchas\ndecision trees and inductive rules) that are human-readable, and hence reviewable by secu-\nrity analysts before making deployment decisions, deep learning outputs blackbox models\nthat are not readable and not easily explainable. It is often not possible to understand what\nfeatures are being used (and how) to arrive at a classification decision. That is, with deep\nlearning, security analysts can no longer check if the output even makes sense from the\npoint-of-viewofdomainorexpertknowledge.\n6.4.2.3 Evasion,Countermeasures,andLimitations\nAttackers are well aware of the detection methods that have been developed, and they are\nemploying evasion techniques to make their attacks hard to detect. For example, they can\nlimit the volume and intensity of attack activities to stay below the detection threshold, and\ntheycanmimiclegitimateuserbehaviourssuchassendingstolendata(asmallamountata\ntime)toa\u2018dropsite\u2019onlywhenauserisalsobrowsingtheInternet.Everymisuseoranomaly\ndetectionmodelispotentiallyevadable.\nIt should also come as no surprise that no sooner had researchers begun using ML than\nattackersstartedtofindwaystodefeattheML-baseddetectionmodels.\nOneofthemostfamousattacksistheMimicryattackondetectionmodelsbasedonsystem\ncall data [670]. The idea is simple: the goal is to morph malicious features to look exactly\nthe same as the benign features, so that the detection models will mistakenly classify the\nattackasbenign.TheMimicryattackinsertssystemcallsthatareinconsequentialtothein-\ntended malicious actions so that the resultant sequences, while containing system calls for\nmaliciousactivities,arestilllegitimatebecausesuchsequencesexistinbenignprograms.A\nKAMalware&AttackTechnologies |October2019 Page217 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nrelatedattackispolymorphicblending[663]thatcanbeusedtoevadeMLmodelsbasedon\nnetwork payload statistics (e.g., the frequency distribution of n-grams in payload data to a\nnetworkservice).Anattackpayloadcanbeencodedandpaddedwithadditionaln-gramsso\nthat it matches the statistics of benign payloads. Targeted noise injection [671] is an attack\ndesignedtotrickamachine-learningalgorithm,whiletrainingadetectionmodel,tofocuson\nfeaturesnotbelongingtomaliciousactivitiesatall.Thisattackexploitsafundamentalweak-\nness of machine learning: garbage in, garbage out. That is, if you give a machine-learning\nalgorithm bad data, then it will learn to classify data \u2018badly\u2019. For example, an attacker can\ninsert various no-op features into the attack payload data, which will statistically produce a\nstrong signal for the ML algorithm to select them as \u2018the important, distinguishing features\u2019.\nAslongassuchfeaturesexist,andastheyareundertheattacker\u2019scontrol,anyMLalgorithm\ncan be misled to learn an incorrect detection model. Noise injection is also known as \u2018data\npoisoning\u2019inthemachinelearningcommunity.\nWe can make attacks on ML harder to succeed. For example, one approach is to squeeze\nfeatures [692] so that the feature set is not as obvious to an attacker, and the attacker has\na smaller target to hit when creating adversarial samples. Another approach is to train sep-\narating classes, which distance the decision boundary between classes [693]. This makes\nit more difficult for an attacker to simply make small changes to features to \u2018jump\u2019 across\ndecisionboundariesandcausethemodeltomisclassifythesample.Anotherinterestingap-\nproach is to have an ML model forget samples it has learned over time, so that an attacker\nhastocontinuouslypoisoneverydataset[694].\nA more general approach is to employ a combination of different ML-based detection mod-\nels so that defeating all of them simultaneously is very challenging. For example, we can\nmodel multiple feature sets simultaneously through ensemble learning, i.e., using multiple\nclassifiers trained on different feature sets to classify a sample rather than relying on singu-\nlarclassifierandfeatureset.Thiswouldforceanattackertohavetocreateattacksthatcan\nevadeeachandeveryclassifierandfeatureset[672].\nAs discussed earlier, deep learning algorithms produce models that cannot be easily exam-\nined. But if we do not understand how a detection model really works, we cannot foresee\nhow attackers can attempt to defeat it and how we can improve its robustness. That is, a\nmodel that seemingly performs very well on data seen thus far can, in fact, be very easily\ndefeatedinthefuture-wejusthavenowayofknowing.Forexample,inimagerecognitionit\nturned out that some deep learning models focused on high-frequency image signals (that\narenotvisibletothehumaneye)ratherthanthestructuralandcontextualinformationofan\nimage (which is more relevant for identifying an object) and, as a result, a small change in\nthe high-frequency data is sufficient to cause a mis-classification by these models, while to\nthehumaneyetheimagehasnotchangedatall[695].\nThere are promising approaches to improve the \u2018explainability\u2019 of deep learning models. For\nexample,anattentionmodel[696]canhighlightlocationswithinanimagetoshowwhichpor-\ntions it is focusing on when classifying the image. Another example is LEMNA [697], which\ngeneratesasmallsetofinterpretablefeaturesfromaninputsampletoexplainhowthesam-\npleisclassified,essentiallyapproximatingalocalareaofthecomplexdeeplearningdecision\nboundaryusingasimplerinterpretablemodel.\nIn both the machine learning and security communities, adversarial machine learning [698]\nis and will continue to be a very important and active research area. In general, attacks on\nmachine learning can be categorised as data poisoning (i.e., injecting malicious noise into\ntraining data) and evasion (i.e., morphing the input to cause mis-classification). What we\nKAMalware&AttackTechnologies |October2019 Page218 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nhavediscussedabovearejustexamplesofevasionandpoisoningattacksonMLmodelsfor\nsecurityanalytics.These attackshavemotivatedthedevelopmentofnewmachine-learning\nparadigms that are more robust against adversarial manipulations, and we have discussed\nhereexamplesofpromisingapproaches.\nIngeneral,attackdetectionisaverychallengingproblem.Amisusedetectionmethodwhich\nis based on patterns of known attacks is usually not effective against new attacks or even\nnew variants of old attacks. An anomaly detection method which is based on a normal pro-\nfile can produce many false alarms because it is often impossible to include all legitimate\nbehavioursinanormalprofile.Whilemachinelearningcanbeusedtoautomaticallyproduce\ndetectionmodels,potential\u2018conceptdrift\u2019canrenderthedetectionmodelslesseffectiveover\ntime[699].Thatis,mostmachine-learningalgorithmsassumethatthetrainingdataandthe\ntestingdatahavethesamestatisticalproperties,whereasinreality,userbehavioursandnet-\nworkandsystemconfigurationscanchangeafteradetectionmodelisdeployed.\n6.5 MALWARE RESPONSE\n[20,700,701,702,703,704]\nIf we have an infected host in front of us, we can remove the malware, and recover the data\nand services from secure backups. At the local network access point, we can update corre-\nspondingFirewallandNetworkIntrusionDetectionSystemrules,topreventanddetectfuture\nattacks.Itisunfeasibletoexecutetheseremediationstrategiesiftheinfectedmachinescan-\nnot be accessed directly (e.g., they are in private residences), and if the scale of infection is\nlarge. In these cases, we can attempt to take down malware command-and-control (C&C)\ninfrastructureinstead[20,700],typicallyattheInternetServiceProvider(ISP)orthetop-level\ndomain(TLD)level.Takedownsaimtodisruptthemalwarecommunicationchannel,evenif\nthehostsremaininfected.Lastbutnotleast,wecanperformattackattributionusingmultiple\nsourcesofdatatoidentifytheactorsbehindtheattack.\n6.5.1 Disruption of Malware Operations\nThere are several types of takedowns to disrupt malware operations. If the malware uses\ndomain names to look up and to communicate with centralised C&C servers, we perform\ntakedown of C&C domains by \u2018sinkholing\u2019 the domains, i.e., making the C&C domains re-\nsolve to the defender\u2019s servers so that botnet traffic is \u2018trapped\u2019 (that is, redirected) to these\nservers[700].Ifthemalwareusespeer-to-peer(P2P)protocolasadecentralisedC&Cmech-\nanism,wecanpartitiontheP2Pbotnetintoisolatedsub-networks,createasinkholingnode,\nor poison the communication channel by issuing commands to stop the malicious activi-\nties[20].However,itshouldbeborneinmindthat,inmostterritoriesactivedefenceorintelli-\ngencegathering,suchashack-backs,accesstoormodificationofservers,DNS,ornetworks,\nisunlawfulwithoutappropriatelegalauthority.\nKAMalware&AttackTechnologies |October2019 Page219 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n6.5.1.1 EvasionandCountermeasures\nMalware often utilises agility provided by DNS fast-flux network and Domain-name Gener-\nation Algorithms (DGAs) to evade the takedown. A DNS fast-flux network points the C&C\ndomain names to a large pool of compromised machines, and the resolution changes\nrapidly [705]. DGAs make use of an algorithm to automatically generate candidate C&C do-\nmains, usually based on some random seed. Among the algorithm-generated domains, the\nbotmastercanpickafewtoregister(e.g.,onadailybasis)andmakethemresolvetotheC&C\nservers.Whatmakesthematterworsearetheso-calledBullet-ProofHosting(BPH)services,\nwhichareresilientagainsttakedownsbecausetheyignoreabusecomplaintsandtakedown\nrequests[701].\nWecandetecttheagileusageofC&Cmechanisms.Asthebotmasterhaslittlecontrolofthe\nIPaddressdiversityanddown-timeforcompromisedmachinesinafast-fluxnetwork,wecan\nusethesefeaturestodetectfast-flux[706].WecanalsoidentifyDGAdomainsbyminingNX-\nDomainstrafficusinginfectedhostsfeaturesanddomainnamecharacteristicfeatures[690],\norreverse-engineeringthemalwaretorecoverthealgorithm.Tocounterbullet-proofhosting,\nweneedtoputlegal,politicalandeconomicpressuresonhostingproviders.Forexample,the\nFBI\u2019sOperationGhostClickissuedacourtorderforthetakedownofDNSChanger[707,708].\nMalwarehasalsobecomeincreasinglyresilientbyincludingcontingencyplans.Acentralised\nbotnet can have P2P as a fallback mechanism in case the DNS C&C fails. Likewise, a P2P\nbotnet can use DNS C&C as a contingency plan. A takedown is effective only if all the C&C\nchannels are removed from the malware. Otherwise, the malware can bootstrap the C&C\ncommunicationagainusingtheremainingchannels.Ifwehastilyconductbotnettakedowns\nwithout thoroughly enumerating and verifying all the possible C&C channels, we can fail to\nactuallydisruptthemalwareoperationsandriskcollateraldamagetobenignmachines.For\nexample, the Kelihos takedown [709] did not account for the backup P2P channel, and the\n3322.orgtakedowndisabledthedynamicDNSserviceformanybenignusers.\nWeneedtohaveacompleteviewoftheC&Cdomainsandotherchannelsthatarelikelytobe\nusedbyabotnet,byusingmultiplesourcesofintelligenceincludingdomainreputation,mal-\nware query association and malware interrogation [700]. We start from a seed set of C&C\ndomains used by a botnet. Then, we use passive DNS data to retrieve related historical IP\naddresses associated with the seed set. We remove sinkholing, parking, and cloud hosting\nproviderIPaddressesfromthemtomitigatethecollateraldamagefromthetakedowns.The\nresulting IPs can also give us related historical domains that have resolved to them. After\nfollowing these steps, we have an extended set of domains that are likely to be used by the\nbotnet.ThissetcapturesagileandevasiveC&Cbehaviourssuchasfast-fluxnetworks.Within\ntheextendedset,wecombine1)lowreputationdomains,2)domainsrelatedtomalware,and\n3) other domains obtained by interrogating the related malware. Malware interrogation sim-\nulates situations where the default C&C communication mechanism fails through blocking\nDNS resolution and TCP connection [704]. By doing so, we can force the malware to reveal\nthe backup C&C plans, e.g., DGA or P2P. After enumerating the C&C infrastructure, we can\ndisablethecompletelistofdomainstotakethebotnetdown.\nKAMalware&AttackTechnologies |October2019 Page220 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n6.5.2 Attribution\nIdeally,lawenforcementwantstoidentifytheactualcriminalbehindtheattacks.Identifying\nthe virtual attacker is an important first step toward this goal. An attacker may have consis-\ntentcodingstyles,reusethesameresourcesorinfrastructures,orusesimilarC&Cpractices.\nFrom the malware data, we can compare its \u2018characteristics\u2019 with those of known historical\nadversaries,e.g.,codingstyles,serverconfigurations,etc.[702].Atthesourcecodelevel,we\ncan use features that reflect programming styles and code quality. For instance, linguistic\nfeatures, formatting style, bugs and vulnerabilities, structured features such as execution\npath,AbstractSyntaxTree(AST),ControlFlowGraph(CFG),andProgramDependenceGraph\n(PDG)canbeused.Otherfeaturesextractedfromthebinaryfilecanalsoindicateauthorship,\ne.g.,thesequenceofinstructionsandregisterflowgraph.\nFrom the enumerated attack infrastructure, we can associate the expanded domain name\nset with previously known adversaries. For instance, unknown TDSS\/TDL4 botnet ad-fraud\nC&CdomainssharethesameIPinfrastructurewithknowndomains,andtheyareregistered\nby the same set of email addresses and name servers. This allows us to attribute unknown\ndomainstoknownTDSS\/TDL4actors[703].\n6.5.2.1 EvasionandCountermeasures\nManymalwareauthorsreusedifferentkitsfortheconvenienceofferedbythebusinessmodel\nof the underground economy. Common for-sale kits allow malware authors to easily cus-\ntomise their own malware. They can also evade attribution by intentionally planting \u2018false\nflags\u2019inmalware.\nDomain registration information, WHOIS, is a strong signal for attack attribution. The same\nattackeroftenusesafakename,addressandcompanyinformationfollowingapattern.How-\never, WHOIS privacy protection has become ubiquitous and is even offered for free for the\nfirstyearwhenauserpurchasesadomainname.Thisremovestheregistrationinformation\nthatcouldbeusedforattackattribution.\nWe need to combine multiple, different streams of data for the analysis. For instance, mal-\nwareinterrogationhelpsrecovermoreC&Cdomainsusedbythefallbackmechanism,which\noffersmoreopportunityforattribution[704,710].\nCONCLUSION\nAttackers use malware to carry out malicious activities on their behalf. Malware can reside\ninanylayerofthesystemstack,andcanbeaprogrambyitselforembeddedinanotherappli-\ncation or document. Modern malware comes with a support infrastructure for coordinated\nattacksandautomatedupdates,andcanoperatelow-and-slowandcoveritstrackstoavoid\ndetection and attribution. While malware can cause wide-spread infection and harm on the\nInternet, it can also be customised for attacks targeting a specific organisation. Malware\nanalysis is an important step in understanding malicious behaviours and properly updating\nourattackpreventionanddetectionsystems.Malwareemploysawiderangeofevasiontech-\nniques,whichincludedetectingtheanalysisenvironment,obfuscatingmaliciouscode,using\ntrigger-conditions to execute, and applying polymorphism to attack payloads, etc. Accord-\ningly, we need to make analysis environments transparent to malware, continue to develop\nspecialised program analysisalgorithms and machine-learning based detection techniques,\nKAMalware&AttackTechnologies |October2019 Page221 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nand apply a combination of these approaches. Response to malware attacks goes beyond\ndetection and mitigation, and can include take-down and attribution, but the challenge is\nenumerating the entire malware infrastructure, and correlating multiple pieces of evidence\ntoavoidfalseflagsplantedbytheattackers.\nCROSS-REFERENCE OF TOPICS VS REFERENCE MATERIAL\nSections Cites\n7.1ACharacterisationofAdversaries [606]:c6\n6.2MaliciousActivitiesbyMalware [606]:c6, [605]:c11-12\n6.3MalwareAnalysis\n6.3.1AnalysisTechniques [605]:c1-10\n6.3.1.1StaticAnalysis [605]:c4-7\n6.3.1.2Dynamicanalysis [605]:c8-10\n6.3.1.3Fuzzing [611,612]\n6.3.1.5ConcolicExecution [613,614,615,616]\n6.3.2AnalysisEnvironments [605]:c2\n6.3.2.1SafetyandLive-EnvironmentRequirements\n6.3.2.2VirtualisedNetworkEnvironments [605]:c2, [617]\n6.3.3.2IdentifyingtheAnalysisEnvironments [605]:c15-18,[618,619,620]\n6.3.3Anti-AnalysisandEvasionTechniques [605]:c15-16, [619,621,622]\n6.4MalwareDetection\n6.4.1IdentifyingthePresenceofMalware\n6.4.1.1FindingMalwareinaHaystack [605]:c11,c14\n6.4.1.1EvasionandCountermeasures [605]:c15-16,c18, [662,663]\n6.4.2DetectionofMalwareAttacks\n6.4.2.1Host-basedandNetwork-BasedMonitoring [605]:c11,c14, [664,665,666,667,668]\n6.4.2.2MachineLearning-BasedSecurityAnalytics [668,669]\n6.4.2.3Evasion,Countermeasures,andLimitations [670,671,672]\n6.5MalwareResponse\n6.5.1DisruptionofMalwareOperations [20,700]\n6.5.1.1EvasionandCountermeasures [701]\n6.5.2Attribution [702,703]\n6.5.2.1EvasionandCountermeasures [704]\nKAMalware&AttackTechnologies |October2019 Page222 Chapter 7\nAdversarial Behaviour\nGianluca Stringhini Boston University\n223 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nINTRODUCTION\nThe technological advancements witnessed by our society in recent decades have brought\nimprovementsinourqualityoflife,buttheyhavealsocreatedanumberofopportunitiesfor\nattackers to cause harm. Before the Internet revolution, most crime and malicious activity\ngenerally required a victim and a perpetrator to come into physical contact, and this limited\nthereachthatmaliciouspartieshad.Technologyhasremovedtheneedforphysicalcontact\ntoperformmanytypesofcrime,andnowattackerscanreachvictimsanywhereintheworld,\nas long as they are connected to the Internet. This has revolutionised the characteristics of\ncrimeandwarfare,allowingoperationsthatwouldnothavebeenpossiblebefore.\nInthisdocument,weprovideanoverviewofthemaliciousoperationsthatarehappeningon\ntheInternettoday.Wefirstprovideataxonomyofmaliciousactivitiesbasedontheattacker\u2019s\nmotivations and capabilities, and then move on to the technological and human elements\nthat adversaries require to run a successful operation. We then discuss a number of frame-\nworksthathavebeenproposedtomodelmaliciousoperations.Sinceadversarialbehaviours\nare not a purely technical topic, we draw from research in a number of fields (computer sci-\nence, criminology, war studies). While doing this, we discuss how these frameworks can be\nusedbyresearchersandpractitionerstodevelopeffectivemitigationsagainstmaliciouson-\nlineoperations.\n7.1 A CHARACTERISATION OF ADVERSARIES\n[711][712][713,714][17,715,716][717][718,719]\nInthissection,wepresentacharacterisationofadversarieswhoperformmaliciousactions.\nThis characterisation is based on their motivation (e.g., financial, political etc.). Although al-\nternative characterisations and taxonomies exist (e.g., from the field of psychology [720]),\nwe feel that the one presented here works best to illustrate known attackers\u2019 capabilities\nand the tools that are needed to set up a successful malicious operation, such as a finan-\ncialmalwareenterprise.Thischaracterisationalsofollowstheevolutionthatcybercrimehas\nfollowed in recent decades, from an ad-hoc operation carried out by a single offender to a\ncommoditisedecosystemwherevariousspecialisedactorsoperatetogetherinanorganised\nfashion [721, 722]. The characterisation presented in this section is driven by case studies\nand prominent examples covered in the research literature, and as such is not meant to be\ncomplete. For example, we do not focus on accidental offenders (e.g., inadvertent insider\nthreats), or on criminal operations for which rigorous academic literature is lacking (e.g., at-\ntacks on financial institutions or supply chain attacks). However, we believe that the set of\ncrimes and malicious activities presented is comprehensive enough to draw a representa-\ntive picture of the adversarial behaviours that are occurring in the wild at thetime of writing.\nWebeginbydefiningtwotypesofcyberoffencesastheyhavebeendefinedintheliterature,\ncyber-enabledandcyber-dependentcrimes,andwecontinuebypresentingdifferenttypesof\nmaliciousactivitiesthathavebeencoveredbyresearchers.\nKAAdversarialBehaviour |October2019 Page224 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nCyber-enabled and cyber-dependent crimes\nOne of the main effects that the Internet has had on malicious activity has been to increase\nthe reach of existing crimes, in terms of the ease of reaching victims, effectively removing\nthe need for physical proximity between the victim and the offender. In the literature, these\ncrimesareoftenreferredtoascyber-enabled [711].\nAccordingtoClough[111],criminalshavefivemainincentivestomovetheiroperationsonline:\n1. UsingtheInternet,itiseasiertofindandcontactvictims.Emaillistsaresoldonunder-\ngroundmarkets[723],whileonlinesocialnetworkshavesearchfunctionalitiesembed-\ndedinthem,allowingcriminalstoeasilyidentifypotentialvictims[724,725].\n2. By using the Internet, criminal operations can be run more cheaply. Sending emails is\nfree, while scammers previously had to pay postage to reach their victims. This also\nallows criminals to increase the scale of their operations to sizes that were previously\nunthinkable.\n3. Compared to their physical counterparts, the Internet allows crimes to be performed\nfaster.Forexample,emailscanreachvictimsinamatterofseconds,withouthavingto\nwaitforphysicalletterstobedelivered.\n4. Using the Internet, it is easier to operate across international boundaries, reaching vic-\ntimslocatedinothercountries.Inthissetting,oftentheonlylimitationislanguage,with\ncriminals only targeting victims who speak a language that they are familiar with (e.g.,\npeopleinEnglish-speakingcountries)[726].\n5. By operating over the Internet, it is more difficult for criminals to get caught. This is\nmainly due to the transnational nature of cybercrime, and the fact that the problem of\nharmonising the appropriate laws of different countries is far from being solved [727].\nIn addition, research shows that online crime is often under reported, both because\nvictims do not know whom to report it to (given that the offender might be located in\nanother country), as well as the fact that they believe that they are unlikely to get their\nmoneyback[728].\nCyber-dependent crimes, on the other hand, are crimes that can only be committed with the\nuse of computers or technology devices [711]. Although the final goal of this type of crime\noften has parallels in the physical world (e.g., extortion, identity theft, financial fraud), the In-\nternetandtechnologygenerallyenablecriminalstogiveanewshapetothesecrimes,making\nthemlarge-scaleorganisedendeavoursabletoreachhundredsofthousands,ifnotmillions,\nofvictims.\nIntherestofthissectionweanalyseanumberofcyber-enabledandcyber-dependentcrimi-\nnalschemesindetail.\nKAAdversarialBehaviour |October2019 Page225 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nInterpersonal offenders\nThe first category that we are going to analyse is that ofinterpersonalcrimes. These crimes\ninclude targeted violence and harassment, directed at either close connections (e.g., family\nmembers) or strangers. While these crimes have always existed, the Internet has made the\nreach of harassers and criminals much longer, effectively removing the need for physical\ncontact for the offence to be committed. As such, these crimes fall into the cyber-enabled\ncategory.Intherestofthissection,weprovideanoverviewoftheseadversarialbehaviours.\nCyberbullying.Willard[712]definescyberbullyingas\u2018sendingorpostingharmfulmaterialor\nengaginginotherformsofsocialaggressionusingtheInternetorotherdigitaltechnologies\u2019.\nWhile not always illegal1, cyberbullying often occupies a grey area between what is consid-\neredaharmfulactandacriminaloffence[729].Thispracticehasbecomeaseriousproblem\nforyoungpeople,whoareoftentargetedbytheirpeersnotonlyinreallife,butalsoononline\nplatforms [730]. While the practice of bullying is nothing new, the Internet has changed the\ndynamics of these harassment practices significantly. What used to be a harmful practice\nlimited to school hours now can be perpetrated at any time, effectively exposing victims to\nnon-stopharassment[731].\nOne aspect that makes cyberbullying different from traditional, physical harassment is that\npeopleonlinecanbeanonymous,anddonothavetheirnameorfaceattachedtotheabusive\nactivity that they are carrying out [732, 733]. Researchers found that interacting with people\nonline creates a disinhibition effect wherby personal traits are accentuated (i.e., negative\npeople become meaner and positive people become nicer) [734]. This disinhibition effect\ncanhavetheeffectofmakingsomepeoplemorelikelytoengageinabusiveactivitythanthey\nwoulddointheofflineworld[733].Anotheraspectthatcontributestodisinhibitionisthefact\nthat online content distributed on certain platforms (e.g., snapchat, 4chan) is ephemeral, in\nthe sense that it is deleted after a certain period of time [735]. As such, harassers feel that\ntheiractionshavenoadverseconsequencessincetherewillbenohardevidenceofitinthe\nfuture.\nDoxing. Another type of online harassment is the practice of doxing, an attack where the\nvictim\u2019sprivateinformationispubliclyreleasedonline[736].Thisoperationisusuallypartof\na larger harassment campaign, where the release of sensitive information is used as a way\nofembarrassingthevictimorfacilitatingfurtherharassment,eveninthephysicalworld(for\nexample,byreleasinginformationattheworkplaceorthehomeaddressofthevictim).\nThe practice of doxing has become increasingly popular in recent years as a way of po-\nlarising online discussion and silencing people. A prominent example is the #GamerGate\ncontroversy,wherewomenactivistswereoftenattackedandhadtheirpersonalinformation\nposted online [737]. Doxing has been a primary vehicle for coordinated hate attacks run by\npolarised online communities such as 4chan\u2019s Politically Incorrect board (\/pol\/) [735]. As\npartoftheseattacks,anonymoususerspostinformationabouttheirtargetsonline(e.g.,so-\ncialmediapages,phonenumbers,physicaladdresses),andtheninviteotherpeopletocarry\nout loosely coordinated attacks (called raids) against those people. These attacks usually\nconsistofhatespeechandotherabusivelanguage.\nWhileprominentintheonlineharassmentspace,thepracticeofdoxingisalsousedbyother\noffenders.Forexample,itisoneofthetechniquesusedbyhacktivistgroupssuchasAnony-\nmoustoputtheirtargetsonnotice.Wewilldiscusstheothertechniquesusedbyhacktivists,\n1WhilethereisnodefinitionofcyberbullyinginUKlaw,someformsofitcanbeprosecutedunderthePro-\ntectionfromHarassmentAct1997.\nKAAdversarialBehaviour |October2019 Page226 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntogetherwiththeirmotivations,laterinthissection.\nCyberstalking. Another harmful activity that has been facilitated by the Internet is stalking.\nCyberstalking is the practice of using electronic means to stalk another person [738, 739].\nBroadlyspeaking,wecanidentifytwotypesofcyberstalkers:thosewhousetheinformation\nthat they find online to help them stalk their victim in real life (e.g., monitoring social media\ntoknowtheirwhereabouts),andthosewhousethemeansofferedbyonlineservicestostalk\ntheirvictimpurelyonline.Further,thestalkerswhooperateonlinearedividedintothosewho\nact purely passively, without any interaction with the victim, and those who perform interac-\ntions,forexample,bysendingtheirmessagesonasocialnetworkplatform[740].Tocounter\ncyberstalking,legislationhasrecentlybeenintroducedinmanycountries,includingthe2012\nProtectionsofFreedomsactintheUKandthe2000ViolenceAgainstWomenActintheUS.\nSextortion.Anemergingcrimethathasrisentorelevanceissextortion,whereacriminallures\nvictims to perform sexual acts in front of a camera (e.g., a webcam in a chatroom), records\nthose acts, and later asks for a monetary payment in order not to release the footage [741].\nSextortionisbecomingsucharelevantthreatthatcrimepreventionagenciessuchastheNa-\ntionalCrimeAgency(NCA)intheUKarelaunchingdedicatedawarenesscampaignsagainst\nit.2\nChild predation. Another crime that is facilitated by the Internet is child predation [742]. On-\nlineservicesareafertilegroundforcriminalstofindvictims,whetheronchats,onlinesocial\nnetworks, or online gaming platforms. The offender will then groom their victims to either\nperform physical or online abuse [742]. Compared to the corresponding offline offence, on-\nline sexual predation has two main differences: first, the victim and the perpetrator almost\nnever know each other in real life. Second, the victim demographics are more skewed to-\nwards adolescents than young children, because the age at which kids start going online is\nslightly higher [743]. Offenders use a range of tactics, including pretending to be young peo-\nple and children in order to groom their victims [744] and research has shown the potential\nvulnerabilityofchildrenofallagestosuchonlineidentitydeception[745].\nOther offenders do not interact with children directly, but download and share child pornog-\nraphyontheInternet.Insuchcaseshands-onabusersoftenknowtheirvictimsanddissemi-\nnatechildabusematerialtothese\u201cusers\u201dofsuchmaterial.Thishasbeenfacilitatedbypeer-\nto-peer sharing platforms [746, 747] as well as anonymising technologies such as Tor [748].\nThechallengesofidentifyingoriginatorsofnewchildabusematerial(andthedeceptivetac-\nticsusedbyoffenders,e.g.,specialisedvocabularyforfilenamestothwartinvestigations)in\nsuchpeer-to-peernetworkshavealsobeenstudied[747].\nCyber-enabled organized criminals\nInthissection,wefocusoncyber-enabledcrimesthatarecarriedoutbycareercriminals.In\nparticular, we provide two prominent examples of cyber-enabled crimes that have received\nsignificant attention by the research community: advance fee fraud and drug dealing. These\ncrimes are not usually carried out by single offenders, but rather by multiple criminals who\nacttogetherinsmallorganisations[749]orinactualstructuredcriminalorganisations[750].\nWe acknowledge that other crimes exist that have seen increased reach because of tech-\nnology. However, these crimes have yet to be studied in depth by the research community\nand, therefore, we decided to focus on the one which the research community has a better\nunderstandingof.\n2http:\/\/www.nationalcrimeagency.gov.uk\/crime-threats\/kidnap-and-extortion\/sextortion\nKAAdversarialBehaviour |October2019 Page227 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nAdvance fee fraud. In this type of scam, the victim is promised a reward (financial or other-\nwise), but in order to obtain it has to first pay a small fee to the fraudster. After the payment\ntakesplace,thevictimoftendoesnothearfromthescammeragain,whilesometimesthere-\nlationshiplastsforlongperiodsoftimeandthevictimisrepeatedlydefraudedoflargesums\nofmoney[751].\nThe archetypal example of advance fee fraud comprises so-called 419 scams [713]. Named\nafterthesectionoftheNigerianCriminalCodedealingwithfraud,thesescamsbecamepop-\nularinthe1980s,whenvictimswouldreceivephysicallettersfromanallegedNigerianprince,\nlookingtotransferlargeamountsofmoneyoutsideofthecountry.Toinitiatetheprocess,the\nvictim is required to transfer a small amount of money to the fraudster (e.g., to cover legal\nfees). As it can be imagined, the Internet allowed this type of fraud to flourish, by enabling\ncriminalstoinstantlyreachalargenumberofpotentialvictims.\nAnother example of advanced fee fraud is consumer fraud perpetrated on classifieds web-\nsites such as Craigslist [752]. As part of this fraud, victims respond to a classified adver-\ntisement for a desirable item (e.g., a used car or a rental property) which has much better\nconditions (such as a lower price) than similar posts. The fraudster responds that they will\nneedasmallupfrontpaymenttodeliverthegoods.Afterreceivingit,thevictimwillnothear\nfromthefraudsteragain.\nA final example of advanced fee fraud is the online romance fraud. Taking place on online\ndating sites, this type of fraud usually consists in criminals posing as attractive individuals\nlookingtostartarelationshipwiththevictim.Unlikethe419scam,theseonlinerelationships\noftenlastformonthsbeforethefraudsterdemandsmoney,forexample,tohelptheirfamily\nor to open a business [749]. By that time, the victim, who is likely emotionally involved with\nthe persona impersonated by the criminal, is likely to comply. Previous research reported\nthat victims of this crime can lose between \u00a350 and \u00a3240,000 [751]. Unlike other types of\nadvanced fee fraud, however, the psychological damage of losing the fictional relation can\nbemuchgreaterthanthefinancialone.\nA common element of every type of advanced fee fraud is the need for criminals to build an\nenticing narrative that will lure victims into paying the fraudulent fee. To this end, criminals\noften target specific demographics and impersonate specific personas. For example, previ-\nous research showed that romance fraudsters often pretend to be members of the military\nstationed abroad [753]. By doing so, the fraudsters can build a credible narrative as to why\nthey cannot meet the victim in person, and they can build an emotional connection with the\nvictim,whichwillincreasethechancesoftheirfallingforthescam.Often,fraudsterspretend\nto be widowed middle-aged men who target widowed women in the same demographic, in\nanattempttoestablishanemotionalconnectionwiththeirvictim[749].Inothercases,fraud-\nsters employ psychological tricks to win their victims over, such as applying time pressure\nor remarking that they specifically selected the victim because of their high moral charac-\nters[713].\nMorecynically,Herleyarguesthatfraudstersareincentivisedtobuildthemostabsurdnarra-\ntivespossible,tomakesurethatonlythosewhoaregullibleenoughtobelievethemwillreply,\nand that these people will be the most likely to fall for the scam [754]. His argument is that\nresponding to the first boilerplate message is expensive for the fraudster, while sending the\nfirstcopytoasmanyvictimsastheywishisfree.Forthisreason,itisintheirinteresttorule\noutthosewhoarenotlikelytofallforthescamassoonaspossible.\nDrug dealing. Another category of crimes for which the Internet has offered opportunities\nKAAdversarialBehaviour |October2019 Page228 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nis the drug trade. Thanks to anonymising technologies such as Tor [755] and cryptocurren-\ncies [756], online marketplaces have emerged where drug users can purchase illicit sub-\nstances and have them delivered directly to their home. Research has shown that this busi-\nness is thriving, despite the instability of these marketplaces, which are often taken down\nby law enforcement [714, 757]. Online drug markets provide an interesting paradigm switch\nfor drug users, because they remove the need for the buyer to interact with criminals in a\nphysicalandpotentiallyunsafesetting.Recentworkhasshown,however,thattheinception\noftheonlinedrugmarkethasnotchangedtheworldwidedrugtradeecosystem:thebigplay-\ners who produce and dispatch drugs remain broadly unchanged, while what has changed\nis the \u2018last mile\u2019 in the delivery (i.e., how local dealers and drug users get in touch and do\nbusiness)[750].\nCyber-dependent organized criminals\nIn this section, we describe crimes that have a financial goal and are carried out using com-\nplextechnicalinfrastructures(e.g.,botnets[758]).Unlikethecyber-enabledcrimesdescribed\nintheprevioussection,wherethecriminalisessentiallyreplicatingaphysicalcriminaloper-\nationandusingtheInternettoenhancehis\/herreach,inthecaseofcyber-dependentcrimes\ncriminals have to set up complex technological infrastructures to achieve their goals. The\ncomplexityoftheseoperationshaspromptedacompartmentalisationinthecriminalecosys-\ntem, where each malicious actor specialises in a specific part of a cybercriminal operation\n(e.g.,infectingcomputerswithmalwareorperformingmoneylaundering)andworkstogether\ntowards achieving a common goal. In this section, we provide some examples of cyber-\ndependent crimes that have been studied by the research literature in recent years. Then,\nin Section 7.2, we cover in detail the various elements that criminals need to put in place to\nmaketheiroperationssuccessful.\nEmail spam. Email spam has been a major nuisance for Internet users for the past two\ndecades, but it has also been at the forefront of very successful criminal operations, who\nhave managed to monetise the sale of counterfeit goods and pharmaceuticals by reaching\nbillionsofpotentialcustomersthroughmaliciousmessages[759].Emailspamisdefinedas\nunsolicited bulk email; this definition highlights the two main elements of the problem: the\nfact that the messages received by victims are unsolicited (i.e., they were not requested in\nthefirstplace),andthattheyaresentinbulktoreachasmanyvictimsaspossible.\nAlthough the very first spam email was recorded in 1978 [760], email spam rose to promi-\nnenceinthe1990s,whencriminalssetupsmalloperations,notdissimilarfromtheadvance-\nfee fraud ones described in the previous section [761]. The goal of these operations was to\nsell goods online, which could span from diet supplements to Nazi memorabilia [761]. At\nthis stage, relying on their own expertise and on the help of a small number of associates,\ncriminalswouldcarryoutalltheactivitiesrequiredtosetupasuccessfulspamoperation:(i)\nharvestingemailaddressestosendthemaliciousmessagesto,(ii)authoringtheemailcon-\ntent,(iii)sendingthespamemailsinbulk,(iv)processingtheordersfrompeoplewhowanted\nto purchase the advertised items, (v) reacting to raids by law enforcement (e.g., the seizure\nof an email server). Although they were still rudimentary compared to the spam operations\nthatcameduringthenextdecade,thesecriminalendeavourspromptedthedevelopmentof\nlegislationtoregulateunsolicitedbulkemails,suchastheDirectiveonPrivacyandElectronic\nCommunications in the EU,3 the Privacy and Electronic Communications Regulations in the\n3https:\/\/eur-lex.europa.eu\/legal-content\/EN\/ALL\/?uri=celex%3A32002L0058\nKAAdversarialBehaviour |October2019 Page229 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nUK4 and the CAN-SPAM Act in the US.5 These pieces of legislation helped prosecute some\nofthoseearly-dayspammers.In2004,AmericaOnline(AOL)wonacourtcaseagainstDavis\nWolfgangHawke,whowassellingNazigadgetsthroughspamemails.Hawkewassentenced\ntopaya12.8MUSDfine.\nThetechnicaladvancementsoftheearly2000s,andinparticularthedevelopmentofbotnets,\nnetworks of compromised computers controlled by the same cybercriminal [758], gave un-\nprecedentedopportunitiestocriminalswhowanttoengageinemailspamtoday.Emailspam\nisnotaone-personoperationanymore,ratheritissupportedbythrivingcriminalecosystems.\nSpammerscanrentbotnetsfromcriminalswhoarespecialisedininfectingcomputerswith\nmalware [723], purchase lists of target email addresses from specialised actors [762] and\nsign up to an affiliate programme [763, 764], which will provide the spammer with a way of\nadvertising,aswellastakingcareofshipmentsandpayments.\nThe arms race connected to spam mitigation has been going on since the 1990s, with a\nnumberofmitigationsbeingproposed[765].Currently,anti-spamtechniquesensurethatthe\nvast majority of malicious emails will never reach their victims\u2019 mailboxes. To solve this is-\nsue,criminalshavetosendtensofbillionsofemails[723]tokeeptheiroperationsprofitable.\nAnotherissueisthat,outofthevictimsreachedbythosespamemailsthatmakeitthrough,\nonly a small fraction will purchase the advertised goods and turn a profit for the criminals.\nResearchers performed a case study for the Storm botnet [17], showing that out of 469 mil-\nlionspamemailssentbythebotnet,only0.01%reachtheirtargets.Ofthese,only0.005%of\ntheusersclickonthelinkscontainedintheemails,whileanevenlowernumberendsuppur-\nchasingitems-only28usersintotaloutofthe469millionreached,or0.0004%ofthetotal.\nDespite this steep drop, McCoy et al. showed that popular spam affiliate programmes were\nabletomakeupto85millionUSDofrevenueoverathree-yearperiod[763].Theyalsoshowed\nthat key to this success are returning customers. In fact, spam emails need to reach an in-\nterested customer only once, and this person can later keep purchasing on the site without\nhavingtoworryaboutspamfilters.\nPhishing.Aparticulartypeofspamisphishing,wherecriminalssendemailsthatpretendto\nbefromgenuineservices(e.g.,onlinebanking,socialnetworkwebsites)[715].Theseemails\ntypically lure users into handing out their usernames and passwords to these services by\npresenting them with a believable email asking them to visit the website (e.g., to retrieve\ntheir latest account statement). By clicking on the link in the email, users are directed to a\nwebsite displaying fake but realistic login pages. Once they have input their credentials, the\ncriminalsgainaccesstothemandtheywillbeabletolaterlogintothoseservicesonbehalf\noftheusers,potentiallymakingmoneydirectlyorsellingthecredentialsontheblackmarket.\nForthecriminal,akeycomponenttothesuccessofphishingpagesissettingupwebpages\nthat resemble the original ones as much as possible. To facilitate this task, specialised cy-\nbercriminalsdevelopandsellso-calledphishingkits[766],programmesthatcanbeinstalled\non a server and will produce an appropriately-looking web page for many popular services.\nThesekitstypicallyalsoprovidefunctionalitiestomakeiteasierforthecriminaltocollectand\nkeeptrackofthestolencredentials[766].Anotherelementneededbycriminalstohostthese\npages is servers under their control. Similar to spam, criminals, researchers, and practition-\nersareinvolvedinanarmsracetoidentifyandblacklistphishingWebpages[767],therefore\nitdoesnotmakeeconomicsenseforcriminalstosetuptheirownservers.Rather,criminals\noftenhostthesewebsitesoncompromisedservers,forwhichtheydonothavetopay[768].\n4https:\/\/en.wikipedia.org\/wiki\/Privacy_and_Electronic_Communications_(EC_Directive)_Regulations_2003\n5https:\/\/en.wikipedia.org\/wiki\/CAN-SPAM_Act_of_2003\nKAAdversarialBehaviour |October2019 Page230 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nAfterstealingalargenumberofcredentials,criminalscaneitherexploittheseaccountsthem-\nselves or sell the usernames and passwords on the black market. Previous research has\nshownthatoftenthesecriminalslogintotheaccountsthemselvesandspendtimeevaluating\ntheirvalue,forexample,bylookingforfinancialinformationinwebmailaccounts.[726,769].\nFinancial malware. Another popular criminal operation is financial malware. In this setting,\ncriminals aim to install malware on their victims\u2019 computers and steal financial credentials\nsuch as credit card numbers and online banking usernames and passwords. This trend\nstarted with the Zeus malware, which criminals could purchase on the black market and\nusetosetuptheiroperations[770].Onceinstalledonavictimcomputer,Zeuswouldwaitfor\ntheusertovisitawebsiteonapre-configuredlistofinterestingonesthatthecriminalcould\nspecify.Itwouldthenrecordusernamesandpasswordsastheusertypedthemin,andsend\nthemtothecommandandcontrolserversetupbythecriminal.\nAmoresophisticatedinformationstealingbotnetwasTorpig[716].UnlikeZeus,Torpigused\nabotnet-as-a-servicemodel,whereasinglespecialisedcriminalwasresponsibleforhosting\nthe botnet infrastructure, while other criminals could run their campaigns to infect victim\ncomputers,payafeetousethetorpiginfrastructureandlaterretrievethestolencredentials.\nResearchers showed that, in 2009, the Torpig botnet was able to steal 8,310 unique bank\naccountcredentialsand1,660uniquecreditcardnumbersoveraten-dayperiod.[716].\nTomonetisetheiroperations,cybercriminalscansellthestolenfinancialinformationondedi-\ncatedundergroundforums[771].Thepricethatcriminalscanaskforthesecredentialsvaries\nbased on the type of records that they were able to steal. For example, on the underground\nmarket there are two types of credit card records that are traded: dumpz, which contain the\ninformationthatallowsacriminaltocloneacreditcard(i.e.,cardnumber,expirationdate,se-\ncurity code), and fullz, which also contain the billing address associated with the card. Fullz\nareworthmoremoneyontheblackmarket,becausetheyallowmiscreantstopurchaseitems\nonline.\nA related type of crime that is becoming more popular is card skimming [772]. In this cyber-\nenabledcrime,criminalsinstalldevicesonATMmachineswhichcollectdetailsofthecards\ninserted into the machines by unwitting users. The criminal can then collect the devices to\nretrieve the stolen financial credentials. While this type of crime is serious, it is also a good\nexampleofthelimitationsofphysicalcrimecomparedtotheironlinecounterparts:theneed\nfor physical action by the criminal limits the scale of the operation, while financial malware\noperationscanaffectmuchhighernumbersofvictims.Forexample,theTorpigmalwarewas\ninstalledonover100,000computers[716].\nNote that malware is not always needed to perform financial fraud. In some cases, insider\nthreatswithinfinancialorganisationscouldactmaliciouslyanddefraudboththeirinstitutions\nandtheircustomers[773,774].Inothercases,financialinformationsuchascreditcardnum-\nbers could be stolen by exploiting a vulnerability in an online system (e.g., by dumping the\ndatabase of an online store) [775]. In other cases, stolen SWIFT credential of banks can be\nusedtoperformlargefraudulentmoneytransfers[776]\nClickfraud.WebadvertisementsarethemainwaytheWebismonetised.AWebadministra-\ntor can decide to host advertisements on his\/her website, and whenever visitors view them\norclickonthemtheyreceiveasmallfeefromanadvertiser.Tomediatethisinteraction,spe-\ncialisedservicesknownasadexchangeshaveemerged.Becauseoftheireasymonetisation,\nWeb advertisements are ripe for fraud. In particular, criminals can host advertisements on\ntheir own websites and then generate \u2018fake\u2019 clicks (e.g., by using bots). This results in an ad\nKAAdversarialBehaviour |October2019 Page231 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nexchangepayingcriminalsforadimpressionsthatwerenot\u2018genuine,\u2019eventuallydefrauding\ntheadvertiser.\nOnceagain,criminalsareinvolvedinanarmsracewithadexchanges,whoareinterestedin\nkeeping fraud on their services minimal. To help criminals generate large numbers of clicks\nandremainundertheradarbygainingaccessfromlargenumbersofIPaddresses,so-called\nclick fraud botnets have emerged. An example is Zeroaccess [16], which was active in 2013.\nOn an infected machine, this malware would act like a regular user, browsing websites and\nclicking on advertisements that its owner chose. Researchers showed that this botnet was\nresponsibleforlossestotheadvertisingindustryofapproximately100,000USDperday[16].\nUnauthorised cryptocurrency mining. With the increasing popularity of cryptocurrencies, a\nnewopportunityhasopenedupforcriminals:usinginfectedcomputerstominecurrency.In\n2014, Huang et al.revealed this threat, showing that botnets were used to mine Bitcoin [15].\nWhile revealing this new monetisation for malware, the authors also concluded that these\noperationsdidnotappeartobemakingmuchmoney,totalingatmost900USDaday.\nAmorerecentstudy,however,showedthatcryptocurrencyminingbybotnetscouldbemuch\nmorerewardingthanpreviouslythought.PastranaandSuarez-Tangilshowedthatbymining\nMoneroandusinganumberoftechniquestoincreasetheirchancesofminingcurrency(e.g.,\nusingminingpools)criminalscouldmakeupto18millionUSDoveratwo-yearperiod.[777].\nAnotheremergingtrendincybercrimecomprisesleveragingWebbrowserstominecryptocur-\nrencies. Instead of installing malware on victim computers and using them for mining, mis-\ncreants add scripts to webpages and have their visitors mine cryptocurrencies. This type of\nmaliciousactivityiscalledcryptojacking.Althoughusingthesescriptsisnotnecessarilyille-\ngal(i.e.,Webadministratorscanlegitimatelyinstallthemontheirwebpagesinasimilarway\nto advertisements), criminals have been caught adding them to compromised websites on\nmultiple occasions. Konoth et al. showed that a malicious campaign can make GBP 31,000\noveraweek[778],whileR\u00fcthetal.[779]showedthat1.18%oftheminedblocksintheMonero\nblockchaincanbeattributedtoCoinhive,themostpopularcryptojackinglibrary.\nRansomware. The newest trend in malware is Ransomware. As part of this operation, crimi-\nnals infect their victim systems with malware which encrypts the user\u2019s personal files (e.g.,\ndocuments)andsendstheencryptionkeytothecriminal,whothenasksforaransominex-\nchange for giving the user access to their data again [780]. The idea of malicious software\nthatusespublickeycryptographytoholdthevictim\u2019sdatahostageisnotnew,anditwasthe-\norised by Yung in 1996 already [781]. In 20 years, however, the technological advancements\nonthemalwaredeliveryendhavemadeitpossibletoreachlargenumbersofvictims,andthe\nintroductionofanonymouspaymentmethodssuchasBitcoinhasmadeitsaferforcriminals\ntocollectthesepayments.\nRansomwareis,atthetimeofwriting,thegoldstandardforcybercriminals.Thistypeofmal-\nwareoperationhassolvedthemonetisationproblemsthatweresoimportantinothertypes\nof cybercriminal schemes: the criminal does not have to convince the victim to purchase a\ngood, like in the case of email spam, or to fall for a fraud, like in the case of phishing. In ad-\ndition, the victim is highly incentivised to pay the ransom, because the probability that the\ncriminals have encrypted files that the user will need (and for which they have no backup\ncopy) is high. In fact, recent research was able to trace 16 million USD in payments on the\nBitcoinblockchainthatcanbeattributedtoransomwarecampaigns[782].\nAlthoughthemostsophisticatedransomwarecampaignsinvolveencryptingthevictim\u2019sfiles,\nKharraz et al. showed that it is not uncommon for malware authors to use other techniques\nKAAdversarialBehaviour |October2019 Page232 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nto lock the victim out of his\/her computer [783]. These techniques include setting up a\npassword-protectedbootloaderandnotgivingthepasswordtotheuserunlesshe\/shepays.\nWhilethesetechniquesarelikelytoyieldaprofitforthecriminal,theyarealsoeasiertomiti-\ngate,asthevictim\u2019sfilesaresafeonthecomputerandasimplecleanupofthemalware(and\nrestoringtheoriginalmasterbootrecord)canfixtheproblem.\nDenialofservice.AfeaturethatallInternet-connecteddeviceshaveisnetworkconnectivity.\nAcriminalcanleveragethebandwidthofaninfecteddevicetoperformaDistributedDenialof\nService(DDoS)attackagainstatarget.Criminalscansimplyusethebandwidthgeneratedby\nthebotnet,orleverageamplificationattacks(i.e.,networktrafficgeneratedbymisconfigured\nnetwork devices, or devices with poor default settings) to enhance the power of their DDoS\nattacks[685].\nThe criminals can then set up services where they offer DDoS for hire. These services are\nappealing for example to unscrupulous actors who want their business competitors to go\noffline or to online gamers who want to knock their opponents off the Internet to win the\ngame [784]. To hide the illicit nature of their business, these services often advertise them-\nselvesas\u2018stresstesters\u2019,servicesthataWebadministratorcanusetotesthowtheirWebap-\nplicationsperformunderstress[784].Inreality,however,theseservicesdonotcheckwhether\nthecustomerpurchasingaDDoSattackisactuallythesamepersonwhoownsthetargetdo-\nmain.\nHacktivists\nWhilecriminalsdrivenbyprofitareabigthreat,notalladversariesaredrivenbymoney.Inpar-\nticular,wedefinetheactofcomputercrimemotivatedbyapoliticalgoalashacktivism[717].\nThese crimes can take various forms, from denial of service attacks [717] to compromising\ncomputersystemswiththegoalofreleasingsensitiveinformationtothepublic[785].There\nis an ongoing debate among scholars on whether actions by hacktivists fall under political\nactivism (e.g., civil disobedience) or cyber terrorism [786]. Holt et al. studied cyber attacks\ncarriedoutbyfarleftgroupsintheUSandfoundthattherewasanincreaseinonlineattacks\nduringperiodsthatobservedadecreaseinphysicalviolencefromthosesamegroups[787].\nDenial of service. The practice of hacktivism started in the 1990s with netstrikes [788]. As\npart of this practice, Internet users would connect to target the websites simultaneously to\ndepletetheirresourcesandmakethemunresponsive.Thiswasoftendonetoprotestagainst\nactions and policies by government agencies and corporations. Twenty years later, with the\nincreasedsophisticationofferedbytechnology,hacktivistgroupssuchasAnonymous[789]\ntook the idea of netstrikes and made it bigger in size. This collective became popular for\nlaunching denial of service attacks against organisations that were guilty of performing ac-\ntionsthatdidnotmatchtheirmoralstance,suchasgovernmentslinkedtotherepressionof\nthe Arab Spring, credit card companies who would not make donations to entities such as\nWikileaksorradicalreligiousorganisations.\nTo perform their attacks, Anonymous would ask its sympathisers to install a computer pro-\ngram,calledLowOrbitIonCannon(LOIC),whichwouldactasabotinabotnet:theircontroller\nwouldusethecomputer\u2019sbandwidthtocarryoutadenialofserviceattackagainstachosen\ntarget. The difference with traditional botnets (and the ones used to carry out DDoS attacks\nin particular) is that the user is accepted to be part of it by installing the LOIC program, and\nsufferedlawenforcementactionasaconsequence.\nData leaks. Another trend that we have been observing in recent years in the area of hack-\nKAAdversarialBehaviour |October2019 Page233 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntivismisthereleaseofstolendocumentsintothepublicdomain,forexample,toraiseaware-\nness about secret surveillance programs by governments [790]. A prominent example of an\norganisationthatperformsthesedataleaksisWikileaks[785].Similartechniqueshavealso\nbeenusedbyAnonymous(e.g.,abouttheidentityof1,000KuKluxKlanmembers).\nWeb Defacements. The last trend that is typical of politically-motivated actors is Web de-\nfacement[791].Aspartofthisactivity,miscreantsexploitvulnerabilities(rangingfromweak\npasswords to software vulnerabilities) in the websites of organisations they disagree with,\nandusethemtochangethehomepageofthewebsitetoapolitically-chargedone.Anexam-\nple of an organisation that is prominently using Web defacements to spread their message\nis the Syrian Electronic Army [792], a group of hackers close to the Assad regime. Although\npopular with criminals with a political agenda, Web defacement is not just their prerogative.\nIn fact, Maimon et al. showed that this is a popular way for early career cybercriminals to\nprovetheirworth[793].\nState actors\nAnother type of malicious actor involved in adversarial behaviours online comprises nation\nstates.Inthepastfewyears,wehaveobservedanescalationintheuseofcomputerattacks\nbystateactorstoachievetheirgoals.Broadlyspeaking,thistypeofattackdiffersfromthose\nperformedbyfinanciallymotivatedcybercriminalsfortworeasons:\n1. Commoditycybercrimeneedstogatherasmanyvictimsaspossibletomaximisetheir\nprofits. For instance, criminals setting up a botnet to steal financial information from\ntheirvictimswillwanttoreachthehighestpossiblenumberofvictimstoimprovetheir\nrevenue. This means that the cybercriminal\u2019s attacks need to be either generic or di-\nversified enough to cover a large population of devices (e.g., by using exploit kits, as\nexplained in Section 7.2). In a state-sponsored attack, on the other hand, there is no\nneed to make money, and usually the victim is well defined (e.g., a specific organisa-\ntionorapersonofinterest).Inthissetting,theattackcanbetailoredtothevictim;this\nincreasesthechancesofsuccess,becauseofthetimethatcanbespentdesigningthe\nattackandthefactthattheattackwillbeunique(e.g.,byusingazerodayattack[794]),\nanditwillbeunlikelythatexistingprotectionsoftwarewillcatchit.\n2. Becauseoftheneedtomakemoney,traditionalcybercriminalsneedtheirattackstobe\nfast. This is not the case for state-sponsored attacks, where the reward for achieving\nitsgoal(e.g.,stealingsensitiveinformationfromagovernment)makesitacceptableto\nwaitforlongperiodsoftimebeforefinalisingtheattack.\nState-sponsored attacks fall broadly into three categories, depending on the purpose of the\nattack: sabotage, espionage, and disinformation. In the following, we describe these three\ntypesofattacksinmoredetail.\nSabotage. Modern critical infrastructure can be disrupted by electronic means. Research\nhas shown that it is not uncommon for critical facilities such as power plants to have some\nsortofnetworkconnectivitybetweenthecomputerscontrollingthemachineryandtheones\nconnectedtotheInternet[795].Inthecaseofastateadversary,evenhavingnetworksecurity\nappliances to guard the boundary between the two networks is not enough, since, as we\nsaid, attacks can be so sophisticated and tailored that off-the shelf solutions fail to detect\nthem[718].Onceapieceofmalwaremanagestogetintothecontrolnetwork,itcouldmake\nthemachinerymalfunctionandpotentiallydestroyit.Evenwhenthereisaphysicalseparation\nKAAdversarialBehaviour |October2019 Page234 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nbetween the control network and the wider Internet, attacks are still possible when we are\nfacedwithadversarieswithvirtuallyunlimitedresources[718].\nA prominent example is the Stuxnet worm [718, 796], a sophisticated attack performed\nagainst the Nathanz nuclear enrichment facility in Iran in 2010. Allegedly, the malware was\nintroduced into the facility by first infecting the laptop of one of the consultants who was\nmaintaining the machinery. Once the malware was in the right environment, it identified the\npieces of equipment that it was designed to target and sabotaged the enrichment experi-\nments,makingthecentrifugesspinoutofcontrol.Todate,Stuxnetisatextbookexampleof\nthelengthstowhichstate-sponsoredattackerscangotoachievetheirobjectives,andofthe\nsophisticationthattheirattackscanachieve.\nSabotageisnotalwayslinkedtostateactors.Majorincidentshavebeencausedbydisgrun-\ntled employees of companies who acted as insider threats, like in the case of the Maroochy\nWater Services [797]. In this incident an insider whose employment had not been confirmed\ndecided to get revenge on the company by spilling sewage, causing major environmental\ndamage[797].\nEspionage. Another goal that state-sponsored actors have for their attacks is spying on op-\nponentsandprominentadversaries.Researchhasshownthatstateactorsmakeprominent\nuse of spearphishing (i.e., targeted phishing) to lure activists and companies into installing\nmalware that is later used to spy on them [726, 798]. In other cases, state actors infect sen-\nsitive systems (e.g., servers in large corporations), with the goal of stealing sensitive infor-\nmation [799]. The security industry has dubbed these long-standing, sophisticated attacks\nAdvancedPersistentThreats.\nDisinformation. In the past two years evidence has emerged that state-sponsored actors\nhave been involved in spreading disinformation on social media [719, 800, 801, 802]. This\nhas been done through troll accounts that acted to polarise online discussion on sensitive\ntopics[803].WhilesocialnetworkssuchasTwitterhavemadedataaboutaccountsrelatedto\nstate-sponsoreddisinformationpubliclyavailable[719,800],rigorousevidenceisstillmissing\nonhowtheseoperationsarecarriedoutonthebackend.Forexample,theextentinwhichthe\naccounts involved in disinformation are controlled by human operators as opposed to bots\nisnotclear.\n7.2 THE ELEMENTS OF A MALICIOUS OPERATION\n[804][805][806][807,808][722][809,810]\nAs we showed in Section 7.1, malicious operations can use rather complex infrastructures,\nparticularlyinthecaseoforganisedcrime,whichismostlymotivatedbytwofacts.First,the\ncriminalneedstheseoperationstobeascosteffectiveaspossible(andconsequentlymake\nthe highest possible profit). Second, multiple actors (law enforcement, security companies,\nthe users themselves) are constantly attempting to take down these malicious operations,\nandthecriminalhas,therefore,aneedtomakethemresilienttothesetakedownattempts.\nTo ensure that the criminals\u2019 needs are met in this scenario, in recent years we have wit-\nnessed a specialisation in the cybercriminal ecosystem, where different actors specialise in\naspecificelementrequiredfortheoperationtosucceed;themiscreantsthentradetheseser-\nviceswitheachotherontheblackmarket.Inthissection,weprovideanoverviewoftheele-\nmentsrequiredforacyber-dependentorganisedcriminaloperationtosucceed,asdescribed\nKAAdversarialBehaviour |October2019 Page235 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nin Section 7.1. Many of the elements discussed, however, also apply to the other types of\nadversarialbehavioursdescribedinthatsection.\nAffiliate Programmes\nThe main goal of organised crime is to make money from their operations. This requires\nnotonlyawell-oiledtechnicalinfrastructuretomakesurethattheirbotnetsoperateproperly\nbut,perhapsmoreimportantly,aworkingmethodtocollectpaymentsfromvictims(orfrom\nsponsors,inthecaseofDoS),whilemakingsurethatalltheactorsinvolvedintheoperation\ngetpaid.\nInthecybercriminalworld,thisistypicallydonethroughaffiliateprogrammes.Anaffiliatepro-\ngrammeisaschemewheremainorganisationprovidesa\u2018brand\u2019andallthemeansrequired\ntocarryoutorders,shipmentsandpayments.Affiliatescanjointheprogram,directtrafficto\nthe platform, and get a cut of the sales that they are responsible for. Although this scheme\nexists for legitimate businesses (e.g., Amazon has an affiliate programme), it has been par-\nticularly successful for cybercriminal operations. The main difference between legitimate\nand criminal affiliate programmes is that the second category of operations typically deals\nwithproductsthatareconsideredillegalinmostjurisdictions(e.g.,counterfeitpharmaceuti-\ncals,gambling,counterfeitdesignerproducts)andtheytypicallyendorsecriminalpromotion\ntechniques(e.g.,theuseofmalwareorblackhatsearchengineoptimisation).\nAffiliateprogrammesarepopularinthecybercriminalworldbecausetheymeanaffiliatesdo\nnot have to set up their operations from start to finish, but rather focus on attracting traffic,\nfor example by setting up botnets and sending email spam advertising the affiliate market-\nplace. The first successful examples of affiliate programmes for cybercrime were centred\naround email spam, and were advertising counterfeit pharmaceuticals [759, 763, 764]. How-\never, affiliate programmes are present in most types of cyber-dependent crime, an example\nbeingtheCryptowallransomwareoperation.6\nIn addition to providing the monetisation necessary for cybercriminal operations, affiliate\nprogrammes also act as facilitators for criminals to get in contact and trade the services\nthat are needed for the operation to succeed. This is typically done by setting up a forum\nwhere affiliates can trade their services [723, 763]. Gaining access to these forums typically\nrequiresvettingbytheaffiliateprogrammeadministrators.\nInfection vectors\nAsdiscussedearlier,thefirststeprequiredbycriminalstoperformamaliciousactivityisof-\nten infecting their victims with malware. To this end, the criminals need to first expose their\npotential victims to the malicious content, and then have them install it on their machines\n(through eitherdeceptionor by exploitingasoftwarevulnerabilityintheir system).Inthe fol-\nlowing, we survey three popular methods on delivering malware to victim computers. Note\nthat, while other infection vectors are possible, such as physical access to a network or hi-\njackingawirelessnetwork,todatewearenotawareofanylarge-scalecompromiseinvolving\ntheseinfectionvectors,andthereforewedonotfocusonthem.\nMalicious attachments. Possibly the oldest method of delivering malware is attaching ma-\nlicious software to spam emails, disguising it as useful content that the user might want to\nopen. Thisspreadingtechnique was madepopular by emailworms in theearly 2000s,such\n6https:\/\/www.secureworks.com\/research\/cryptowall-ransomware\nKAAdversarialBehaviour |October2019 Page236 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nasthe\u2018Iloveyou\u2019worm[811],butitisstillapopularwayofdeliveringmalwaretovictims[723].\nIn the commoditised economy described previously, it is often the case that a criminal who\nwantstospreadamalwareinfectionpaysanothercriminalwhoalreadyhascontrolofabot-\nnettodeliverthepayloads[716].Tobesuccessful,thecontentusedforthisinfectionvector\nneeds to convince the user to click on the attachment and install it. To this end, criminals\noften use deception techniques to make the content look interesting and appealing, similar\nto the techniques discussed for phishing [715]. This deception falls into the area of social\nengineering[812].\nBlack hat search engine optimisation. Search Engine Optimization (SEO) is a popular prac-\nticewherebywebmastersoptimisetheircontentsothatitisbetterindexedbysearchengines\nandappearsamongthefirsthitsforrelevantsearches.Cybercriminalsarealsointerestedin\nhaving their malicious Web pages appear high in search results, because this increases the\nchances that potential victims will find them and click on them. To accomplish this, spe-\ncialisedcriminalsofferblackhatSEOservices.Asaresultoftheseservices,maliciousweb-\nsites are pushed high up in search engine rankings for keywords that are unrelated to the\nwebsite [813]. This happens particularly often in proximity with popular events (e.g., sports\nandpoliticalevents),becausepeoplewillbemorelikelytosearchforkeywordsrelatedtothe\nevent. To achieve effective black hat SEO, cybercriminals compromise vulnerable websites\nandusethemtopromotetheircustomers\u2019webpages(e.g.,byaddinginvisiblelinksandtext\npointingtothetargetwebpage).\nDrive-bydownloadattacks.Althoughdeceptivelyluringusersintoinstallingmalwareworks,\nhavinganautomatedmethodthatdoesnotrequirehumaninteractionismoreadvantageous\nfor cybercriminals. To this end, cybercriminals have perfected so-called drive-by download\nattacks [805]. As part of one of these attacks, the victim visits a webpage under the control\nof the criminal (e.g., encountered through black hat SEO). The webpage contains malicious\nJavaScriptcodethatwillattempttoexploitavulnerabilityintheuser\u2019sWebbrowserorinone\nof its plugins. If successful, the Web browser will be instructed to automatically download\nandinstallthemalware.\nTo host their malicious scripts, cybercriminals often compromise legitimate websites [814].\nAn alternative trend is purchasing Web advertisement space and serving the malicious con-\ntentaspartofthead,inapracticeknownasmalvertisement[815].\nCompromising of Internet-connected devices. As more devices get connected to the Inter-\nnet(e.g.,InternetofThings(IoT)devices),anadditionalopportunityprovidedtoattackersis\nscanningtheInternetfordevicesthatpresentknownvulnerabilitiesandexploitthemtobuild\nlargebotnets.AprominentexampleofthiswastheMiraibotnet[682].\nInfrastructure\nAnother important element that criminals need for their operations to succeed is where to\nhosttheirinfrastructure.Thisisimportantforbothaffiliateprogrammes(e.g.,wheretohost\nfraudulent shopping websites) as well as for botnet operations. Law enforcement and Inter-\nnet Service Providers (ISPs) are continuously monitoring servers for evidence of malicious\nactivity [806], and will take them down if this activity can be confirmed, which would put the\ncriminaloperationinjeopardy.\nBulletproof hosting service providers. To maximise the chances of their operations being\nlong-lived,cybercriminalsresorttousingso-calledbulletproofhostingserviceproviders[759,\n816].Theseprovidersarewellknownnottocomplywithlawenforcementtakedownrequests.\nKAAdversarialBehaviour |October2019 Page237 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nThisismadepossiblebyeitherbeinglocatedincountrieswithlaxcybercrimelegislation,or\nby the service provider operators actively bribing local law enforcement [759]. Bulletproof\nhosting service providers typically charge their customers more money than a regular ISP\nwould. As such, they become a hotspot of illicit activity, since malicious users congregate\nthere because of their guarantees, but legitimate users have no incentive to use them. De-\nspite providing higher guarantees for cybercriminals, bulletproof hosting service providers\narenotinvincibletotakedownefforts.Inparticular,ISPsneedtobeconnectedtoeachother\nto be able to route traffic, and an ISP that is uniquely hosting malicious content could be\ndisconnectedbytheotherproviderswithoutmanyconsequencesforlegitimateInternettraf-\nfic[759].\nCommandandcontrolinfrastructure.Abotnetrequiresacommandandcontrol(C&C)infra-\nstructurethatinfectedcomputerscanbeinstructedtoconnectto,receiveordersandreport\nonprogressinthemaliciousoperation.Originally,botnetswoulduseasinglecommandand\ncontrolserver,althoughthiswouldbeasinglepointoffailure.Evenassumingthattheserver\nwashostedbyabulletproofhostingprovider,andcouldnotthereforebetakendown,thefact\nthat the server had a unique IP address meant that it could easily be blacklisted by security\ncompanies.\nTomitigatethisproblem,cybercriminalscameupwithC&Cinfrastructuresthatareredundant\nand more difficult to take down. An example is the multi-tier botnet infrastructure, where\nbots are instructed to connect to an intermediary C&C server, which is then responsible for\nrelayingtheinformationtoandfromacentralcontrolserver[817].Thisinfrastructuremakes\nthebotnetmoreresilient,becauseevenifsomeoftherelaysaretakendown,thecentralC&C\nis still operational and additional relays can be added. In addition, the infected computers\nnever see the IP address of the central C&C server, making it more difficult to locate and\ntake down. A variation of this model is peer-to-peer botnets, where infected computers with\nparticularly good connectivity and public IP addresses are \u2018elected\u2019 to act as relays [818].\nThis infrastructure increases the flexibility that the criminal has and reduces the cost of the\noperation, because the criminal does not have to spend money to install relays. However,\nthe botnet infrastructure becomes vulnerable to infiltration, whereby researchers can create\nfake bots, be elected as relays and are thus suddenly able to monitor and modify the traffic\ncomingfromthecentralC&C[17].\nAdditional techniques used by cybercriminals to make their control infrastructure more re-\nsilientareFastFlux[706],wherecriminalsusemultipleserversassociatedwiththeC&Cinfra-\nstructure and rotate them quickly to make takedowns more difficult, and Domain Flux [819],\nin which the domain name associated to the C&C server is also rotated quickly. Both meth-\nods are effective in making the operation more resilient, but they also make the operation\nmoreexpensiveforthecriminaltorun(i.e.,theyhavetopurchasemoreserversanddomain\nnames).\nKAAdversarialBehaviour |October2019 Page238 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nSpecialised services\nInthissection,wedescribespecialisedservicesthathelpcriminalstosetuptheiroperations.\nIn addition to these dedicated malicious services, others that have a legitimate use (e.g.,\nVPNs, Tor) are also misused by criminals, for example hosting drug market websites on the\nDarkNet[757,820].\nExploit kits. In the previous section, we saw that drive-by download attacks are a powerful\nweapon that a cybercriminal can use to infect computers with malware without any human\ninteraction. The problem with effectively performing these attacks, however, is that they re-\nquire an exploit to a software vulnerability in the victim\u2019s system. Since cybercriminals want\nto infect as many victims as possible, it is challenging to find an exploit that can work on\nthesystemsofthemajorityofpotentialvictims.Inadditiontothisissue,exploitsdonotage\nwell, since software vendors routinely patch the vulnerabilities that they know about. A cy-\nbercriminal performing a sustained drive-by download operation, therefore, would need to\ncontinuously collate exploits to multiple vulnerabilities, a task that is unfeasible, especially\nwhen the criminal also has to run other parts of the business (e.g., the monetisation part).\nOnce a victim visits the exploit kit\u2019s webpage, this tool first fingerprints the victim\u2019s system,\nlookingforapotentialvulnerabilitytobeexploited.Itthendeliverstheexploittothevictim.If\nsuccessful, the victim\u2019s computer is instructed to download the malware of the customer\u2019s\nchoice.\nTheseissueshavecreatedanopportunityforspecialisedcriminalstoprovideservicesforthe\nrest of the community. This has led to the creation of exploit kits [807], which are tools that\ncollectalargenumberofvulnerabilitiesandaresoldontheblackmarketforothercriminals\nto use. An exploit kit is typically accessible as a Web application. Customers can point their\nvictimstowardsitbycompromisingwebsitesorusingmaliciousadvertisements.\nPay-per-install services. Infecting victim computers and maintaining a botnet is a complex\ntask, and research has shown that malware operators who attempt to do so without the\nproper expertise struggle to make profits [821]. To solve this issue and satisfy the demand\nforstablebotnets,anewcriminalservicehasemergedcalledPayPerInstallservice(PPI)ser-\nvices[808].PPIoperatorsareproficientinsettingupabotnetandhavingitrunproperly.Other\ncriminalscanthenpaythePPIoperatortoinstallmalwareontheinfectedcomputersontheir\nbehalf.PPIservicestypicallyofferagoodlevelofchoicegranularitytotheircustomers,who\nnotonlychoosehowmanyinfectionstheywanttoinstall,butalsotheirgeographicallocation\n(withbotsindevelopedcountriescostingmorethaninfectionsindevelopingones[808]).\nAn advantage of using PPI services is that they make their customers\u2019 cybercriminal opera-\ntions more resilient: if their malware stops working, for example, because law enforcement\nhastakendowntheC&Cserversthatituses,thecriminalcanresumeoperationsbyaskingthe\nPPI operator to install an updated version of their malware on the victim machines. For this\nreason, this malware symbiosis between PPI services and other botnets is very common in\nthecriminalecosystem(see,forexample,thesymbiosisbetweenPushdoandCutwail[723],\nandbetweenMebrootandTorpig[716]).\nKAAdversarialBehaviour |October2019 Page239 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nHuman services\nIn this section, we discuss the auxiliary services that are needed for an end-to-end cyber-\ncriminaloperationtosucceed.Althoughtheseelementsarenotusuallythoughttobepartof\ncybercrime, they are as important to the success of a cybercriminal operation as the more\ntechnicalelements.\nCAPTCHA solving services. In some cases, cybercriminals need to set up accounts on\nonline services to initiate their operations (e.g., a spam operation running on social net-\nworks [724, 725]). To protect themselves against large-scale automated account creation,\nhowever,onlineserviceswidelyuseCAPTCHAs,whicharenotoriouslydifficultforautomated\nprogramstosolve.Tosolvethisproblemfacedbycybercriminals,newCAPTCHAsolvingser-\nviceshavebeenestablished[822].Theseservicestakeadvantageofcrowdsourcedworkers.\nOnce the CAPTCHA solving customer encounters a CAPTCHA, this is forwarded by the ser-\nvicetooneoftheseworkers,whowillsolveit.Thisway,thecustomercanproceedandcreate\ntheaccountontheonlineservice.\nIn other cases, online services require whoever has created an online account to receive a\ncode texted to a phone number and issue that code back to the service. To overcome this\nissue,cybercriminalscanuseservicesthatautomatethistypeofinteraction[722].\nFakeaccounts.Sincecreatingfakeaccountsistimeconsumingandrequirestheuseofaux-\niliaryservicessuchasCAPTCHAsolvers,cybercriminalshavestartedspecialisinginthecre-\nationoffakeaccountsonmultipleonlineservices,andsellingthemontheblackmarket[823].\nAccounts on different services can have different prices, depending on the ease of creating\nnewaccountsontheplatformandonhowaggressivelytheservicesuspendssuspectedfake\naccounts.\nA problem with newly purchased fake accounts is that they do not have an established \u2018re-\npuation\u2019 on the social network, thus reducing their credibility to potential victims and their\nreachinspreadingmaliciousmessages.Thiscanbemitigatedbyusing\u2018reputationboosting\u2019\nservices, which help to build a network of contacts for accounts that otherwise would not\nhave any. Examples of these are services offering fake likes on Facebook [824] and luring\ncompromisedaccountsintofollowingtheservice\u2019scustomersonTwitter[825].\nContent generation. In some cases, cybercriminals need to set up fake content to send to\ntheirvictims,whetherthisisforspamemails,fakewebsitesusedforblackhatSEOoronline\nsocial network sites. To generate this content, the criminals can recruit workers on under-\ngroundforums[826].\nMoneymules.Themaingoalofmanycybercriminaloperationsistomakemoneyfromtheir\nvictims.However,extractingmoneyfromanoperationisnoteasy.Inthecaseofbankfraud,\nfor example, even if the criminals obtain access to the victim\u2019s bank account, they still need\ntotransfermoneytoaccountsundertheircontrolwithoutbeingdetectedandapprehended.\nTo facilitate these monetisation operations, criminals take advantage of money mules [827].\nThese are people who are recruited by criminals to perform money laundering operations\nandmakeitmoredifficultforlawenforcementtotrackthemoneyobtainedfromanillicitop-\neration. In a money mule scheme, the criminal recruits a person to act as a mule and sends\nthem money by using traceable means (e.g., a check or a wire transfer). The mule is then\ninstructedtotransferthemoneytoanaccountunderthecriminal\u2019scontrolbyusinguntrace-\nable means (e.g., Western Union). The mule is also told that they can keep a percentage of\nthe amount as a payment. Since these untraceable transactions need to be carried out in\nKAAdversarialBehaviour |October2019 Page240 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\npersonbythemule,theyconstituteaweakpointinthemonetisationoperation,meaningthat\nlaw enforcement could identify and arrest the mule before the money is transferred. In fact,\nevenifstolenmoneyisnevermentioned,themuleisparticipatinginmoneylaunderingwhen\nhe\/sheacceptsthisjob.\nAn alternative way of monetising malicious operations, which is used in the case of stolen\ncredit cards, is reshipping mules [775]. In these operations, criminal agencies recruit unsus-\npectingusersadvertisinga\u2018shippingagent\u2019job.Thenothercriminalscanrecruittheservices\noftheseagencies,andpurchaseexpensiveitemsusingstolencreditcards(e.g.,electronics,\ndesignergoods),whilesendingthemtothemule\u2019shomeaddress.Themuleistheninstructed\nto open the packages and reship the goods to a foreign address, where they will be sold on\ntheblackmarket.\nPayment methods\nAs criminals need to have money transferred to them, they can use a number of different\npayment methods, each carrying a different level of risk and being more or less familiar to\nthevictims.\nCredit card processors. Most transactions online are performed by credit cards. To collect\nas many customers as possible, cybercriminals tend to accept credit card payments too.\nMcCoyetal.showedthat95%spamaffiliateprogrammesbetween2007and2012accepted\ncreditcardpayments[763],andthatDDoSservicesthatdidnotacceptcreditcardssuffered\nwith regard to the numbers of customers that they were able to attract [784]. Credit card\nprocessorskeeptrackofthechargebacksthatacompanyhasonitsaccounts,andtoomany\ncomplaints from customers usually result in the company\u2019s accounts being terminated. For\nthisreason,manycybercriminaloperationsoffer\u2018customersupport\u2019totheirvictims,offering\nrefundsiftheyarenotsatisfiedwiththeirpurchases[809].\nA challenge that cybercriminals face is finding banks that are willing to process their pay-\nments. Typically, these banks would charge them higher transaction fees (10-20%) to cover\ntheriskofdealingwithcriminaloperations[763].Despitetheseincreasedfees,itisnotguar-\nanteedthatthecriminaloperationwillbesafe:similartowhathappenswithbulletproofhost-\ning ISPs, banks need to maintain good relations with their peers, otherwise they will be dis-\nconnectedfromthefinancialnetwork[804].\nPaypal. Another payment method that is familiar to users is Paypal. For this reason, Paypal\nis often accepted by criminals offering illicit services. While user friendly, criminals face the\nissuethattheplatformiscentralised,andPaypalcankeeptrackoffraudulentpaymentsand\nterminatetheaccountsthatarefoundtobeinbreachofthetermsofservice[813].\nWestern Union and other \u2018untraceable\u2019 payments. Other forms of payment offer more\nanonymityforcybercriminals,andarelessriskyaswellasbeingnotaswellregulated.Exam-\nples are money exchanges (e.g., Western Union, Money Gram) or pre-paid vouchers (Money\nPark).Theseareoftenusedbycriminalstotransferfunds[828].Tocashthemoney,theseser-\nvices only require a unique code and an identification document. Depending on the country\nwherethecriminalislocated,however,theIDrequirementmightnotbeveryrigorous.\nHistoricallyother\u2018anonymous\u2019paymentmethodshaveexistedsuchasLibertyReserve,Web\nMoneyandeGold[722].Thesevirtualcurrenciesallowedcriminalstoeasilymakepayments\nastheytookadvantageofthelooseregulationsintheircountryoforigin(e.g.,LibertyReserve\nwasbasedinCostaRica).Aftercrackdownsonthesepaymentmethodsbylawenforcement,\nKAAdversarialBehaviour |October2019 Page241 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n15\nBreak Into Server\nExploit Vulnerability Steal Password\nDevelop Purchase Install Guess Extort From\nExploit Exploit Keylogger Password Owner\nFigure7.1:Exampleofanattacktreedescribingtheactionofbreakingintoaserver.\ncriminalsmovedtootherpaymentmethods.\nCryptocurrencies. At the time of writing, probably the safest form of payment for cyber-\ncriminals is cryptocurrencies. These payments have become popular for multiple types of\ncybercriminal operations, from ransomware [783] to drug market payments [714]. While re-\nsearch has shown that customers are reluctant to use services that only accept cryptocur-\nrencies[784],thistypeofpaymentstillworkswhenvictimshavenochoice(e.g.,inthecase\nofransomware)orareverymotivated(e.g.,inthecaseofdrugmarkets).\nWhile more anonymous than other payment methods, research has shown that payments\nmadeinBitcoincanbetraced[810].Inaddition,oftencryptocurrenciesneedtobeconverted\nintorealmoneybycriminals,andthemoneyceasestobeanonymousatthatpoint.Additional\nconcerns arise from the risks involved in making payments on cryptocurrency exchanges.\nMoore et al. showed that it is not uncommon for Bitcoin exchanges to suffer breaches that\nresult in losses of currency [829]. Exit scams, where an exchange vanishes with all the cur-\nrencystoredinit,arealsoaproblem[830].\n7.3 MODELS TO UNDERSTAND MALICIOUS OPERATIONS\n[79][831][832,833,834][722][835]\nAs shown in the previous sections, malicious operations can be quite complex and entail\nmultiple technical elements and multiple actors. It is, therefore, necessary for defenders to\nhave the appropriate means to understand these operations, so that they can develop the\nbest countermeasures. In the following, we survey a number of models that have been pro-\nposedtomodelmaliciousoperations.Thesemodelscomefromanumberofresearchareas,\nincluding computer security, criminology and war studies. Note that for space reasons we\ncannotdiscussallthetechniquesthathavebeenproposedintheliteraturetomodelattacks.\nForamorecomprehensivelist,wepointthereaderto[836].\nAttack trees\nThe first way to model attacks against computer systems involve attack trees [79]. Attack\ntreesprovideaformalisedwayofvisualisingasystem\u2019ssecurityduringanattack.Inanattack\ntree,therootnodeisthegoaloftheattack,anditschildnodesarethewaysanattackercan\nachievethatgoal.Goingdownthetree,eachnodebecomesasub-goalthatisneededforthe\nKAAdversarialBehaviour |October2019 Page242 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nattacktosucceed,anditschildrenarepossiblewaystoachieveit.\nFigure 7.1 represents an example of an attack tree. In this example, the attackers aim to\ncompromiseaserver.Todothis,theyhavetwochoices:theycaneitherexploitavulnerability\northeycanobtainthepasswordtotherootaccountandloginusingnormalmeans.Toexploit\navulnerability,theycaneitherdeveloptheexploitthemselvesorpurchaseanalreadyexisting\none,perhapsthroughanexploitkit.Iftheattackersdecidetousetheaccount\u2019spasswordto\nlogintotheserver,theyfirstneedtoobtainit.Todothis,theycaneitherinstallmalwareonthe\nserveradministrator\u2019scomputertologthepasswordastheyinputit(i.e.,akeylogger),guess\nthepasswordusingalistofcommonlyusedonesorperformabruteforceattack,andfinally\nextort the password from the owner. The attack graph could then be further refined with\nthe possible ways the attacker could perform these actions (e.g., extorting the password by\nblackmailingtheowner,bykidnappingthemetc.).\nAttack trees allow two types of nodes, \u2018or\u2019 nodes and \u2018and\u2019 nodes. \u2018Or\u2019 nodes represent the\ndifferentwaysattackerscanachieveagoal(i.e.,thechildrenofanynodeinFigure7.1).\u2018And\u2019\nnodes, on the other hand, represent the different steps that all need to be completed to\nachieve the goal. Once the tree has been created, security analysts can annotate it to as-\nsessthesystem\u2019srisktotheattack,forexample,bymarkingthevariousattackstrategiesas\nfeasible or unfeasible, by assigning likelihood scores to them or by estimating the cost for\nan attacker to perform a certain action. The scores can then be propagated along the tree\nfollowingspecificrules[79]toassesstheoverallfeasibilityandlikelihoodoftheattack.\nAnother model that is related to attack trees is attack graphs [837]. While attack trees are\nlimited to single targets, attack graphs allow to model attack actors, vectors, vulnerabilities,\nandassets.Anotherusefulmodeltounderstandnetworkattacksareattacknets[838].\nKill chains\nAnother useful tool that can be used to model and understand attacks is kill chains. In the\nmilitary context, a kill chain is a model that identifies the various phases involved in an at-\ntack.7 In the computer world, Hutchins et al. developed a Cyber Kill Chain [831] that models\nthe different steps involved in a malicious operation conducted against computer systems.\nIn their model, Hutchins et al. identify seven phases. The model is designed for operations\nwheretheattackeridentifies,compromisesandlaterexploitsacomputersystem,and,there-\nfore, not all the phases apply to all the adversarial behaviours discussed in this document.\nThesevenphasesarethefollowing:\n1. Reconnaissance,whenattackersidentifypossibletargets.Thisphasecouldcomprise\nanattackerscanningthenetworklookingforvulnerableserversoraspammerpurchas-\ningalistofvictimemailaddressesontheblackmarket.\n2. Weaponisation, when an attacker prepares the attack payload for use. This could con-\nsist in developing a software exploit against a newly identified vulnerability or crafting\nanadvance-fee-fraudemail.\n3. Delivery, when the attacker transmits the payload to its victim. This could consist in\nsettingupamaliciouswebserver,purchasingadvertisementspacetoperformamalver-\ntisingattackorsendinganemailcontainingamaliciousattachment.\n7https:\/\/en.wikipedia.org\/wiki\/Kill_chain\nKAAdversarialBehaviour |October2019 Page243 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n4. Exploitation,whenthetarget\u2019svulnerabilityisexploited.Thisphasecouldentailadrive-\nby download attack, or the victim being lured into clicking on a malicious attachment\nthroughdeception.\n5. Installation,whenmalicioussoftwareisdownloaded,thusallowingtheattackertoben-\nefitfromthevictimmachine.Intheirpaper,Hutchinsetal.consideredanattackerwant-\ningtomaintainconstantaccesstothevictimcomputer,usingatypeofmalwareknown\nasaRemoteAccessTrojan(RAT)[839].\n6. Command and control, when the attacker establishes aC&C infrastructure and a com-\nmunicationprotocoltocontroltheinfectedcomputer.\n7. Actions on objectives, when the infection is monetised. This could entail stealing\nsensitive information from the victim computer, encrypting the victim\u2019s data with ran-\nsomware,miningcryptocurrencies,etc.\nFor each of the seven steps, Hutchins et al. identified strategies to disrupt the malicious\noperations,followingfivepossiblegoals(Detect,Deny,Disrupt,Degrade,Deceive).Examples\nof these techniques include patching vulnerabilities, setting up intrusion detection systems\nonthenetworkordeceivingtheattackerbysettinguphoneypots[840].\nSimilarkillchainshavebeenproposedbyotherresearchersovertheyears.Anexampleisthe\noneproposedbyGuetal.tomodelbotnetinfections[688].Inthismodel,theauthorsidentify\nfive phases where an infection is separated: an inbound scan (similar to phase one in the\npreviously described model), an inbound infection (similar to phase four from the previous\nmodel), an \u2018egg\u2019 download (analogous to phase five), a C&C phase (the same as phase six),\nand an outbound scan. At the time of developing this model, botnets were mostly acting as\ncomputer worms [841], scanning for vulnerable computers, infecting them, and using them\nto propagate further. While this model correctly depicted early botnets, it ceased to map\nreality when botmasters started using other methods to install their malware and monetise\ntheir infections. Nowadays, worms are almost extinct, with the exception of the infamous\nWannaCrymalware[842].Thisexampleshowsthatitisdifficulttodevelopmodelsofattacker\nbehaviourthatareresilienttochangesinthemodusoperandiofattackers.\nEnvironmental criminology\nWhile cybercrime is a relatively new threat, physical crime has been studied by scholars for\ndecades. It is, therefore, interesting to investigate whether this established body of knowl-\nedge can be applied to better understand and mitigate the emerging threat of online crime.\nEnvironmental criminology, in particular, is a branch of criminology that focuses on criminal\npatternsinrelationtothespacewheretheyarecommittedandtotheactivitiesoftheactors\ninvolved(victims,perpetrators,andguardians)[832].Aparticularchallengethatariseswhen\nwe attempt to apply environmental criminology theory to cybercrime is that the concept of\n\u2018place\u2019 on the Internet is not as well defined as in the real world. In the following, we briefly\nreview the key concepts of environmental criminology, and provide some examples of how\ntheycouldbeappliedtomitigatingInternetcrime.\nRoutineactivitytheory.Routineactivitytheoryisacommonlyusedconceptinenvironmental\ncriminology, postulating that the occurrence of crime is mostly influenced by an immediate\nopportunity for one to commit a crime [843]. In particular, routine activity theory states that\nfor a crime to happen, three components need to converge: (i) a motivated offender, (ii) a\nsuitabletargetand(iii)theabsenceofacapableguardian.\nKAAdversarialBehaviour |October2019 Page244 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nThese concepts could be useful for better modelling malicious activity online. For example,\nresearch has shown that botnet activity reaches a peak during daytime, when most vulner-\nable computers are switched on and the victims are using them, while it drops significantly\novernight [716]. In routine activity theory terms, this can be translated to the fact that when\nmorepotentialvictimsareonline,theopportunityforcriminalstoinfectthemincreasesand\nthisresultsinanincreaseinbotnetactivity.\nRational choice theory. Rational choice theory aims to provide a model as to why offenders\nmake rational choices to commit crime [844]. In the case of cybercrime, this model could\nbe useful for understanding the reaction of criminals to mitigation as a rational choice, and\nhelp to model the implementation issues introduced by situational crime prevention such\nas displacement. For example, when a bulletproof hosting provider is taken down by law\nenforcement,whatfactorsplayapartinthecriminal\u2019schoiceofthenextprovider?\nPatterntheoryofcrime.Anothertheory,calledthepatterntheoryofcrime,allowsresearchers\nto identify various places that are related to crime. These places are likely to attract offend-\ners (crime attractors), they generate crime by the availability of crime opportunities (crime\ngenerators)andtheyenablecrimebytheabsenceofplacemanagers(crimeenablers).\nAlthoughdefiningplacesincyberspaceisnotasstraightforwardasinphysicalspace,think-\ning in terms of pattern theory can help identify locations that are hotspots for cybercrime,\nwhether they are particularly appealing targets, such as corporations storing sensitive data\n(attractors),poorlyconfiguredsystemsthatareeasiertocompromise(generators)oronline\nserviceswithpoorhygienethatdonotreactpromptlytospam\/malwarepostedontheirplat-\nforms(enablers).Identifyingthesehotspotscanthenbeusedtodesignappropriatecounter-\nmeasuresagainstthemaliciousactivity(e.g.,towhomtodirecteducationcampaigns).\nSituational crime prevention. Situational crime prevention comprises a set of theories and\ntechniquesthataimtoreducecrimebyreducingtheopportunitiesforcrime[845].Theideas\nbehind situational crime prevention are based on three main concepts, which also apply to\ncybercrime:\n\u2022 Crime is much more likely to happen in certain places (hotspots). This idea applies to\nthe context of cybercrime. As we have seen, criminals tend to concentrate their mali-\nciousserversinbulletproofhostingserviceproviders,whichprovidethemwithguaran-\ntees that their operations can continue for long periods of time. At the opposite end\nof the spectrum, regarding victims, criminals tend to target computers with vulnerable\nsoftwareconfigurations,whichalsoconstitutehotspotsinthisacception.\n\u2022 Crimeisconcentratedinparticular\u2018hotproducts\u2019.Thisalsoappliestocybercrime,with\nmiscreants focusing on whichever operations yield the highest profits (i.e., at the time\nofwriting,ransomware).\n\u2022 Repeat victims are more likely to experience crime compared to other people. In the\ncontext of cybercrime, the same concept applies. A vulnerable computer that is not\npatched is likely to be compromised again [841]. Similarly, in the case of advance fee\nfraud,victimsarelikelytorepeatedlyfallforthefraud,becausethenarrativeusedbythe\ncriminalsparticularlyresonateswiththem[751].Inadditiontothenaturalpredisposition\nofvictimstofallforsimilarscamsagain,criminalsactivelyseektocontactpastvictims\noffraud,bycompilingso-calledsuckerslistsandsharingthemwitheachother[846].\nToreducetheopportunitiesforcrime,situationalcrimepreventionproposesfivecategories\nofmitigations.Inthefollowing,welistthemalongwithsomeexamplesofmitigationsagainst\nKAAdversarialBehaviour |October2019 Page245 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ncybercrime that have been proposed in the computer science literature and that can be\ngroupedintothesecategories:\n\u2022 Increase the effort of crime. Mitigations here include deploying firewalls and setting\nupautomatedupdatesforsoftwareinstalledoncomputers.\n\u2022 Increasetheriskofcrime.Mitigationshereincludereducingpaymentanonymity(e.g.,\nrequestinganIDwhensomeonecashesmoneyfromWesternUnion).\n\u2022 Reduce rewards. Mitigations here include blocking supicious payments or parcels, or\npenalisingmalicioussearchresults.\n\u2022 Reduceprovocations.ExampleshereincludeapplyingpeerpressuretorogueISPsand\nbanks.\n\u2022 Remove excuses. Typical mitigations in this category include running education cam-\npaignsorsettingupautomatedredirectstodivertvictimswhowouldhaveviewedmali-\nciouscontent,explaintothemwhathappenedandurgethemtosecuretheirsystems.\nAn interesting aspect of the situational crime prevention framework is that it identifies,\nfor each mitigation, the implementation issues that arise when putting the mitigation in\nplace[845].Inthecaseofcybercrime,thetwoimplementationissuesthataremostrelevant\nareadaptationanddisplacement.\nAdaptation embodies the fact that criminals will actively attempt to circumvent any mitiga-\ntion by making their operation stealthier or more sophisticated. This is a typical arms race\nthat can be observed in computer security research. When researchers started compiling\nblacklists of IP addresses known to belong to C&C servers, criminals reacted by developing\nFast Flux. When making payments through traditional means became more difficult due to\nincreasedvetting,criminalsmovedontocryptocurrencies.Consideringadaptationisimpor-\ntant when designing mitigations against cybercrime. In particular, effective mitigations are\nthose which the criminal cannot easily react to, or where adaptation comes at a financial\nprice(e.g.,areductioninrevenue).\nDisplacementrepresentsthefactthatoncemitigationsareputinplace,criminalscansimply\nmove their operations elsewhere. While in the physical world how far criminals can travel is\ndictated by practical constraints, on the Internet moving from one \u2018place\u2019 to another is virtu-\nallyfree.ExamplesofdisplacementincludecriminalsstartingtoregisterDNSdomainswith\nanotherregistraraftertheirpreferredoneincreasedthedomainpricetocurbmisuse[847],or\namultitudeofdrugmarketsopeningtofillthegapleftbySilkRoad\u2019stakedown[714].Displace-\nment effects are important when planning action against cybercrime. Generally speaking, a\nmitigation should make it difficult for criminals to move elsewhere. Conversely, a mitigating\naction that simply displaces a cybercriminal operation without affecting its effectiveness is\nprobablynotworthpursuing.\nResearchers have applied Situational Crime Prevention to a number of computer crimes,\nincluding organisational data breaches [833] and the mitigation of software vulnerabili-\nties[834].Followingthediscussioninthissection,however,thisframeworkcouldbeapplied\ntoanycriminalactivitythathappensonline.\nCrimescripting.Anotherusefultechniquethatcanaidtheanalysisofmaliciousactivitieson\nthe Internet from the field of criminology is crime scripting [848]. As part of this technique,\nresearchers extrapolate the sequence of steps performed by an adversary to commit their\noffences. For example, in a romance scam, fraudsters create a fake account on a dating\nKAAdversarialBehaviour |October2019 Page246 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nprofile, the identify a suitable victim, go through a grooming phase, followed by the actual\nfraud when the scammer asks their victim for money. Dissecting the various steps of an\noffence can be useful to better understand it and to identify potential interventions. Crime\nscripting is somewhat related to kill chains, although the two techniques were developed in\ncompletelyindependentareas.\nModelling the underground economy as a flow of capital\nAsdiscussedinSection7.1,manymaliciousoperationsareperformedbycriminalswiththe\ngoal of making money from their victims. For this reason, following the flow of money is a\nuseful way to better understand malicious operations, and in particular identify bottlenecks\nthatcouldbeleveragedtodevelopmitigationsagainstthemandstopcriminals[804,849].\nThomasetal.presentedamodelthatisdesignedtokeeptrackofamoneyflowwithinacyber-\ncriminaloperation[850].Aspartofthismodel,theyintroducedtwoelementsthatareneeded\nfor a cybercrime operation to run: profit centres, through which victims transfer new capital\nintothecriminaloperation,andsupportcentres,whichcanfacilitatethecriminaloperationby\nproviding several services for a fee. Money is introduced into the ecosystem through profit\ncentres, and is then consumed by the various actors involved in it, who provide tools and\nservices for each other. As an example, in an email spam operation, the profit centre would\nbevictimspurchasingcounterfeitpharmaceuticalsfromanaffiliateprogramme,whileallthe\nservicesneededbythespammerstooperate(e.g.,bulletproofhosting providers tohostthe\nC&C servers, pay-per-install services to deliver the malware, content generation services to\ncreatethespamcontent)aresupportcentres.Thismodelprovidesaninterestingconceptu-\nalisation of how money flows into the cybercriminal ecosystem and how wealth is divided\nbetween the different actors there. By cross-referencing it with real world data, it can also\nhelp to form an idea of the profit that each criminal is making, and of the revenue of the\noperation.\nAnother interesting aspect of tracing the cash flow of cybercriminal operations is that at\nsomepointthecriminalswillwanttocashout,whichwillbedoneusingtraditionalpayment\nmethods(seeSection7.2).Sincetheseinteractionshappeninthephysicalworld,itiseasier\nforlawenforcementtotracethemandpotentiallyapprehendthecriminals[849].\nAttack attribution\nWhen talking about malicious activities, attribution is important. Law enforcement is inter-\nested in understanding what criminals are behind a certain operation, and in particular at-\ntributing apparently unrelated cybercriminal operations to the same actors could help build\na legal case against them. In similar fashion, governments are interested in identifying the\nculpritsbehindtheattacksthattheyreceive.Inparticular,theyareinterestedinfindingwhich\nnationstates(i.e.,countries)arebehindtheseattacks.\nAttribution, however, is a controversial topic in cyberspace. As we discussed previously, the\nconcept of \u2018place\u2019 is relative for computer attacks, and attackers can easily route their net-\nwork connections through proxies or compromised machines in third countries, thus hiding\ntheir actual location. It is reasonable to assume that the same actors will follow a similar\nmodusoperandiintheirattacks,andinparticularwillusethesamesoftwareexploitstobreak\nintotheirvictims\u2019systems.Theseexploitsandcodeartefactscouldbeusedtoidentifystate-\nsponsoredgroupsorotherattackers(SeetheMalware&AttackTechnologyKnowledgeArea\n(Section6.5.2),formoredetails).Unfortunately,thisapproachhastwomaindrawbacks.The\nKAAdversarialBehaviour |October2019 Page247 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nfirst is that the commodisation of cybercrime services has enabled attackers to use exploit\nkits,whichcontainalargenumberofexploitsand,therefore,increasethelikelihoodofanat-\ntackhappening.Whileadvantageousforattackers,thistrendmeansthattheexploitsusedbe-\ncomealesssignificantsignalforidentifyingattackers,especiallythosewhodonothavethe\nsophisticationtoexploitvulnerabilitiesinhouse(e.g.,cyber-enabledcybercriminals).Theex-\nceptiontothistrendisstate-sponsoredactors,whounliketraditionalcriminalsusuallyhave\nvery specific targets. For this reason, they can tailor their attacks more carefully, and even\ndevelop new exploits to hit a specific victim. Most importantly, they often develop exploits\nfor vulnerabilities that are not publicly known, also known as zero days attacks [794]. Being\nunique to an actor, they could be used to identify who is behind a specific attack. An issue\nhere is that, once an exploit is used, it could be intercepted by the victim (or anyone on the\nnetwork)andlaterusedagainstanothertargetaffectedbythesamevulnerability.Thiswould\nactivelymisleadattribution.RecentleakshaveshownthattheCIAhasbeenactivelycollect-\ningexploitsusedbyothernationstatesandaddingthemtotheirarsenal,thusallowingthem\ntomakeitlooklikeanothercountrywasbehindanygivencomputerattack.8\nRid et al. proposed a framework to systematise the attribution efforts of cyberattacks [835].\nWithin this framework, they identified three layers of analysis that are needed to correctly\nperform attribution: tactical, operational and strategic. The tactical component consists of\nunderstanding the technical aspects that composed the attack (the how), the operational\ncomponentconsistsofunderstandingtheattack\u2019shigh-levelcharacteristicsarchitectureand\nthetypeofattackerthatwearedealingwith(thewhat),whilethestrategiccomponentdeals\nwithunderstandingthemotivationbehindtheattack(thewhy).\nWhile this framework was developed with state-sponsored attacks in mind, it could be used\nto attribute other types of malicious activity. For example, to attribute an online hate attack\norchestratedby4chan\u2019sPoliticallyIncorrectBoard, [735]onecouldtracethehatemessages\nreachingthevictim(how),observethepersonalinformationofthevictimontheboard(what)\nandanalysethediscussionaboutthevictimtounderstandthemotivationbehindtheattack\n(why).\nCONCLUSION\nIn this document, we presented an overview of the adversarial behaviours that exist on the\nInternet at the time of writing. We surveyed various types of malicious operations, depend-\ning on the attacker\u2019s motivations and capabilities, and analysed the components that are\nrequired to set up successful malicious operations. Finally, we described a number of mod-\nelling techniques from a variety of fields (computer science, criminology, war studies) that\ncanhelpresearchersandpractitionerstobettermodeltheseoperations.Wearguedthathav-\ning good models is of fundamental importance to developing effective mitigations that are\ndifficulttocircumvent.\n8https:\/\/en.wikipedia.org\/wiki\/Vault_7\nKAAdversarialBehaviour |October2019 Page248 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nCROSS REFERENCE OF TOPICS VS REFERENCE MATERIAL\nSections Cites\n1ACharacterisationofAdversaries\nCyber-enabledandcyber-dependentcrimes [711]\nInterpersonaloffenders [712,736,739,741,742]\nCyber-enabledorganisedcriminals [713,714,751]\nCyber-dependentorganisedcriminals [15,16,17,715,716,783,784]\nHacktivists [717,726,791]\nStateactors [718,719,798,801]\n2Theelementsofamaliciousoperation\nAffiliateprogrammes [764,804]\nInfectionvectors [723,805]\nInfrastructure [706,806,818]\nSpecialisedservices [807,808]\nHumanservices [775,822,823,827]\nPaymentmethods [763,809,810]\n3ModelstoUnderstandMaliciousOperations\nAttacktrees [79]\nEnvironmentalcriminology [832,833,834]\nModellingtheundergroundeconomyasaflowofcapital [722]\nAttackattribution [835]\nKAAdversarialBehaviour |October2019 Page249 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nKAAdversarialBehaviour |October2019 Page250 Chapter 8\nSecurity Operations &\nIncident Management\nHerv\u00e9 Debar Telecom SudParis\n251 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nINTRODUCTION\nTherootsofSecurityOperationsandIncidentManagement(SOIM)canbetracedtotheorig-\ninal report by James Anderson [851] in 1981. This report theorises that full protection of the\ninformation and communication infrastructure is impossible. From a technical perspective,\nitwouldrequirecompleteandubiquitouscontrolandcertification,whichwouldblockorlimit\nusefulness and usability. From an economic perspective, the cost of protection measures\nand the loss related to limited use effectively require an equilibrium between openness and\nprotection, generally in favour of openness. From there on, the report promotes the use of\ndetectiontechniquestocomplementprotection.Thenexttenyearssawthedevelopmentof\nthe original theory of intrusion detection by Denning [852], which still forms the theoretical\nbasisofmostoftheworkdetailedinthisKA.\nSecurity Operations and Incident Management can be seen as an application and automa-\ntion of the Monitor Analyze Plan Execute-Knowledge (MAPE-K) autonomic computing loop\nto cybersecurity [853], even if this loop was defined later than the initial developments of\nSOIM. Autonomic computing aims to adapt ICT systems to changing operating conditions.\nTheloop,describedinfigure8.1,isdrivenbyeventsthatprovideinformationaboutthecurrent\nbehaviour of the system. The various sequential steps of the loop analyse the event stream\n(trace)toprovidefeedback tothesystem,changingitsbehaviouraccordingtoobservations\nand policies, enabling automatic adaptation to best provide service for users. The develop-\nments of SOIM have increased in automation and complexity over the years, as a result of\nour increasing reliance on the proper service delivery of the ICT infrastructure. These devel-\nopmentshaveslowlycoveredmostofthespectrumoftheMAPE-Kloop.\nAfternearly40yearsofresearchanddevelopment,theSecurityOperationsandIncidentMan-\nagement domain has reached a sufficient maturity to be deployed in many environments.\nWhileearlyadoptersweremainlylocatedinICT-intensivesectorssuchastelecomsandbank-\ning, it is finding its place in sectors that are increasingly embracing or converting to digital\ntechnologies. Yet, research is still very active in addressing the many remaining challenges.\nWith respect to detection, new emerging environments driven by new technologies and ser-\nvices are requiring the acquisition and analysis of new data streams. The tools, techniques\nand processes available today for detecting and mitigating threats also regularly fail to pre-\nvent successful attackers from penetrating and compromising ICT infrastructures, without\nregularusersnoticing.Extremelylarge-scaleeventsalsooccuratregularintervals,andthere\nisadefiniteneedforprogressintermsofreactiontoattacks.\nThe Security Operations and Incident Management knowledge area description starts by in-\ntroducing some of the vocabulary, processes and architecture in section 8.1. It then follows\nthe loop concepts, discussing detection at the sensor level, both looking at data sources\n(Monitor,section8.2)anddetectionalgorithms(Analyze,section8.3).ItthendiscussesSecu-\nrityInformationandEventManagement,instantiatingAnalyzefromamoreglobalperspective\nthan sensors, Plan in section 8.4 and examples of Execute. Using the SecurityOrchestration,\nAnalytics and Reporting (SOAR) concept, it further develops the modern aspects of the Plan\nandExecuteactivitiesinsection8.5.Ofcourse,alltheseactivitiesarebuiltuponaKnowledge\nbase. Several knowledge components are described in section 8.6. The KA concludes with\nhumanfactorsinsection8.7.\nKASecurityOperations&IncidentManagement |October2019 Page252 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nCONTENT\n8.1 FUNDAMENTAL CONCEPTS\n[852,854]\nTheSOIMdomainassumesthattheworkflowoftheMAPE-Kloopisimplementedintechnical\ncomponents,deployedinanICTinfrastructure.Section8.1.1establishes afewfundamental\nvocabulary references in the SOIM domain, and section 8.1.2 describes the deployment of\ntheseconceptsinagenericICTinfrastructure.\n8.1.1 Workflows and vocabulary\nFigure8.1adaptsthegenericMAPE-KlooptoSOIM.InadditiontotheICTsystembeingpro-\ntectedandmonitoredtodetectattacks,twomajoractorsinfluencetheevolutionoftheloop;\ntheInternetasawholeandtheregulatorycontextinwhichtheICTsystemprovidesservices.\nTheInternetisthesourceofbothservicerequestsandthreats,butalsoofintelligenceabout\nthese threats. Regulatory bodies such as national agencies, and industry bodies provide ad-\nditionalthreatanddetectioninformationandrequestinformationsharing.\nFigure8.1:MAPE-KAutonomiccomputingloopinstantiatedtoSOIM\nFigure8.1illustratesthepositionsofthecomponentsthatcarryouttheSOIMworkflows,us-\ningthreepartialloops.Theinnermostone,IntrusionDetectionSystems(IDS),wasthesubject\noftheearliestwork,coveringmonitoringanddetection.Thesecondone,SecurityInformation\nKASecurityOperations&IncidentManagement |October2019 Page253 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nandEventManagement(SIEM)platforms,extendeddetectionandstartedcoveringresponse\nplanningandexecution.Morerecently,SecurityOrchestration,AnalyticsandReporting(SOAR)\nplatforms have driven further analytics and responses, enabling more advanced and global\nresponses to cyberthreats. The knowledge base used in SOIM has gradually expanded over\nthe years, as more intelligence has become necessary to detect and mitigate attacks. The\nkey difference between knowledge and events is time. Events are produced and consumed,\nwhileknowledgeismorestable.\nTheMonitoractivityisessentiallycoveredbyIDSes.Thevariousdatasourcesincludedwithin\nthescopeofmonitoringaredescribedinsection8.2.\nTheAnalyseactivity,alsocoveredbyIDSes,aimstodeterminewhethersomeoftheinforma-\ntion acquired constitutes evidence of a potential attack. From 1990 to 2000, many research\nprojects developed advanced Intrusion Detection System prototypes. As a result, the first\nnetwork-based IDS was commercialised in 1996, automating the first part of the MAPE-K\nloop. However, section 8.3 illustrates that the constraints associated with real-time event\nprocessingandlimitedcoveragerequireadditionaltools.Thisistheobjectiveofthesecond\nloop,SIEMplatforms.\nTechnology has evolved to a point where IDSes have been transformed into Intrusion Pre-\nvention Systems (IDPS) [855]. This is elaborated further in section 8.5.1. The text of the KA\nwilluseIDPSfromnowon,exceptwhentheconceptisfocusingondetection,whereIDSwill\nremain.\nPlanactivityisessentiallytherealmofSIEMplatforms.ThedeploymentoftheseIDSsensors\ncreated the need to manage operationally large volumes of alerts, which led to the develop-\nmentoftheseSIEMplatforms.Theyprovidebothadditionalanalysisandinitialplanningtore-\nspondtoattacks.Theselarge-scale,complexandexpensiveplatformsarenowconsolidated\nin the Security Operating Center (SOC), providing both technological and human resources.\nWe are now deploying the second generation of these SIEM platforms to accommodate in-\ncreasinglylargevolumesofdiversedata,andtoprovideadditionalprocessingcapabilities.\nExecute activity started being implemented in SIEM platforms mostly through manual pro-\ncesses. Security orchestrators or dedicated components are now enabling partial automa-\ntion of feedback to the ICT infrastructure, although this activity is less mature than the oth-\ners.\nThe first three (Monitor, Analyse, Plan) activities are now fully or partially automated. Au-\ntomation is absolutely necessary to handle the huge amounts of event data generated by\nmodern ICT systems, and to describe the huge body of knowledge related to cyberattacks.\nTheyallrelyonalargebodyofknowledge,covering,forexample,theconfigurationofamon-\nitoredsystem,ordetectionsignaturesofmanytypesandforms.Newtrendsarealsoemerg-\ning,forexample,Cyber-ThreatIntelligence(CTI)(section8.6.3),tobetterunderstandandde-\nfendagainstcyberattacks.ThisisthetopicofSecurityOrchestration,AnalyticsandReporting\n(SOAR), which aims to support better responses to threat, as well as more global informa-\ntion exchange. The SOAR acronym describes an increasingly required set of functionalities\nextendingSOIMcoverageforriskandincidentmanagement.\nKASecurityOperations&IncidentManagement |October2019 Page254 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n8.1.2 Architectural principles\nCybersecuritydoesnotfunctioninavacuum.TheSecurityOperationsandIncidentManage-\nment domain assumes that there is an ICT system to be protected. Thus, an SOIM deploy-\nment assumes a few general architectural principles on which tools and processes can be\ndeployed.Theseconceptsaredescribedinfigure8.2.\nFigure8.2:SimplifieddeploymentofSOIMtechnologiesinanICTinfrastructure\nAnInformationSystem,connected(ornot)totheInternet,issubjecttoattacks.Notallthese\nattacks can be blocked by protection mechanisms such as firewalls. Best practices recom-\nmend defining zones of different sensitivities, to control the data exchange. This frequently\nand minimally takes the form of a Demilitarised Zone (DMZ) located between the inside pri-\nvatenetworkandtheoutsideInternet,toserveascommunicationtermination,exchangeand\nincreased scrutiny through monitoring. To detect threats that are not blocked by protection\nmechanisms, operators deploy Intrusion Prevention Systems (IDPS). IDPS sensors can use\nsystem (section 8.2.5 ) or application log files (section 8.2.4), depicted as pages in figure\n2. They can also be deployed at the network level (section 8.2.1), depicted as the two larger\npiecesofequipmentwithmagnifiers.\nTheSOIMinfrastructureisshownatthebottomoffigure8.2.Thesensorsoftenhaveatleast\ntwonetworkattachments,aninvisibleoneinthemonitoredInformationSystemnetworkfor\ncollecting and analysing data, and a regular one in a protected specific SOIM network infra-\nstructure, where the SIEM is installed and receives the alerts. Analysts man consoles to re-\nceivealerts,assesstheirimpactanddeploytheappropriatemitigationactions.Sensorman-\nagement might either use this secondary network attachement as a maintenance channel\nfor software and signature updates, or use yet another mechanism such as a virtual private\nnetworktocarryoutthesensormaintenance.\nThe SOIM domain also implies processes, which are defined by the Chief Information Secu-\nrity Officer and followed by analysts. The first process is related to alert processing, where\nKASecurityOperations&IncidentManagement |October2019 Page255 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nthe operator, with the help of decision support techniques provided by the SIEM, will decide\ntoignorethealert,reacttoitfollowingprocedures,orescalatethealerttoskilledanalystsfor\nfurtheranalysis,diagnosisanddecision.Thesecondprocessisthedeploymentandmainte-\nnance of sensors, deciding on where to locate them, what to capture and how to maintain\ncontinuous monitoring. The third process is reporting, particularly crucial for managed ser-\nvices,wherethefunctioningoftheSIEMandSOCareanalysedforimprovement.\nThe Security Orchestration, Analytics and Reporting components are included through the\nCyber-ThreatIntelligence(CTI,red)andInformationSharingandAnalysisCenter(ISAC,green)\ndisks, representing the added benefit for the management platform to obtain information\nfrom external, relevant sources and to leverage this information to increase their detection\nefficiency (section 8.3) and impact assessment (section 8.5). While both interfaces provide\ninformationtoaSOC,thisinformationisofafundamentallydifferentnature.CERTandISAC\nentities are trusted organisations, sometimes enabling sectoral information exchange, of-\ntenestablishedandgovernedbyregulations.CTIisamuchmorefuzzyarea,includingopen\nsource intelligence as well as dedicated information feeds provided by commercial compa-\nnies.\n8.2 MONITOR: DATA SOURCES\n[852,856]\nThe detection issue is relatively simple; from a continuous stream of data, the objective is\ntodetectlocalisedattemptstocompromiseICTinfrastructuresinrealtime.Thisisachieved\nfirst by collecting information about the operation of these ICT infrastructures from traces\nwithmanydifferentorigins.\nFigure8.3:Datasourceslandscape\nFigure 8.3 provides a simplified conceptual view of possible data sources. The rectangles\ndescribeconcepts.Theovalsdescribeconcreteimplementationsofthesedatasources.The\nroundedrectanglesdescribeanactualformat,syslog,documentedandstandardised,which\nplaysaspecificrole.Sinceitisastandardisedprotocolandformat,italsosupportslogfeeds\nprovidedbynetworkingequipment,operatingsystemsandapplications.\nKASecurityOperations&IncidentManagement |October2019 Page256 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nFigure8.3isbynomeanscomplete.Manydatasourceshavebeenconsideredovertheyears,\ndependingontherequirementsoftheusecaseandthedetectionalgorithms.\nData sources broadly describe either host behaviours reporting on operating systems or ap-\nplications,ornetworkbehavioursreportingcommunicationpatterns.\nDatasourcesareeventstreams,tracesofactivitythatrepresenttheservicesaccessedbythe\nusersofanInformationSystem.Datasourcesareinputstosensors,whichproducealertsas\noutputs. Alerts represent information of interest from a security perspective. In the general\ncase,aneventorastreamofevents,acquiredbyasensor,generatesanalertthatsynthesises\nthesecurityissuefoundbythesensor.Alertsarecoveredinsection8.4.1.\nThe move to external resources such as cloud providers or Internet Service Providers may\nlimit the availability of some of the data sources, for practical reasons such as volume, or\nduetoprivacyconstraintsandentanglementofmultiplecustomerdatainthesametrace.It\nis also possible that traces from hosted environments might be compromised or be made\navailablewithouttheknowledgeorauthorisationofthecustomer.\n8.2.1 Network traffic\nNetworkdatahavebecomethede-factostandardforcollectinginputdataforintrusiondetec-\ntion purposes, because of the overall reliance on networks and the ease of use of standard\nformats. While the capture of packets is the most prevalent format, the scientific literature\nhasalsousedotherinformationsourcesforsecurity.Networkinformationissometimesnot\navailableinternallyanditmaybenecessarytorelyonInternetServiceProviders,forexample,\ntoidentifyattackers\u2019addressesandroutes.\nThemostprevalenttypeofnetworktrafficdataisthefullpacketcapture,exemplifiedbythe\nlibpcaplibraryandthetcpdumpandwiresharkapplications.Thepcaplibraryhasbeenported\ntomanyenvironments,andiswidelyavailableasopensource,henceitssuccess.Numerous\ndatasets have been made available or exchanged privately as pcaps, for almost as long as\nintrusiondetectionresearchhasexistedandneedstobeevaluated.Whilepacketcaptureis\nwidelyused,itdoesnotmeanthatthisinformationisstoredinsensors.Storingpcapsrequire\nanenormousamountofstorage,hencepcapfilesareoftenreservedforresearchdatasetsor\nforensics purposes. Network-based sensors may offer the capability to store a few packets\nalongwithanalertwhenadetectionoccurs,generallythepacketthattriggeredthedetection\nand a few ones belonging to the same context (TCP, etc.) that appeared quickly afterwards.\nThiscapabilityisgenerallylimitedtomisusedetection.\nThepcaplibraryrequirestheavailabilityofanetworkinterfacethatcanbeplacedinso-called\npromiscuousmode,meaningthattheinterfacewillretrieveallpacketsfromthenetwork,even\nthe ones that are not addressed to it. Also, there is no need to bind an IP address to the net-\nworkinterfacetocapturetraffic.Infact,thisisarecommendedpractice,toavoidinterference.\nThis means that, in general, packet capture can occur silently and is undetectable. Despite\nits popularity, there are a few issues with the pcap format that need to be considered when\nmanipulatingit.\nVolume Pcap files tend to be extremely large for any practical operational use. This often\nlimits capture to the investigation. Sensors generally analyse network traffic on the fly\nbutdonotrecordactualpackets.\nPacketsize Thedefaultconfigurationofthelibraryacquiresonlythebeginning(headers)of\nanIPpacket.Thismeansthatapackettracemightbelimitedtoonlyheaderinformation.\nKASecurityOperations&IncidentManagement |October2019 Page257 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nAnincompleteormissingpacketpayloadstronglylimitsdetection.\nSegmentationandfragmentation Information circulated on the network is recorded on\na per-packet basis. This implies that the receiving software must reconstruct the\napplication-level data stream. Beginnings or ends of communications might be miss-\ning.\nTimestamps Network packet headers do not include any timestamp. This is added by the\ncapturingsoftwareandreliesonanexternalclock.\nMAClayerinterpretation CapturingtheMAClayerispossible,butrequiresaspecificconfig-\nuration.InterpretingofMAClayerinformationrequiresknowledgeoftheconfiguration\nof the network segment to which the collection network interface is attached. Captur-\ning the MAC layer is required in order to detect attacks such as ARP poisoning. For\ncertain types of industrial control networks which run directly on top of the Ethernet\nlayer,capturingtrafficrequiresaddinganodeandmaybreakreal-timeassumptions.\nApplicationlayerinterpretation The most crucial aspect of pcap analysis for cybersecurity\nis analysing the application layer. IP packets are relatively autonomous bits of data.\nReliable transports, such as TCP, have inherent dynamics that need to be taken into\naccount when analysing the data, such as the existence of a connection or not. At the\napplicationlayer,insidetheTCP\/IPpayload,informationmightbeinconsistentwiththe\nheaders,orrequireanunderstandingofapplicationlogic,whichisoftenhardtoacquire,\nunderstandandreproduce.\nEncryption Encrypted traffic, and particularly TLS, is widespread. TLS ensures both the au-\nthenticationoftheservertotheclient,andtheconfidentialityoftheexchangeoverthe\nnetwork. For monitoring, the issue is the second aspect, the impossibility to analyse\nthe payload of packets. The classic approach to this problem is to put an additional\ndedicated box close to the application server (web, mail, etc.), often named the Hard-\nwareSecurityModule(HSM).TheHSMisresponsibleforestablishingtheTLSsession\nbefore the application server provides any content. This moves the load of establish-\ningtheTLSsessionoutsideoftheapplicationserver.TLS-protectedtrafficisencrypted\nanddecryptedattheHSM,andflowsincleartotheserver.Thisenablesnetwork-based\nIDPSesandWAFstoanalysethetraffic.\nDue to changing requirements, new network protocols have been introduced to support the\nInternetofThings(IoT).Low-powercommunicationprotocolssuchasLORAhavelimitations\nin both packet size and the number of the packets that can be transmitted per day. These\ncommunication protocols are used mostly today as data harvesting on a large scale. Thus,\nIDPSes will need information about the context of the communication to provide useful de-\ntection.IsosynchronousprotocolsinusesuchasPROFINETIRThavestringentrequirements\nin terms of communication cycle time and determinism. These protocols are typically used\ninmanufacturingenvironments.Astheymostlyrelyonhubsforcommunication,insertinga\nnetwork-based sensor may seem easy. However, the strict timing requirements of such pro-\ntocols require careful validation that the IDPS does not alter these requirements. Also, this\nnecessitatesthedeploymentofasecondcommunicationchannelfortheIDPStosendalerts\ntoaSIEM,whichmaybecostly,technicallydifficultandmayintroduceadditionalvulnerabili-\ntiestothesystem.\nKASecurityOperations&IncidentManagement |October2019 Page258 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n8.2.2 Network aggregates: Netflow\nThesheersizeofpacketcaptureshascreatedtheneedtoobtainasyntheticviewofnetwork\nactivity. This has created the need for a synthetic aggregated view of traffic at a relatively\nlowlayer.Networkaggregatesaremechanismsforcountingpacketssharingcertaincharac-\nteristics, such as source, destination, protocol or interface. These counts are performed by\nnetworkequipmentaspacketscrosstheirinterfaces.\nNetflow[857,858]isawidelyusednetworkmonitoringtoolusedfordetectingandvisualising\nsecurity incidents in networks [859, 860]. In brief, this protocol records counters of packet\nheaders flowing through router network interfaces. Initially developed by Cisco, it has been\nstandardisedasIPFix,RFC7011.\nAs Netflow was developed by network equipment providers, it is extremely well integrated\nin networks, and widely used for network management tasks. It is standardised, and even\nthough the commercial names differ, similar information is collected by the manufacturers\nsupporting the technology. Its strongest uses are certainly visualising network communica-\ntionsandrelationships,[859]andhighlightingcommunicationpatterns.Visualanalyticspro-\nvideauser-friendlywayofunderstandinganomaliesandtheirimpact.Hence,Netflowisalso\nwidelyusedforcybersecuritytasks.\nNetflow, however, may suffer from performance degradation, both in terms of computation\nandstorage.HandlingpacketstocomputeNetflowcountersrequiresaccesstoroutersCPU\n(centraloroninterfaceboards).Thissignificantlyreducestheperformanceofnetworkequip-\nment. Newer routers are now able to generate netflow records at the hardware layer, thus\nlimiting the performance impact. Another alternative is to span or tap a network interface\nandtogeneratethenetflowrecordsindependentelyoftheroutingequipment.\nOriginally, to limit the CPU performance impact, operators often deploy Netflow in sampling\nmode,whereonlyoneineveryseveralthousandpacketsisanalysed.Thus,theviewrecorded\nbyNetflowmightbeextremelylimitedandmaycompletelymisseventsthatdonotreachthe\nscale of the sampling. Except for large-scale Denial of Service events, it is thus difficult to\nrelyonsampledNetflowaloneforsecurity.\n8.2.3 Network infrastructure information\nThenetworkinginfrastructurereliesonmanyprotocolsforpropercommunication.Twoofits\nmain components, the naming and the routing infrastructure, are also of significant interest\nforbothattacksanddetection.Reportingonroutingornamingoperationsrequiresdirectac-\ncesstoaviewoftheinfrastructure.Operatorswhoparticipateinroutingandnamingusually\nrelyonsyslogtocollectinformation.\nKASecurityOperations&IncidentManagement |October2019 Page259 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n8.2.3.1 Naming\nTheDomainNameSystem(DNS)isoneofthemostcrucialservicesontheInternet.Itresolves\ndomainnames,meaningfulbitsoftext,toIPaddressesrequiredfornetworkcommunications\nbut which are difficult to remember. In addition, naming is required for the Transport Layer\nSecurity(TLS,RFC8446)protocolandcertainHTTPmechanismssuchasvirtualhosting.\nDespite its importance, DNS has been the subject of many vulnerabilities and attacks. The\nmain problem with DNS is its lack of authentication in its basic form. An attacker can thus\nstealadomainthroughfakeDNSmessagesorresponses.ThedeploymentofDNSSECoffers\nan authenticated response to DNS queries that will provide users with evidence of domain\nnameownership.\nThe DNS protocol is also a natural DDoS amplifier, as it is possible for an attacker to mimic\ntheIPaddressofavictiminaDNSrequest,thuscausingtheDNSservertosendunsolicited\ntraffic to the victim [861, 862]. Unfortunately, the current move to DNSSEC is unlikely to be\nabletohelp[863,864].\nAnotherissuerelatedtoDNSisthedetectionofbotnetactivity.Onceamalwarehasinfected\nacomputer,itneedstocommunicatewiththeC&Cservertoreceiveordersandcarryoutthe\nrequested activity. While it is not the only C&C communication channel used by bot herders,\nDNSisattractiveasacommunicationchannelforattackersbecauseitisoneofthefewpro-\ntocols that is highly likely to go through firewalls, and whose payload will be unaltered. In\norder for this to work, attackers need to set up, and defenders need to detect malicious do-\nmains[865].ThemostcommondefencemechanismisDNSdomainnameblacklists,butits\nefficiencyishardtoevaluate [866].Thisblacklistdefencemechanismcanalsobeextended\ntootherC&Cchannels.\nNotethatDNSisnottheonlyprotocoltobepronetoDDoSamplificationattacks.NTPisalso\nafrequentculprit[867].MoreinformationaboutDDoSattackscanbefoundin [868].\n8.2.3.2 Routing\nAnotherrelatedsourceofinformationforattacksisroutinginformation.IncidentsintheBor-\nderGatewayProtocolroutinginfrastructurehavebeenstudiedforsometime[869,870],but\nmanyoftherecordedincidentsareduetohumanerror.Therearerecordedinstancesofma-\nlicious BGP hijacks [871, 872], but the effort required by attackers to carry out these attacks\nseems,atthispointintime,notbeworththegain.\n8.2.4 Application logs: web server logs and files\nHigher up the computing stack, application logs provide an event stream that documents\nthe activity of a specific application. The main advantage of application logs over system\nlogs is their similarity to reality and the precision and accuracy of the information proposed.\nThese logs were initially created for debugging and system management purposes, so they\naretextualandintelligible.\nApplicationscansharelogfilesthroughthesysloginfrastructure(section8.2.6).Forexample,\ntheauth.loglogfilewillstoreuserconnectioninformationregardlessofthemechanismused\n(pam,ssh,etc.).\nKASecurityOperations&IncidentManagement |October2019 Page260 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n8.2.4.1 Webserverlogs\nAfrequentsourceofinformationisprovidedbywebserverandproxylogs,knownastheCom-\nmon Log Format (CLF) and Extended Common Log Format (ECLF). This format is a de-facto\nstandard provided by the Apache web server and others. While it is very similar to Syslog,\nthere are no standards documents normalising the format. At this stage, the W3C standard\nfor logging remains a draft document. This format is extremely simple and easy to read. It\nprovides information about the request (the resource that the client is trying to obtain) and\nthe response of the server, as a code. Thus, it has been widely used in Intrusion Detection\nSystemsovertheyears.The mainissuewiththe formatisthe lackofinformationabout the\nserver,sincethelogfileislocaltothemachinegeneratingthelog.\nAs server logs are written once the request has been served by the server, the attack has al-\nready occurred when the sensor receives the log information. Thus, this information source\ndoes not satisfy the requirements of Intrusion Detection and Prevention Systems (IDPS),\nwhichneedtobehookedasinterceptorstoactonthedatastream(packetstream,instruction\nstream),toblocktherequestormodifyitscontent.\n8.2.4.2 Filesanddocuments\nAnother source of application-level information that is particularly interesting and can be\nfoundbothintransit(innetworks)oratrest(insystems)comprisesthedocumentsproduced\nbysomeoftheseapplications.TheintroductionofrichdocumentformatssuchasPDF,Flash\norofficesuites,nottomentiontherichHTMLformatusedinmailexchangestoday,hascre-\natedawealthofopportunityforattackerstoincludemalware.Exchangedovertheweborvia\nemail, they constitute another trace of exchange that can reveal malicious code embedded\ninthesedocuments,suchasmacrosorjavascript.\nParsing information in documents, both simple ones such as TLS certificates or complex\nones such as PDF, is complex and provides attackers with a wealth of opportunity to cre-\nate different interpretations of the same document, leading to vulnerabilities and malware.\nAt the same time, it should be acknowledged that the rich document formats are here to\nstayandthatrich(andthuscomplex)specificationssuchasHTML5needtobewellwritten\nso that they can be unambiguously interpreted, thus leaving less room for attackers in the\nspecificationitself.\nUsingdocumentsasadatasourceisincreasinglyrequiredformalwaredetection.\n8.2.5 System and kernel logs\nTheearliest\u2018intrusiondetection\u2019paperbyDenning[852]alreadyincludedinthemodelthegen-\nerationofanaudittrailbythesystembeingmonitored.Operatingsystemsgenerallyprovide\nlogsfordebuggingandaccountingpurposes.Theselogswereexploitedinearlydesignssuch\nasHaystack.However,Denninghasalreadystatedthatmostsystemlogsareinsufficientfor\nintrusiondetection,astheylacktherequiredprecision.Forexample,theUnixaccountingsys-\ntem records only the first eight characters, without a path, of any command launched by a\nuser. This makes it impossible to differentiate commands with identical names at different\nlocations,orlongcommandnames.\nAnother trend pursued by intrusion detection researchers and operating system designers\nwas the creation of a specific audit trail to generate a trace of privileged user activity, as\nrequired by the Orange Book. This led to the development of more precise host-based IDS\nKASecurityOperations&IncidentManagement |October2019 Page261 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nsuchasSTIDEandeXpert-BSM.Thesespecificsystemtracesareacquiredthroughtheinter-\nception of system calls, which represent the transition between regular program execution\nand request to protected kernel resources. This is typically implemented using a dedicated\naudit trail, as specified in the Orange book, or kernel\/processor debugging accesses such\nas ptrace for Linux. However, the complexity of the specification led to divergences in the\nimplementation of the audit trail by the different operating system vendors. It also imposed\nsuch a performance penalty to program execution that it became impossible to operate ICT\nsystems with the audit trail being activated. It therefore became of little use and was qui-\netly removed from most operating systems. This factor has prevented the emergence of a\nstandardsystemaudittrail,evenincertifiedoperatingsystems.\nKernel logs now focus on monitoring the internal operations of an operating system, close\nto the hardware. They have also greatly diversified, targeting a broad range of devices. They\nhavebeenintegratedinthecommercialworldundertheterm\u2018endpointprotection\u2019,whichhas\nbecomeageneralisedtermforantivirusengines.Thisaddressesthegeneralproblemofpro-\ntecting not only the system but also the applications, such as the browser or the mail client,\nwhichnotonlyexchangedatabutalsoexecuteuntrustedcodeprovidedbyexternalsources.\nThey rely on dedicated interceptors that capture only the activity that they are interested in\nanalysing.Thissolvesthemainissueofthisdatasource,averyfinegranularitythatensures\neverythingiscaptured,butmakesanalysisanddetectionverydifficult,asitishardtolinkthe\nassembly code being executed on the processor with programs and information that a user\nor analyst can easily understand and react to. Malware is the subject of the Malware & At-\ntackTechnologyKnowledgeArea(Chapter6),andinthecontextofSOIMmalwaredetection\nenginesandendpointprotectiontoolsareconsideredsensors.\nOther logs provide higher level information, such as a report of the boot process on Unix\nmachines,oronthemainkernelactivity.TheselogsoftenrelyonaSysloginfrastructure,as\ndescribedinsection8.2.6.\n8.2.6 Syslog\nAs already mentioned in this section several times, Syslog provides a generic logging infra-\nstructurethatconstitutesanextremelyefficientdatasourceformanyuses.\nTheinitialsourcefortheselogsistheSyslogprotocol,introducedinBSDUnix,retro-specified\nfrom existing implementations by RFC 3164.The current specification of Syslog is provided\nby RFC 5424.This new specification introduces several improvements over the original im-\nplementation.\nASyslogentryisatimestampedtextmessagecomingfromanidentifiedsource.Itcontains\nthefollowinginformationinthisorder:\nTimestamp Thedateandtimeoftheeventcreation,usuallyintextformatwitharesolution\nuptothesecond.\nHostname Thenameoftheequipmentgeneratingthelog.Itmightbeafullyqualifiedname\nor an IP address, or the localhost for the local machine. Using IP addresses in private\nrangesorlocalhostmayinduceerrorswhenconsolidatinglogs.\nProcess Thenameoftheprocess(program)generatingthelog.\nPriority The priority (category and severity, computed according to a standard formula) of\nthelog.Inpractice,itisoftensummedupaccordingtoseverityonascaleof0(system\nKASecurityOperations&IncidentManagement |October2019 Page262 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\npanicandcrash)to7(debugginginformation).\nPID TheprocessIDoftheprocessgeneratingthelog.\nMessage An ASCII 7-bit message qualifying the information, provided by the developer of\ntheapplication.\nSyslog also uses the notion of facility to categorise and orient logs. This information is ag-\ngregatedindifferentfiles,usuallyinthe\/var\/log\/directoryinUnixsystems.\nSyslog is also a protocol, running on UDP\/513. This facilitates transmission, as UDP can be\nresilienttodifficultnetworkconditionsandloseafewmessageswithoutlosingthecapability.\nHowever,usingUDPoftenrequiresthesegmentationtobelimited,thusasuggestedlimitof\naSyslogmessage\u2019ssizeisoftenaroundathousandbytes.Manysystemsincludeastandard\nprogramminginterfacetoimplementcallstoSysloginapplications.\nAsatextmessage,Syslogisextremelyuseful.Many,ifnotmost,heavySOCimplementations\nrely on Syslog to centralise both events and alerts. This use of Syslog is covered in section\n8.4.1.\n8.3 ANALYSE: ANALYSIS METHODS\n[852,854,856,873]\nCollected traces are analysed according to different strategies that aim to separate \u2018good\u2019\nevents from those that indicate attacks. The fundamental work of Denning [852] already de-\nfinedthetwofamiliesofdataanalysistechniquesthathavebeenresearched,developedand\ncommercialised over the years. Misuse detection, detailed first, aims to characterise mali-\ncious behaviours present in the traces in order to send an alert when the set of malicious\nbehavioureventsisrecognisedinthetraces.Conversely,anomalydetectionaimstocharac-\nterise \u2018normal\u2019 behaviour, and sends an alert when events in traces are not associated with\nnormal behaviours. In both cases, a large number of algorithms have been described in the\nscientificliterature.Afewofthesealgorithmshavebeenappliedbothtomisuseandanomaly\ndetection.\nInSOIMprocesses,andasshowninfigure8.1,analysisisperformedbytwocomponents,the\nsensors and the SIEM platform. Figure 8.4 refines this process. The monitored Information\nSystem generates traces representative of activity, as log files or through dedicated IDPS\nappliancesorsoftware(shownaslooking-glass-boxesandfilesinfigure8.2).Oneorseveral\neventsineachtracemaytriggerthegenerationofanalertbyasensor.Severalofthesealerts,\npossiblycomingfromseveralsensors,maybeassembledbytheSIEMinincidentsthatneed\ntobehandledbyoperators.\nInthissection,theKAaddressesthetransformationofeventsinalerts,thatmaycharacterise\nmaliciousactivity.Insection8.4,theKAaddressesthetransformationofalertsinincidents.\nKASecurityOperations&IncidentManagement |October2019 Page263 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nFigure8.4:Analysis:fromeventtoalerttoincident\n8.3.1 Misuse detection\nMisuse detection leverages the vast body of knowledge characterising malicious code and\nthe vulnerabilities that this malicious code exploits. Software vulnerabilities, particularly in\ntheCommonVulnerabilitiesandExposures(CVE)nomenclature,areparticularlyrelevantfor\nthis approach, but misuse detection has a broader reach. A misuse Intrusion Detection Sys-\ntem seeks evidence of known malicious events in the trace, and alerts when they are found,\ninformingtheanalystaboutthespecificsofthevulnerabilityexploitedanditsimpact.\nThe earliest Intrusion Prevention Systems in this area are antivirus engines, which capture\nexecutiontracessuchassystemcalls,librarycallsorassembly,identifyknownmaliciouspat-\nternsusingso-calledsignaturesthatdescribethesemaliciouscodes,andquarantinetheas-\nsociatedcontainer.TheIDPSthusseeksexploits,veryspecificinstancesofmaliciouscodes\nrepresentedasbitstrings.\nModern malicious code has evolved complex mechanisms to avoid detection, and modern\nanti-malware tools have become extremely complex in response, in order to create more ef-\nficient representations of exploits and vulnerabilities. More recently, researchers have pro-\nposed more generic signatures, to attempt to capture malicious behaviour more gener-\nally [856]. Also, the emergence of sandboxes and tainting [874, 875] has enabled newer de-\ntection and protection methods that can detect malware despite obfuscation and polymor-\nphism.Therisksofgenericsignaturesare,ofcourseincreasedfalsepositivesandincreased\ndifficultyinunderstandingthepreciseattack.\nAnotherbranchofsystemanalysisisUNIXsystemanalysis,exemplifiedbytheHaystackand\nNIDES prototypes. These prototypes aimed to create high-level audit trails for analysis. The\ncanonisationaspectofthedatahadasignificantimpactondetectionperformance,andthe\ncurrentstateoftheartisfocusingonassemblyandbinarylanguageanalysisfordetection.\nFrom a network perspective, an IDPS seeks evidence of malicious activity in multiple forms.\nThe malicious code can be found in the packets\u2019 payloads. Malicious code can also exhibit\nspecific network activity related to command and control, access to known addresses or\nKASecurityOperations&IncidentManagement |October2019 Page264 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nto known services. The best known network-based misuse Intrusion Detection System is\nprobably Snort [876]. Snort\u2019s signature language is simple and was a de-facto standard for\ndescribing attack patterns, before being superseded by YARA. The initial version relied only\non string matching, which made it sensitive to false positives [877]. The Suricata IDS, using\nthe same signature language but newer implementation technologies [878], is also being\nusedinresearchandoperations.\nThekeyadvantageofmisusedetectionistheabilitytodocumentthecauseofthealert,from\na security perspective. This helps the analyst decide how to further process the alert, par-\nticularly its relevance and its impact on the monitored system. The key difficulty of misuse\ndetectionistheprocessofcreatingsignatures,whichrequirestime,expertiseandaccessto\nthepropervulnerabilityinformation.Frequentsignatureupdatesarerequired,mostlytotake\nintoaccountarapidlyevolvingthreatenvironment,butalsototakeintoaccounterrorsinthe\ninitialsignature,ornewIndicatorsofCompromisewhichwerenotinitiallydetected.\n8.3.2 Anomaly detection\nAnomaly detection is a fundamental tool for detecting of cyber attacks, due to the fact\nthat any knowledge about the attacks cannot be comprehensive enough to offer coverage.\nAnomalydetectionisadomainwherenotonlyresearchhasbeenextremelyactive,butthere\nareseveralthousandpatentsthathavebeengrantedonthetopic.\nThekeyadvantageofanomalydetectionisitsindependencefromtheknowledgeofspecific\nvulnerabilities.Thistheoreticallyenablesthedetectionof0-dayattacks,providedthatthese\nattacks effectively show up as deviations in the traces. Also, these methods are often com-\nputationally fast, which enables them to keep pace with the increasing volume of traces to\nbeprocessed.\nHowever,purestatisticalmethodshighlightanomaliesthatarehardtounderstandandqual-\nify for analysts. The lack of precise diagnosis, and of a clear link to security (instead of an\nanomalyrelatedtoanothercause)requiresanin-depthunderstandingofboththemonitored\nsystemandthedetectionprocess,whichishardtocombine.Thus,anomalydetection,while\nheavily marketed, must be operated with caution as a first line of detection, because it re-\nquiresstrongdomainknowledgetotransformadiagnosedanomalyintoactionabledefence.\nApplied to alert streams, which are richer in information, anomaly detection is often more\nsuccessfulinSIEMsandisimplementedinnewerSIEMplatformssuchastheElasticsearch-\nKibana-LogstashstackorcommercialtoolssuchasSplunk.\nAnomalydetectionwasincludedinDenning\u2019smodel[852]fromthestart,andhasconsistently\nbeendevelopedovertheyears[873,879,880].Asthedifficultyofcreatingattacksignatures\nbecamemoresignificant,IDPSvendorsalsoincludedthesemodelsintheirproducts.\nKASecurityOperations&IncidentManagement |October2019 Page265 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n8.3.2.1 Models\nAnomalydetectionreliesonthedefinitionofamodelagainstwhichthecurrentobservations\nof the trace are evaluated. Very early researchers proposed behaviour models to detect de-\nviations from the norm. However, the statistical models developed in early IDS prototypes\nsuch as Haystack and NIDES were not accurate enough to detect skilled attackers. There-\nfore,morecomplexmodelshavebeendevelopedovertheyears.\nInnetworkanomalydetection,themodelmustfirstdefinewhetheritwilllookatmultipledata\npointsorcompareasingledatapointtothemodel.Adatapointcouldbeapacket,oracom-\nplete connection. Models can also correlate between connections to detect more complex\nattacks spanning multiple packets. An example of this kind of behaviour is the correlation\nbetween web traffic and DNS traffic. When using regular browsers, the user is likely to per-\nformaDNSrequestbeforeaccessingawebsite;ananomalycouldmanifestitselfiftheweb\nrequestdirectlyaddressesthewebsitethroughitsIPaddress.Ofcourse,inthiscasecaching\nphenomenamustbetakenintoaccount.\nAnother interesting aspect of network anomaly detection is the definition of the technique.\nUnsupervised techniques look at outliers, creating clusters out of the data and using a dis-\ntancetodetermineoutliersthatcannotbecoveredinclusters.Inthistechnique,theselection\noffeatures,thatbecomethecoordinatesforeachdatapoint,iscritical.Featurecombinations\nmusteffectivelydifferentiatebetweennormalbehavioursandattacks.Frequentmethodsfor\ncreating clusters and measuring distance include k-nearest neighbors or the Mahalanobis\ndistance. Supervised anomaly detection techniques use labelled features to create optimal\nclusters.SupportVectorMachinesorC4.5arefrequentlyusedforthistask.\nGraph-basedmodelsrepresentthestructureofthenetworkandofthecommunicationpaths.\nTheyenablearepresentationofnetworkbehaviourthathighlightschangesincommunication\npatterns.Thesetechniquesalsoofferattractivevizualisationcapabilities,thatenableopera-\ntorstoweighttheexchangesbetweenvariouspartsoftheirnetworks,toidentifyanomalous\ncommunicationpatterns,andthentodigfurtherintoqualifytheanomalyassecurityrelevant\nornot.\nThe choice of an anomaly model is extremely important. In fact, many publications related\nto anomaly detection are made in thematic venues such as statistics, signal processing or\ninformationfusion,outsideofthecybersecuritydomain.Thisfieldofstudyisthusextremely\nrichandfundamentallymulti-disciplinary.\n8.3.2.2 Specificationversuslearning\nAprevalentformofanomalydetectionisspecification-baseddetection.Anattackisconsid-\nered to be a breach of the specification of a system. The key issue in this approach is to\nobtain a specification that can be reliably recognised in the traces. This approach was ini-\ntially developed for network-based IDPS, such as Bro [667], which was developed at around\nthe same time as Snort, but follows a radically different approach. Bro is built up as a stack\nofprotocolanalysers,checkingateachlayerthecoherenceofthecapturedinformationwith\nthestandards,inthiscasetheRFCs.\nFurther development of specification-based detection is expected in industrial control net-\nworks[881],wherespecificationsaremuchmorepreciseandenablethedetectionofpertur-\nbations.Inthesenetworks,thebehaviourismuchbetterspecified,becauseoftheunderlying\ncontrol loop of the physical process that is piloted by networked controllers. This also cre-\nKASecurityOperations&IncidentManagement |October2019 Page266 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nates additional regularity that can be picked up by anomaly detection algorithms. Also, the\nsystemspecificationsaremoreaccurate.\nAlternatively,supervisedlearningisusedtocreatemodelswhengroundtruthisavailable,or\nunsupervisedlearningtoletmodelsselforganise.Inbothcases,itisfrequentlynecessaryto\nselect a threshold that will separate data points considered normal from those considered\noutsideofthemodel.Theapplicationofmachinelearningtechniquesfordetectionisfurther\ndevelopedinsection8.3.4.\n8.3.2.3 Adherencetousecases\nAnimportantpointonanomalydetectionisitsadherencetoausecase,possiblyevenaspe-\ncific deployment. Network anomaly detection has been broadly applied to TCP\/IP networks\ninitially,andhasovertheyearsfocusedonnewapplications,coveringad-hocnetworks,sen-\nsornetworksand,morerecently,industrialcontrolsystems[881].Malwareanomalydetection\nhasalsoevolvedfrompersonalcomputerstowebmalwaretoAndroidmalwaretoday[882].\nThis adherence to a use case is important for creating the model, validation and testing. It\nrequires that from the start, operators understand the behaviour of their systems and have\nsufficientbusinessdomainknowledgetounderstandwhyandhowanomaliesmanifestthem-\nselves, and what their significance is with respect to cybersecurity. Specific care must be\ntaken to associate the detection of anomalies with as much domain knowledge as is possi-\nble to diagnose and qualify the anomaly. Equipment roles imply different behaviour models,\nandthusdifferentqualificationsforanomalies.\nThis adherence to use cases also prevents the definition and qualification of generic be-\nhaviour models. Therefore, operators deploying anomaly detection systems must prepare\nfor a period of testing and qualification. It is also likely that new systems, new services,\nor upgrades to existing systems or services, will perturb existing models and require re-\nqualification.\n8.3.3 Blended misuse and anomaly detection\nIn practice, it is very hard to separate anomaly detection and misuse detection, as they are\noftenintertwinedincurrentsensors.Forexample,itisextremelyusefultopre-filterinputdata\nbeforeapplyingmisusedetection.Thepre-filteringperformedonapacketstreamfollowsthe\nTCP\/IP specification, for example. Whena network-based misuse-detection sensor suchas\nSnort [876], Suricata [878] or Bro [667] processes a packet stream, it verifies that the packet\nheaders are correct before applying more complex detection processes such as signatures.\nThisnotonlyincreasesefficiencybutalsopreventsfalsepositiveswhenasignaturepattern\nis found in the wrong traffic context [877], for example, when a packet circulates over the\nnetworkbuttheTCPsessionhasnotbeenestablished.\nAsimilarapproachcanbeappliedtoIDSesusingapplicationlogs[883,884].Thisapproach\norganises both misuse and anomaly detection in order to leverage the strengths of both ap-\nproaches and limit their drawbacks. It also leverages the specifications of the application\nprotocol to understand not only the syntax of the trace but also its semantic, in order to pro-\nposeabetterdiagnosis.\nKASecurityOperations&IncidentManagement |October2019 Page267 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n8.3.4 Machine learning\nAnother, more subtle, way of mixing anomaly and misuse detection is using machine learn-\ning techniques, and particularly supervised learning, which requires ground truth. Machine\nlearning basically associates an output class with a characteristics vector presented at the\ninput.Ifthemachinelearningalgorithmrequiresadefinitionofthedifferentclassestowhich\nitassignstheinput,thenthedefinitionoftheoutputclasses(forexample,normalandattack)\ninitselfenablesmixinganomalyandmisusedetection.\nMachine learning, in many forms, has been applied to anomaly detection, and particularly\nin the network domain to the infamous Lincoln Lab\/KDD dataset [885]. There are so many\nresearch papers presenting the use of support vector machines, C4.5, random forest, that\none can only reference the best survey published so far by Chandola et al. [873]. There has\nalso been a lot of work looking at Internet traffic classification [886]. Another study looks at\nthe aspect of pre-processing network traces for anomaly detection [879]. This is a crucial\noperation,asshownbythefailureoftheKDDdataset,asitmayeitherremoveartefactsthat\narenecessaryfordetection,orintroducenewonesthatcreatefalsepositives,asdiscussed\ninsection8.3.5.\nOn the system and application side, there has been a lot of work on using machine learn-\ning for malware detection, both at the system call level [887], at file system [888] or for PDF\nfiles[889,890].Gandotra[891]listsmanyrelevantapproachesofapplyingmachine-learning\ntechniques to malware analysis, principally looking at whether they rely on static analysis\n(the file) or on dynamic analysis (the behaviour). Also, the recent development of the smart-\nphoneecosystem[892],Androidanditsrichecosystemofapplications,withtheassociated\nmaliciouscode,hascreatedsignificantinterestinAndroidmalwaredetection.\nLooking further afield, there is increasing interest in using machine learning and artificial\nintelligenceforcybersecurity,asshownbytheDARPACyberGrandChallenge.Onecanexpect\nequalinterestfromattackersandthustheemergenceofadversarialmachinelearningwhere,\nasshownforthespecificsofNeuralNetworks,attackerscanintroduceirrelevantinformation\ntoescapedetectionortomakeitharder.\n8.3.5 Testing and validating Intrusion Detection Systems\nOneofthekeyissuesforIntrusionDetectionSystemdesignersistestingandvalidatingtheir\ntools. Thisissue hasbeen aroundfor along timein theresearchcommunity,as exposedby\nanearlypaperonthetopicbyMcHugh[885].\nThedetectionproblemisaclassificationtask.TheevaluationofanIDSthereforecompares\ntheoutputofthedetectorwiththegroundtruthknowntotheevaluator,butnottothedetector.\nTrue Negatives (TN) are normal events that exist in the trace and should not be reported\nin alerts by the detector. True Positives (TP) are attack events that should be reported in\nalertsbythedetector.Asdetectorsarenotperfect,therearetwoundesirablemeasuresthat\nquantify the performance of a detector. False positives (FP), also known as false alerts or\ntype I errors, are defined as an attack that does not exist in the trace, but is reported by the\nIDS.Falsenegatives(FN),alsoknownasmissortypeII errors,aredefinedasanattackthat\nexistsinthetrace,buthasnotbeendetectedbytheIDS.\nThe first issue is to define the criteria for detection. In misuse detection (section 8.3.1), the\nIDS developer must define a set of attacks that he wants to detect and create the set of\nsignaturesthatwilldetectthem.Theissuewithtestingisthentocreatetracesthatwilltrigger\nKASecurityOperations&IncidentManagement |October2019 Page268 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nsignaturesonbehavioursthatareconsiderednormal(FP),ortolaunchattacksinawaythat\ncompromisesthesystembutisnotrecognisedbytheIDS(FN).\nIn anomaly detection (section 8.3.2), the IDS developer must define normal behaviours. As\nmost anomaly detectors use machine learning approaches, this means that the developer\nmust obtain one or several datasets of significant size, possibly labelled. These datasets\nshould, for some or all of them, include attack data. The detector is then trained on part\nof the datasets, and its performance evaluated on the others. For parametric and learning\nalgorithms, several trials should be performed to obtain an average performance. Determin-\ning FP and FN also relies on the availability of reliable ground truths associated with the\ndatasets.\nGenerating datasets, as already mentioned, is very difficult. The most commonly used one,\nthe Lincoln Lab\/KDD dataset, suffers from several of such issues which are good exam-\nples [893]. For example, the process by which the attack and normal traffic were generated\n(manual versus simulations) created obvious differences in the packet\u2019s Time To Live (TTL)\nand session duration. These features, which are not normally distinguishable in operations,\ntend to be picked up by learning algorithms, inducing a significant bias in the process with\nrespect to TP. Another example is the lack of distinguishing features in the SNMP traffic,\nwhichleadstolargeFN rates.\nThesecondissueishowtodetermineandpresenttheactualsuccesscriteriaofanIDS.From\ntherawTP,FP,TN,FN values,detectorsareoftenevaluatedontwometrics,Precisionand\nRecall.Precision(equation8.1)measuresthefractionofrealalertsinallalerts.This,inshort,\nmeasurestheusefulnessofthealerts.\nPrecision = TP\/(TP +FP) (8.1)\nRecall (equation 8.2) measures the fraction of real alerts over all the relevant information\npresent in the ground truth. Thus, recall evaluates the completeness of the detection. An\nunavailableorincompletegroundtruthmaylimititsusefulness.\nRecall = TP\/(TP +FN) (8.2)\nSeveralothermetricsarereportedintheliterature,butthesetwomustbeconsideredthemin-\nimum information provided for evaluation. Another relevant aspect of evaluation is the fact\nthatdetectionalgorithmsrequiretheoperatortoselecttheparameter,suchasthresholdsor\nnumbers of clusters. Setting these parameters strongly influences the performance of the\nsensors.Thus,itisagoodpracticetoevaluatetheperformanceofadetectionalgorithmus-\ning Receiver Operating Characteristic (ROC) curves to explicitly present the relationship and\ntrade-off between FP and FN. A gain in one direction often decreases the performance of\ntheother.\nDepending on the detector and definition, the actual values computed during the evaluation\nofthedetectormayvary.Forexample,itmightbesufficientforadetectortofindandreport\none attack event in the trace to consider it a TP, even if the attack consists of many events.\nConversely, another evaluator may require the IDS to highlight all the malicious events in a\ngiven attack to consider it a TP. Again, the experimental validation process should be ex-\ntremelydetailedandpeer-reviewedtoensurethatitdoesnotcontainanyobviouserrors.\nKASecurityOperations&IncidentManagement |October2019 Page269 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nAnotherissueistheoperationalqualificationoftheIDS.Albin[878]comparesSnortandSuri-\ncata,bothonsyntheticandonrealtraffic.Synthetictrafficprovidestheevaluatorwithaccess\nto the ground truth, thus enabling him to effectively compute FN and FP. When testing on\nrealtraffic,theevaluatormaybeabletoapproximatetheFP betterbecauserealtrafficarte-\nfacts are always likely to trigger cases that the IDS has not encountered during validation.\nThis process, however, does not support evaluating FN. As evaluation is the basis for certi-\nfication, it is no surprise that Intrusion Detection Systems are generally not certified at any\nsecuritylevel.\n8.3.6 The base-rate fallacy\nOne of the fundamental problems of intrusion detection is the base-rate fallacy formalised\nbyAxelsson[854].Theproblemstemsfromthefactthatthereisalargeasymmetrybetween\nthenumberofmaliciouseventsandthenumberofbenigneventsinthetrace.\nThegeneralhypothesisfollowedbyAxelssonisthattherearefewattacksperday.Thismay\nnotbetrueanymore,butanICTsystemfloodedwithattacksisalsounrealistic,unlessweare\nconcernedwithDenialofService.Also,inthecaseofDDoS,maliciouspacketsfaroutnumber\nnormaltraffic,sotheasymmetryisreversed,butstillexists.InAxelsson\u2019scase,itcomesfrom\nBayes\u2019 theorem that the probability of detecting an actual attack is proportional to the false\nalarmrateFP.\nIn essence, the base-rate fallacy must be addressed by IDS sensors that rely on process-\ning large amounts of data, which is typically the case for machine-learning-based anomaly\ndetection.\nWhilethismaysoundlikeatheoreticalissue,ithascrucialimplicationswithrespecttohuman\noperators in front of a SIEM console, who have to deal with thousands of alerts, most of\nwhich are \u2018false\u2019. There is thus a significant risk of missing an important alert and thus an\nincident.ThisriskisevenhigherinMSSPsettings,whereoperatorshavealimitedamountof\ntimetoprocessalerts.Theusualprocessforsolvingthisistolimitthedetectiontothemost\nrelevant elements. For example, it is not necessary to look for attacks against a windows\nserver when the monitored server is running the Linux operating system. This tuning of the\ndetectionrangecanhappeneitherbeforedetection,byremovingirrelevantsignaturesinthe\nIDS,orafterthefactintheSIEMbyenteringthepropercorrelationrules.Thedetectiontuning\napproachhas,however,encounteredlimitationsinrecentyears,becausecloudplatformsare\nmoredynamicandlikelytohostavarietyofoperatingsystemsandapplicationsatanygiven\npointintime.Itthenbecomeshardertoensurepropercoverageofthedetection.\n8.3.7 Contribution of SIEM to analysis and detection\nFrom the Analyse perspective, a SIEM aims to provide further information about malicious\nactivityreportedbysensors.\nDue to the event volume and real-time nature of the detection performed by IDS sensors,\nthese sensors usually look at a single information source in a specific location of the ICT\ninfrastructure. Therefore, it is difficult for them to detect large-scale or distributed attacks.\nTherefore, the centralisation of alerts, which is the initial central characteristic of SIEM plat-\nforms, as described in section 8.4.1, enables additional detection algorithms that may indi-\ncate attacks or anomalies that have not been significantly indicated by sensors, but whose\npropertieswhenaggregatedaresignificant.\nKASecurityOperations&IncidentManagement |October2019 Page270 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n8.4 PLAN: SECURITY INFORMATION AND EVENT\nMANAGEMENT\n[894]\nSecurity Information and Event Management form the core of the contribution to the Plan\nactivityoftheMAPE-Kloop,thebottom(blue)partoffigure8.2,andtheleft-handpartoffigure\n8.4(transformingalertsinincidents).Itshouldbeconsideredadecisionsupportsystemand,\nas such, covers the Analyse and Plan activities. From a Plan perspective, the SIEM platform\naims to define the set of actions that can be performed to block an attack or mitigate its\neffects.\nThe fundamentals of Security Information and Event Management can be traced back to\nDecember 1998, at a meeting organised by DARPA. The original goal was to enable a com-\nparisonoftheperformancesofthevariousintrusiondetectionresearchprojectsthatDARPA\nwas funding, and this delivered several works, the Lincoln Labs\/KDD dataset [895], the cri-\ntique by McHugh [885] and, much later on, the three requests for comment that formalised\nthe SIEM domain, the requirements (RFC 4766 [896]), the alert message format Intrusion\nDetection Message Exchange Format (IDMEF) (RFC 4765 [897]) and the Intrusion Detection\neXchangeProtocol(IDXP)(RFC4767[898]).\n8.4.1 Data collection\nThe first objective of a SIEM platform is to collect and centralise information coming from\nmultiplesensorsintoasingleenvironment.Severalissuesneedtobeaddressedtomakethis\nhappen.\nFirstofall,theremustbeacommunicationchannelbetweenthesensorsprovidingthealerts\nand the SIEM platform. This communication channel must be strongly protected, because\nsensitive information may be included in the alerts. It must also be properly sized so that\nthereissufficientbandwidthtocarrytherequiredinformation.Assensorsoftenhavelimited\nstoragecapabilities,theavailabilityofthelinkisessential.\nSecondly, the SIEM must be able to interpret the information provided by the sensors in a\ncoherent manner. Given the wide range of available data sources and detection methods,\nthis requires a lot of work to match the information from the alerts with the SIEM internal\ndata formats. The general approach of a SIEM platform is to define a single data structure\nfor the alerts, often a single database table. This means that the database contains many\ncolumns,butthatinsertinganalertoftenresultsinsparsefillingofthecolumns.\nData collection is generally handled by the SIEM platform, benefiting from hooks from the\nsensors.SIEMplatformvendorsgenerallydefinetheirownconnectorsandformats,handling\nboththeissueoftransportsecurityandofdataimportatthesametime.\nClassically,communicatinganalertmessagerequiresthedefinitionofthreelayers:\nSchema The schema defines the structure of messages and the type and semantic of the\nattributes.Italsoincludesthedefinitionoruseofdictionaries.Manyalertschemas,for\nexample,relyonCVEtodocumentattacks.\nEncoding The encoding defines how the messages and attributes are encoded to form a\nbitstring.ExamplesoftextualformatincludeSyslog,JSONXMLorYAML.Examplesof\nbinaryformatsincludeBER,CERorBSON.Textualformatsareusuallyeasiertoprocess\nKASecurityOperations&IncidentManagement |October2019 Page271 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nbecausetheycanbereaddirectlybyhumans.Binaryformatsaremorecompact,which\neasesstorageandtransport.\nTransportprotocol The transport protocol describes how the alert bitstring is moved from\none place to another. Examples of transport protocols include Syslog, IDXP, HTTP or\nAMQP. Transport protocols typically take care of the access control, confidentiality,\ncompressionandreliabilityofthecommunication.\nTable8.1providesafactualanalysisoffrequentlyusedalertmessageformats.Thefirsttwo,\nCEF and LEEF, are proprietary formats of commercial SIEM vendors, but whose specifica-\ntion is at least partially open for analysis. The next two formats (CIM and CADF) have been\nspecified by the DMTF, but not specifically for cybersecurity purposes. Nevertheless, they\nhave been used to convey alerts. The last two have been specifically designed with the pur-\npose of standardising the transmission of events or alerts. The text in italics indicates that\nthe specification does not force a specific technology. However, when the specification, al-\nthoughgeneric,includesaproposal,thistextisin(brackets).\nNumberof\nFormat Owner Transport Encoding Structure\nattributes(keys)\nCEF HP\/Arcsight Syslog Key\/value Flat 117\nLEEF IBM\/QRadar Syslog Key\/value Flat 50\nCIM DMTF Any (XML) UML 58\nClasseswith\nCADF TheOpenGroup, Any (JSON) 48\ncommonattributes\nDMTF,(NetIQ)\nStructured:\nCEE MITRE (Syslog) JSON,XML CEEeventmodel, 56\nCEEprofile\nIDMEF IETF IDXP XML UML 166\nTable8.1:Formatscharacteristicssummary\nThe flexibility of textual encodings enables large-scale deployment, and as such is the only\nonepresentedintable8.1.\nSyslog(RFC5424) is the de-facto standard for SIEM platforms alert acquisition, as it is\nwidely available, easy to understand and parse, and quite reliable. When using UDP,\nthereisnotransport-layersecurity.Thereisnoguaranteeofmessageintegrityordeliv-\nery. Yet, in practice, it is very successful and scalable. Its drawback is the limitation of\nitsschema(timestamp,originandASCIItextstring)andthesizeofthemessage(prac-\ntically limited to 1000 bytes). Syslog is widely used by network operators or for large\nsystemssuchastheOlympicGames.\nCEF The Common Event Format is the proprietary exchange format of the Arcsight SIEM\nplatform.Itisorientedtowardstheexpressionofsecurityrelevanteventsandincludes\nthe essential information required to describe them. This format is representative of\nthe flat structures used in SIEM platform databases. While it has a large number of\nattributes,somearenotsufficientlydocumentedforuse.\nLEEF TheLogEventEnhancedFormatistheproprietaryexchangeformatoftheQRadarSIEM\nplatform.Itfocusesonnetworksecurityevents,andassuchisnotasrichasCEF.\nKASecurityOperations&IncidentManagement |October2019 Page272 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nCIM The Common Information Model is a standard of the Distributed Management Task\nForce(DMTF).Itiswidelyusedformanagingdistributedsystems.Asitisverygeneric,\nitsexpressivenessforcybersecurityeventsislimited.\nXDAS\/CADF The Cloud Auditing Data Federation is still being developed, initially as XDAS,\nand discussions are ongoing with DMTF to include it in CADF. It focuses on system\neventsandcloudenvironments.\nCEE The Common Event Expression was initiated by the MITRE corporation as a standard\nformatforlogfilesincomputersystems.ItwasdevelopedincollaborationbetweenUS\ngovernmentalentitiesandSIEMvendors.Itclearlyseparatesthemessageformat(CEE\neventModelorProfile),encoding(CEELogSyntax)andtransport(CEELogTransport).\nUnfortunately,theworkonCEEhasstopped.\nIDMEF The Intrusion Detection Message Exchange Format [897] is an informational docu-\nment from the IETF. It does not specify a standard, and as such its adoption by the\nindustry has been very limited. It is seen as complex, and in fact the specification is\nlarge in size. The IDMEF specification attempts to be very precise and unambiguous,\nwhich is shown in the number of attributes, the largest of all the considered formats.\nThis difference in expressiveness is probably even greater, as the use of dictionaries\n(enumerated types) in the IDMEF UML design further increases its ability to represent\ninformation. Its attempt to be exhaustive has also made some of the data structures\nobsolete over time. The choice of XML messages also creates a significant burden\nin transport, particularly as the IDXP transport protocol, based on BEEP, has not been\nwidelydeployed.\nThe broad scope of the available specifications demonstrates that at this stage, there is no\nconsensusbetweenSIEMvendorsandsensorvendorstoagreeonwhatanalertshouldcon-\ntain. While many of the specifications are accessible to sensor vendors, SIEM platform ven-\ndorsprovidetheconnectorsandtakechargeoftranslatingthesensorinformationintotheir\nown formats, at the risk of missing information or misinterpreting the content. The issue\nof conveying alerts remains an issue in the lower layers, while the standards related to inci-\ndentinformationexchange,suchasMILEIODEF(RFC7970),havebeenmuchmoresuccess-\nful[899].\n8.4.2 Alert correlation\nAlert correlation [900, 901], aims to make sense of the alert stream received by the SIEM\nplatform.Thecorrelationhasseveralobjectives;\n1. to reduce the number of alerts that the analyst has to process by grouping alerts to-\ngether,\n2. to add contextual elements to enable more accurate and faster analysis of the group\nofalerts,\n3. toaddalertstoongoinghigher-levelplanningandmitigationelementssothattheyare\nhandledproperly,and\n4. todiscardalertsthatareconsideredfalsepositivesanddonotrequirefurtherprocess-\ning.\nTomeettheseobjectives,alertcorrelationcantakeseveralforms:\nKASecurityOperations&IncidentManagement |October2019 Page273 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nCorrelationbetweenalerts The first kind of alert correlation aims to group together alerts\nfrom one or several sensors that correspond to the same threat. IDPS sensors tend to\nhaveanarrowviewofthedatastream.Ifeventsoccurrepeatedlyinthetrace,forexam-\nple,whenamalwarepropagates,multiplealertswillbereportedtotheSIEM.Grouping\nalerts that correspond to the same phenomenon helps the analyst to recognise it and\ntojudgeitsimportance.\nCorrelationbetweenalertsandtheenvironment Anotherimportantsourceofknowledgeis\nrelatedtothecontextofthedetection,theenvironmentinwhichthesensorsarelocated.\nInformationabouttheenvironmentcomesfrommanysources,thetwomostinteresting\nonesbeingnetworkinventoryandvulnerabilityscans.Thesetwosourcesidentifyactive\nassetsandtheriskstheyarepotentiallysubjectto.Thistypeofcorrelationisparticularly\ninteresting as it provides the analyst with information about the impact the alerts are\nhaving.\nCorrelationbetweenalertsandexternalsources Recently, situational awareness has\nstarted to provide information about attackers and their motivations [902]. This again\nprovides additional information about the paths that an attacker might follow, and\nhelps the analyst proactively to decide to block the attacker\u2019s progress, instead of\nreactingaftertheevent.\nIncidentandinformationexchange Another relevant trend is information exchange.\nThrough regulatory pressure, critical infrastructure operators are required to inform\nauthorities when they are the victims of cybersecurity breaches. This has been the\ncase for banks and credit unions for a long time. Sharing information about breaches\nhelps others in the same domain, or using similar technologies, to protect themselves\nproactively.\nThe initial approach to alert correlation was based on rules. Rule-based correlation explic-\nitly describes logical relationships between alerts, or rules to infer such relationships [901,\n903, 904, 905]. A variety of languages and techniques have been used over the years by\nthe research community, leading to exhaustive and formal models. This led to the develop-\nment of the first generation of SIEM platforms, which combined strongly structured, high-\nperformance SQL databases with logic engines interpreting rules. This first generation en-\ncounteredtwoissues,performanceasthevolumeofalertsincreased,andthedifficultyofcre-\nating andmaintaining therule base.SQL databasesincur asignificant performancepenalty\nforindexing.Thisisgoodforquerying,whereasSIEMplatformsareinsert-intensivetools.\nDespiteperformanceincreaseanddatabasetuning,asecondgenerationofSIEMplatforms\nhasbeendeveloped,leveragingless-structureddatabasetechnologiessuchasNoSQL.This\nbig data, or data-intensive approach started quite early on using counters [900], statistical\nmodels [906] or other techniques [859, 907]. Technologically, this approach is implemented\nthrough log aggregation and summarising queries, as can be done with the well-known\nElasticSearch-Kibana-Logstash (ELK) stack. This data-oriented approach has become very\ncommon today, as it is able to cope with large volumes of incoming unstructured informa-\ntion.Itremainstobeseenwhetherthelackofrelationalstructuredoesnotintroduceinconsis-\ntencies and naming confusion, impacting analysts\u2019 ability to diagnose and mitigate threats,\nandwhetherthefocusonvolumedoesnotpreventhandlingrareattackphenomenasuchas\nAPTs.\nKASecurityOperations&IncidentManagement |October2019 Page274 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n8.4.3 Security operations and benchmarking\nTheactivityofaSOCneedstobemeasured,forseveralreasons.First,aSOCisthecombina-\ntionoftechnologyplatforms,information,processesandskilledpersonnel.Thus,itisdifficult\ntoidentifywhereaspecificSOCisperformingwell,andwhichareasshouldbeimproved.As\nSOCs are sometimes outsourced to MSSPs, the security service level agreement must be\nnegotiatedbetweenthecustomerandtheserviceprovider,andverifiedbythecustomer.The\ncustomermayalsobesubjecttoregulations,whichmustbesatisfiedbytheserviceprovider\naspartofitscontract.ItisthusnecessarytomeasuretheactivityofaSOCinawaythaten-\nablesmeasurement,comparisonbetweenindustriesandtothestateoftheart,andtodecide\nwhichareasofactivityshouldbeimproved.\nTheInformationSecurityIndicators(ISI)IndustrySpecificationGroupatETSIdevelopsindica-\ntorstothiseffect.Theseindicatorsaretheproductofaconsensusapproach,whereseveral\nindustryleaders(Thales,Airbus),users(banks,telcos)andtechnologyproviders(ESIGroup,\nBertin)havedefinedandtestedtheseindicatorsjointly.TheapproachisEurope-wide,asthe\nETSI ISI group is supported by members from France, Germany and Italy, as well as the net-\nworkofR2GSchaptersinEurope(inadditiontothecountriesinETSIISI,theUK,Luxembourg,\nBelgium, the Netherlands). In the end, these indicators should enable a comparative mea-\nsurement of SOC performance, and a general measurement of the resistance of any given\norganisationtothreats,cyber,physicalororganisational.\nTheISIspecificationisfreelyavailablefromETSI,andreferenceinformationchartsareavail-\nablefromseveralsources.Themaindifficultyofthisapproachistheabilitytoautomatically\nproduce the indicators, or at least a subset of them, as some indicators are of a very high\nlevel.\n8.5 EXECUTE: MITIGATION AND COUNTERMEASURES\n[908]\nFor a long time, the SOIM community has focused on detection and analysis, both from a\nresearch and operational deployment aspect. There is a clear reluctance to automate the\nlast part of the loop of figure 8.1, as system and network operators fear losing control over\ncomplex environments, although there are many reasons why it has become important to\ninclude automated mitigation in scope. This is an extremely important area, as exemplified\nbytheRespond andRecover topicsoftheNISTcybersecurityframework.\n8.5.1 Intrusion Prevention Systems\nIDPS sensors have been rapidly extended to include Execute capabilities to respond to at-\ntacks.IDPShastheadditionalcapabilitytoactonthemonitoredstreamupondetection.This\nrequirestheabilitytoactasagatewayorproxythroughwhichallexchangeswillbeanalysed,\ninordertoreachabenignormaliciousdecision.Onceamaliciousdecisionhasbeenreached,\nadditionalactionscanbeappliedtothedatastream,suchasblocking,terminatingoraltering\nadatastream.Ofcourse,theadditionalactionreliesheavilyonthereliabilityofthedetection,\nwhichiswhycommonpracticelimitsactionstoasubsetofthesignaturesofamisuse-based\nsensor.\nActions executed by the sensors are linked directly to the result of detection. As such, the\nPlan phase is performed through static configuration, and the response to an attack is thus\nKASecurityOperations&IncidentManagement |October2019 Page275 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nindependentofthecontextduringwhichtheattackoccurs.\nTheinitialdeploymentofnetwork-basedIDSsensorswasbasedonpassivedevices,unable\ntoactonthenetwork.Theresponsewasthuscarriedoutbysendingreconfigurationactions\ntoafirewalllocatedupstreamordownstreamfromthesensor,throughout-of-banddedicated\ncommunications. This mechanism induced significant delays in responding, as the first few\npackets of the attack were accepted before the rule was put in place. There were also un-\ndesirablesideeffectstodynamicallychangingtheconfigurationofafirewall,suchaslosing\nconnexiontracking.Also,systemoperatorsareextremelyattentiveaboutmaintainingstable\nfirewallconfigurations,asanessentialpartofSRE.\nGiven the need to respond in real time to well-identified attacks, modern network-based\nIDPSes are positioned inline in the network, to couple detection and firewalling. If malicious\nactivity is detected by the sensor, the packet is immediately dropped or rejected, or the con-\nnection is terminated. The advantage of this solution is that attacks are handled at line rate,\nassoonastheyoccur.Ofcourse,FP andFN ofthedetectionmechanismwillhaveadirect\nimpactontheefficiencyoftheIDPS,denyingservicetolegitimateusersorlettingattacksgo\nthrough undetected. The main drawback of the IDPS is the action in the packet layer. This\ncreates side effects that may leak information to an attacker. It also requires a device to be\nput into the network that has the ability to break the connection, injecting another point of\nfailureintotheICTinfrastructure.\nSpecialised examples of IDPS technology include Session Border Controllers (SBC) or Web\nApplication Firewalls (WAF). In the example of a WAF, the implementation could take the\nformofanexternaldeviceactingasaproxy(and\/orreverseproxy)orbeimplementedasan\ninterceptingmoduleinawebserver.\nMore recently, inline IDPSes have been given the ability to modify the payloads of packets,\nunder the term of \u2018virtual patching\u2019. The result is that the server receives innocuous content\ninstead of the content, and that the response sent back to the attacker indicates that the\nattack has failed. The main advantage of this approach is that it does not require breaking\ntheflow,asdoapplication-layersensorssuchasWAForSBC.\n8.5.2 Denial-of-service\nThe most obvious area where automated network-based mitigation is required is Denial of\nService(DoS),andparticularlylarge-scaleDistributedDenialofService(DDoS)attacks.DDoS\nattacks have grown continuously in terms of volume and the number of sources involved,\nfrom 300 Gbps in 2013 to 680 Gbps (the Krebs-on-security incident) and 1 Tbps (the Mi-\nrai\/OVH incident). The Arbor Networks survey of 2016 stated that half of the responding\ncloud infrastructure providers suffered from a loss of connectivity, which had a fundamen-\ntal impact on their businesses. The emergence of attacks compromising Internet of Things\n(IoT) infrastructures and using them for DDoS, such as Mirai, helped reach new attack vol-\numerecords,althoughtheaverageDDoSattacksremainrelativelysmallat500Mbps.[909]\nand [910] provide surveys and taxonomies of DDoS attacks and defences. There has also\nbeen more recent work, particularly on amplification attacks [868], which abuse protocols\nsuch as DNS [864] and NTP [867] to create large volumes of traffic with low bandwidth re-\nquirements.\nDDoSattacksarelarge-scalephenomenawhichaffectmanycomponentsandoperatorsinIn-\nternetinfrastructures,fromAutonomousSystem(AS)operatorstocloudproviderstoservice\nproviders.Attacksoncertainservicesalsohavealarge-scaleimpact.Forexample,theDDoS\nKASecurityOperations&IncidentManagement |October2019 Page276 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nattack on DynDNS impacted the availability of well-known services such as Netflix, Spotify,\nTwitteretc.Themovetocloudinfrastructuresobviouslymeansthatthesecascadingeffects\nwillcontinue.\nGiven their scale and impact, DDoS attacks are prime targets for automated remediation.\nThishasledtotheemergenceofdedicatedDDoSmitigationserviceoperatorsincloudmode.\nTheseserviceoperatorsofferloadmanagementservices,suchasaddingnewserverstoface\ntheflow,redirectingtraffictootherservices,orselectivelydecreasingtraffic.\nClassic techniques for decreasing traffic include blacklisting, for example, with IP ingress\nfiltering, or at the application level using TCP Syn cookies to ensure legitimate TCP session\nestablishment.ThishelpsresistDDoSattacks,althoughonehastoacknowledgethatthese\nserviceswillbeunabletopreventorfightverylarge-scaleattacks.\nAt the core network, MPLS provides an interesting option to mitigate DDoS attacks [911], as\nitenablesbandwidthreservationandbandwidthusagecontrol,toensurethatthelegitimate\ntrafficreceivessufficientbandwidthandthatpotentiallymalicioustrafficisgotridof.Atthe\nedge, the deployment of Software Defined Networking (SDN) as the fundamental network\ncontrol technique for cloud centres permits flexibility of the network configuration and con-\ntrol, and enables collaboration between Internet service providers and cloud infrastructure\noperatorstomitigateDDoSattacks[912].\nBeyond networking access (which is at this time the biggest threat), DoS attacks may also\ntargetcomputingresources,storage,orpower.TheemergenceoftheInternetofThings,and\nthe increasing requirement of connecting low-cost, battery-operated objects to the Internet\nmightincreasetheDoSattacksurfaceinthefuture.\n8.5.3 SIEM platforms and countermeasures\nThe contribution of SIEM platforms to the MAPE-K Execute activity today is limited; once\nplans have been defined and validated by analysts, other functions such as change-control\nticketing systems take over to ensure that the deployed actions are appropriate and do not\nadverselyimpactbusinessactivity.\nInternally in SOCs, analysts use ticketing systems to follow up on the progress of incident\nresolution and escalate issues to more skilled or specialised analysts when needed. Ticket-\ningsystemscanalsoserveforincidentpost-mortemanalysis,toevaluateandimproveSOC\nprocesses.\nSOCanalystsalsointeractwithticketingplatformstopushchangerequeststootherteams,\ninchargeofnetworkorsystemmanagement.Thiscanevenextendtosecurityfunctions,for\nexample, if the organisation has a dedicated firewall management platform. The fact that\nthis remains mostly a manual activity introduces a significant delay in threat mitigation. It\nalsoreliesonsystemornetworkoperatorsontheothersideoftheticketingsystemtounder-\nstand the requested change and effectively implement it. However, this delay is often seen\nas necessary to deal with potential false positives, and to assess the effective impact on\nbusinessactivities,aselaboratedinthefollowingsection.\nKASecurityOperations&IncidentManagement |October2019 Page277 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n8.5.4 SOAR: Impact and risk assessment\nRisk assessment in cybersecurity mainly focused in the past on protecting ICT assets, ma-\nchines,networkequipmentandlinks.Riskassessmentmethodologiesfocusondetermining\nassets, analysing their vulnerabilities, and modelling cascading effects. Attack trees, infor-\nmally described by Schneier [79] and formally defined by Mauw [913], are now implemented\nasattackgraphsinsoftwaretools[914].Theyenableanetworkorsystemsecurityofficerto\nmodel the ICT environment and the associated vulnerabilities, to determine the paths an at-\ntacker might follow to compromise interesting targets. These more complex attack graphs\nenable a quantification of the likelihood that an attacker will propagate in an Information\nSystem,ofthedamage,andofthepossibleprotectionmeasuresthatcouldblocktheattack.\nFrom a business perspective, attack graphs and vulnerability management technologies en-\nable risk management and compliance with regulations. As the impact of cyber-attacks in-\ncreases, and potentially becomes a threat to human life or business continuity, regulators\nimpose protection and detection measures to ensure that cyber-risk is properly managed in\norganisations. While there are many possible protection techniques available, from identifi-\ncation and authentication to filtering and firewalling, the complexity and interconnectivity of\ncomplexICTinfrastructuresmakesitunfeasible,eithertechnicallyoreconomically,toprotect\nthemagainstallpossiblethreats.Assuch,cybersecuritybecomesaneconomictrade-offbe-\ntween deploying protection measures, assuming the risk, and insuring it. Cyber-insurance\nhasbeendifficultbutthereisanincreasinginterestintheeconomicsofcybersecurity,which\nmightsupportthedevelopmentofcyber-insurancemodels[915].\nAnotheraspectofattackgraphsistheiruseforcountermeasures.Workoncountermeasures\nhasfocusedontechnicalassets,astheycanbeactivatedtoblockthreats.Thismeansadding\normodifyingfirewallrulestoblockunwantedtraffic,disablingorremovingprivilegesofuser\naccounts, preventing unauthorised or suspected machines of connecting to the network or\ntheInformationSystem,orshuttingdownaserviceormachine.However,thedeploymentof\ncountermeasures requires an impact assessment, not only at the asset level but also at the\nbusinesslevel.TheheavyrelianceofbusinessmissionsontechnicalICTassetsmeansthat\nthese firewall rules or blocked accounts may have a detrimental effect on an organisation\u2019s\nbusiness. This detrimental effect might even be worse than suffering an attack, at least for\nsome time. New models for impact assessment must take into account not only the ICT\nasset fabric but also the business services that they support to determine their criticality\nandthecostofalteringtheirbehaviour[916].\nOne cannot emphasise enough, as in section 8.5.3, the importance of the processes and\nworkflowsassociatedwiththesetoftoolsimplementedforSOAR.This,forexample,implies\nthat there is a clear understanding of responsibilities in the SOC, a chain of validation when\ncountermeasures are deployed, and an effective verification that the mitigation is efficient\nandhasstoppedtheattackoritseffects.\nKASecurityOperations&IncidentManagement |October2019 Page278 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n8.5.5 Site reliability engineering\nAnother relevant aspect of threat protection and mitigation is that ICT environments have\nto prepare for incident management and mitigation. As is required for safety engineering,\noperatorshavetodefineanddeployproceduressuchasactivitycontinuityplanningtoensure\nthattheywillcontinuetooperateevenwhenfacedwithcertainthreats[917].Thismeansthat\noperatorsmustdeployandoperatesensorsuptoacertainlevelofefficiency.Theymustalso\ndeploy and operate protection tools such as firewall or authentication systems that might\nimpacttheperformanceandusualbehaviouroftheirsystems.Also,allofthisnewequipment\nwillrequiremanpowerformonitoringandmaintenance.\nArecentsignificantchangetoSREisanextensionofscope.Much,ifnotall,oftheequipment\nused in any organisation will include digital technology and will require maintenance. Many\ndevices powering physical access control or building management will be interconnected\nwith and accessible through the ICT infrastructure. As such, they will be subject to similar,\nif not identical, attacks as the ICT infrastructure. New maintenance models should be de-\nveloped and adapted to include these IoT devices in the reliability engineering process. The\nNetwork and Information Systems (NIS) European Union directive requires that all devices\nshould be patched to remove vulnerabilities. Remote maintenance will become a require-\nment for many objects, large and small. Depending on their computing abilities, storing and\ncommunicating security elements, these maintenance processes will be difficult to develop\nandputintoplace[918].However,therearemanysystems,forexample,inthetransportation\norhealthdomains,wherethemovetodigitaltechnologymustincludesoftwaremaintenance\nthatistimelyandsecure.\nThis is driving increased convergence between reliability, safety and cybersecurity. SRE\nteams in cyber-physical environments thus need to operate systems, monitoring them for\nfailures and attacks, in order to ensure continuous operation. SRE is thus also increasingly\napplied in pure IT environments such as cloud computing platforms, which must be robust\nagainstaccidentalfailuressuchaspower.\n8.6 KNOWLEDGE: INTELLIGENCE AND ANALYTICS\n[894,908]\nIntelligenceandanalyticsfocusontwospecificcomponents,asshowninfigure8.2,CTIand\nCERTs. The CTI platform (section 8.6.3) replaces and includes honeypots to provide a com-\nprehensiveviewofmaliciousactivitythatmayimpactanorganisation.CERTsandISACsare\nregulatorybodieswithwhichanorganisationcanobtainadditional information,suchasthe\nindustry-specific indicator of compromise, or best practice for incident detection and han-\ndling.\nKASecurityOperations&IncidentManagement |October2019 Page279 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n8.6.1 Cybersecurity knowledge managment\nAsdescribedinsection8.4,SIEMplatformsarethemaintechnicaltoolsupportinganalyststo\ndefendInformationSystemsandnetworks.Theearliestattemptatmanagingcybersecurity-\nrelated knowledge is vulnerability information sharing, formalised as CERT advisories first\nand now managed through the Common Vulnerabilities and Exposures (CVE) dictionary, the\nCommonVulnerabilityScoringSystem(CVSS)anddatabasessuchastheNISTNationalVul-\nnerabilityDatabase.However,theperformanceoftheseplatformsreliesheavilyontheinfor-\nmation made available to the analysts manning them. Understanding attackers has been a\nlong-standing area of research, but there have been many recent advances in the state of\nthe art on understanding attack processes and motivations, and on providing analysts with\nbetterinformationtomakeappropriatedecisions.\nCVEprovidesawaytoreferencespecificvulnerabilitiesattachedtospecificversionsofprod-\nucts. This information is very useful for IDS signatures, because they clearly identify the tar-\ngeted product. However, they are insufficient for more global processing, hence higher level\nclassificationshavebeendefined.\nThe Common Vulnerability Scoring System (CVSS) provides a standard way to rate the im-\npact of vulnerabilities by providing a synthetic numerical score that is easy to comprehend.\nEach vulnerability is assigned a score according to six base metrics that reflect the intrinsic\ncharacteristicsofavulnerability,andinparticulartheeasewithwhichthevulnerabilitycanbe\nleveragedbyanattackertoimpactconfidentiality,integrityandavailability.Thisbasemetric\nismodulatedbythreetemporalmetricsthatindicatewhetherexploits(increasingtherisk)or\npatches (decreasing the risks) are available; these three temporal metrics evolve over time,\nasmoreinformationbecomesavailable.Finally,fourtemporalmetricsmeasurethespecific\nexposureofanorganisation.EachCVEentryisusuallyqualifiedbyaCVSSscore.\nThe Common Weakness Enumeration (CWE) dictionary provides a higher level structure on\ntop of the CVE dictionary, to qualify further the kind of software weaknesses involved in the\nvulnerability. It serves as an additional description of the CVE entry, to identify weaknesses\nthat appear in multiple software tools, and to identify common mitigation and prevention\nstrategies. The structure of the CWE is relatively complex, and identifying commonalities\naccross vulnerabilities is sometimes difficult. CWE references are frequently found in CERT\nadvisories.\nThe Common Attack Pattern Enumeration and Classification (CAPEC) and Adversarial Tac-\ntics, Techniques & Common Knowledge (ATT&CK) frameworks provide two additional views\nfocusingonattackeractivities.CAPECreferencesmultipleCWEentriesfocusingoncommon\nattributes and techniques used by attackers. Examples include SQL injection or Cross-Site\nRequestForgery.Morerecently,ATT&CKhasbeenformalisingoperationalinformationabout\nattackers,todevelopthreatmodelsandoperationalproceduresfordefendingnetworks.\nIt is important to note that the performance of SIEM and SOAR relies on accurate and com-\nplete information being present in the knowledge base. As such, this information must be\nmaintained, and the appropriate links to other system or network management functions\nshouldbeestablishedtothiseffect.\nKASecurityOperations&IncidentManagement |October2019 Page280 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n8.6.2 Honeypots and honeynets\nHoneypots are a relatively old technology, as exemplified in Stoll\u2019s book [330]. They were\npopularised by the Honeynet Project and Spitzner\u2019s book [919]. The community commonly\ndefines a honeypot as an Information System resource whose value lies in unauthorised or\nillicit use of that resource. More concretely, a honeypot is a machine (a honeynet is a set of\nmachines) which is offered as bait to attackers. As such, honeypots use \u2018free\u2019 resources in\nanInformationSystemornetworktoproviderealistic-lookingservicesfortheoutsideworld.\nIn normal use, these machines should never be accessed by legitimate users, thus any in-\nteraction is deemed to be related to malicious use. By monitoring the attackers\u2019 use of the\nhoneypot, researchers hope to obtain relevant information about attack processes and new\nmaliciouscode,andtoleveragethisinformationforattackdetectionandmitigation.\nThere are several categories of honeypots. Initially, honeypots were very simple tools, alert-\ning on the connection to a given port with a given IP address. However, as attackers and\nmalwareevolved,theybecameabletodetectinteractionsthataredifferentfromtheservice\nthatshouldbeofferedbytheplatformtowhichtheyareconnected.Honeypotandhoneynet\ntechnologies have thus developed in a fairly sophisticated manner in large-scale, complex\ninfrastructures. They have given rise to attacker analytics, from observations to statistical\nanalysis,towhatisnowidentifiedastheIndicatorOfCompromise(IoC),organisedpiecesof\nevidencethatanattackeristryingtocompromiseanInformationSystemornetwork.\nThemainhypothesisbehindhoneypotsisthatattackerswillactivelyseekvictims,whileregu-\nlaruserswillonlyuseresourcesthatarepubliclyandofficiallyadvertisedthroughconfigura-\ntion,routingandnaming.ThiswasprobablytrueduringthemainperiodofInternet-scanning\nwormssuchasSlammer.However,attackershaveothermeansofsilentlygatheringinforma-\ntion about their targets, for example, through search engines. The scanning is thus done by\nlegitimate,oratleastknownactors,butitprovidesnoinformationabouttheattackers.Also,\nthere is a significant amount of background noise activity on the Internet [920]. Thus, the\nmainpremiseofhoneypots,thattherearenofalsepositivesbecauseallactivityismalicious,\ncannotbeguaranteed.\nTheinformationcollectedbyhoneypotsisprovidedentirelybytheattackers,andtheyarealso\ndevelopingtechniquestounderstandwhethertheyarerunningincontrolledenvironmentsor\nnot. If they detect a controlled environment such as a virtual machine, they will stop interac-\ntions.Whilecloudcomputinghasgeneralisedtheuseofvirtualisation,thereareothertell-tale\nsignsthatindicatecontrolandmonitoring.Today\u2019sbestuseofhoneypotsisprobablywithin\nsensitivedata,intheformoffakeemailaddressesandfakerowsorcolumnsindatabases.\n8.6.3 Cyber-threat intelligence\nHoneypots have shown that it is useful to observe malicious activity, to capture malware\nand to detect new threats before they can spread widely. Since the peak of the honeypot\nperiod,researchershavestartedlookingatattackmechanismsandtrendsfromawiderper-\nspective[921],butmaintainingtheobjectiveofbothlookingatInternet-widemaliciousactiv-\nity[922,923]andatmalwareanalysis[924,925].\nIn addition to honeypots, cyber-threat intelligence has included the dimension of informa-\ntionsharing,asincreasinglyrequiredbynationalauthorities.Informationsharingisboththe\noutcome of data analytics [926] and is extremely useful for defenders to better understand\nthe risks and possibilities for protection and mitigation. As such, it is as much a human pro-\ncess [927] as platforms and tools, such as the open source Malware Information Sharing\nKASecurityOperations&IncidentManagement |October2019 Page281 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nPlatform(MISP)[928],alsoincludedinTheHiveproject.\nAnotherimportanttopicisthedefinitionofIoCs[908],whichisamoregeneraltermthansig-\nnatures.Signatures,asisgenerallyunderstood,arepiecesofevidenceofanongoingattack.\nIoCsgeneralisetheconceptintwoways.First,theyindicateevidenceofanattackbeingpre-\nparedoroftheevidencethatremainsafterasystemhasbeencompromisedbyanattacker.\nIoCsaredefinedforsharing,hencetheirinclusioninstandardssuchasRFC7970,theIncident\nObjectDescriptionExchangeFormat(IODEF)version2andtheStructuredThreadInformation\neXchange(STIX).\nWhileearlysignaturesharingattemptsusedtheSnortsignaturelanguage,theYARAlanguage\nhas been quite widely adopted and is, for example, the support of the YARA Signature Ex-\nchangeGroup,anon-commercialindicatorofcompromiseexchangeplatform.\nInordertosupportandregulateinformationsharing,theauthoritieshavealsopromotedthe\ncreation of Information Sharing and Analysis Centers (ISAC). These ISACs are both regional\n(in the U.S., in Europe, etc.) and sectoral (for energy, transportation, banking, etc.). The ob-\njective is to facilitate information sharing between persons with similar organisations and\nobjectives.Italsobringstheeconomicdimensiontocybersecurity,analysingthebenefitsof\ninformationsharingfororganisationsforbetterefficiency.\n8.6.4 Situational awareness\nSituationalAwarenessisacomplexsubject,whichhasbeenthesubjectofresearchbothfrom\natechnicalandasocialsciencesstandpoint.Earlyworkfocusedonusersoperatingcomplex\nsystems, for example, pilots in aircrafts [929], defining situational awareness as a cognitive\nprocess,theperceptionoftheelementsintheenvironmentwithinavolumeoftimeandspace,\nthe comprehension of their meaning and the projection of their status in the near future. This\nwork was considered foundational for a lot of the later work in CyberSA and a 2014 survey\npaper by Franke and Brynielsson [894] promoted this definition by Endsley [929]. In the con-\ntext of cyberattacks and the digital society, this definition implies that CyberSA implies the\nawarenessofanykindofsuspiciousorinterestingactivitytakingplaceincyberspace[894].\nBeyond technology [930], cyber-situational awareness has seen broad contributions from\nthe social sciences. It has also been widely studied in military circles [931]. Several of the\naforementioned contributions also use machine-learning techniques. When analysing the\nperformance of cyber-responders (SOC operators and analysts) Tadda [930] already uses\nexistingSIEMsandIntrusionDetectionSystemsasthetechnicalplatformforimplementing\ncyber-situationalawareness.\nTheSIEMworldisundergoingprofoundchangesthroughregulationandtheimpactofcyber-\nattacks.Fromaregulationperspective,criticalinfrastructureoperatorsarerequiredtoembed\ndetection and mitigation capabilities. This represents the instantiation of the European NIS\ndirectiveinnationallaw.ENISAregularlyprovidesinformationaboutcyber-incidents,particu-\nlarlyproceduresfordetectionandmanagement.Themostrecentreportonacyber-incident\nsimulation in June 2017 indicated that progress is still required in CyberSA, but that cooper-\nationisincreasingandthatinformationsharingisoftheutmostimportanceforappropriate\ndecision-making.\nKASecurityOperations&IncidentManagement |October2019 Page282 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n8.7 HUMAN FACTORS: INCIDENT MANAGEMENT\n[908]\nIn the current state of affairs, it remains clear that complete protection is both technically\nunfeasible and economically undesirable. Hence, systems will be compromised, and it is\nlikely that attacks will bring them down, having a significant impact. There have been, for\nexample,severalinstancesofbusinessesshuttingdownfordaysduetoransomwareattacks,\nsuchasWannacry.Beyondensuringbusinesscontinuity,technicalandregulatoryobligations\nrequire that investigations are undertaken, following a cybersecurity compromise. This is a\nmandatorystepinrestoringanICTsystemtoareliablestate.Thisstepiswhere,beyondtools\nandprocesses,thehumanaspectsarekey,particularlyeducation,trainingandexercising.\nFigure 8.5 presents a simplified incident management process inspired from NIST SP800-\n61[932],adefinitionofchallengesbyAhmadetal.[933]andasurveybyTondeletal.[934].It\ndefinesthreebroadactivitiesthatanorganisationmustcarryout,prepareitselfforincidents,\nhandleincidentswhentheyoccur,andfollowuponincidentswhentheyareclosed.\nFigure8.5:incidentmanagementlifecycle\nWhile the incident management topic comes at the end of the KA, it leverages all the capa-\nbilities and tools that have been described in the previous sections. It is also necessary to\nhighlightthatthereisarequiredbalancebetweenpreventionandresponse[935].Fullpreven-\ntionhasbeendemonstratedtobeunfeasible,foreaseofuseandcostreasonsononehand,\nandbecauseattackershavewaysandimaginationbeyondwhatsystemdesignersenvisage\non the other hand. Therefore, devoting resources to prevention versus response is highly\norganisation-specific, but it is an important exercise that must be carried out carefully be-\ncauseoftheconsequencesithasforanorganisation.Ononehand,preventionwillincrease\nthe operational costs of an organisation. On the other hand, relying only on response may\nlead to fatal consequences where the organisation would not be able to recover from an in-\ncident. Also, responding properly to incidents incurs costs that should not be ignored. Risk\nassessmentisthusanintegralpartofincidentmanagement.\nKASecurityOperations&IncidentManagement |October2019 Page283 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n8.7.1 Prepare: Incident management planning\nAsshowninfigure8.5,thefirststepinincidentmanagementistoputinplacetheappropriate\nprocessesandcapabilitiesbeforeanincidentoccurs.Thisis,infact,alegalrequirementfor\nallcriticalinfrastructureoperators,andisestablishedbyregulationssuchastheEUNetwork\nandInformationSystems(NIS)directive.\nEstablishing policies and procedures relies on the structure of the organisation and the sec-\ntor to which it belongs. Policies must involve higher level management, in order to properly\ndefinethescopeandtheorganisationalstructurethatisdevotedtoincidentmanagement,as\nwell as performance and reporting procedures. Policies must include formalised response\nplans that provide a roadmap for implementing the incident response capability, based on\nrisk assessment methods. Plans should be refined in procedures, in order to define stan-\ndard operating procedures that can be quickly followed by responders to concretely define\nthe actions that need to be taken when specific situations occur. All of these policies, plans\nandproceduresareorganisationandsector-dependent,andwillbeaffectedbydifferentreg-\nulations. As an example, financial organisations have to take into account the Basel II and\nSarbanes-Oxleyregulationsintheirincidentmanagementprocedures,toproperlyimplement\nreportingtoregulators.\nAnimportantpartofthispreparationactivityisrelatedtocommunicationinmanyforms.First\nof all, regulations now generally require that incidents are reported to the authorities, either\na national CERT hosted by a national cybersecurity agency, law enforcement agencies, or a\nsectoral organisation such as an ISAC. It is also important beforehand to establish trusted\ncommunication channels with technology and service providers such as software vendors\nand Internet service providers. Similar channels should be set up between peers such as\nCISOs, to facilitate sharing of early warnings and best practices. Transnational organisers\nand facilitators of exchanges include the Computer Security Incident Response Teams (TF-\nCSIRT),theForumofIncidentResponseandSecurityTeams(FIRST)andtheEuropeanUnion\nAgencyforCybersecurity(ENISA).\nAnother constituency comprises customers, media and the general public. Organisations\nshould be ready to communicate when cyber-security incidents affect customers, or when\nthey become largely visible. For example, the European General Data Protection Regulation\n[122](GDPR)establishestheneedtoreporttousersincaseofinformationleakage.Therefore,\nwe expect that the requirements of GDPR compliance will have an impact on cyber-security,\nas organisations realise that they have to protect and monitor their systems to comply with\nthisregulation.\nFinally,preparationalsoincludestheestablishmentofateam,usuallyaCSIRT.Thisincludes\npracticalconsiderationssuchasthedecisiontohandleincidentsinternallyortosubcontract,\nfully or partially, the tasks to qualified MSSPs, the choice of a centralised or distributed or-\nganisationforincidentresponse,andthereportingchain.Choosingbetweenacentralisedor\na distributed structure is guided by the structure of the organisation. A distributed structure\nenables better proximity (geographical as well as functional) between the incident respon-\nders and the business units. However, it may increase the required coordination efforts and\ncost.\nIncident response is very much a person-intensive task, which is related to crisis manage-\nment. It requires the ability to work under pressure, both internally (to prevent the incident\nfrompropagatingorblockingtheorganisation)andexternally(todealwithmanagement,reg-\nulatory or media pressure). There is thus a need for qualified personnel to practise incident\nKASecurityOperations&IncidentManagement |October2019 Page284 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nresponse exercises, as is done in the military, for example. It also requires continuous train-\ning in order to keep up with the most recent threats. The integration of key people with the\nrelevant communities such as ISACs or CERTs also helps information sharing and ensures\nthatbestpracticesareexchangedwithintherightcommunity.\n8.7.2 Handle: Actual incident response\nAsshowninfigure8.5,handlingincidentsrequiresthreedifferentactivities,analysis,mitiga-\ntionandcommunication.\nAnalysisisrelatedtoincidentinvestigation,tounderstandtheextentofthecompromiseand\nof the damage to the systems, particularly data. If data have been lost or altered, the dam-\nage might be extremely significant. Therefore, the investigation must assess what exactly\nwas compromised, and what was not, as well as the time the compromise occurred. This is\nextremely difficult, due to the duration of certain attacks (months), the stealthy techniques\nattackers deploy to remain hidden (erasing logs or systems, encrypting communications),\nand the difficulty of freezing and interacting with systems (attackers detecting interaction\nmaytakeverydestructiveaction)andgatheringevidence.\nMitigation is related to the deployment of emergency measures that can contain the inci-\ndent and limit its impact. Mitigation must first limit the damage that is brought to systems,\nsuch as information erasure or disclosure, that an attacker could trigger if he is discovered.\nIt must also ensure that attackers do not propagate to other systems. Containment may in-\nclude blocking network accesses in certain perimeters, or shutting down services, systems\nor communications. Containment may unfortunately have an adverse impact on desirable\nfunctions.Forexample,cuttingnetworkaccesspreventsattackersfromcommunicatingwith\ncompromisedsystems,butalsomakespatchingthemorbackingthemupmoredifficult.\nIt is common that mitigation measures reveal additional information about the attacker, its\nmethods and targets. Hence, figure 8.5 includes a closed loop between analysis and miti-\ngation, to emphasise the fact that analysis and mitigation should be understood as feeding\neachother.\nAsalreadymentionedinsection8.7.1,communicationisanintegralpartofincidenthandling.\nOnce the extent of the damage has been established, it is necessary to alert the authorities\nandcomplywithregulationsasneeded.\n8.7.3 Follow-up: post-incident activities\nThe final step in an incident response is to verify that the full extent of the compromise has\nbeen realised and to clean up the system. Restoring a system is also connected to reliabil-\nity engineering, as system integrators must plan and system operators must maintain for\nrestorationinthecaseofcompromise.\nAnother important aspect of post-incident activities is to measure the performance of the\nteam and the procedures, in order to improve them. This is often difficult, and Ahmad et\nal.[933]pointedoutseveralfactorsrelatedtothisdifficulty.First,thismeanssacrificingshort-\nterm goals (handling current incidents and returning to normal operations) to improve long-\nterm behaviour (e.g., faster and\/or more accurate mitigation). Another aspect of follow-up\nthat should be taken into account is the impact of the incident. While major incidents gen-\nerally lead to post-mortem analysis and changes in policy, low-impact incidents may be left\noutofthefollow-upprocedure.However,itisoftenthecasethattheselow-impactincidents\nKASecurityOperations&IncidentManagement |October2019 Page285 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntake up a major part of the resources devoted to incident management and they should be\nexploredaswell.\nCommunication is also an important aspect of follow-up. Lessons learned from incidents\nshouldimpactincidenttraining,toensurethatrespondersareuptodatewithattackermeth-\nods. It should also enable information sharing with peers, so that best practices are propa-\ngated to the community as a whole, to learn from incidents beyond the ones affecting each\norganisation.\nAnother relatedsubject is attack attribution [835].The objective is to understandwhere and\nwhy the attack came from, and in particular the motivations of the attacker. This will help\nrestorethesystemtoaworkingstateandpreventlatercompromise.\nSome of the work on attribution has focused on malware analysis, to provide technical evi-\ndenceofthesourceoftheattack.Theobjectiveistofindinthemalwarecodeevidenceofits\nroots,suchascodereuseorcommentsthatmayexplainthemotivationsoftheauthor.This\nenables the definition of malware families, which then may help define more generic IoCs\ntodetectthepropagation ofmaliciouscodeeveniftheexactvariantisnotknown.Malware\nauthorsdousemanytechniquestomakethisdifficult,asexplainedinsection8.3.1.\nOther works on attribution observe network activity to extract commonalities. Groups of at-\ntackersmayshareCommandandControl(C&C)infrastructures,thusattacksmaycomefrom\nthe same IP addresses or use the same domain names. They might reuse services, thus us-\ningsimilar-lookingURLsorcommands.\nHowever, attribution is very expensive, particularly if the objective is to use forensics tech-\nniques to support legal action. At this point in time, forensics and attribution remain an ex-\ntremelyspecificfieldand are notincludedinSecurity Operationsand IncidentManagement,\nbecausetheyrequireexpertise,toolsandtimebeyondwhatSIEManalystsmanningconsoles\ncanprovide.\nLegalactionusingtheinformationgatheredthroughforensicstechniquesisdiscussedinthe\nForensicskeyareadescription.\n8.8 CONCLUSION\nThe Security Operations and Incident Management domain includes many topics. From a\ntechnical standpoint, SOIM requires the ability to observe the activity of an Information Sys-\ntem or network, by collecting traces that are representative of this activity. It then requires\ntheabilitytoanalysethesetracesinrealtime,oralmostrealtime,todetectmaliciousevents\nincluded in these traces, and to send out alerts related to these events. The definition of a\nmaliciouseventdependsontheanalysistechniqueandonthedatasourceusedtoperform\nthe detection. Once an attack is detected, it must be reported and analysed on a SIEM plat-\nform,toassesstheimpactoftheattackandtodeterminethepotentialremedialactionsthat\ncanbeappliedtoblocktheattackormitigateitseffects.\nFrom an operational standpoint, SOIM is very much a process, and the definition of this pro-\ncessrequiresstrongmanagement.Itreliesonpeopletoperformmanyofthetasks,fromcon-\nfiguring the detectors to analysing the alerts to deciding on remediations. Therefore, skilled\nanalysts are one of the cornerstones of Security Operations and Incident Management. An-\notherkeyaspectisplanning,asallthetoolsandpersonnelmustbeinplacebeforeanything\ncan happen. Finally, SOIM is expensive, requiring both complex tools and skilled, round-the-\nKASecurityOperations&IncidentManagement |October2019 Page286 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nclock personnel to man them. However, the heavy reliance of our society on digital tools, as\nwell as the regulatory context, require that these tools and processes are put in place every-\nwhere.\nCROSS-REFERENCE OF TOPICS VS REFERENCE MATERIAL\n8.1Fundamentalconcepts X X\n8.2Monitor:datasources X X\n8.3Analyse:analysismethods X X X X\n8.4Plan:SecurityInformationandEventManagement X\n8.5Execute:Mitigationandcountermeasures X\n8.6Knowledge:Intelligenceandanalytics X X\n8.7Humanfactors:Incidentmanagement X\nKASecurityOperations&IncidentManagement |October2019 Page287\n]458[esab0002nosslexa\n]378[ylamona9002alodnahc\n]258[noisurtni7891gninned\n]658[yevrus2102elege ]498[rebyc4102eknarf\n]809[gnica6102oail TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nKASecurityOperations&IncidentManagement |October2019 Page288 Chapter 9\nForensics\nVassil Roussev University of New Orleans\n289 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nINTRODUCTION\nDigital forensic science, or digital forensics, is the application of scientific tools and meth-\nods to identify, collect and analyse digital (data) artifacts in support of legal proceedings.\nFrom a technical perspective, it is the process of identifying and reconstructing the relevant\nsequenceofeventsthathasledtothecurrentlyobservablestateofatargetITsystemor(dig-\nital)artifacts.Theimportanceofdigitalevidencehasgrowninlockstepwiththefastsocietal\nadoption of information technology, which has resulted in the continuous accumulation of\ndataatanexponentialrate.Simultaneously,therehasbeenrapidgrowthinnetworkconnec-\ntivity and the complexity of IT systems, leading to more complex behaviour that may need\ninvestigation.\nThe primary purpose of this Knowledge Area is to provide a technical overview of digital\nforensictechniquesandcapabilities,andtoputthemintoabroaderperspectivewithregard\nto other related areas in the cybersecurity domain. The discussion on legal aspects of digi-\ntal forensics is limited only to general principles and best practices, as the specifics of the\napplicationoftheseprinciplestendtovaryacrossjurisdictions.Forexample,theKnowledge\nArea discusses the availability of different types of evidence, but does not work through the\nlegal processes that have to be followed to obtain them. The Law & Regulation Knowledge\nArea(Chapter3)discussesspecificconcernsrelatedtojurisdictionandthelegalprocessto\nobtain,process,andpresentdigitalevidence.\nCONTENT\n9.1 DEFINITIONS AND CONCEPTUAL MODELS\n[936,937,938,939,940]\nBroadly,forensicscienceistheapplicationofscientificmethodstocollect,preserveandanal-\nyse evidence related to legal cases [936]. Historically, this involved the systematic analysis\nof (samples of) physical material in order to establish causal relationships between various\nevents, as well as to address issues of provenance and authenticity. The rationale behind it,\nLocard\u2019sexchangeprinciple,isthatphysicalcontactbetweenobjectsinevitablyresultsinthe\nexchangeofmatter,leavingtracesthatcanbeanalysedto(partially)reconstructtheevent.\nWith the introduction of digital computing and communication, which we refer to as the cy-\nberdomain,thesamegeneralassumptionswereextendedlargelyunchallenged.Althougha\ndetailed conceptual discussion is beyond the scope of this chapter, it is important to recog-\nnise that the presence of a persistent digital (forensic) trace is neither inevitable, nor is it a\n\u201cnatural\u201dconsequenceoftheprocessingandcommunicationofdigitalinformation.\nAdigital(forensic)traceisanexplicit,orimplicit,recordthattestifiestotheexecutionofspe-\ncificcomputations,orthecommunicationand\/orstorageofspecificdata.Theseeventscan\nbetheresultofhuman-computerinteraction,suchasauserlaunchinganapplication,orthey\ncan be the result of the autonomous operation of the IT system (e.g., scheduled backup).\nExplicit traces directly record the occurrence of certain types of events as part of the nor-\nmal operation of the system; most prominently, these include a variety of timestamped sys-\ntem and application event logs. Implicit traces take many forms, and allow the occurrence\nof some events to be deduced from the observed state of the system, or artifact, and en-\ngineering knowledge of how the system operates. For example, the presence on a storage\nKAForensics |October2019 Page290 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ndevice of a unique chunk of data that is part of a known file can demonstrate that the file\nwas likely to have been present once, and was subsequently deleted and partially overwrit-\nten. The observed absence of normal log files can point to a security breach during which\ntheperpetratorswipedthesystemlogsasameanstocovertheirtracks.\nAlthoughtheyfrequentlyexist,thesetracesofcyberinteractionsaretheresultofconscious\nengineering decisions that are not usually taken to specifically facilitate forensics. This has\nimportant implications with respect to the provenance and authenticity of digital evidence,\ngiventheeasewithwhichdigitalinformationcanbemodified.\n9.1.1 Legal Concerns and the Daubert Standard\nThefirstpublishedaccountsofmisuseandmanipulationofcomputersystemsforillegalpur-\nposessuchastheft,espionageandothercrimesdatebacktothe1960s.Duringthe1970s,the\nfirst empirical studies of computer crime were carried out using established criminological\nresearch methods. In the early-to-mid 1980s, targeted computer crime legislation emerged\nacrossEuropeandNorthAmerica[941,942];inrecognitionoftheinherentcross-jurisdictional\nscopeofmanysuchcrimes,internationalcooperationagreementswerealsoputinplace.\nIntheUK,theComputerMisuseAct1990[937]definescomputer-specificcrimes\u2013S1Unau-\nthorisedAccessToComputerMaterial,S2UnauthorisedAccesswithIntenttoCommitOther\nOffences, S3 Unauthorised Acts with Intent to Impair Operation, and S3A Making, Supplying\norObtaining.ThePolice&CriminalEvidenceAct1984andCriminalJustice&PoliceAct2001\naddresscomputer-specificconcernswithrespecttowarrants,searchandseizure.\nIn many jurisdictions, legal statutes related to misuse of telecommunications are separate\n(and older than) those related to computer crimes. We use the umbrella term cybercrime to\ncollectivelyrefertoallcrimesrelatedtocomputerandtelecommunicationsmisuse;broadly,\nthese include the use of cyber systems to commit any type of crime, as well as the criminal\ntargetingofcybersystems.\nAsisusuallythecase,legalsystemsrequiretimetoassimilatenewlawsandintegratethem\nintoroutinelawpractice.Conversely,legislationusuallyrequirescorrections,clarificationand\nunifiedinterpretationinresponsetoconcernsencounteredinthecourtroom.Oneoftheearli-\nestandmostinfluentiallegalprecedentswassetbytheUSSupremeCourt,whichusedthree\nspecificcases\u2013Daubertv.MerrellDowPharmaceuticals,509U.S.579(1993);GeneralElec-\ntricCo.v.Joiner,522U.S.136(1997);andKumhoTireCo.v.Carmichael,526U.S.137(1999)\n\u2013toestablishanewstandardforthepresentationofscientificevidenceinlegalproceedings,\noftenreferredtoastheDaubertstandard[943].\nAsperGoodstein[938],\u201cThepresentationofscientificevidenceinacourtoflawisakindof\nshotgunmarriagebetweenthetwodisciplines....TheDaubertdecisionisanattempt(notthe\nfirst,of course)toregulatethat encounter.\u201d Thesecases seta newstandardfor expert testi-\nmony,overhaulingthepreviousFryestandardof1923(Fryev.UnitedStates,293F.1013,D.C.\nCir.1923).Inbrief,theSupremeCourtinstructedtrialjudgestobecomegatekeepersofexpert\ntestimony,andgavefourbasiccriteriatoevaluatetheadmissibilityofforensicevidence:\n1. Thetheoreticalunderpinningsofthemethodsmustyieldtestablepredictionsbymeans\nofwhichthetheorycouldbefalsified.\n2. Themethodsshouldpreferablybepublishedinapeer-reviewedjournal.\n3. Thereshouldbeaknownrateoferrorthatcanbeusedinevaluatingtheresults.\nKAForensics |October2019 Page291 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n4. Themethodsshouldbegenerallyacceptedwithintherelevantscientificcommunity.\nThecourtalsoemphasisedthatthesestandardsareflexibleandthatthetrialjudgehasalot\nofleewayindeterminingtheadmissibilityofforensicevidenceandexpertwitnesstestimony.\nTheDaubertcriteriahavebeenbroadlyaccepted,inprinciple,byotherjurisdictionssubjectto\ninterpretation in the context of local legislation. In the UK, the Law Commission for England\nandWalesproposedinconsultationpaperNo.190[939]theadoptionofcriteriathatbuildon\nDaubert.\nThe ACPO Good Practice Guide for Digital Evidence codifies four basic principles for the ac-\nquisitionandhandlingofdigitalevidence:\n1. Noactiontakenbylawenforcementagencies,personsemployedwithinthoseagencies\northeiragentsshouldchangedatawhichmaysubsequentlyberelieduponincourt.\n2. Incircumstanceswhereapersonfindsitnecessarytoaccessoriginaldata,thatperson\nmustbecompetenttodosoandbeabletogiveevidenceexplainingtherelevanceand\ntheimplicationsoftheiractions.\n3. An audit trail or other record of all processes applied to digital evidence should be cre-\nated and preserved. An independent third party should be able to examine those pro-\ncessesandachievethesameresult.\n4. Thepersoninchargeoftheinvestigationhasoverallresponsibilityforensuringthatthe\nlawandtheseprinciplesareadheredto.\nTheseprinciplesseektoprovideoperationalguidancetodigitalforensicinvestigatorsonhow\ntomaintaintheintegrityoftheevidenceandtheinvestigativeprocess,suchthattheevidence\ncanbeusedinacourtoflaw.\nIn the UK, the Forensic Science Regulator mandates that any provider of digital forensic sci-\nence must be \u201caccredited to BS EN ISO\/IEC 17020:2012 for any crime scene activity and\nBS EN ISO\/IEC 17025:2005 for any laboratory function (such as the recovery or imaging of\nelectronic data)\u201d [944]. ISO\/IEC 17025 [945] is an international standard specifying general\nrequirements for the competence of testing and calibration laboratories; in other words, the\ncertification attests to the quality and rigour of the processes followed in performing the\nforensicexamination.\nIntheUS,thereisnostrictlegalrequirementfordigitalforensicscienceproviderstobecerti-\nfiedtoparticularstandards.MostlargefederalandstateforensiclabsdomaintainISO17025\ncertifications;asof2019,eightyfiveofthemhavesuchcredentialsfortheprocessingofdig-\nitalevidence.\nDigitalforensictechniquesarealsoappliedinamuchbroaderrangeofinquiries,suchasin-\nternalcorporateinvestigations,thatoftendonotresultinformalproceedingsinpubliccourt.\nDespitethefactthatinvestigationsmaynotrequirethesamestandardofproof,forensicana-\nlystsshouldalwaysfollowsoundforensicpracticesincollectingandanalysingtheartifacts.\nThisincludesadherencetoanyjudicialrequirementswhenworkingwithinherentlypersonal\ndata,whichcanbeanon-trivialconcernwhentheinvestigationismulti-jurisdictional.Insuch\ncases,itisimportanttoseektimelylegaladvicetopreservetheintegrityoftheinquiry.\nKAForensics |October2019 Page292 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n9.1.2 Definitions\nIn 2001, the first Digital Forensics Research Workshop (DFRWS) was organised in response\nto the need to replace the prevalent ad hoc approach to digital evidence with a systematic,\nmulti-disciplinaryefforttofirmlyestablishdigitalforensicsasarigorousscientificdiscipline.\nTheworkshopproducedanin-depthreportoutliningaresearchagendaandprovidedoneof\nthemostfrequentlyciteddefinitionsofdigitalforensicscienceintheliterature:\n[DFRWS] Digital forensics is the use of scientifically derived and proven methods toward\nthe preservation, collection, validation, identification, analysis, interpretation, documenta-\ntion and presentation of digital evidence derived from digital sources for the purpose of\nfacilitating or furthering the reconstruction of events found to be criminal, or helping to\nanticipateunauthorisedactionsshowntobedisruptivetoplannedoperations.[946]\nThis definition, although primarily stressing the investigation of criminal actions, also in-\ncludes an anticipatory element, which is typical of the notion of forensics in operational en-\nvironments, and brings it closer to incident response and cyber defence activities. In these\nsituations,theanalysisisprimarilytoidentifythevectorofattackandthescopeofasecurity\nincident; the identification of adversaries with any level of certainty is rare and prosecution\nisnotthetypicaloutcome.Incontrast,thereferencedefinitionprovidedbyNISTafewyears\nlater [940] is focused entirely on the legal aspects of forensics, and emphasises the impor-\ntanceofastrictchainofcustody:\n[NIST]Digitalforensics(NIST)isconsideredtheapplicationofsciencetotheidentification,\ncollection, examination, and analysis of data while preserving the integrity of the informa-\ntionandmaintainingastrictchainofcustodyforthedata.Datareferstodistinctpiecesof\ndigitalinformationthathavebeenformattedinaspecificway.[940]\nTheabovelaw-centricdefinitionsprovidealitmustestfordeterminingwhetherspecificinves-\ntigative tools and techniques qualify as being forensic. From a legal perspective, a flexible,\nopen-endeddefinitionisnormalandnecessaryduringlegalproceedingstofitthecase.How-\never,fromatechnicalperspective,theydonotprovideameaningfulstartingpoint;therefore,\nwecanadaptarefinementoftheworkingdefinitionfirstintroducedin[947]:\n[Working] Digital forensics is the process of identifying and reconstructing the relevant\nsequenceofeventsthathaveledtothecurrentlyobservablestateofatargetITsystemor\n(digital)artifacts.\nThe notion of relevance is inherently case-specific, and a large part of forensic analysts\u2019 ex-\npertiseistheabilitytoidentifyevidencethatconcernsthecaseathand.Frequently,acritical\ncomponentofforensicanalysisisthecausalattributionofeventsequencetospecifichuman\nactors of the system (such as users, administrators, attackers). The provenance, reliability,\nandintegrityofthedatausedasevidencedataisofprimary importance.\nAccording to this definition, we can view every effort made to perform system or artifact\nanalysis after the fact as a form of digital forensics. This includes common activities such\nasincidentresponseandinternalinvestigations,whichalmostneverresultinanylegalaction.\nOn balance, only a tiny fraction of forensic analyses make it to the courtroom as formal evi-\ndence,althoughthisshouldnotconstrainusfromexploringthefullspectrumoftechniques\nKAForensics |October2019 Page293 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nfor reconstructing the past of digital artifacts. The benefit of employing a broader view of\nforensic computing is that it helps us to identify closely related tools and methods that can\nbeadaptedandincorporatedintoforensics.\n9.1.3 Conceptual Models\nIn general, there are two possible approaches to rebuilding the relevant sequence of events\nintheanalysisofacybersystemfromtheavailabledatasources\u2013state-centric,andhistory-\ncentric\/log-centric.Thestartingpointforstate-centricapproachesisasnapshotofthestate\nofthesystemofinterest;forexample,thecurrentcontentofaharddriveoranotherstorage\nmedium. Using the knowledge of how a particular system\/application operates, we can de-\nduceapriorstateofinterest.Forexample,ifuniquepiecesofaknownfileareonthemedium,\nbut the file is not available via the normal file system interface, the most likely explanation\nis that the file was once stored in the file system but was subsequently deleted (the space\nwas marked for reuse) and partially overwritten by newer files. The main constraint here is\nthedearthofhistoricaldatapoints,whichlimitsourabilitytodeducethestateofthesystem\natanygivenpointinthepast.\nLog-centric approaches rely on an explicit, timestamped history of events (a log) that docu-\nments the updates to the system\u2019s state. For example, a packet capture contains the com-\nplete history of network communications over a period of time. Operating Systems (OSs)\nmaintain a variety of monitoring logs that detail various aspects of the operation of the OS\nkernel and different applications; additional auditing and security monitoring tools can pro-\nvide yet more potentially relevant events. Many applications, especially in the enterprise do-\nmain,provideapplication-levellogs.Thus,alog-richenvironmentcontainspotentiallyallthe\nrelevantdetailstoaninvestigation;thechallengeistosiftthroughthelogentries,whichoften\nnumberinthemillions,tofindandputtogethertherelevantevents.\nHistorically,storagehasbeenapreciousresourceincomputersystems,leadingtosoftware\ndesigns that emphasise space efficiency by updating the information in place, and keeping\naminimalamountofloginformation.Consequently,theprincipalapproachtoforensicshas\nbeenpredominantlystate-centric.\nOver the last ten to fifteen years, technology advances have made storage and bandwidth\nplentifulandaffordable,whichhasledtoamassiveincreaseintheamountoflogdatamain-\ntainedbyITsystemsandapplications.Thereisacleartrendtowardsincreasingtheamount\nand granularity of telemetry data being sent over the network by operating systems and in-\ndividualapplicationsaspartoftheirnormaloperations.Consequently,thereisasubstantial\nneedtoevolveaforensicmethodologysuchthatloginformationtakesonacorrespondingly\nhigher level of importance. In other words, the current period marks an important evolution\nin digital forensic methodology, one that requires substantial retooling and methodological\nupdates.\nKAForensics |October2019 Page294 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n9.1.3.1 CognitiveTaskModel\nDifferential analysis [948] is a basic building block of the investigative process, one that is\napplied at varying levels of abstraction and to a wide variety of artifacts. However, it does\nnotprovideanoverallviewofhowforensicexpertsactuallyperformaninvestigation.Thisis\nparticularlyimportantinordertobuildforensictoolsthatbettersupportcognitiveprocesses.\nUnfortunately, digital forensics has not been the subject of any serious interest on the part\nofcognitivescientistsandtherehasbeennocoherentefforttodocumentforensicinvestiga-\ntions. Therefore, we adopt the sense-making process originally developed by Pirolli & Card\n[949] to describe intelligence analysis - a cognitive task that is very similar to forensic anal-\nysis. The Pirolli & Card cognitive model is derived from an in-depth Cognitive Task Analysis\n(CTA),andprovidesareasonablydetailedviewofthedifferentaspectsofanintelligencean-\nalyst\u2019s work. Although many of the tools are different, forensic and intelligence analysis are\nvery similar in nature - in both cases analysts have to go through a mountain of raw data\nto identify (relatively few) relevant facts and put them together into a coherent story. The\nbenefitofusingthismodelisthat:a)itprovidesafairlyaccuratedescriptionoftheinvestiga-\ntive process in its own right, and allows us to map the various tools to the different phases\nof the investigation; b) it provides a suitable framework for explaining the relationships of\nthe various models developed within the area of digital forensics; and c) it can seamlessly\nincorporateinformationfromotherlinesoftheinvestigation.\nTheoverallprocessisshowninFigure9.1.Therectangularboxesrepresentdifferentstages\nin the information processing pipeline, starting with raw data and ending with presentable\nresults.Thearrowsindicatetransformationalprocessesthatmoveinformationfromonebox\nto another. The x axis approximates the overall level of effort required to move information\nfromtherawtothespecificprocessingstage.Theyaxisshowstheamountofstructure(with\nrespecttotheinvestigativeprocess)intheprocessedinformationforeverystage.Thus,the\noverall trend is to move the relevant information from the lower left-hand to the upper right-\nhand corner of the diagram. In reality, the processing can both meander through multiple\niterationsoflocalloopsandjumpoverphases(forroutinecaseshandledbyanexperienced\ninvestigator).\nExternaldatasourcesincludeallpotentialevidencesourcesforaspecificinvestigationsuch\nas disk images, memory snapshots, network captures and reference databases such as\nhashes of known files. The shoebox is a subset of all the data that have been identified as\npotentially relevant, such as all the email communications between two persons of interest.\nAtanygiventime,thecontentsoftheshoeboxcanbeviewedastheanalyst\u2019sapproximation\nof theinformation content that ispotentially relevant to the case.The evidencefilecontains\nonly the parts that are directly relevant to the case such as specific email exchanges on a\ntopicofinterest.\nTheschemacontainsamoreorganisedversionoftheevidencesuchasatimelineofeventsor\nagraphofrelationships,whichallowshigher-levelreasoningovertheevidence.Ahypothesis\nisatentativeconclusionthatexplainstheobservedevidenceintheschemaand,byextension,\ncouldformthefinalconclusion.Oncetheanalystissatisfiedthatthehypothesisissupported\nby the evidence, the hypothesis turns into a presentation, which is the final product of the\nprocess. The presentation usually takes on the form of an investigator\u2019s report that both\nspeaks to the high-level conclusions that are relevant to the legal case and also documents\nthelow-leveltechnicalstepsbasedonwhichtheconclusionhasbeenformed.\nThe overall analytical process is iterative in nature with two main activities loops: a foraging\nKAForensics |October2019 Page295 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nFigure 9.1: Notional model of sense-making loop for analysts derived from cognitive task\nanalysis[950,p.44].\nloopthatinvolvestheactionstakentofindpotentialsourcesofinformation,andwhichthen\nqueries them and filters them for relevance; and a sense-making loop in which the analyst\ndevelops \u2013 in an iterative fashion \u2013 a conceptual model that is supported by the evidence.\nThe information transformation processes in the two loops can be classified into bottom-\nup (organising data to build a theory) or top-down (finding data based on a theory) ones.\nAnalystsapplythesetechniquesinanopportunisticfashionwithmanyiterations,inresponse\ntobothnewlydiscoveredpiecesofevidence,andtohigh-levelinvestigativequestions.\n9.1.3.2 Bottom-UpProcesses\nBottom-upprocessesaresynthetic\u2013theybuildhigher-level(moreabstract)representations\nofinformationfrommorespecificpiecesofevidence.\n\u2022 Searchandfilter:Externaldatasources,harddrives,networktraffic,etc.aresearchedfor\nrelevant data based on keywords, time constraints and others in an effort to eliminate\nthevastmajorityofirrelevantdata.\n\u2022 Read and extract: Collections in the shoebox are analysed to extract individual facts\nandrelationshipsthatcansupportordisproveatheory.Theresultingpiecesofartifacts\n(e.g.,individualemailmessages)areusuallyannotatedwiththeirrelevancetothecase.\n\u2022 Schematize: At this step, individual facts and simple implications are organised into a\nschema that can help organise and identify the significance of and relationships be-\ntween a growing number of facts and events. Timeline analysis is one of the basic\nKAForensics |October2019 Page296 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntoolsofthetrade;however,anymethodoforganisingandvisualisingthefacts-graphs,\ncharts,etc.-cangreatlyspeeduptheanalysis.Thisisnotaneasyprocesstoformalise,\nandmostforensictoolsdonotdirectlysupportit.Therefore,theresultingschemasmay\nexistonapieceofpaper,onawhiteboardoronlyinthemindoftheinvestigator.Since\nthe overall case could be quite complicated, individual schemas may cover specific\naspectsofitsuchasthediscoveredsequenceofevents.\n\u2022 Build case: From the analysis of the schemas, the analyst eventually comes up with\ntestable theories, or working hypotheses, that can explain the evidence. A working hy-\npothesis is a tentative conclusion and requires more supporting evidence, as well as\nrigoroustestingagainstalternativeexplanations.Itisacentralcomponentoftheinves-\ntigativeprocessandisacommonpointofreferencethatbringstogetherthelegaland\ntechnicalsidesinordertobuildacase.\n\u2022 Tellstory:Thetypicalresultofaforensicinvestigationisafinalreportand,perhaps,an\noralpresentationincourt.Theactualpresentationmayonlycontainthepartofthestory\nthatisstronglysupportedbythedigitalevidence;weakerpointsmaybeestablishedby\ndrawingonevidencefromothersources.\n9.1.3.3 Top-DownProcesses\nTop-down processes are analytical \u2013 they provide context and direction for the analysis of\nless structured data search and they help organise the evidence. Partial or tentative conclu-\nsionsareusedtodrivethesearchforsupportingandcontradictorypiecesofevidence.\n\u2022 Re-evaluate: Feedback from clients may necessitate re-evaluations, such as collecting\nstrongerevidenceorpursuingalternativetheories.\n\u2022 Search for support: A hypothesis may need more facts to be of interest and, ideally,\nwouldbetestedagainstevery(reasonably)possiblealternativeexplanation.\n\u2022 Search for evidence: Analysis of theories may require the re-evaluation of evidence to\nascertain its significance\/provenance, or it may trigger the search for more\/better evi-\ndence.\n\u2022 Search for relations: Pieces of evidence in the file can suggest new searches for facts\nandrelationsonthedata.\n\u2022 Search for information: The feedback loop from any of the higher levels can ultimately\ncascade into a search for additional information; this may include new sources, or the\nre-examinationofinformationthatwasfilteredoutduringpreviouspasses.\n9.1.3.4 TheForagingLoop\nIthasbeenobserved[951]thatanalyststendtostartwithahigh-recall\/low-selectivityquery,\nwhichencompassesafairlylargesetofdocuments\u2013manymorethantheanalystcanread.\nTheoriginalsetisthensuccessivelymodifiedandnarroweddownbeforethedocumentsare\nreadandanalysed.\nThe foraging loop is a balancing act between three kinds of processing that an analyst can\nperform-explore,enrichandexploit.Explorationeffectivelyexpandstheshoeboxbyincluding\nlargeramountsofdata;enrichmentshrinksitbyprovidingmorespecificqueriesthatinclude\nfewer objects for consideration; exploitation is the careful reading and analysis of an arti-\nfact to extract facts and inferences. Each of these options has varying costs and potential\nKAForensics |October2019 Page297 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nrewards and, according to information foraging theory [952], analysts seek to optimise their\ncost\/benefittrade-offs.\nInformation foraging in this context is a highly iterative process with a large number of in-\ncremental adjustments in response to the emerging evidence. It is the responsibility of the\ninvestigatortokeeptheprocessontargetandwithintheboundariesofanylegalrestrictions.\n9.1.3.5 TheSense-MakingLoop\nSense-making is a cognitive term and, according to Klein\u2019s [953] widely quoted definition, is\ntheabilitytomakesenseofanambiguoussituation.Itistheprocessofcreatingsituational\nawareness and understanding to support decision making in the face of uncertainty \u2013 an\neffort to understand connections between people, places and events in order to anticipate\ntheirtrajectoriesandacteffectively.\nThere are three main processes involved in the sense-making loop: problem structuring-the\ncreationandexplorationofhypotheses,evidentiaryreasoning\u2013theemploymentofevidence\nto support\/disprove a hypothesis and decision making-selecting a course of action from a\nsetofavailablealternatives.\nItisimportanttorecognizethatthedescribedinformationprocessingloopsarecloselytied\ntogether and often trigger iterations in either directions. New evidence may require a new\nworkingtheory,whereasanewhypothesismaydrivethesearchfornewevidencetosupport\nordisproveit.\n9.1.3.6 DataExtractionvs.Analysisvs.LegalInterpretation\nConsidering the overall process from Figure 9.1, we gain a better understanding of the roles\nand relationships among the different actors. At present, digital forensic researchers and\ntooldevelopersprimarilyprovidethemeanstoacquirethedigitalevidencefromtheforensic\ntargets, extract (and logically reconstruct) data objects from it, and the essential tools to\nsearch, filter, and organize it. In complex cases, such as a multi-national security incident,\nidentifyingandacquiringtherelevantforensictargetscanbeadifficultandlengthyprocess.\nItisoftenpredicatedinsecuringthenecessarylegalrulingsinmultiplejurisdictions,aswell\nasthecooperationofmultipleorganizations.\nForensicinvestigatorsaretheprimaryusersofthesetechnicalcapabilities,employingthem\nto analyse specific cases and to present legally-relevant conclusions. It is the responsibility\noftheinvestigatortodrivetheprocessandtoperformalltheinformationforagingandsense-\nmakingtasks.Asthevolumeofthedatabeinganalysedcontinuestogrow,itbecomesever\nmore critical for the forensic software to offer higher levels of automation and abstraction.\nDataanalyticsandnaturallanguageprocessingmethodsarestartingtoappearindedicated\nforensic software, and \u2013 going forward \u2013 an expanding range of statistical and machine\nlearningtoolswillneedtobeincorporatedintotheprocess.\nLegalexpertsoperateintheupperright-handcornerofthedepictedprocessintermsofbuild-\ning\/disprovinglegaltheories.Thus,theinvestigator\u2019staskcanbedescribedasthetranslation\nof highly specific technical facts into a higher level representation and theory that explains\nthem. The explanation is almost always connected to the sequence of the actions of the\npeoplethatarepartofthecase,suchassuspects,victims,andwitnesses.\nIn summary, investigators need not be forensic software engineers, but they must be tech-\nnically proficient enough to understand the significance of the artifacts extracted from data\nKAForensics |October2019 Page298 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nsources, and they must be able to read the relevant technical literature (peer-reviewed arti-\ncles)infull.Asthesophisticationofthetoolsgrows,investigatorswillneedtohaveaworking\nunderstanding of a growing list of data science methods that are employed by the tools in\norder to correctly interpret the results. Similarly, analysts must have a working understand-\ningofthelegallandscape,andtheymustbeabletoproduceacompetentreportandpresent\ntheirfindingsonthewitnessstand,ifnecessary.\n9.1.3.7 ForensicProcess\nThedefiningcharacteristicofforensicinvestigationsisthattheirresultsmustbeadmissible\nincourt.Thisentailsfollowingestablishedproceduresforacquiring,storing,andprocessing\noftheevidence,employingscientificallyestablishedanalyticaltoolsandmethods,andstrict\nadherencetoaprofessionalcodeofpracticeandconduct.\nData Provenance and Integrity. Starting with the data acquisition process, an investigator\nmustfollowacceptedstandardsandproceduresinordertocertifytheprovenanceandmain-\ntain the integrity of the collected evidence. In brief, this entails acquiring a truthful copy of\nthe evidence from the original source using validated tools, keeping custodial records and\ndetailed case notes, using validated tools to perform the analysis of the evidence, cross-\nvalidating critical pieces of evidence, and correctly interpreting the results based on peer-\nreviewedscientificstudies.\nAsdiscussedinthefollowingsection,dataacquisitioncanbeperformedatdifferentlevelsof\nabstractionandcompleteness.Thetraditionalgoldstandardisabit-levelcopyoftheforensic\ntarget, which can then be analysed using knowledge of the structure and semantics of the\ndatacontent.Asstoragedevicesincreaseincomplexityandencryptionbecomesthedefault\ndata encoding, it is increasingly infeasible to obtain a true physical copy of the media and a\n(partial)logicalacquisitionmaybetheonlypossibility.Forexample,theonlyreadilyavailable\nsource of data content for an up-to-date smartphone (with encrypted local storage) might\nbe a cloud backup of the user\u2019s data. Further, local data may be treated by the courts as\nhavinghigherlevelsofprivacyprotectionthandatasharedwithathirdparty,suchasaservice\nprovider.\nScientific Methodology. The notion of reproducibility is central to the scientific validity of\nforensic analysis; starting with the same data and following the same process described\ninthecasenotesshouldallowathirdpartytoarriveatthesameresult.Processingmethods\nshouldhavescientificallyestablishederrorratesanddifferentforensictoolsthatimplement\nthesametypeofdataprocessingshouldyieldresultsthatareeitheridentical,orwithinknown\nstatisticalerrorboundaries.\nThe investigator must have a deep understanding of the results produced by various foren-\nsic computations. Some of the central concerns include: inherent uncertainties in some of\nthe source data, the possibility for multiple interpretations, as well as the recognition that\nsomeofthedatacouldbefakeinthatitwasgeneratedusinganti-forensicstoolsinorderto\nconfuse the investigation. The latter is possible because most of the data item used in the\nforensic analysis is produced during the normal operation of the system, and is not tamper-\nproof.Forexample,anintruderwithsufficientaccessprivilegescanarbitrarilymodifyanyof\nthe millions of file timestamps potentially making timeline analysis \u2013 a core analytical tech-\nnique\u2013unreliable.Experiencedforensicanalystsarealerttosuchissuesandseek,whenever\npossible,tocorroborateimportantpiecesofinformationfrommultiplesources.\nToolValidation.Forensictoolvalidationisascientificandengineeringprocessthatsubjects\nKAForensics |October2019 Page299 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nspecific tools to systematic testing in order to establish the validity of the results produced.\nFor example, data acquisition software must reliably produce an unmodified and complete\ncopyoftheclassofforensictargetsitisdesignedtohandle.\nForensic Procedure. The organizational aspect of the forensic process, which dictates how\nevidence is acquired, stored, and processed is critical to the issue of admissibility. Strict ad-\nherencetoestablishedstandardsandcourt-imposedrestrictionisthemosteffectivemeans\nof demonstrating to the court that the results of the forensic analysis are truthful and trust-\nworthy.\nTriage. The volume of data contained by a forensic target typically far exceeds the amount\nof data relevant to an inquiry. Therefore, in the early stages of an investigation, the focus of\nthe analysis is to (quickly) identify the relevant data and filter out the irrelevant. Such initial\nscreeningofthecontent,oftenreferredtoastriage,resultsineitherfollowupdeepexamina-\ntion,orindeprioritisation,orremovalofthetargetfromfurtherconsideration.\nLegally, there can be a number of constraints placed on the triage process based on the the\ncase and the inherent privacy rights in the jurisdiction. From a technical perspective [954],\n\u201ctriageisapartialforensicexaminationconductedunder(significant)timeandresourcecon-\nstraints.\u201dInotherwords,investigatorsemployfastexaminationmethods,suchaslookingat\nfilenames,examiningwebsearchhistory,andsimilar,toestimate(basedonexperience)the\nvalue of the data. Such results are inherently less reliable than a deep examination as it is\neasytocreateamismatchbetweendataattributeandactualcontent.Therefore,courtsmay\nplaceconstraintsontheuseofcomputersbyconvictedoffenderstofacilitatefastscreening\nbyofficersinthefieldwithoutimpoundingthedevice.\n9.2 OPERATING SYSTEM ANALYSIS\n[940,955,956]\nModerncomputersystemsgenerallystillfollowtheoriginalvonNeumannarchitecture[957],\nwhich models a computer system as consisting of three main functional units \u2013 CPU, main\nmemory,andsecondarystorage\u2013connectedviadatabuses.Tobeprecise,theactualinves-\ntigativetargetsarenotindividualpiecesofhardware,butthedifferentOperatingSystem(OS)\nmodulescontrollingthehardwaresubsystemsandtheirrespectivedatastructures.\nOur discussion takes a high level view of OS analysis \u2013 it is beyond the scope of the Knowl-\nedge Area to delve into the engineering details of how different classes of devices are anal-\nysed. For example, smartphones present additional challenges with respect to data acquisi-\ntion;however,theyarestillcommoditycomputerswiththevastmajorityofthemrunningon\na Linux kernel. The same applies to other classes of embedded devices, such as UAVs and\nvehicleinfotainmentsystems.\nThe OS functions at a higher level of privilege relative to user applications and directly man-\nagesallthecomputersystem\u2019sresources\u2013CPU,mainmemory,andI\/Odevices.Applications\nrequest resources and services from the OS via the system call interface and employ them\nto utilize them to accomplish a specific task. The (operating) system maintains a variety of\naccountinginformationthatcanbearwitnesstoeventsrelevanttoaninquiry[955].\nSystem analysis employs knowledge of how operating systems function in order to reach\nconclusions about events and actions of interest to the case. Average users have very little\nunderstanding of the type of information operating systems maintain about their activities,\nKAForensics |October2019 Page300 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nandusuallydonothavetheknowledgeand\/orprivilegeleveltotamperwithsystemrecords\ntherebymakingthemforensicallyuseful,eveniftheydonotfitaformaldefinitionforsecure\nandtrustworthyrecords.\n9.2.1 Storage Forensics\nPersistentstorageintheformofHardDiskDrives(HDDs),SolidStateDrives(SSDs),optical\ndisks,external(USB-connected)mediaetc.istheprimarysourceofevidenceformostdigital\nforensic investigations. Although the importance of (volatile) memory forensics in solving\ncases has grown significantly, a thorough examination of persistent data has remained a\ncornerstoneofmostdigitalforensicinvestigations.\n9.2.1.1 DataAbstractionLayers\nComputersystemsorganiserawstorageinsuccessivelayersofabstraction\u2013eachsoftware\nlayer (some may be in firmware) builds an incrementally more abstract data representation\nthat is only dependent on the interface provided by the layer immediately below it. Accord-\ningly, forensic analysis of storage devices can be performed at several levels of abstraction\n[956]:\nPHYSICALMEDIA.Atthelowestlevel,everystoragedeviceencodesasequenceofbitsanditis\npossible,inprinciple,touseacustommechanismtoextractthedatabitbybit.Dependingon\ntheunderlyingtechnology,thiscanbeanexpensiveandtime-consumingprocess,andoften\nrequiresreverseengineering.Oneexampleofthisprocessistheacquisitionofmobilephone\ndata, in some of which it is possible to physically remove (desolder) the memory chips and\nperform a true hardware-level acquisition of the content [958]. A similar \u201cchip-off\u201d approach\ncan be applied to a flash memory devices, such as SSD, and to embedded and Internet of\nThings (IoT) devices with limited capabilities and interfaces. Another practical approach is\ntoemployengineeringtoolsthatsupportthehardwaredevelopmentprocessandemploy,for\nexample,astandardJTAG interface[959]\u2013 designedfortestingand debuggingpurposes\u2013\ntoperformthenecessarydataacquisition.\nIn practice, the lowest level at which typical examinations are performed is the Host Bus\nAdapter (HBA) interface. Adapters implement a standard protocol (SATA, SCSI) through\nwhich they can be made to perform low-level operations, such as accessing the drive\u2019s con-\ntent. Similarly, the NVMe protocol [960] is used to perform acquisition from PCI Express-\nbasedsolid-statestoragedevices.\nAll physical media eventually fail and (part of) the stored data may become unavailable. De-\npending on the nature of the failure, and the sophistication of the device, it may be possible\nto recover at least some of the data. For example, it may be possible to replace the failed\ncontrollerofaHDDandrecoverthecontent.Suchhardwarerecoverybecomesmoredifficult\nwithmoreintegratedandcomplexdevices.\nBLOCK DEVICE. The typical HBA presents a block device abstraction \u2013 the medium is pre-\nsented as a sequence of fixed-size blocks, commonly consisting of 512 or 4096 bytes, and\nthecontentsofeachblockcanbereadorwrittenusingblockread\/writecommands.Thetyp-\nicaldataacquisitionprocessworksattheblockdeviceleveltoobtainaworkingcopyofthe\nforensictarget\u2013aprocessknownasimaging\u2013onwhichallfurtherprocessingisperformed.\nHistorically,thetermsectorisusedtorefertothedatatransferunitsofmagneticharddisks;\na (logical) block is a more general term that is independent of the storage technology and\nphysicaldatalayout.\nKAForensics |October2019 Page301 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nFILE SYSTEM. The block device has no notion of files, directories or \u2013 in most cases \u2013 which\nblocksareconsideredallocatedandwhichonesarefree;itisthefilesystem\u2019stasktoorganise\ntheblockstorageintoafile-basedstoreinwhichapplicationscancreatefilesanddirectories\nwith all of their relevant metadata attributes \u2013 name, size, owner, timestamps, access per-\nmissionsetc.\nAPPLICATION ARTIFACTS. User applications use the filesystem to store various artifacts that\nareofvaluetotheend-user\u2013documents,images,messagesetc.Theoperatingsystemitself\nalsousesthefilesystemtostoreitsownimage\u2013executablebinaries,libraries,configuration\nandlogfiles,registryentries\u2013andtoinstallapplications.Someapplicationartifactssuchas\ncompounddocumentshaveacomplexinternalstructureintegratingmultipleartifactsofdif-\nferenttypes.Ananalysisofapplicationartifactstendstoyieldthemostimmediatelyrelevant\nresults,astherecordedinformationmostdirectlyrelatestoactionsandcommunicationsini-\ntiated by people. As the analysis goes deeper (to a lower level of abstraction), it requires\ngreater effort and more expert knowledge to independently reconstruct the actions of the\nsystem.Forexample,byunderstandingtheon-diskstructuresofaspecificfilesystem,atool\ncan reconstitute a file out of its constituent blocks. This knowledge is particularly costly to\nobtainfromaclosedsystemsuchasMicrosoftWindows,becauseofthesubstantialamount\nofblackboxreverseengineeringinvolved.\nDespite the cost, independent forensic reconstruction is of critical importance for several\nreasons:\n\u2022 Itenablestherecoveryofevidentiarydatanotavailablethroughthenormaldataaccess\ninterface.\n\u2022 Itformsthebasisforrecoveringpartiallyoverwrittendata.\n\u2022 It allows the discovery and analysis of malware agents that have subverted the nor-\nmalfunctioningof thesystem,thusmakingthe dataobtainedviatheregularinterface\nuntrustworthy.\n9.2.2 Data Acquisition\nIn line with best practices [940], analysing data at rest is not carried out on a live system.\nThetargetmachineispowereddown,anexactbit-wisecopyofthestoragemediaiscreated,\ntheoriginalisstoredinanevidencelockerandalltheforensicworkisperformedonthecopy.\nThereareexceptionstothisworkflowincaseswhereitisnotpracticaltoshutdownthetarget\nsystemand,therefore,amediaimageisobtainedwhilethesystemislive.Evidently,suchan\napproach does not provide the same level of consistency guarantees, but it can still yield\nvaluable insights. The problem of consistency, also referred to as data smearing, does not\nexistinvirtualisedenvironments,whereaconsistentimageofthevirtualdiskcanbetrivially\nobtainedbyusingthebuilt-insnapshotmechanism.\nAs already discussed, obtaining data from the lowest level system interface available and\nindependentlyreconstructinghigher-levelartifactsisconsideredthemostreliableapproach\nto forensic analysis. This results in a strong preference for acquiring data at lower levels of\nabstractionandtheconceptsofphysicalandlogicalacquisition.\nPhysical data acquisition is the process of obtaining the data directly from hardware\nmedia,withoutthemediationofany(untrusted)third-partysoftware.\nKAForensics |October2019 Page302 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nAnincreasinglycommonexampleofthisapproachismobilephonedataacquisitionthatre-\nlies on removing the physical memory chip[958] and reading the data directly from it. More\ngenerally, getting physical with the evidence source is usually the most practical and nec-\nessary method for low-end embedded systems with limited hardware capabilities. Physical\nacquisition also affords access to additional over-provisioned raw storage set aside by the\nstoragedeviceinordertocompensatefortheexpectedhardwarefailures.Asageneralrule,\ndevicesoffernoexternalmeanstointerrogatethisshadowstoragearea.\nChip-offtechniquespresenttheirownchallengesinthattheprocessisinherentlydestructive\ntothedevice,thedataextractionandreconstructionrequiresadditionaleffort,andtheoverall\ncostcanbesubstantial.\nForgeneral-purposesystems,toolsuseanHBAprotocolsuchasSATAorSCSItointerrogate\nthe storage device and obtain a copy of the data. The resulting image is a block-level copy\nofthetargetthatisgenerallyreferredtoasphysicalacquisitionbymostinvestigators;Casey\nuses the more accurate term pseudo-physical to account for the fact that not every area of\nthephysicalmediaisacquiredandthattheorderoftheacquiredblocksdoesnotnecessarily\nreflectthephysicallayoutofthedevice.\nIn some cases, it is necessary to perform additional recovery operations before a usable\ncopy of the data is obtained. One common example is RAID storage devices, which contain\nmultiplephysicaldevicesthatfunctiontogether asasingleunit,providingbuilt-inprotection\nagainstcertainclassesoffailures.IncommonconfigurationssuchasRAID5and6thecon-\ntent acquisition of individual drives is largely useless without the subsequent step of RAID\ndatareconstruction.\nModernstoragecontrollersarequicklyevolvingintoautonomousstoragedevices,whichim-\nplement complex (proprietary) wear-levelling and load-balancing algorithms. This has two\nmajor implications: a) the numbering of the data blocks is completely separated from the\nactualphysicallocation;andb)itispossibleforthestoragecontrolleritselftobecomecom-\npromised[961],thusrenderingtheacquisitionprocessuntrustworthy.Thesecaveatsnotwith-\nstanding, we will refer to block-level acquisition as being physical, in line with the accepted\nterminology.\nLogical data acquisition relies on one or more software layers as intermediaries to ac-\nquirethedatafromthestoragedevice.\nInotherwords,thetoolusesanApplicationProgramingInterface(API),ormessageprotocol,\ntoperformthetask.Theintegrityofthismethodhingesonthecorrectnessandintegrityofthe\nimplementationoftheAPI,orprotocol.Inadditiontotherisk,however,thereisalsoareward\u2013\nhigherlevelinterfacespresentadataviewthatiscloserinabstractiontothatofuseractions\nandapplicationdatastructures.Experiencedinvestigators,ifequippedwiththepropertools,\ncan make use of both physical and logical views to obtain and verify the evidence relevant\ntothecase.\nBlock-levelacquisitioncanbeaccomplishedinsoftware,hardwareoracombinationofboth.\nThe workhorse of forensic imaging is the dd Unix\/Linux general purpose command-line util-\nity, which can produce a binary copy of any file, device partition or entire storage device. A\nhardware write blocker is often installed on the target device to eliminate the possibility of\noperatorerror,whichcanleadtotheaccidentalmodificationofthetarget.\nCryptographichashesarecomputedfortheentireimageand(preferably)foreveryblock;the\nKAForensics |October2019 Page303 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nlattercanbeusedtodemonstratetheintegrityoftheremainingevidenceiftheoriginaldevice\nsuffers a partial failure, which makes it impossible to read its entire contents. The National\nInstituteofStandardsandTechnology(NIST)maintainstheComputerForensicToolTesting\n(CFTT) project [962], which independently tests various basic tools, such as write blockers\nandimageacquisitiontoolsandregularlypublishesreportsonitsfindings.\nEncryption Concerns\nApart from having the technical capability to safely interrogate and acquire the content of\na storage device, one of the biggest concerns during data acquisition can be the presence\nof encrypted data. Modern encryption is pervasive and is increasingly applied by default to\nboth stored data and data in transit over the network. By definition, a properly implemented\nand administered data security system, which inevitably employs encryption, will frustrate\neffortstoacquiretheprotecteddataand,byextension,toperformforensicanalysis.\nTherearetwopossiblepathstoobtainingencrypteddata\u2013technicalandlegal.Thetechnical\napproachreliesonfindingalgorithmic,implementation,oradministrativeerrors,whichallow\nthe data protection to be subverted. Although it is nearly impossible to create a complex IT\nsystem that has no bugs, the discovery and exploitation of such deficiencies is becoming\nincreasinglymoredifficultandresourceintensive.\nThelegalapproachreliesoncompellingthepersonwithknowledgeoftherelevantencryption\nkeys to surrender them. This is relatively new legal territory and its treatment varies across\njurisdictions.IntheUK,theRegulationofInvestigatoryPowersAct2000specifiesthecircum-\nstancesunderwhichindividualsarelegallyrequiredtodisclosethekeys.Disclosuremayrun\ncounter the legal right against self-incrimination and in some jurisdictions, such as in the\nUnitedStates,itisnotyetdefinitivelyresolved.\nThe remainder of this discussion assumes that access to the raw data is ensured by either\ntechnical,orlegalmeans,whicharebeyondthescopeofthisknowledgearea.\n9.2.3 Filesystem Analysis\nA typical storage device presents a block device interface with B number of blocks of\nmax\nsize B . All read and write I\/O operations are executed at the granularity of a whole block;\nsize\nhistorically,thestandardblocksizeadoptedbyHDDmanufacturershasbeen512bytes.With\nthe 2011 introduction of the Advanced Format standard [963], storage devices can support\nlargerblocks,with4,096bytesbeingthenewpreferredsize.\nRegardless of the base block size, many operating systems manage storage in clusters; a\ncluster is a contiguous sequence of blocks and is the smallest unit at which raw storage is\nallocated\/reclaimed.Thus,ifthedeviceblock\/sectorsizeis4KiBbutthechosenclustersize\nis16KiB,theOSwillallocateblocksingroupsoffour.\nFor administration purposes, the raw drive may be split into one or more contiguous areas\ncalledpartitions,eachofwhichhasadesignateduseandcanbeindependentlymanipulated.\nPartitions can further be organised into volumes \u2013 a physical volume maps onto a single\npartition,whereasalogicalvolumecanintegratemultiplepartitionspotentiallyfrommultiple\ndevices.Volumespresentablockdeviceinterfacebutallowforthedecouplingofthephysical\nmediaorganisationfromthelogicalviewpresentedtotheoperatingsystem.\nWith a few exceptions, volumes\/partitions are formatted to accommodate a particular file\nKAForensics |October2019 Page304 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nsystem (filesystem), which organizes and manages the blocks to create the abstraction of\nfilesanddirectoriestogetherwiththeirrelevantmetadata.TheOperatingSystem(OS),aspart\nofitssystemcallinterfaceusedbyapplicationstorequestservices,providesafilesystemAPI\nthat allows applications to create, modify and delete files; it also allows files to be grouped\nintoahierarchicalstructureofdirectories(orfolders).\nAfileisanamed(opaque)sequenceofbytesthatisstoredpersistently.\nAs a general rule, the format and interpretation of file content is almost always outside the\npurview of the operating system; it is the concern of relevant applications acting on behalf\nofusers.\nA file system (filesystem) is an OS subsystem that is responsible for the persistent stor-\nageandorganisationofuserandsystemfilesonapartition\/volume.\nItprovidesahigh-levelstandardAPIsuchasPOSIX,thatisusedbyapplicationstostoreand\nretrievefilesbynamewithoutanyconcernforthephysicalstoragemethodemployedorthe\nlayoutofthedata(andmetadata)content.\nFilesystemforensicsusesknowledgeofthefilesystem\u2019sdatastructuresandthealgorithms\nused to create, maintain, and delete them to: a) extract data content from devices indepen-\ndently of the operating system instance which created it; and b) extract leftover artifacts to\nwhichtheregularfilesystemAPIdoesnotofferaccess.\nThefirstfeatureisimportanttoensurethatthedataarenotbeingmodifiedduringacquisition\nand that any potential security compromises do not affect the validity of the data. The sec-\nondprovidesaccessto(partsof)deallocatedfilesthathavenotbeenoverwritten,purposely\nhiddendata,andanimpliedhistoryofthefilesystemoperation\u2013thecreation\/deletionoffiles\n\u2013thatisnotexplicitlymaintainedbytheOS.\n9.2.4 Block Device Analysis\nBeforetheOScanorganiseafilesystemonarawdevice,ittypicallysplitsitintoasetofone\normoredisjointpartitions.\nA block device partition, or physical volume, is a contiguous allocation of blocks for a\nspecificpurpose,suchastheorganisationofafilesystem.\nPartitions are the basic method used for coarse-grained storage management; they allow a\nsinglephysicaldevicetobededicatedtomultiplepurposessuchashostingdifferentfilesys-\ntems or separating system from user files. If a subdivision is not needed, the entire device\ncanbetriviallyallocatedtoasinglepartition.\nAlogicalvolumeisacollectionofphysicalvolumespresentedandmanagedasasingle\nunit.\nLogicalvolumesallowstoragecapacityfromdifferentdevicestobepooledtransparently(to\nthe filesystem) to simplify the use of available capacity. They also enable automated block-\nlevelreplicationintheformofRAIDs[964]forenhancedperformanceanddurability.\nKAForensics |October2019 Page305 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n9.2.5 Data Recovery & File Content Carving\nOne of the early staples of data recovery tools was the \u2018undelete\u2019 functionality, which can\nreverse the effects of users deleting data. The most common case is that of users deleting\na file and needing to reverse the operation. On a HDD, this reversal is readily achievable im-\nmediatelyafterthedeletion-thestoragetakenupbythefile\u2019scontentismerelydeallocated\n(markedasavailable),butnoactualdestruction(sanitisation)ofthedatatakesplace.\nA more difficult case is a HDD that has been in use for some time and that has been subse-\nquently formatted (e.g., by somebody attempting to destroy evidence). The often employed\nquickformatcommandhastheeffectofoverlayingasetofdatastructuresthatcorrespond\ntoanemptyfilesystem(afullformatsanitizesthecontentofthemediabutcantakehoursto\ncompletesoitisusedlessfrequently).Thus,thenormalfilesysteminterface,afterquerying\nthesestructures,willreportthattherearenofiles.Therealityisthat\u2013atthatmoment\u2013only\nfilesystem metadata has been partially overwritten, and all the data blocks representing the\nfilecontentarestillpresentonthemediainfull.\nForensiccomputing,unlikemostothertypesofcomputation,isveryinterestedinallrecover-\nable(partial)artifacts,including(andsometimesespecially)deallocatedones.Unlessauser\nhas taken special measures to securely wipe a hard disk, at any given time the media con-\ntainsrecoverableapplicationartifacts(files)thathaveostensiblybeendeleted.Theprocess\nofrestoringtheartifactsiscommonlyaccomplishedbycarving.\nFile(content)carvingistheprocessofrecoveringandreconstructingfilecontentdirectly\nfrom block storage without using the filesystem metadata. More generally, data (struc-\nture)carvingistheprocessofreconstructinglogicalobjects(suchasfilesanddatabase\nrecords) from a bulk data capture (disk\/RAM image) without using metadata that de-\nscribesthelocationandlayoutoftheartifacts.\nFile carving is the oldest and most commonly used, technique and its basic form is based\nontwosimpleobservations:a)mostfileformatshavespecificbeginningandendtags(a.k.a.\nheader and footer); and b) file systems strongly favour a sequential file layout to maximise\nthroughput.\nPut together, these yield a basic recovery algorithm: 1) scan the capture sequentially until a\nknown header is found; for example, JPEG images always start with the (hexadecimal) FF\nD8 FFheader;2)scansequentiallyuntilacorrespondingfooterisfound;FF D9forJPEG;3)\ncopy the data in between as the recovered artifact. Figure 9.2 illustrates some of the most\ncommoncasesencounteredduringfilecarving:\n1. No fragmentation is the most typical case, as modern filesystems require extra effort\ntoensuresequentiallayoutforoptimalperformance.\n2. Nestedcontentisoftentheresultofdeletion;intheexample,aftertheinitialsequential\nback-to-back layout of the files, the content ahead and behind file B was deleted and\nreplaced by A. In some cases, the file format allows nesting; e.g., JPEGs commonly\nhaveathumbnailversionoftheimage,whichisalsoinJPEGformat.Thiscasecanbe\nsolvedbymakingmultiplepasses\u2013onceB iscarvedout(anditsblocksremovedfrom\nfurtherconsideration)thecontentofAbecomescontiguous,soasubsequentpasswill\nreadilyextractit.\n3. Bi-fragmented files are split into two contiguous pieces with the other content in be-\nKAForensics |October2019 Page306 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n\u2026 A A A A A \u2026 B B B \u2026\n1 2 3 4 5 1 2 3\na) Contiguous file content\n\u2026 A A A B B B A A \u2026\n1 2 3 1 2 3 4 5\nheader\nb) Nested file content\nfooter\n\u2026 A A A A A \u2026\n1 2 3 4 5\nc) Bifragmented file\n\u2026 A A A B B A A B \u2026\n1 2 3 1 2 4 5 3\nd) Interleaved file content\nFigure9.2:Commonfilecontentlayoutencounteredduringcarving.\ntween, which also determines how difficult the reconstruction is; if the content in the\nmiddle is easily distinguished from the content of the file (e.g., the pieces of text in\nthemiddleofacompressedimage)thentheproblemisrelativelyeasy.Otherwise,itis\nambiguousanditcouldbequitedifficulttoidentifythematchingpieces.\n4. Interleaved content is a more complicated version of nesting which happens when\nlargerfilesareusedtofillthegapscreatedbythedeletionofsmallerones.\nThissimplecarvingapproachusuallyyieldsagoodnumberofusableartifacts;however,real\ndatacancontainanumberofatypicalpatterns,whichcanleadtoalargenumberofrepetitive\nand\/or false positive results. One major reason is that file formats are not designed with\ncarvinginmindandrarelyhaverobustinternalmetadatathatconnecttheconstituentpieces\ntogether. Some do not even have a designated header and\/or footer, and this can result in a\nlarge number of false positives, potentially producing results substantially larger in volume\nthanthesourcedata.\nSlackspacerecovery.BothRAMandpersistentstoragearealmostalwaysallocatedinmulti-\nplesofachosenminimumallocationunits.Therefore,attheendoftheallocatedspace,there\nis storage capacity \u2013 slack space \u2013 that is not used by the application, but is also not avail-\nableforotheruses.Forexample,iftheminimumallocationis4KiB,andafileneeds14KiB,the\nfilesystem will allocate four 4KiB blocks. The application will fully use the first three blocks,\nbutwillonlyuse2KiBfromthelastblock.Thiscreatesthepotentialtostoredatathatwould\nbeinaccessibleviathestandardfilesysteminterfaceandcanprovideasimplemeanstohide\ndata.\nSlackspaceisthedifferencebetweentheallocatedstorageforadataobject,suchasfile,\noravolume,andthestorageinactualuse.\nKAForensics |October2019 Page307 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nOnce aware of the potential for storing hidden data in slack space, it is relatively easy to\nidentifyandexamineit,andthisisastandardstepinmostinvestigations.\nUpcoming challenges. As solid state drives continue to grow in capacity and displace hard\ndisksfromanincreasingproportionofoperationaldatastorage,filecarving\u2019sutilityissetto\ndiminish over time. The reason lies in the fact that SSD blocks need to be written twice in\norder to be reused (the first write resets the state of the block, thereby enabling its reuse).\nToimproveperformance,theTRIMandUNMAPcommandswereaddedtotheATAandSCSI\ncommand sets, respectively; they provide a mechanism for the filesystem to indicate to the\nstoragedevicewhichblocksneedtobegarbagecollectedandpreparedforreuse.\nKing & Vidas [965] established experimentally that file carving would only work in a narrow\nsetofcircumstancesonmodernSolidStateDrives(SSDs).Specifically,theyshowthatfora\nTRIM-aware operating system, such as Windows 7 and after, the data recovery rates in their\ntestswerealmostuniversallyzero.Incontrast,usingapre-TRIMOS(WindowsXP)allowsfor\nnear-perfectrecoveryratesunderthesameexperimentalconditions.\n9.3 MAIN MEMORY FORENSICS\n[966]\nTheearlyviewofbestforensicpracticeswastoliterallypulltheplugonamachinethatwas\nto be impounded. The rationale was that this would remove any possibility of alerting the\nprocesses running on the host and would preempt any attempts to hide information. Over\ntime, experience has shown that these concerns were largely exaggerated and that the sub-\nstantial and irreversible loss of important forensic information such as open connections\nand encryption keys was rarely justified. Studies have clearly demonstrated that data tend\nto persist for a long time in volatile memory ([967], [968]). There is a wealth of information\naboutasystem\u2019srun-timestatethatcanbereadilyextracted,evenfromasnapshot[966]:\nProcess information. It is practical to identify and enumerate all the running processes,\nthreads and loaded systems modules; we can obtain a copy of the individual processes\u2019\ncode, stack, heap, code, and data segments. All this is particularly useful when analysing\ncompromisedmachines,asitallowstheidentificationofsuspiciousservices,abnormalpar-\nent\/child relationships, and, more generally, to search for known symptoms of compromise,\norpatternsofattack.\nFileinformation.Itispracticalforidentifyinganyopenfiles,sharedlibraries,sharedmemory,\nandanonymouslymappedmemory.Thisisparticularlyusefulforidentifyingcorrelateduser\nactionsandfilesystemactivities,potentiallydemonstratinguserintent.\nNetworkconnections.Itispracticalforidentifyingopenandrecentlyclosednetworkconnec-\ntionsandprotocolinformation,aswellassendingandreceivingqueuesofdatanotyetsent\nor delivered, respectively. This information could readily be used to identify related parties\nandcommunicationpatternsbetweenthem.\nArtifactsandfragments. Just like the filesystem, the memory management system tends to\nbe reactive and leaves a lot of artifact traces behind. This is primarily an effort to avoid any\nprocessing that is not absolutely necessary for the functioning of the system; caching disk\nandnetworkdatatendstoleavetracesinmemoryforalongtime.\nMemory analysis can be performed either in real time on a live (running) system, or it could\nKAForensics |October2019 Page308 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nbeperformedonasnapshot(memorydump)ofthestateofthesystem.Inadditiontousing\nspecializedmemoryacquisitionstools,orabuild-insnapshotmechanism(invirtualizedenvi-\nronments)memorycontentcanalsobeobtainedfromasystemhibernationfile,pageswap,\noracrashdump.\nIn live forensics, a trusted agent (process) designed to allow remote access over a secure\nchannel is pre-installed on the system. The remote operator has full control over the moni-\ntoredsystemandcantakesnapshotsofspecificprocesses,ortheentiresystem.Liveinves-\ntigations are an extension of regular security preventive mechanisms, which allow for maxi-\nmumcontrolanddataacquisition;theyareprimarilyusedinlargeenterprisedeployments.\nThe main conceptual problem of working on a live system is that, if it is compromised, the\ndataacquisitionandanalysisresultsarenottrustworthy;therefore,forensicanalysisismost\nfrequentlyperformedonasnapshotofthetargetsystem\u2019sRAM.Analysingasnapshotiscon-\nsiderably more difficult than working with a live system, which provides access to the state\nof the running system via a variety of APIs and data structures. In contrast, a raw memory\ncapture offers no such facilities and forensic tools need to rebuild the ability to extract se-\nmanticinformationfromthegroundup.Thisisasemanticgapproblem,andthepurposeof\nmemoryforensicsistobridgeit.\n9.4 APPLICATION FORENSICS\nApplication forensics is the process of establishing a data-centric theory of operation for a\nspecificapplication.Thegoaloftheanalysisistoobjectivelyestablishcausaldependencies\nbetween data input and output, as a function of the user interactions with the application.\nDepending on whether an application is an open or closed source and on the level of the\naccompanying documentation, the analytical effort required can vary from reading detailed\nspecificationstoreverseengineeringcode,datastructuresandcommunicationprotocols,to\nperformingtime-consumingblackboxdifferentialanalysisexperiments.Alternatively,foren-\nsic tool vendors may license code from the application vendor to gain access to the propri-\netarydatastructures.\nThe big advantage of analysing applications is that we have a better chance of observing\nanddocumentingdirectevidenceofuseractions,whichisofprimaryimportancetothelegal\nprocess. Also, the level of abstraction of the relevant forensic traces tend to have a level of\nabstractioncorrespondingtoaparticulardomain.\n9.4.1 Case Study: the Web Browser\nAlthough there are at least four major web browsers in common use, after more than 20\nyearsofdevelopment,theircapabilitieshaveconverged,thusallowingustotalkaboutthem\nincommonterms.Therearesixmainsourcesofforensicallyinterestinginformation:\nURL\/search history. At present, there are no practical barriers to maintaining a complete\nbrowsinghistory(alogofvisitedwebsites),andmakingitavailabletousersisamajorusabil-\nity feature; most users rarely delete this information. Separately, service providers such as\nGoogle and Facebook, are interested in this information for commercial reasons, and make\nit easy to share a browsing log with multiple devices. Combined with the content of the lo-\ncal file cache, the browsing history allows an investigator to almost look over the shoulder\nof the user of interest as they were navigating the Web. In particular, analysing user queries\nto search engines is among the most commonly employed techniques. The search query is\nKAForensics |October2019 Page309 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nencoded as part of the URL, and can often provide very clear and targeted clues as to what\ntheuserwastryingtoaccomplish.\nFormdata.Browsersoffertheconvenienceofrememberingauto-completingpasswordsand\notherformdata(suchasaddressinformation).Thiscanbeveryhelpfultoaninvestigator,es-\npeciallyiftheuserislesssecurityconsciousanddoesnotuseamasterpasswordtoencrypt\nallofthisinformation.\nTemporaryfiles.Thelocalfilecacheprovidesitsownchronologyofwebactivities,includinga\nstoredversionoftheactualwebobjectsthatweredownloadedandshowntotheuser(these\nmaynolongerbeavailableonline).Althoughcachinghasbecomeconsiderablylesseffective\nowing to the increased use of dynamic content, this is tempered by the large increase in\navailablestoragecapacity,whichplacesveryfew,ifany,practicalconstraintsontheamount\nofdatacached.\nDownloaded files are, by default, never deleted providing another valuable source of activity\ninformation.\nHTML5 local storage provides a standard means for web applications to store information\nlocally; for example, this could be used to support disconnected operations, or to provide a\nmeasure of persistence for user input. Accordingly, the same interface can be interrogated\ntoreconstructwebactivities.\nCookies are opaque pieces of data used by servers to keep a variety of information on the\nweb client in order to support transactions such as web mail sessions. In practice, most\ncookies are used by websites to track user behaviour, and it is well-documented that some\nproviders go to great lengths to make sure that this information is resilient. Some cookies\naretime-limitedaccesstokensthatcanprovideaccesstoonlineaccounts(untiltheyexpire);\nothershaveaparsablestructureandmayprovideadditionalinformation.\nMost local information is stored in SQLite databases, which provide a secondary target for\ndata recovery. In particular, ostensibly deleted records may persist until the database is ex-\nplicitly\u2018vacuumed\u2019;otherwise,theyremainrecoverableatalatertime([969,970]).\n9.5 CLOUD FORENSICS\nCloudcomputingisfastemergingastheprimarymodelfordeliveringinformationtechnology\n(IT) services to Internet-connected devices. It brings both disruptive challenges for current\nforensictools,methodsandprocesses,aswellasqualitativelynewforensicopportunities.It\nisnotdifficulttoforeseethat,afteranintermediateperiodofadjustment,digitalforensicswill\nenteranewperiodmarkedbysubstantiallyhigherlevelsofautomationandwillemploymuch\nmoresophisticateddataanalytics.Cloudcomputingenvironmentswillgreatlyfacilitatethis\nprocess,butnotbeforebringingaboutsubstantialchangestocurrentlyestablishedtoolsand\npractices.\nKAForensics |October2019 Page310 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nSoftware Platform Infrastructure\nas a Service (SaaS) as a Service (PaaS) as a Service (IaaS)\nr\nApplication Application e Application\nm\no\ne c iv\nr\nes\nr e d\nRuD na tt ima e\ne\nRuD na tt ima e t s u C RuD na tt ima e r e m o\nt s u\nS d u o lCiv o r P Op VM e ir rai td utd i anl le ig zw aSa ty ir s oe t nem c iv r e S d u o lCs r e d iv o r P Op VM e ir rai td utd i anl le g izw aS ta y isr oe t nem e c iv r e S ds r e d iv\no\nOp VM e ir rai td utd i anl le g izw aS ta y isr oe t nem C\nHardware Hardware u or P Hardware\nlC\nFigure 9.3: Layers of cloud computing environment owned by customer and cloud service\nprovideronthreeservicemodels:IaaS,PaaS,andSaaS(publiccloud).\n9.5.1 Cloud Basics\nConceptually,cloud-basedITabstractsawaythephysicalcomputeandcommunicationinfra-\nstructure, and allows customers to rent as much compute capacity as needed. Cloud sys-\ntems have five essential characteristics: on-demand self service, broad network access, re-\nsourcepooling,rapidelasticity,andmeasuredservice.[141]\nThe cloud is enabled by a number of technological developments, but its adoption is driven\nprimarilybybusinessconsiderations,whichdrivechangestohoworganisationsandindividu-\nalsuseITservices.Accordingly,italsochangeshowsoftwareisdeveloped,maintainedand\ndelivered to its customers. Cloud computing services are commonly classified into one of\nthree canonical models \u2013 Software as a Service (SaaS), Platform as a Service (PaaS) and\nInfrastructureasaService(IaaS).Inactualdeployments,thedistinctionscanbeblurredand\nmanyclouddeployments(andpotentialinvestigativetargets)incorporateelementsofallof\nthese.\nThe differences between the models are best understood when we consider the virtualised\ncomputing environments as a stack of layers: hardware such as storage, and networking;\nvirtualisation, consisting of a hypervisor allowing the installation and lifecycle management\nof virtual machines; operating system, installed on each virtual machine; middleware and\nruntimeenvironment;andapplicationanddata.\nEach of the cloud models splits the responsibility between the client and the Cloud Service\nProvider (CSP) at different levels in the stack (Figure 9.3). In a private (cloud) deployment,\nthe entire stack is hosted by the owner and the overall forensic picture is very similar to the\nproblem of investigating a non-cloud IT target. Data ownership is clear, as is the legal and\nprocedural path to obtain it; indeed, the very use of the term \u2018cloud\u2019 in this situation is not\nparticularlysignificanttoaforensicinquiry.\nInapublicdeployment,theSaaS\/PaaS\/IaaSclassificationbecomesimportant,asitindicates\nthe ownership of data and service responsibilities. Figure 9.3 shows the typical ownership\noflayersbycustomerandserviceprovidersunderdifferentservicemodels.Inhybriddeploy-\nments, layer ownership can be split between the customer and the provider, and\/or across\nmultipleproviders.Further,itcanchangeovertime,as,forexample,thecustomermayhandle\nthebaseloadonprivateinfrastructure,butburstintothepubliccloudtohandlepeakdemand,\norsystemfailures.\nKAForensics |October2019 Page311 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n9.5.2 Forensic Challenges\nThe main technical challenges to established forensic practices can be summarised as fol-\nlows.\nLogical acquisition is the norm. The existing forensic toolset is almost exclusively built to\nwork with the leftover artifacts of prior computations. It relies on algorithmic knowledge of\ndifferent OS subsystems such as the filesystem in order to interpret the physical layout of\nthedataasacquiredfromthedevice.\nPhysical acquisition is almost completely inapplicable to the cloud, where data moves, re-\nsources are shared and ownership and jurisdictional issues can be complicated. Cloud ser-\nviceAPIsareemergingastheprimarynewinterfacethroughwhichdataacquisitionisbeing\nperformed.\nThecloudistheauthoritativedatasource.Anotherimportantreasontoquerycloudservices\nfor relevant information is that they store the primary historical record of computations and\ninteractionswithusers.Mostresidualinformationontheclient,suchasaclouddriveistran-\nsientandoftenofuncertainprovenance.\nLogging is pervasive. Cloud-based software is developed and organised differently. Instead\nofonemonolithicpieceofcode,theapplicationlogicisdecomposedintoseverallayersand\nmodulesthatinteractwitheachotheroverwell-definedserviceinterfaces.Oncethesoftware\ncomponentsandtheircommunicationareformalised,itbecomeseasytoorganiseextensive\nlogging of every aspect of the system. Indeed, it becomes critical to have this information\njusttobeabletodebug,testandmonitorcloudapplicationsandservices.\nThese developments point to logs (of user and system activities) becoming the primary\nsource of forensic information. The immediate implication is that much more will be explic-\nitlyknown\u2013asopposedtodeduced\u2013aboutthehistoricalstateofapplicationsandartifacts.\nThiswillrequireanewsetofdataanalyticstoolsandwillcompletelytransformthewayforen-\nsicinvestigationsareperformed.Itwillalsobringnewchallengesintermsoflong-termcase\ndatapreservation.\nDistributed computations are the norm. The key attribute of the client\/standalone model is\nthatpracticallyallcomputationstakeplaceonthedeviceitself.Applicationsaremonolithic,\nself-contained pieces of code that have immediate access to user input and consume it\ninstantly with (almost) no traces left behind. Since a large part of forensics comprises at-\ntributing the observed state of a system to user-triggered events, forensic research and de-\nvelopment has relentlessly focused on two driving problems \u2013 discovering every last piece\nof log\/timestamp information, and extracting every last bit of discarded data left behind by\napplicationsortheoperatingsystem.\nThecloudmodel,particularlySaaS,completelybreakswiththisapproach\u2013thecomputation\nissplitbetweentheclientandtheserver,withthelatterperformingtheheavycomputational\nlifting and the former performing predominantly user interaction functions. Code and data\nare downloaded on demand and have no persistent place with regard to the client. The di-\nrect consequence is that the vast majority of the established forensic tool chain becomes\nirrelevant,whichpointstoaclearneedforadifferentapproach.\nKAForensics |October2019 Page312 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n9.5.3 SaaS Forensics\nThe software industry\u2019s traditional delivery model is Software as a Product (SaaP); that is,\nsoftware acquired like any physical product and is installed by the owner on a specific ma-\nchine,whereallthecomputationsareperformed.Asaresult,thetraditionalanalyticalmodel\nofdigitalforensicsisphysicaldevice-centric\u2013theinvestigatorworkswithphysicalevidence\ncarriers such as storage media or integrated compute devices (e.g., smartphones). On the\nclient(orstandalone)device,itiseasytoidentifywherethecomputationsareperformedand\nwhere the results\/traces are stored. The new software delivery model \u2013 Software as a Ser-\nvice(SaaS)\u2013issubscription-basedanddidnotstartbecomingpracticaluntilthewidespread\nadoptionoffastbroadbandaccesssometentofifteenyearsago.\nThe cloud renders many device-centric methods \u2014 especially those focused on low-level\nphysicalacquisitionandanalysis\u2014irrelevent.Italsorequiresthedevelopmentofnewtools\nthatcanworkinthenewdeploymentenvironment,wherethecodeexecutionissplitbetween\nthe server and the client devices, the primary storage interface is a service API and the ap-\nplication artifacts are not persistently stored on the device (although local storage may be\nusedasacache).\nCaseStudy:CloudDriveAcquisition.Clouddriveservices,suchasDropbox,GoogleDriveand\nMicrosoftOneDrivearetheSaaSversionofthelocalstoragedevice,whichiscentraltomod-\nern digital forensics. The problem of cloud drive acquisition, a clear first investigative step,\nis a good illustration of the challenges and opportunities offered by SaaS with respect to\nforensics.\nAtfirst,itmayappearthatsimplycopyingalocalreplicaofthedrive\u2019scontentisasimpleand\neffectivesolution.However,thisapproachoffersnoguaranteeswithrespecttotheaccuracy\nandcompletenessoftheacquisition.Specifically,therearethreemajorconcerns:\nPartial replication. The most obvious problem is that there is no guarantee that any of the\nclients attached to an account will have a complete copy of the (cloud) drive\u2019s content. As\ndataaccumulatesonline,itquicklybecomesimpracticaltokeepfullreplicasoneverydevice;\nindeed, it is likely that most users will have no device with a complete copy of the data. Fur-\nthermore,theacquisitiontoolneedsdirectaccesstotheclouddrive\u2019smetadatatoascertain\nits contents; without this information, the acquisition is of an unknown quality, subject to\npotentiallystaleandomitteddata.\nRevisionacquisition.Mostdriveservicesprovidesomeformofrevisionhistory;thelook-back\nperiod varies, but this is a standard feature that users expect, especially in paid services. Al-\nthoughtherearesomeanalogousdatasourcesintraditionalforensics,suchasarchivalver-\nsionsofimportantOSdatastructures,thevolumeandgranularityoftherevisioninformation\nincloudapplicationarequalitativelyandquantitativelydifferent.Revisionsresideinthecloud\nand clients rarely have anything but the most recent version in their cache; a client-side ac-\nquisitionwillclearlymisspriorrevisions,anddoesnotevenhavethemeanstoidentifythese\nomissions.\nCloud-native artifacts. The mass movement towards web-based applications means that\nforensics needs to learn how to deal with a new problem \u2013 digital artifacts that have no\nserialised representation in the local filesystem. For example, Google Docs documents are\nstored locally as a link to the document which can only be edited via a web app. Acquiring\nanopaquelinkwithouttheactualcontentofthedocumenthasminimalforensicutility.Most\nservicesprovidethemeanstoexportthewebappartifactinastandardformatsuchasPDF;\nKAForensics |October2019 Page313 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nhowever,thiscanonlybeaccomplishedbyrequestingdirectlyfromtheservice(manuallyor\nviaanAPI).\nInsummary,bringingthetraditionalclient-sideapproachtodriveacquisitiontobearonSaaS\nacquisition has major conceptual flaws that are beyond remediation; a new approach is\nneeded,onethatobtainsthedatadirectlyfromthecloudservice.\n9.6 ARTIFACT ANALYSIS\n[971,972,973,974,975]\nOnce the external (serialised) representation of a digital artifact such as a text document\nor an image is standardised, it provides a convenient level of abstraction, thus allowing the\ndevelopmentofartifact-centricforensictechniques.\n9.6.1 Finding a Known Data Object: Cryptographic Hashing\nThe lowest common denominator for all digital artifacts is to consider them as a sequence\nofbits\/byteswithouttryingtoparse,orassignanysemanticstothem.Despitethislowlevel\nof abstraction, some crucial problems can be addressed, the most important one being to\nidentifyknowncontent,usuallyfiles.\nCryptographic hashing is the first tool of choice when investigating any case; it provides a\nbasic means of validating data integrity and identifying known artifacts. Recall that a hash\nfunctiontakesanarbitrarystringofbinarydataandproducesanumber,oftenreferredtoas\na digest, within a predefined range. Ideally, given a set of different inputs, the hash function\nwillmapthemontodifferentoutputs.\nHash functions are collision-resistant if it is computationally infeasible to find two different\ninputsforwhichtheoutputisthesame.CryptographichashfunctionssuchasMD5,RIPEMD-\n160, SHA-1, SHA-2 and the current NIST standard SHA-3[971], are designed to be collision-\nresistant and produce large 128- to 512-bit results.1 Since the probability that hashing two\ndifferentdataobjectswillproducethesamedigestbychanceisastronomicallysmall,wecan\nsafely assume that, if two objects have the same crypto digest, then the objects themselves\nareidentical.\nCurrent practice is to apply a crypto hash function either to an entire target (drive, partition\netc.)ortoindividualfiles.Theformerisusedtovalidatetheintegrityoftheforensictargetby\ncomparing before-and-after results at important points in the investigation (e.g., to demon-\nstrate that the integrity of the evidence throughout the chain of custody) whereas the latter\nare used to work with known files. This involves either removing from consideration com-\nmonfilessuchasOSandapplicationinstallationsorpinpointingknownfilesofinterestsuch\nas malware and contraband. The US National Institute of Standards and Technology (NIST)\nmaintainstheNationalSoftwareReferenceLibrary(NSRL)[972],whichcoversthemostcom-\nmon operating system installation and application packages. Other organisations and com-\nmercialvendorsofdigitalforensictoolsprovideadditionalhashsetsofotherknowndata.\nFrom a performance and efficiency perspective, hash-based file filtering is very attractive \u2013\nusinga20-byteSHA-1hash,therepresentationof50millionfilestakesonly1GB.Thismakes\n1Adiscussionontheknownvulnerabilitiesofcryptographichashfunctionsisoutsidethescopeofthistext.\nKAForensics |October2019 Page314 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nit possible to load a reference set of that size in the main memory and filter out, on the fly,\nanyknownfilesinthesetasdataisreadfromaforensictarget.\n9.6.2 Block-Level Analysis\nIn addition to whole files, investigators are often interested in discovering known file rem-\nnants, such as those produced when a file is marked as deleted and subsequently partially\noverwritten.Oneroutinelyusedmethodtoaddressthisproblemistoincreasethegranularity\nof the hashes by splitting the files into fixed-size blocks and storing the hash for each indi-\nvidual block. The block size is commonly set to 4 KiB to match the minimum allocation unit\nusedbymostoperatingsystems\u2019installations.Givenablock-basedreferenceset,aforensic\ntarget(RAMcaptureordiskimage)canbetreatedasasequenceofblocksthatcanberead\nblockbyblock,hashedandcomparedtothereferenceset.\nIn this context, we say that a block is distinct, if the probability that its exact content arises\nby chance more than once is vanishingly small. If we knew for a fact that a specific block\nwas unique and specific to a particular file, then (in terms of evidentiary value) finding it on\na forensic target would be almost the same as finding the entire file from which it was de-\nrived.Inpractice,wecannotdefinitelyknowthedistinctivenessofeverypossibledatablock;\ntherefore,weuseanapproximatingassumptionbasedonempiricaldata:\n\u201cIf a file is known to have been manufactured using some high-entropy process, and if the\nblocksofthatfileareshowntobedistinctthroughoutalargeandrepresentativecorpus,then\nthose blocks can be treated as if they are distinct.\u201d [973] Perhaps the most common trans-\nformation that yields high-entropy data is data compression, which is routinely employed in\nmanycommonfileformats,suchasaudio\/videoandofficedocuments.\nApart from the direct use of blocks as trace evidence for the (past or current) presence of\nknown files, block hashes can be used to improve file carving results by excluding every\nknown blocks before performing the carving process. This can improve results by reducing\ngapsandeliminatingcertainclassesoffalsepositiveresults.\n9.6.3 Approximate Matching\nAnaturalgeneralisationoftheproblemoffindingidenticaldataobjectsistofindsimilarones.\nInthecontextofdigitalforensics,theacceptedumbrellatermforsimilarity-basedtechniques\nis Approximate Matching(AM). As per NIST\u2019s definition, \u2018approximatematching is a generic\ntermdescribinganytechniquedesignedtoidentifysimilaritiesbetweentwodigitalartifacts\u2019.\n[974]\nThisbroadtermencompassesmethodsthatcanworkatdifferentlevelsofabstraction.Atthe\nlowestlevel,artifactscanbetreatedasbitstrings;atthehighestlevels,similaritytechniques\ncould employ, for example, natural language processing and image recognition methods to\nprovidealevelofreasoningthatismuchclosertothatofahumananalyst.Withregardtothe\nwhole spectrum of similarity methods, lower-level ones are more generic and computation-\nally affordable, whereas higher-level ones tend to be more specialised and require consider-\nably more computational resources. Therefore, we would expect a forensic investigation to\ncustomiseitsuseofAMtechniquesbasedonthegoalsoftheanalysisandthetargetdata.\nUseCases.Usingacommoninformationretrievalterminology,itisusefultoconsidertwovari-\nationsofthesimilaritydetectionproblem:resemblanceandcontainment[976].Resemblance\nqueries compare two comparably-sized data objects (peers) and seek to infer how closely\nKAForensics |October2019 Page315 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nrelated they are. Two common forensic applications include: (a) object similarity detection\n\u2013 correlating artifacts that a person would classify as versions of each other; and (b) cross\ncorrelation \u2013 correlating objects that share the same components, such as an embedded\nimage.\nInthecaseofcontainment,wecompareartifactsthathavealargedisparityintermsofsize\nandseektoestablishwhetheralargeronecontains(piecesof)asmallerone.Twocommon\nvariationsareembeddedobjectdetection\u2013establishingwhetherasmallerobject(suchasan\nimage)ispartofalargerone(suchasaPDFdocument),andfragmentdetection-establishing\nwhether a smaller object is a fragment (such as a network packet or disk block) of a bigger\none,suchasafile.\nThe difference between resemblance and containment is case-specific and the same tool\nmay work in both cases. However, it is important for analysts to put the tool results into the\ncorrect context and to understand the performance envelope of the tools they are using in\nordertocorrectlyinterprettheresults.\nDefinitions.Thenotionofsimilarityisspecifictotheparticularcontextinwhichitisused.An\napproximatematchingalgorithmworksbydefiningtwoessentialelements\u2013featuresanda\nsimilarity function. Features are the atomic components derived from the artifacts through\nwhichtheartifactsarecompared.Comparingtwofeaturesyieldsabinaryoutcome\u2013zeroor\none\u2013indicatingwhetherthefeaturematchwassuccessfulornot.Thesetofallthefeatures\ncomputedbyanalgorithmforagivenartifactconstitutesafeatureset.Itcanbeviewedasan\napproximate representation of the original object for the purposes of matching it with other\nobjects.\nThe similarity function maps a pair of feature sets to a similarity range; it is increasingly\nmonotonicwithrespecttothenumberofmatchingfeatures.Thatis,allelsebeingequal,more\nfeaturematchesyieldahighersimilarityscore.\nClasses. It is useful to consider three general classes of approximate matching algorithms.\nBytewisematchingconsiderstheobjectsitcomparestoasequenceofbytes,andmakesno\neffort to parse or interpret them. Consequently, the features extracted from the artifact are\nalso byte sequences, and these methods can be applied to any data blob. The utility of the\nresult depends heavily on the encoding of the data. If small changes to the content of the\nartifact result in small changes to the serialised format (e.g., plain text), then the bytewise\nsimilaritytendstocorrelatewellwithaperson\u2019sperceptionofsimilarity.Conversely,ifasmall\nchangecantriggerlargechangesintheoutput(e.g.,compresseddata),thenthecorrelation\nwouldbesubstantiallyweaker.\nSyntacticmatchingreliesonparsingtheformatofanobject,potentiallyusingthisknowledge\nto split it into a logical set of features. For example, a zip archive or a PDF document could\neasily be split into constituent parts without understanding the underlying semantics. The\nbenefit is that this results in a more accurate solution with more precisely interpretable re-\nsults; the downside is that it is a more specialised solution, requiring additional information\ntoparsedifferentdataformats.\nSemanticmatching(partially)interpretsthedatacontentinordertoderivesemanticfeatures\nforcomparison.Examplesincludeperceptualhashesthatcandetectvisuallysimilarimages,\nandmethodsofinformationretrievalandnaturallanguageprocessingthatcanfindsimilari-\ntiesinthesubjectandcontentoftextdocuments.\nResearchersuseavarietyoftermstonamethedifferentapproximatematchingmethodsthey\nKAForensics |October2019 Page316 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nhavedeveloped:fuzzyhashingandsimilarityhashingrefertobytewiseapproximatematching;\nperceptualhashingandrobusthashingrefertosemanticapproximatematchingtechniques.\nBytewise Approximate Matching algorithms are the most frequently used AM algorithms in\nforensics; they follow an overall pattern of extracting a feature set and generating a similar-\nity digest, followed by a comparison of the digests. A similarity digest (a.k.a., fingerprint or\nsignature) is a (compressed) representation of the feature set of the target artifact. It often\nemploys hashing and other techniques to minimise the footprint of the set and to facilitate\nfastcomparison.\n9.6.4 Cloud-Native Artifacts\nForensic analysis of cloud systems is still in its early stages of development, but it will\nquickly grow in importance. One new and promising area is the analysis of cloud(-native)\nartifacts\u2014data objects that maintain the persistent state of web\/SaaS applications. [975]\nUnlike traditional applications, in which the persistent state takes the form of files in a local\nfile system, web apps download the necessary state on the fly and do not rely on local stor-\nage.Recallthatawebapp\u2019sfunctionalityissplitbetweenserverandclientcomponents,and\nthe two communicate via web APIs. From a forensic perspective, the most interesting API\ncalls involve (complete) state transfer; for example, opening a document or loading a prior\nversion,triggersthetransferofitsfullcontent.Conceptually,thisisanalogoustotheprocess\nofopeningandreadingthecontentofalocalfilebyanapplicationinstalledonadevice.The\nmain difference is that cloud artifacts are internal data structures that, unlike a file, are not\nreadilyavailableforanalysis.\nCloudartifactsoftenhaveacompletelydifferentstructurefromtraditionalsnapshot-centric\nencoding.Forexample,internally,GoogleDocs\u2019documentsarerepresentedasthecomplete\nhistory (log) of every editing action performed on it; given valid credentials, this history is\navailableviaGoogleDocs\u2019internalAPI.Itisalsopossibletoobtainasnapshotoftheartifact\nofinterestinastandardformatsuchasaPDF,viathepublicAPI.However,thisisinherently\nforensically deficient in that it ignores potentially critical information on the evolution of a\ndocumentovertime.\n9.7 CONCLUSION\nDigital forensics identifies and reconstructs the relevant sequence of events that has led\nto a currently observable state of a target IT system or (digital) artifacts. The provenance\nand integrity of the data source and the scientific grounding of the investigative tools and\nmethods employed are of primary importance in determining their admissibility to a court\nof law\u2019s proceedings. Digital forensic analysis is applied to both individual digital artifacts\nsuch as files and to complex IT systems comprising multiple components and networked\nprocesses.\nFollowing the rapid cloud-based transition from Software as a Product (SaaP) to Software\nas a Service (SaaS), forensic methods and tools are also in a respective process of transi-\ntion.Oneaspectisachangeofemphasisfromstate-centricanalysis,whichseekstodeduce\neventsandactionsbylookingatdifferentsnapshotsandapplyingknowledgeaboutthesys-\ntem\u2019s operations, to log-centric analysis, which employs explicitly collected log entries to\ninfer the sequence of relevant (to the inquiry) events. Another aspect is the transition from\nthe low-level physical acquisition of storage device images to the high-level logical acquisi-\nKAForensics |October2019 Page317 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntionof(primarily)applicationartifactsviawell-definedcloudserviceAPIs.Someofthemost\nimportant emerging questions in digital forensics are the analysis of the large variety of IoT\ndevices,whichareforecasttoincreaseinnumbertoasmanyas125billionby2030,andthe\nemploymentofmachinelearning\/AIinordertoautomateandscaleupforensicprocessing.\nCROSS-REFERENCE OF TOPICS VS REFERENCE MATERIAL\nTopics Cites\n9.1DefinitionsandConceptualModels [936,937,938,939,940]\n9.2OperatingSystemAnalysis [940,955,956]\n9.3MainMemoryForensics [966]\n9.4ApplicationForensics\n9.5CloudForensics\n9.6ArtifactAnalysis [971,972,973,974,975]\nKAForensics |October2019 Page318 III Systems Security\n319  Chapter 10\nCryptography\nNigel Smart KU Leuven\n321 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nINTRODUCTION\nThe purpose of this chapter is to explain the various aspects of cryptography which we feel\nshould be known to an expert in cyber-security. The presentation is at a level needed for an\ninstructor in a module in cryptography; so they can select the depth needed in each topic.\nWhilstnotallexpertsincyber-securityneedbeawareofallthetechnicalaspectsmentioned\nbelow, we feel they should be aware of all the overall topics and have an intuitive grasp as\nto what they mean, and what services they can provide. Our focus is mainly on primitives,\nschemes and protocols which are widely used, or which are suitably well studied that they\ncouldbeused(orarecurrentlybeingused)inspecificapplicationdomains.\nCryptography by its very nature is one of the more mathematical aspects of cyber-security;\nthus this chapter contains a lot more mathematics than one has in some of the other chap-\nters.Theoverallpresentationassumesabasicknowledgeofeitherfirst-yearundergraduate\nmathematics,orthatfoundinadiscretemathematicscourseofanundergraduateComputer\nSciencedegree.\nThe chapter is structured as follows: After a quick recap on some basic mathematical nota-\ntion(Section10.1),wethengiveanintroductiontohowsecurityisdefinedinmoderncryptog-\nraphy. This section (Section 10.2) forms the basis of our discussions in the other sections.\nSection 10.3 discusses information theoretic constructions, in particular the one-time pad,\nand secret sharing. Sections 10.4 and 10.5 then detail modern symmetric cryptography; by\ndiscussingprimitives(suchasblockcipherconstructions)andthenspecificschemes(such\nas modes-of-operation). Then in Sections 10.6 and 10.7 we discuss the standard method-\nologiesforperformingpublickeyencryptionandpublickeysignatures,respectively.Thenin\nSection 10.8 we discuss how these basic schemes are used in various standard protocols;\nsuchasforauthenticationandkeyagreement.Allofthesections,uptoandincludingSection\n10.8,focusexclusivelyonconstructionswhichhavewidespreaddeployment.\nSection10.9beginsourtreatmentofconstructionsandprotocolswhicharelesswidelyused;\nbutwhichdohaveanumberofnicheapplications.Thesesectionsareincludedtoenablethe\ninstructor to prepare students for the wider applications of the cryptography that they may\nencounterasnicheapplicationsbecomemoremainstream.Inparticular,Section10.9covers\nObliviousTransfer,Zero-Knowledge,andMulti-PartyComputation.Section10.10coverspub-\nlickeyschemeswithspecialproperties,suchasgroupsignatures,identity-basedencryption\nandhomomorphicencryption.\nThe chapter assumes the reader wants to use cryptographic constructs in order to build se-\ncure systems, it is not meant to introduce the reader to attack techniques on cryptographic\nprimitives.Indeed,allprimitivesherecanbeassumedtohavebeenselectedtoavoidspecific\nattack vectors, or key lengths chosen to avoid them. Further details on this can be found in\ntheregularEuropeanKeySizeandAlgorithmsreport,ofwhichthemostuptodateversionis\n[977].\nForasimilarreasonwedonotincludeadiscussionofhistoricalaspectsofcryptography,or\nhistorical ciphers such as Caesar, Vigen\u00e8re or Enigma. These are at best toy examples, and\nsohavenoplaceinasuchabodyofknowledge.Theyarebestlefttopuzzlebooks.However\ntheinterestedreaderisreferredto[978].\nKACryptography |October2019 Page322 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nCONTENT\n10.1 MATHEMATICS\n[979,c8\u2013c9,AppB][980,c1\u2013c5]\nCryptography is inherently mathematical in nature, the reader is therefore going to be as-\nsumedtobefamiliarwithanumberofconcepts.Agoodtextbooktocoverthebasicsneeded,\nandmore,isthatofGalbraith[981].\nBeforeproceeding wewillset upsomenotation: Theringof integersisdenoted byZ,whilst\nthe fields of rational, real and complex numbers are denoted by Q, R and C. The ring of in-\ntegers modulo N will be denoted by Z\/NZ, when N is a prime p this is a finite field often\ndenotedbyF .Thesetofinvertibleelementswillbewritten(Z\/NZ)\u2217 orF\u2217.AnRSAmodulus\np p\nN willdenoteanintegerN,whichistheproductoftwo(large)primefactorsN = p\u00b7q.\nFinite abelian groups of prime order q are also a basic construct. These are either written\nmultiplicatively, in which case an element is written as gx for some x \u2208 Z\/qZ; when written\nadditivelyanelementcanbewrittenas[x]\u00b7P.Theelementg (inthemultiplicativecase)and\nP (intheadditivecase)iscalledthegenerator.\nThestandardexampleoffiniteabeliangroupsofprimeorderusedincryptographyareelliptic\ncurves. An elliptic curve over a finite field F is the set of solutions (X,Y) to an equation of\np\ntheform\nE : Y2 = X3 +A\u00b7X +B\nwhere A and B are fixed constants. Such a set of solutions, plus a special point at infinity\ndenoted by O, form a finite abelian group denoted by E(F ). The group law is a classic law\np\ndating back to Newton and Fermat called the chord-tangent process. When A and B are\nselected carefully one can ensure that the size of E(F ) is a prime q. This will be important\np\nlaterinSection10.2.3toensurethediscretelogarithmproblemintheellipticcurveishard.\nSomecryptographicschemesmakeuseoflatticeswhicharediscretesubgroupsofthesub-\ngroups of Rn. A lattice can be defined by a generating matrix B \u2208 Rn\u00b7m, where each column\nof B forms a basis element. The lattice is then the set of elements of the form y = B \u00b7 x\nwherexrangesoverallelementsinZm.Sincealatticeisdiscreteithasawell-definedlength\noftheshortestnon-zerovector.InSection10.2.3wenotethatfindingthisshortestnon-zero\nvectorisahardcomputationalproblem.\nSampling a uniformly random element from a set A will be denoted by x \u2190 A. If the set A\nconsists of a single element a we will write this as the assignment x \u2190 a; with the equality\nsymbol = being reserved for equalities as opposed to assignments. If A is a randomized\nalgorithm, then we write x \u2190 A(y;r) for the assignment to x of the output of running A on\ninputy withrandomcoinsr.\nKACryptography |October2019 Page323 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n10.2 CRYPTOGRAPHIC SECURITY MODELS\n[979,c1\u2013c4][980,c11]\nModerncryptographyhasadoptedamethodologyof\u2018ProvableSecurity\u2019todefineandunder-\nstand the security of cryptographic constructions. The basic design procedure is to define\nthesyntaxforacryptographicscheme.Thisgivestheinputandoutputbehavioursofthealgo-\nrithms making up the scheme and defines correctness. Then a security model is presented\nwhich defines what security goals are expected of the given scheme. Then, given a specific\ninstantiation which meets the given syntax, a formal security proof for the instantiation is\ngivenrelativetosomeknownhardproblems.\nThesecurityproofisnotanabsoluteguaranteeofsecurity.Itisaproofthatthegiveninstan-\ntiation,whenimplementedcorrectly,satisfiesthegivensecuritymodelassumingsomehard\nproblemsareindeedhard.Thus,ifanattackercanperformoperationswhichareoutsidethe\nmodel, or manages to break the underlying hard problem, then the proof is worthless. How-\never,asecurityproof,withrespecttowellstudiedmodelsandhardproblems,cangivestrong\nguaranteesthatthegivenconstructionhasnofundamentalweaknesses.\nIn the next subsections we shall go into these ideas in more detail, and then give some ex-\namples of security statements; further details of the syntax and security definitions can be\nfound in [982, 983]. At a high level the reason for these definitions is that the intuitive no-\ntion of a cryptographic construction being secure is not sufficient enough. For example the\nnatural definition for encryption security is that an attacker should be unable to recover the\ndecryption key, or the attacker should be unable to recover a message encrypted under one\nciphertext. Whilst these ideas are necessary for any secure scheme they are not sufficient.\nWe need to protect against an attacker aims for find some information about an encrypted\nmessage,whentheattackerisabletomountchosenplaintextandchosenciphertextattacks\nonalegitimateuser.\n10.2.1 Syntax of Basic Schemes\nThe syntax of a cryptographic scheme is defined by the algorithms which make up the\nscheme,aswellasacorrectnessdefinition.Thecorrectnessdefinitiongiveswhatbehaviour\nonecanexpectwhenthereisnoadversarialbehaviour.Forexample,asymmetricencryption\nscheme is defined by three algorithms (KeyGen,Enc,Dec). The KeyGen algorithm is a proba-\nbilistic algorithm which outputs a symmetric key k \u2190 KeyGen(); Enc is a probabilistic algo-\nrithm which takes a message m \u2208 M, some randomness r \u2208 R and a key and returns a\nciphertext c \u2190 Enc(m,k;r) \u2208 C; whilst Dec is (usually) a deterministic algorithm which takes\naciphertextandakeyandreturnstheunderlyingplaintext.Thecorrectnessdefinitionis:\n\u2200k \u2190 KeyGen(),r \u2190 R,m \u2190 M, Dec(Enc(m,k;r),k) = m.\nFor public key encryption schemes the definitions are similar, but now KeyGen() outputs key\npairsandthecorrectnessdefinitionbecomes:\n\u2200(pk,sk) \u2190 KeyGen(),r \u2190 R,m \u2190 M, Dec(Enc(m,pk;r),sk) = m.\nThe equivalent constructions for authentication mechanisms are Message Authentication\nCodes (or MACs) in the symmetric key setting, and digital signatures schemes in the public\nkey setting. A MAC scheme is given by a triple of algorithms (KeyGen,MAC,Verify), where\nthe MAC function outputs a tag given a message and a key (and possibly some random\nKACryptography |October2019 Page324 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ncoins), and the Verify function checks the message, tag and key are consistent. A signature\nschemeisgivenbyasimilartriple(KeyGen,Sign,Verify),wherenowthetagproducediscalled\na\u2018signature\u2019.Thusthecorrectnessdefinitionsfortheseconstructionsareasfollows\nk \u2190 KeyGen(),r \u2190 R,m \u2190 M, Verify(m,MAC(m,k;r),k) = true.\nand\n(pk,sk) \u2190 KeyGen(),r \u2190 R,m \u2190 M, Verify(m,Sign(m,sk;r),pk) = true.\nNote, that for deterministic MACs the verification algorithm is usually just to recompute the\nMACtagMAC(m,k),andthencheckitwaswhatwasreceived.\n10.2.2 Basic Security Definitions\nAsecuritydefinitionisusuallygiveninthecontextofanattacker\u2019ssecuritygoal,followedby\ntheircapabilities.So,forexample,anaivesecuritygoalforencryptioncouldbetorecoverthe\nunderlying plaintext, so-called One-Way (or OW) security. This process of an attacker trying\ntoobtainaspecificgoaliscalledasecuritygame,withtheattackerwinningthegame,ifthey\ncan break this security goal with greater probability than random guessing. This advantage\ninprobabilityoverrandomguessingiscalledtheadversary\u2019sadvantage.Thecapabilitiesare\nexpressed in terms of what oracles, or functions, we give the adversary access to. So, for\nexample,inanaivesecuritygameforencryptionwemaygivetheadversarynooraclesatall,\nproducingaso-calledPassiveAttack(orPASS)capability.\nThe attacker is modelled as an arbitrary algorithm, or Turing machine, A, and if we give the\nadversary access to oracles then we write these as subscripts AO. In our naive security\ngame (called OW-PASS) the adversary has no oracles and its goal is simply to recover the\nmessage underlying a given ciphertext. The precise definition is given in Figure 10.1, where\nAdvOW\u2212PASS(A,t)denotetheadvantageoverarandomguessthatagivenadversaryhasafter\nrunning for time t. We say that a given construction is secure in the given model (which our\nnaive example would be named OW-PASS), if the above advantage is negligible for all prob-\nabilistic polynomial time adversaries A. Here, negligible and polynomial time are measured\nintermsofasecurityparameter(whichonecanthinkofasthekeysize).Note,forOW-PASS\nthisassumesthatthemessagespaceisnotbiggerthanthespaceofallpossiblekeys.Also\nnote, that this is an asymptotic definition, which in the context of schemes with fixed key\nsize, makes no sense. In such situations we require that (t\/Adv) is greater than some given\nconcrete bound such as 2128, since it is believed that performing an algorithm requiring 2128\nstepsisinfeasibleevenforanation-stateadversary.\nIn the context of encryption (both symmetric and public key) the above naive security goal\nisnotseenasbeingsuitableforrealapplications.Instead,thesecuritygoalofIndistinguish-\nable encryptions (or IND) is usually used. This asks the adversary to first come up with two\nplaintexts, of equal length, and then the challenger (or environment) encrypts one of them\nand gives the resulting challenge ciphertext to the adversary. The adversary\u2019s goal is then\nto determine which plaintext was encrypted. In the context of a passive attack this gives an\nadvantagestatementasgiveninthesecondpartofFigure10.1,wherethetwostagesofthe\nadversaryaregivenbyA andA .\n1 2\nIn terms of encryption, the above passive attack is almost always not sufficient in terms\nof capturing real-world adversarial capabilities, since real systems almost always give the\nattacker additional attack vectors. Thus two other (increasingly strong) attack capabilities\nare usually considered. These are a Chosen Plaintext Attack (or CPA capability), in which\nKACryptography |October2019 Page325 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nthe adversary is given access to an encryption oracle to encrypt arbitrary messages of his\nchoice,andaChosenCiphertextAttack(orCCAcapability),inwhichtheadversaryhasboth\nanencryptionanddecryptionoracle.Inthecaseofapublickeyschemetheadversaryalways\nhasaccesstoanencryptionoraclebecauseitcanencryptplaintextsforitselfusingthepublic\nkey,sointhiscasePASSandCPAareequivalent.Inthecase ofaCCAcapabilitywerestrict\nthe decryption oracle so that the adversary may not ask of it the challenge ciphertext c\u2217;\notherwiseitcantriviallywinthesecuritygame.ThustheadvantageofanIND-CCAadversary\nagainstapublickeyencryptionschemewouldbedefinedasthethirddefinitioninFigure10.1.\nOthersecuritydefinitionsarepossibleforencryption(suchasReal-or-Random)buttheabove\narethemainones.\nOW-PASSDefinition:\n(cid:104)\nAdvOW\u2212PASS(A,t) = Pr k \u2190 KeyGen(), m\u2217 \u2190 M, r \u2190 R,\n(cid:105) 1\nc\u2217 \u2190 Enc(m,k;r), m \u2190 A(c\u2217) : m = m\u2217 \u2212 .\n|M|\nOne reads the probability statement as the being the probability that m = m\u2217, given that m and\nm\u2217 are produced by first sampling k from algorithm KeyGen(), then sampling m\u2217 and r from the\nspaces M and R at random, then determining c\u2217 by calling Enc(m,k;r) and finally passing c\u2217 to\ntheAdversaryA,andgettingminreturn.\nIND-PASSSymmetricKeyEncryptionDefinition:\n(cid:104)\nAdvIND\u2212PASS(A,t) = Pr k \u2190 KeyGen(), b \u2190 {0,1}, m , m , state \u2190 A (),\n0 1 1\n(cid:105) 1\nr \u2190 R, c\u2217 \u2190 Enc(m ,k;r), b(cid:48) \u2190 A (c\u2217,state) : b = b(cid:48) \u2212 .\nb 2\n2\nIND-CCAPublicKeyEncryptionDefinition:\n(cid:104)\nAdvIND\u2212CCA(A,t) = Pr (pk,sk) \u2190 KeyGen(), b \u2190 {0,1}, m , m ,state \u2190 ADec(\u00b7,sk) (pk),\n0 1 1\n(cid:105) 1\nr \u2190 R, c\u2217 \u2190 Enc(m ,pk;r), b(cid:48) \u2190 ADec(\u00b7,sk) (c\u2217,state) : b = b(cid:48) \u2212 .\nb 2 2\nUF-CMASignatureSecurityDefinition:\n(cid:104) (cid:105)\nAdvUF\u2212CMA(A,t) = Pr (pk,sk) \u2190 KeyGen(), (m,\u03c3) \u2190 ASign(\u00b7,sk)(pk) : Verify(m,\u03c3,pk) = true .\nIND-CCAKEMSecurityDefinition:\n(cid:104)\nAdvIND\u2212CCA(A,t) = Pr (pk,sk) \u2190 KEMKeyGen(), b \u2190 {0,1}, k \u2190 K, r \u2190 R,\n0\n(cid:105)\nk ,c\u2217 \u2190 KEMEnc(pk;r), b(cid:48) \u2190 AKEMDec(\u00b7,sk) (c\u2217,k ) : b = b(cid:48) \u2212 1.\n1 2 b 2\nFigure 10.1:TechnicalSecurityDefinitions\nFor MACs (resp. digital signature schemes) the standard security goal is to come up with a\nmessage\/tag (resp. message\/signature) pair which passes the verification algorithm, a so-\nKACryptography |October2019 Page326 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ncalledUniversalForgery(orUF)attack.Wemakenoassumptionaboutwhetherthemessage\nhasanymeaning,indeed,theattackerwinsifheisabletocreateasignatureonanybit-string.\nIf the adversary is given no oracles then he is said to be mounting a passive attack, whilst\nif the adversary is given a tag generation (resp. signing oracle) he is said to be executing a\nChosen Message Attack (CMA). In the latter case the final forgery must not be one of the\noutputs of the given oracle. In the case of MAC security, one may also give the adversary\naccess to a tag verification oracle. However, for deterministic MACs this is implied by the\nCMA capability and is hence usually dropped, since verification only involves re-computing\ntheMAC.\nAgainwedefineanadvantageandrequirethistobenegligibleinthesecurityparameter.For\ndigital signatures the advantage for the UF-CMA game is given by the fourth equation in\nFigure10.1.\n10.2.3 Hard Problems\nAs explained above, security proofs are always relative to some hard problems. These hard\nproblemsareoftencalledcryptographicprimitives,sincetheyarethesmallestatomicobject\nfromwhichcryptographicschemesandprotocolscanbebuilt.Suchcryptographicprimitives\ncome in two flavours: Either they are keyed complexity theoretic definitions of functions, or\ntheyaremathematicalhardproblems.\nIn the former case one could consider a function F (\u00b7) : D \u2212\u2192 C selected from a function\nk\nfamily {F } and indexed by some index k (thought of as a key of varying length). One can\nk\nthen ask whether the function selected is indistinguishable (by a probabilistic polynomial\ntime algorithm A which has oracle access to the function) from a uniform random function\nfromD toC.Ifsuchanassumptionholds,thenwesaythefunctionfamilydefinesa(keyed)\nPseudo-RandomFunction(PRF).InthecasewhenthedomainDisequaltotheco-domainC\nwe can ask whether the function is indistinguishable from a randomly chosen permutation,\ninwhichcasewesaythefamilydefinesa(keyed)Pseudo-RandomPermutation(PRP).\nIn the case of a block cipher, such as AES (see later), where one has C = D = {0,1}128, it is\nabasicassumptionthattheAESfunctionfamily(indexedbythekeyk)isaPseudo-Random\nPermutation.\nInthecaseofmathematicalhardproblemswehaveasimilarformulation,butthedefinitions\nareoftenmoreintuitive.Forexample,onecanaskthequestionwhetheragivenRSAmodulus\nN = p\u00b7q canbefactoredintoitsprimecomponentspandq,theso-calledfactoringproblem.\nThe RSA group Z\/NZ defines a finite abelian group of unknown order (the order is known\nto the person who created N), finding the order of this group is equivalent to factoring N.\nThe RSA function x \u2212\u2192 xe (mod N) is believed to be hard to invert, leading to the so-called\nRSA-inversionproblemof,giveny \u2208(Z\/NZ)\u2217,findingxsuchthatxe = y (mod N).Itisknown\nthatthefunctioncaneasilybeinvertedifthemodulusN canbefactored,butitisunknownif\ninvertingthefunctionimpliesN canbefactored.Thuswehaveasituationwhereoneproblem\n(factoring) seems to be harder to solve than another problem (the RSA problem). However,\ninpractice,weassumethatbothproblemsarehard,givenappropriatelychosenparameters.\nDetailsonthebestmethodtofactorlargenumbers,theso-calledNumberFieldSieve,canbe\nfoundin[984].\nIn finite abelian groups of known order (usually assumed to be prime), one can define other\nproblems.Theproblemofinvertingthefunctionx \u2212\u2192 gx,isknownastheDiscreteLogarithm\nProblem (DLP). The problem of, given gx and gy, determining gx\u00b7y is known as the Diffie\u2013\nKACryptography |October2019 Page327 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nHellmanProblem(DHP).Theproblemofdistinguishingbetweentriplesoftheform(gx,gy,gz)\nand (gx,gy,gx\u00b7y) for random x,y,z is known as the Decision Diffie\u2013Hellman (DDH) problem.\nWhenwrittenadditivelyinanellipticcurvegroup,aDDHtriplehastheform([x]\u00b7P,[y]\u00b7P,[z]\u00b7P).\nGenerally speaking, the mathematical hard problems are used to establish the security of\npublic key primitives. A major issue is that the above problems (Factoring, RSA-problem,\nDLP, DHP, DDH), on which we base all of our main existing public key algorithms, are eas-\nily solved by large-scale quantum computers. This has led designers to try to build crypto-\ngraphic schemes on top of mathematical primitives which do not appear to be able to be\nbroken by a quantum computer. Examples of such problems are the problem of determin-\ning the shortest vector in a high dimensional lattice, the so-called Shortest Vector Problem\n(SVP), and the problem of determining the closest lattice vector to a non-lattice vector, the\nso-called Closest Vector Problem (CVP). The best algorithms to solve these hard problems\nare lattice reduction algorithms, a nice survey of these algorithms and applications can be\nfound in [985]. The SVP and CVP problems, and others, give rise to a whole new area called\nPost-QuantumCryptography(PQC).\nExample: Putting the above ideas together, one may encounter statements such as: The\npublic key encryption scheme XYZ is IND-CCA secure assuming the RSA-problem is hard and\nAESisaPRP.ThisstatementtellsusthatanyattackagainsttheXYZschememusteitherbe\nagainstsomeweaknessintheimplementation,ormustcomefromsomeattacknotcaptured\nin the IND-CCA model, or must come from solving the RSA-problem, or must come from\nshowingthatAESisnotaPRP.\n10.2.4 Setup Assumptions\nSome cryptographic protocols require some setup assumptions. These are assumptions\nabout the environment, or some data, which need to be satisfied before the protocol can\nbe considered secure. These assumptions come in a variety of flavours. For example, one\ncommon setup assumption is that there exists a so-called Public-Key Infrastructure (PKI),\nmeaningthatwehaveatrustedbindingbetweenentities\u2019publickeysandtheiridentities.\nAnothersetupassumptionistheexistenceofastring(calledtheCommonReferenceString\norCRS)availabletoallparties,andwhichhasbeensetupinatrustedmanner,i.e.suchthat\nnopartyhascontrolofthisstring.\nOthersetupassumptionscouldbephysical,forexample,thatthealgorithmshaveaccessto\ngood sources of random numbers, or that their internal workings are not susceptible to an\ninvasiveattacker,i.e.theyareimmunetoside-channelattacks.\n10.2.5 Simulation and UC Security\nThe above definitions of security make extensive use of the notion of indistinguishability\nbetween two executions. Indeed, many of the proof techniques used in the security proofs\nconstruct simulations of cryptographic operations. A simulation is an execution which is in-\ndistinguishable from the real execution, but does not involve (typically) the use of any key\nmaterial. Another method to produce security models is the so-called simulation paradigm,\nwhereweaskthatanadversarycannottellthesimulationfromarealexecution(unlessthey\ncan solve some hard problem). This paradigm is often used to establish security results for\nmorecomplexcryptographicprotocols.\nKACryptography |October2019 Page328 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nA problem with both the game\/advantage-based definitions defined earlier and the simu-\nlation definitions is that they only apply to stand-alone executions, i.e. executions of one\ninstance of the protocol in one environment. To cope with arbitrarily complex executions\nandcompositionofcryptographicprotocolsanextensiontothesimulationparadigmexists\ncalledtheUniversalComposability(UC)framework.\n10.3 INFORMATION-THEORETICALLY SECURE\nCONSTRUCTIONS\n[979,c2][980,c19]\nWhilst much of cryptography is focused on securing against adversaries that are modelled\nasprobabilisticpolynomialtimeTuringmachines,someconstructionsareknowntoprovide\nsecurity against unbounded adversaries. These are called information-theoretically secure\nconstructions. A nice introduction to the information theoretic side of cryptography can be\nfoundin[986].\n10.3.1 One-Time Pad\nThemostfamousprimitivewhichprovidesinformation-theoreticsecurityistheone-timepad.\nHere, a binary message m \u2208 {0,1}t is encrypted by taking a key k \u2208 {0,1}t uniformly at\nrandom,andthenproducingtheciphertextc = m\u2295k.Intermsofourearliersecuritymodels,\nthisisanIND-PASSschemeeveninthepresenceofacomputationallyunboundedadversary.\nHowever, the fact that it does not provide IND-CPA security is obvious, as the encryption\nscheme is determinisitic. The scheme is unsuitable in almost all modern environments as\none requires a key as long as the message and the key may only be used once; hence the\nnameone-timepad.\n10.3.2 Secret Sharing\nSecret sharing schemes allow a secret to be shared among a set of parties so that only a\ngiven subset can reconstruct the secret by bringing their shares together. The person who\nconstructs the sharing of the secret is called the dealer. The set of parties who can recon-\nstruct the secret are called qualified sets, with the set of all qualified sets being called an\naccessstructure.\nAnysetwhichisnotqualifiedissaidtobeanunqualifiedset,andthesetofallunqualifiedsets\niscalledanadversarystructure.Theaccessstructureisusuallyassumedtobemonotone,in\nthatifthepartiesinAcanreconstructthesecret,thensocananysuper-setofA.\nManysecretsharingschemesprovidedinformation-theoreticsecurity,inthatanysetofpar-\ntieswhichisunqualifiedcanobtainnoinformationaboutthesharedsecreteveniftheyhave\nunboundedcomputingpower.\nAspecialformofaccessstructureisaso-calledthresholdstructure.Hereweallowanysub-\nsetoft+1partiestoreconstructthesecret,whereasanysubsetoftpartiesisunabletolearn\nanything.Thevaluetisbeingcalledthethreshold.Oneexampleconstructionofathreshold\nsecret sharing scheme for a secret s in a field F , with n > p is via Shamir\u2019s secret sharing\np\nscheme.\nKACryptography |October2019 Page329 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nIn Shamir secret sharing, one selects a polynomial f(X) \u2208 F [X] of degree t with constant\np\ncoefficients s, the value one wishes to share. The share values are then given by s = f(i)\ni\n(mod p), for i = 1,...,n, with party i being given s . Reconstruction of the value s from a\ni\nsubsetofmorethantvaluess canbedoneusingLagrangeinterpolation.\ni\nDue to an equivalence with Reed-Solomon error correcting codes, if t < n\/2, then on receipt\nofnsharevaluess ,areconstructingpartycandetectifanypartyhasgivenitaninvalidshare.\ni\nAdditionally,ift < n\/3thenthereconstructingpartycancorrectforanyinvalidshares.\nReplicatedsecretsharingisasecondpopularschemewhichsupportsanymonotoneaccess\nstructure. Given a boolean formula defining who should have access to the secret, one can\ndefine a secret sharing scheme from this formula by replacing all occurrences of AND with\n+andalloccurrencesofORwithanewsecret.Forexample,giventheformulae\n(P ANDP )OR(P ANDP ),\n1 2 2 3\nonecanshareasecretsbywritingitass = s +s = s(cid:48) +s andthen,givingpartyP thevalue\n1 2 2 3 1\ns ,partyP thepairofvaluess ands(cid:48),andpartyP thevalues .Replicatedsecretsharingis\n1 2 2 2 3 3\ntheschemeobtainedinthiswaywhenputtingthebooleanformulaeintoConjunctiveNormal\nForm.\nOfimportanceinapplicationsofsecretsharing,especiallytoSecureMulti-PartyComputation\n(seeSection10.9.4)iswhethertheadversarystructureisQ orQ .Anadversarystructureis\n2 3\nsaidtobeQ ifnosetofiunqualifiedsetshaveunionthefullsetofplayers.Shamir\u2019ssecret\ni\nsharing scheme is Q if t < n\/2 and Q when t < n\/3. The error detection (resp. correction)\n2 3\nproperties of Shamir\u2019s secret sharing scheme mentioned above follow through to any Q\n2\n(resp.Q )adversarystructure.\n3\n10.4 SYMMETRIC PRIMITIVES\n[979,c3\u2013c6][980,c11\u2013c14]\nSymmetric primitives are a key component of many cryptographic constructions. There are\nthreesuchbasicprimitives:blockciphers,streamciphers,andhashfunctions.Theoretically,\nall are keyed functions, i.e. they take as input a secret key, whilst in practice one often con-\nsiders hash functions which are unkeyed. At a basic level, all are functions f : K\u00d7D \u2212\u2192 C\nwhereKisthekeyspace,Disthedomain(whichisofafixedfinitesizeforblockciphersand\nstreamciphers).\nAsexplainedintheintroductionwewillnotbediscussinginthisreportcryptanalysisofsym-\nmetric primitives, we will only be examining secure constructions. However, the main two\ntechniques for attacks in this space are so-called differential and linear cryptanalysis. The\ninterested reader is referred to the excellent tutorial by Howard Heys [987] on these topics,\northebook[988].\nKACryptography |October2019 Page330 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n10.4.1 Block Ciphers\nAblockcipherisafunctionf : K\u00d7{0,1}b \u2212\u2192 {0,1}b,wherebistheblocksize.Despitetheir\nnames such functions should not be thought of as an encryption algorithm. It is, however,\na building block in many encryption algorithms. The design of block ciphers is a deep area\nof subject in cryptography, analogous to the design of number theoretic one-way functions.\nMuch like number-theoretic one-way functions, cryptographic constructions are proved se-\ncurerelativetoanassociatedhardproblemwhichagivenblockcipherisassumedtosatisfy.\nFor a fixed key, a block cipher is assumed to act as a permutation on the set {0,1}b, i.e. for\na fixed key k, the map f : {0,1}b \u2212\u2192 {0,1}b is a bijection. It is also assumed that inverting\nk\nthis permutation is also easy (if the key is known). A block cipher is considered secure if\nno polynomial time adversary, given oracle access to a permutation on {0,1}b, can tell the\ndifferencebetweenbeinggivenauniformlyrandompermutationorthefunctionf forsome\nk\nfixed hidden key k, i.e. the block cipher is a PRP. In some applications, we only require that\ntheblockcipherisafunction,i.e.notabijection.Inwhichcasewerequiretheblockcipheris\naPRF.\nOne can never prove that a block cipher is a PRP, so the design criteria is usually a task\nof building a mathematical construction which resists all known attacks. The main such at-\ntackswhichoneresistsareso-calledlinearcryptanalysis,whereoneapproximatesnon-linear\ncomponentswithintheblockcipherbylinearfunctions,anddifferentialcryptanalysis,where\nonelooksathowtwooutputsvaryonrelatedinputmessages,e.g.oneappliesf tovarious\nk\ninputsm andm wherem \u2295m = \u2206afixedvalue.\n0 1 0 1\nThe design of a block cipher is made up of a number of simpler components. There are\nusuallylayersofsimplefixedpermutations,andlayersoftablelookups.Thesetablelookups\nare called S-boxes, where the S stands for substitutions. There are two main techniques to\ndesign block ciphers. Both repeat a simple operation (called a round) a number of times.\nEachroundconsistsofacombinationofpermutationsandsubstitutions,andakeyaddition.\nThemainkeyisfirstexpandedintoround-keys,witheachroundhavingadifferentround-key.\nIn the first methodology, called a Feistel Network, the S-Boxes allowed in each round can\nbe non-injective, i.e. non-invertible. Despite this, the Feistel constructions still maintain the\noverall invertibility of the block cipher construction. The second method is a Substitution-\nPermutation Network design in which each round consists of a round-key addition, followed\nbyafixedpermutation,followedbytheapplicationofbijectiveS-boxes.Ingeneral,theFeistel\nconstructionrequiresmoreroundsthantheSubstitution-Permutationnetworkconstruction.\nThe DES (Data Encryption Standard) block cipher (with an original key of 56-bits and block\nsize of b = 64) is a Feistel construction. The DES algorithm dates from the 1970s, and the\nkey size is now considered far too small for any application. However, one can extend DES\nintoa112-or168-bitkeyblockciphertoconstructanalgorithmcalled2DESor3DES.Theuse\nof 2DES or 3DES is still considered secure, although in some applications, the block size of\n64-bitsisconsideredinsecureforreal-worlduse.\nThe AES (Advanced Encryption Standard) block cipher is the modern replacement for DES,\nanditisablockcipherwitha128-,192-or256-bitkey,andwithablocksizeofb = 128bits.The\nAES algorithm has hardware support on many microprocessors, making operations using\nAESmuchfasterthanusingothercryptographicprimitives.Readerswhowishtounderstand\nmoreaboutthedesignoftheAESblockcipherreferredto[989].\nKACryptography |October2019 Page331 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n10.4.2 Stream Ciphers\nA stream cipher is one which produces an arbitrary length string of output bits, i.e. the co-\ndomain of the function is essentially unbounded. Stream ciphers can be constructed from\nblock ciphers, by using a block cipher in Counter Mode (see Section 10.5.1). However, the\nstreamcipherisusuallyreservedforconstructionswhicharespecial-purposeandforwhich\nthehardwarecomplexityismuchreduced.\nClearly,astreamciphercannotbeapermutation,butwerequirethatnopolynomialtimead-\nversarycandistinguishoracleaccesstothestreamcipherfromoracleaccesstoauniformly\nrandom function with infinite co-domain. The design of stream ciphers is more ad-hoc than\nthat of the design of block ciphers. In addition, there is less widespread adoption outside\nspecific application areas. The interested reader is referred to the outcome of the eStream\ncompetitionfordetailsofspecificad-hocstreamcipherdesigns[990].\n10.4.3 Hash Functions\nHashfunctionsaremuchlikeblockciphersinthattheyshouldactasPRFs.However,theinput\ndomaincanbeunbounded.SinceaPRFneedstobekeyedtomakeanysenseintheoretical\ntracts, a hash function is usually a keyed object. In practice, we often require an unkeyed\nobject,inwhichcaseoneconsiderstheactualhashfunctionusedtohaveanimplicitinbuilt\nfixedkey,andhavebeenchosenfromafunctionfamilyalready.\nWhen considering a fixed hash function, one is usually interested in the intractability of in-\nverting the hash function (the one-way property), the intractability of finding two inputs with\nthe same output (the collision resistance property), or the intractability of finding, given an\ninput\/outputpair,anewinputwhichgivesthesameoutput(thesecond-preimageresistance\nproperty).\n10.4.3.1 Merkle-Damg\u00e5rdConstruction\nEarly hash functions were based on the Merkle-Damg\u00e5rd construction. The family of such\nfunctions (MD4, MD5, SHA-1, SHA-2) have a number of issues, with only SHA-2 now being\nconsidered secure. The Merkle-Damg\u00e5rd construction takes a compression function f(x,y)\ntakingtwoinputsx,y offixedlengthwiththeoutputlengthofx.Thisisusedtoderiveafunc-\ntionwhichallowsarbitrarylengthinputsbyfirstdividingamessagemintotblocksm ,...,m\n1 t\neachoflength|y|,andthenapplying\nh = f(h ,m )fori = 1,...,t,\ni i\u22121 i\nwheretheoutputish andh issomeinitialvalue,whichcanbethoughtofasafixedkeyfor\nt 0\nthehashfunction.\nTheabovemethodologyrequiresamethodtopadtheinitialinputblocktoencodethelength,\nand it suffers from a number of practical issues. For example, there are obvious length ex-\ntensionattacks(namelyahashonamessagemcanbeextendedtoahashonm(cid:107)m(cid:48) without\nknowing the whole of m) which render the use of such hash functions problematic in some\napplications. For example, in HMAC (see Section 10.5.2), one requires two applications of\nthehashfunctiontopreventsuchattacks.\nKACryptography |October2019 Page332 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n10.4.3.2 SpongeConstructions\nA more modern approach to hash function design is to create a so-called sponge construc-\ntion.ThisisthedesignphilosophybehindSHA-3(a.k.a.Keccak).Aspongeisafunctionwhich\noperates in two phases. In the first phase, one enters data into the sponge state and, in the\nsecondphase,onesqueezesdataoutfromthesponge.\nThespongestateisapair(r,c) \u2208 {0,1}|r|+|c|,wherethelengthofr denotestheinput\/output\nrate and c is a variable holding an internal state hidden from any attacker. The size of c is\ndirectly related to the security of the construction. At each round, a public permutation p is\nappliedtothestate(r,c).\nIn the input phase of the sponge, the input data m, after suitable padding, is divided into t\nblocksm ,...,m ofsize|r|.Thenthestateisupdatedviathemapping\n1 t\n(r ,c ) = p(r \u2295m ,c )fori = 1,...,t,\ni i i\u22121 i i\u22121\nwhere r and c are initialized to be fixed all-zero bit strings. After data is entered into the\n0 0\nsponge,onecanobtainsblocksof|r|-bitoutputso ,...,o bycomputing\n1 s\n(o ,c(cid:48)) = p(o ,c(cid:48) )fori = 1,...,s,\ni i i\u22121 i\u22121\nwhereo = r andc(cid:48) = c .Thusthewholefunctionisgivenby\n0 t 0 t\nH(m ,...,m ) = o ,...,o .\n1 t 1 s\nFurther details on sponge constructions, and the further objects one can construct from\nthem,andtheSHA-3designinparticularcanbefoundattheKeccakwebpage[991].\n10.4.3.3 RandomOracleModel\nMany cryptographic constructions are only secure if one assumes that the hash function\nused in the construction behaves \u2018like a random oracle\u2019. Such constructions are believed to\nbe secure in the real world, but theoretically, they are less pleasing. One can think of a proof\nof security in the random oracle model as a proof in which we allow the attacker to have\ntheir usual powers; however, when they (or any of the partners they are attacking) call the\nunderlyinghashfunctionthecallismadetoanexternalpartyviaanoraclecall.Thisexternal\nparty then simply plays back a random value, i.e. it does not use any algorithm to generate\ntherandomvalues.Allthatisrequiredisthatiftheinputisgiventotheoracletwice,thenthe\nsameoutputisalwaysreturned.\nThis clearly does not capture attacks in which the adversary makes clever use of exactly\nhow the hash function is defined etc, and how this definition interacts with other aspects\nof the scheme\/protocol under analysis. However, this modelling methodology has proved\nremarkablygoodinenablingcryptographerstodesignschemeswhicharesecureinthereal\nworld.\nKACryptography |October2019 Page333 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n10.5 SYMMETRIC ENCRYPTION AND AUTHENTICATION\n[979,c3\u2013c4][980,c13\u2013c14]\nA block cipher, such as AES or DES, does not provide an effective form of data encryption\nordata\/entityauthenticationonitsown.Toprovidesuchsymmetriccryptographicconstruc-\ntions, one needs a scheme, which takes the primitive and then utilizes this in a more com-\nplex construction to provide the required cryptographic service. In the context of symmetric\nencryption,theseareprovidedbymodesofoperation.Inthecaseofauthentication,itispro-\nvidedbyaMACconstruction.Additionally,blockciphersareoftenusedtotakesomeentropy\nand then expand, or collapse, this into a pseudo-random stream or key; a so-called XOF (or\nExtendableOutputFunction)orKDF(orKeyDerivationFunction).Furtherdetailsonblockci-\npherbasedconstructionscanbefoundat[992],whereasfurtherdetailsonSponger\/Keccak\nbasedconstructionscanbefoundat[991].\nP P P PP\n0 1 2 nn\nIV\nk ENC k ENC k ENC \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 kk EENNCC\nC C C CC\n0 1 2 nn\nFigure 10.2: CBC Mode Encryption (All Figures are produced using TikZ for Cryptographers\nhttps:\/\/www.iacr.org\/authors\/tikz\/).\n10.5.1 Modes of Operation\nHistorically,therehavebeenfourtraditionalmodesofoperationtoturnablockcipherintoan\nencryption algorithm. These were ECB, CBC, OFB and CFB modes. In recent years, the CTR\nmode has also been added to this list. Among these, only CBC mode (given in Figure 10.2)\nandCTRmode(giveninFigure10.3)areusedwidelywithincurrentsystems.IntheseFigures,\ntheblockcipherisrepresentedbythefunctionEnc\nIV,Ctr+0 IV,Ctr+1 IV,Ctr+2 IV,Ctr+n\nk ENC k ENC k ENC \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7 k ENC\nP P P P\n0 1 2 n\nC C C C\n0 1 2 n\nFigure10.3:CTRModeEncryption\nOntheirown,however,CBCandCTRmodesonlyprovideIND-CPAsecurity.Thisisfarweaker\nthan the \u2018gold standard\u2019 of security, namely IND-CCA (discussed earlier). Thus, modern sys-\ntems use modes which provide this level of security, also enabling additional data (such as\nKACryptography |October2019 Page334 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nsession identifiers) to be tagged into the encryption algorithm. Such algorithms are called\nAEAD methods (or Authenticated Encryption with Associated Data). In such algorithms, the\nencryption primitive takes as input a message to be encrypted, plus some associated data.\nTodecrypt,theciphertextisgiven,alongwiththeassociateddata.Decryptionwillonlywork\nif both the key is correct and the associated data is what was input during the encryption\nprocess.\nThe simplest method to obtain an AEAD algorithm is to take an IND-CPA mode of operation\nsuch as CBC or CTR, and then to apply a MAC to the ciphertext and the data to be authenti-\ncated,givingustheso-calledEncrypt-then-MACparadigm.Thus,toencryptmwithauthenti-\ncateddataa,oneappliesthetransform\nc \u2190 Enc(m,k ;r), c \u2190 MAC(c (cid:107)a,k ;r),\n1 1 2 1 2\nwiththeciphertextbeing(c ,c ).Insuchaconstruction,itisimportantthattheMACisapplied\n1 2\ntotheciphertextasopposedtothemessage.\nCounter incr Counter incr Counter\n0 1 2\nENC ENC ENC\nk k k\nPlaintext Plaintext\n1 2\nCiphertext Ciphertext\n1 2\nAuthData mult mult\n1 H H\nmult\nH\nlen(A)||len(C)\nmult\nH\nAuthTag\nFigure10.4:GCMModeEncryption\nA majorissue with theEncrypt-then-MACconstruction is thatone needs topass the data to\nthe underlying block cipher twice, with two different keys. Thus, new constructions of AEAD\nschemes have been given which are more efficient. The most widely deployed of these is\nGCM(orGaloisCounterMode),seeFigure10.4,whichiswidelydeployedduetothesupport\nforthisinmodernprocessors.\nKACryptography |October2019 Page335 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nOnetimeAEADconstructions,otherwiseknownasDEMs,canbeobtainedbysimplymaking\ntherandomizedAEADdeterministicbyfixingtheIVtozero.\n10.5.2 Message Authentication Codes\nMessage authentication codes can be produced in roughly the same manner as modes of\noperation.Inparticular,thestandardMACfunctionistoutilizeCBCmodewithazero-IV,and\nthentooutputthefinalciphertextblockastheMACtag,thusproducingadeterministicMAC\nfunction. On its own, even with suitable padding of the message, this is only secure when\nused with fixed length messages. Thus, often a form of post-processing of the MAC output\ntagisperformed.Forexample,thefinalCBCciphertextblockisthenpassedthroughanother\napplicationoftheunderlyingblockcipher,butusingadifferentkey.\nThe GCM AEAD method of the previous section can be thought of as an Encrypt-then-MAC\nconstruction, with the IND-CPA encryption being CTR mode, and the MAC function being a\nfunctioncalledGMAC.AlthoughthisisrarelyusedonitsownasaMACfunction.\nHash functions can also be used to construct MAC functions. The most famous of these\nis HMAC which is a construction designed for use with Merkle\u2013Damg\u00e5rd-based hash func-\ntions.SinceMerkle\u2013Damg\u00e5rd-basedhashfunctionssufferfromlengthextensionattacks,the\nHMAC function requires two applications of the underlying hash function. The construction\nproducesadeterministicMACfunctiongivenby\nHMAC(m,k) = H((k\u2295opad)(cid:107)H((k\u2295ipad)(cid:107)m)),\nwhereopadisthestring0x5c5c...5c5candipadisthestring0x3636...3636.\nAs HMAC is designed specifically for use with Merkle\u2013Damg\u00e5rd-based hash functions, it\nmakesno-sensetousethisconstructionwhenusingaspongebasedhashfunctionsuchas\nSHA-3.ThestandardizedMACfunctionderivedfromSHA-3iscalledKMAC(orKeccakMAC).\nIn this function, the sponge construction is used to input a suitably padded message, then\nthe required MAC output is taken as the squeezed output of the sponge; whereas as many\nbitsassqueezedareasneededfortheMACoutput.\n10.5.3 Key Derivation and Extendable Output Functions\nThe security definition of a deterministic MAC is essentially equivalent to the definition that\nthe output of the MAC function is indistinguishable from a random string, if one does not\nknowtheunderlyingsecretkey.Assuch,MACfunctionscanbeusedforothercryptographic\noperations. For example, in many situations, one must derive a long (or short) string of ran-\ndom bits, given some random input bits. Such functions are called KDFs or XOFs (for Key\nDerivation Function and Extendable Output Function). Usually, one uses the term KDF when\nthe output is of a fixed length, and XOF when the output could be of an arbitrary length. But\ntheconstructionsare,usually,essentiallythesameinbothcases.\nSuchfunctionscantakeanarbitrarylengthinputstring,andproduceanotherarbitrarylength\noutputstringwhichispseudo-random.Therearethreemainconstructionsforsuchfunctions;\nonebasedonblockciphers,oneontheMerkle\u2013Damg\u00e5rdhashfunctions,andonebasedon\nsponge-basedhashfunctions.\nTheconstructionsbasedonablockcipherare,attheirheart,usingCBC-MAC,withazerokey\ntocompresstheinputstringintoacryptographickeyandthenusetheCTRmodeofoperation\nKACryptography |October2019 Page336 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nunderthiskeytoproducetheoutputstring.Hence,theconstructionisessentiallygivenby\nk \u2190 CBC-MAC(m,0), o \u2190 Enc(1,k), o \u2190 Enc(2,k), ...\n1 2\nwhereEncistheunderlyingblockcipher.\nThe constructions based on the Merkle\u2013Damg\u00e5rd hash function use a similar structure, but\nusingonehashfunctionapplicationperoutputblock,inamethodsimilartothefollowing\no \u2190 H(m(cid:107)1), o \u2190 H(m(cid:107)2), ...\n1 2\nDuetothewayMerkle\u2013Damg\u00e5rdhashfunctionsareconstructed,theaboveconstruction(for\nlarge enough m) can be done more efficiently than simply applying H as many times as the\nnumberofoutputblockswilldictate.\nAs one can imagine, the functions based on Keccak are simpler\u2014one simply inputs the suit-\nably padded message into the sponge and then squeezes as many output bits out as re-\nquired.\nSpecial KDFs can also be defined which take as input a low entropy input, such as a pass-\nwordorPIN,andproduceakeyforuseinasymmetricalgorithm.Thesepasswordbasedkey\nderivation functions are designed to be computationally expensive, so as to mitigate prob-\nlemsassociatedtobruteforceattackingoftheunderlyinglowentropyinput.\n10.5.4 Merkle-Trees and Blockchains\nAn application of cryptographic hash functions which has recently come to prominance is\nthatofusingMerkle-Treesandbyextensionblockchains.AMerkle-Tree,orhash-tree,isatree\nin which each leaf node contains data, and each internal node is the hash of its child nodes.\nTherootnodeisthenpubliclypublished.Merkle-Treesenableefficientdemonstrationthata\nleafnodeiscontainedinthetree,inthatonesimplypresentsthepathofhashesfromtheleaf\nuptotherootnode.Thusverificationislogarithmicinthenumberofleafnodes.Merkle-Trees\ncan verify any form of stored data and have been used in various protocols such as version\ncontrolsystems,suchasGit,andbackupsystems.\nA block chain is a similar structure, but now the data items are aligned in a chain, and each\nnode hashes both the data item and a link to the previous item in the chain. Block chains\nare used in cryptocurrencies such as Bitcoin, but they have wider application. The key prop-\nerty a blockchain provides is that (assuming the current head of the chain is authenticated\nand trusted) the data provides an open distributed ledger in which previous data items are\nimmutable,andtheorderingofdataitemsispreserved.\n10.6 PUBLIC KEY ENCRYPTION\n[979,c11][980,c15\u2013c17]\nAs explained above, public key encryption involves two keys, a public one pk and a private\nonesk.Theencryptionalgorithmusesthepublickey,whilstthedecryptionalgorithmusesthe\nsecretkey.Muchofpublickeycryptographyisbasedonnumbertheoreticconstructions,thus\n[981]providesagoodcoverageofmuchinthissection.Thestandardsecurityrequirementfor\npublic key encryptionis that the scheme should be IND-CCA. Note that sincethe encryption\nkey is public we have that IND-PASS is the same as IND-CPA for a public key encryption\nscheme.\nKACryptography |October2019 Page337 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n10.6.1 KEM-DEM Philosophy\nIn general, public key encryption schemes are orders of magnitude less efficient than sym-\nmetric key encryption schemes. Thus, the usual method in utilizing a public key scheme,\nwhenlargemessagesneedtobeencrypted,isviaahybridmethod.Thishybridmethodology\nis called the KEM-DEM philosophy A KEM, which stands for Key Encapsulation Mechanism,\napublickeymethodtotransmitashortkey,selectedatrandomfromasetK,toadesignated\nrecipient.Whereas,aDEM,orDataEncryptionMechanism,isessentiallythesameasanIND-\nCCA symmetric encryption scheme, which has key space K. Since a DEM is only ever used\nonce with the same key, we can actually use a weaker notion of IND-CCA encryption for the\nDEM, in which the adversary is not given access to an encryption oracle; which means the\nDEMcanbedeterministic.\nFor a KEM, we call the encryption and decryption mechanisms encapsulation and decapsu-\nlation, respectively. It is usual for the syntax of the encapsulation algorithm to not take any\ninput,bartherandomness,andthentoreturnboththeciphertextandthekeywhichitencap-\nsulates.Thus,thesyntax,andcorrectness,ofaKEMbecomes\n(pk,sk) \u2190 KEMKeyGen(),r \u2190 R,(k,c) \u2190 KEMEnc(pk;r), KEMDec(c,sk) = k.\nThesecuritydefinitionforaKEMisdescribedinthelastequationofFigure10.1.Toconstruct\nthehybridpublickeyencryptionschemewedefineKeyGen()tobeequaltoKEMKeyGen,then\nEnc(m,pk;r)outputs(c ,c )where\n0 1\nk,c \u2190 KEMEnc(pk;r), c \u2190 DEM(m,k),\n0 1\nwithDec((c ,c ),sk)beinggivenby\n0 1\nk \u2190 KEMDec(c ,sk), m \u2190 DEM\u22121(c ,k).\n0 1\n10.6.2 Constructions based on RSA\nThe simplest public key encryption scheme is the RSA scheme, which is based on the dif-\nficulty of factoring integers. In the key generation algorithm, two large primes p and q are\nselected and multiplied together to form N = p \u00b7 q. Then a (usually small) integer e is se-\nlected which is co-prime to \u03c6(N) = (p\u22121)\u00b7(q \u22121). Finally, the integer d is found, using the\nextended Euclidean algorithm, such that d = 1\/e (mod \u03c6(N)). The public key is set to be\npk = (N,e),whereasthesecretkeyissettobesk = (N,d).Notethatgiventhepkonly,finding\nthesecretkeyskisprovablyequivalenttofactoringN.\nThe public\/private keys are used via the RSA function x \u2212\u2192 xe (mod N), which has the in-\nversemapx \u2212\u2192 xd (mod N).Thus,theRSAfunctionisatrapdoorpermutationonthegroup\n(Z\/NZ)\u2217.ItisnotbelievedthatinvertingtheRSAmapisequivalenttofactoring,soinversion\nofthismapisidentifiedasaseparateproblem(theRSAproblem).Atthetimeofwriting,one\nshouldselectpandq tobeprimesofatleast1536bitsinlengthtoobtainsuitablesecurity.\nThere are many historic ways of using the RSA function as a public key encryption scheme,\nmanyofwhicharenowconsideredobsoleteand\/orinsecure.Thetworecommendedmethod-\nologies in using RSA for encryption are RSA-OAEP and RSA-KEM; which are both IND-CCA\nsecureintherandomoraclemodel.\nOAEP, or Optimized Asymmetric Encryption Padding, is a method to use the RSA function\ndirectlyasanIND-CCApublickeyencryptionalgorithm.OAEPisparametrizedbytwointegers\nKACryptography |October2019 Page338 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nk ,k \u2265 128suchthatn = log N \u2212k \u2212k \u2265 0.Wethenencryptmessagesofatmostnbits\n0 1 2 0 1\ninlengthasfollows,usinghash-functions(whichareassumedtoberandomoraclesforthe\nsecurityproof)\nG : {0,1}k0 \u2212\u2192 {0,1}n+k1\nH : {0,1}n+k1 \u2212\u2192 {0,1}k0.\nWethenencryptusingthefunction\nc \u2190\n(cid:0) {(cid:0)\nm (cid:107)\n0k1(cid:1) \u2295G(R)}(cid:107){R\u2295H(cid:0)(cid:0) m(cid:107)0k1(cid:1) \u2295G(R)(cid:1) }(cid:1)e\n(mod N)\nwhere\n\u2022 m (cid:107) 0k1 meansmfollowedbyk zerobits,\n1\n\u2022 R isarandombitstringoflengthk ,\n0\n\u2022 (cid:107)denotesconcatenation.\nRSA-KEM, on the other hand, is a KEM which is much simpler to execute. To produce the\nencapsulatedkeyandtheciphertext,onetakestherandominputr (whichonethinksofasa\nuniformlyrandomelementin(Z\/NZ)\u2217).ThentheKEMisdefinedby\nc \u2190 re (mod N), k \u2190 H(r),\nwhereH : (Z\/NZ) \u2212\u2192 K isahashfunction,whichwemodelasarandomoracle.\n10.6.3 Constructions based on Elliptic Curves\nElliptic Curve Cryptography, or ECC, uses the fact that elliptic curves form a finite abelian\ngroup. In terms of encryption schemes, the standard method is to use ECIES (Elliptic Curve\nIntegrated Encryption Scheme) to define a public key, KEM which is IND-CCA in the random\noracle model, assuming the DDH problem in the subgroup of the elliptic curve being used.\nIn practice, this means that one selects a curve E(F ) for which there is a point P \u2208 E(F )\np p\nwhoseorderisaprimeq > 2256.\nFor ECIES, the KeyGen algorithm is defined as follows. A secret key sk \u2190 F\u2217 is selected uni-\nq\nformly at random, and then the public key is set to be Q \u2190 [sk]P. Key encapsulation is very\nsimilartoRSA-KEMinthatitisdefinedby\nr \u2190 F\u2217, C \u2190 [r]\u00b7P, k \u2190 H([r]\u00b7Q),\nq\nwhere H : E(F ) \u2212\u2192 K is a hash function (modelled as a random oracle). To decapsulate\np\nthekeyisrecoveredvia\nk \u2190 H([sk]C).\nCompared to RSA-based primitives, ECC-based primitives are relatively fast and use less\nbandwidth. This is because, at the time of writing, one can select elliptic curve parameters\nwith p \u2248 q \u2248 2256 to obtain security equivalent to a work-factor of 2128 operations. Hence, in\ncurrentsystemsellipticcurve-basedsystemsarepreferredoverRSA-basedones.\nKACryptography |October2019 Page339 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n10.6.4 Lattice-based Constructions\nA major problem with both RSA and ECC primitives is that they are not secure against quan-\ntum computers; namely, Shor\u2019s algorithm will break both the RSA and ECC hard problems\nin polynomial time. Hence, the search is on for public key schemes which would resist the\nadvent of a quantum computer. The National Institute of Standards and Technology (NIST)\nis currently engaged in a process to determine potential schemes which are post-quantum\nsecure,see[993]formoredetailsonthis.\nThemostprominentoftheseso-calledpost-quantumschemesarethosebasedonhardprob-\nlems on lattices. In particular, the NTRU schemes and a variety of schemes based on the\nLearning With Errors (LWE) problem, and its generalisation to polynomial rings, known as\ntheRing-LWEproblem.Thereareotherproposalsbasedonhardproblesincodingtheory,on\nthe difficulty of computing isogenies between elliptic curves and other constructs. NIST is\ncurrentlyconductingaprogramtoselectpotentialpost-quantumreplacements.\n10.7 PUBLIC KEY SIGNATURES\n[979,c12][980,c16]\nPublic key encryption assumes that the recievers public key is known to be associated with\nthe physical entity that the sender wishes to communicate with. This binding of public key\nwithanentityisdoneviameansofasocalleddigialcertificate.Adigitalcertificateisasigned\nstatement that a given entity is associated with a given public key. This certificate is issued\nbyacertificateauthority,andutilizesthesecondmainpublickeyconstruct;namelyadigital\nsignature.\nJustaswithpublickeyencryptionalgorithms,moderndigitalsignaturealgorithmsarebased\neitherontheRSAproblemoravariantofthediscretelogarithmproblem;hencethereaderis\nalsodirectedagainto[981]formoreadvanceddetails.Forpost-quantumsecurity,therearea\nnumberofproposalsbasedonlatticeconstructions;butnonehaveyetbeenwidelyaccepted\nor deployed at the time of writing this document. Again for PQC signatures we refer to the\ncurrentNISTprocess[993].\nThe prototypical digital signature scheme given in text-books is loosely called RSA-FDH,\nwhere FDH stands for Full Domain Hash. The algorithm takes a message m and signs it\nbyoutputting\ns = H(m)d (mod N).\nVerificationisthenperformedbytestingwhetherthefollowingequationholds\nse = H(m) (mod N).\nHere, the hash function is assumed to have domain {0,1}\u2217 and co-domain (Z\/NZ)\u2217. This\nscheme comes with a security proof in the random oracle model, but is almost impossible\nto implement as no standardized hash function has co-domain the whole of (Z\/NZ)\u2217, since\nN ismuchbiggerthantheoutputofhashfunctionssuchasSHA-2.\nAllstandardizedhashfunctionsoutputavaluein{0,1}t forsomet,thuswhatisusuallydone\nistotakeahashvalueandthenprependitwithsomeknownpre-determinedvalues,andthen\n\u2018sign\u2019 the result. This forms the basic idea behind the Public Key Cryptography Standards\n(PKCS)v1.5signaturestandard.Thissignsamessagebycomputing\ns = (0x01(cid:107)0xFF ...0xFF(cid:107)0x00(cid:107)H(m))d (mod N),\nKACryptography |October2019 Page340 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nwhereenoughpaddingof0xFF bytesisdonetoensurethewholepaddedstringisjustless\nthan N in size. Despite the close relationship to RSA-FDH, the above signature scheme has\nnoproofofsecurity,andhenceamoremodernschemeisusuallytobepreferred.\n10.7.1 RSA-PSS\nThe modern way to use the RSA primitive in a digital signature scheme is via the padding\nmethod called PSS (Probabilistic Signature Scheme). This is defined much like RSA-OAEP\nviatheuseoftwohashfunctions,onewhichexpandsdataandonewhichcompressesdata:\nG : {0,1}k1 \u2212\u2192 {0,1}k\u2212k1\u22121,\nH : {0,1}\u2217 \u2212\u2192 {0,1}k1,\nwherek = log N.FromGwedefinetwoauxiliaryfunctions\n2\nG : {0,1}k1 \u2212\u2192 {0,1}k0\n1\nwhichreturnsthefirstk bitsofG(w)forw \u2208 {0,1}k1,\n0\nG : {0,1}k1 \u2212\u2192 {0,1}k\u2212k0\u2212k1\u22121\n2\nwhichreturnsthelastk \u2212k \u2212k \u22121bitsofG(w)forw \u2208 {0,1}k1,i.e.G(w) = G (w)(cid:107)G (w).\n0 1 1 2\nTosignamessagemtheprivatekeyholderperformsthefollowingsteps:\n\u2022 r \u2190 {0,1}k0.\n\u2022 w \u2190 H(m(cid:107)r).\n\u2022 y \u2190 0(cid:107)w(cid:107)(G (w)\u2295r)(cid:107)G (w).\n1 2\n\u2022 s \u2190 yd (mod N).\nToverifyasignature(s,m)thepublickeyholderperformsthefollowing\n\u2022 y \u2190 se (mod N).\n\u2022 Split y into the components b(cid:107)w(cid:107)\u03b1(cid:107)\u03b3 where b is one bit long, w is k bits long, \u03b1 is k\n1 0\nbitslongand\u03b3 isk \u2212k \u2212k \u22121bitslong.\n0 1\n\u2022 r \u2190 \u03b1\u2295G (w).\n1\n\u2022 The signature is verified as correct if and only if b is the zero bit, G (w) = \u03b3 and\n2\nH(m(cid:107)r) = w.\nDespite being more complicated than PKCS-1.5, the RSA-PSS scheme has a number of ad-\nvantages.Itisarandomizedsignaturescheme,i.e.eachapplicationofthesigningalgorithm\non the same message will produce a distinct signature, and it has a proof of security in the\nrandomoraclemodelrelativetothedifficultyofsolvingtheRSAproblem.\nKACryptography |October2019 Page341 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n10.7.2 DSA, EC-DSA and Schnorr Signatures\nThe standard methodology for performing signatures in the discrete logarithm setting is to\nadapt interactive verification protocols, using proofs of knowledge of a discrete logarithm\n(see Sections 10.8.1 and 10.9.3), and then to convert them into a non-interactive signature\nschemeusingahashfunction.\nThe two most well known of these are the DSA (Digital Signature Algorithm) method and a\nmethodduetoSchnorr.Theformerhaswidespreaddeploymentbutestablishingsecurityvia\nsecurityproofsuseslesswell-acceptedassumptions,whereasthelatterislessdeployedbut\nhas well-established security proofs. The former also has, as we shall see, a more complex\nsigningprocess.BothcasesuseahashfunctionH withco-domain(Z\/qZ)\u2217,unlikeRSA-FDH\nthisiseasytoconstructasq isrelativelysmall.\nWe will describe both algorithms in the context of elliptic curves. Both make use of a public\nkeyoftheformQ = [x]\u00b7P,wherexisthesecretkey.Tosignamessagem,inbothalgorithms,\nonefirstselectsarandomvaluek \u2208 (Z\/qZ)\u2217,andcomputesr \u2190 x\u2212coord([k]\u00b7P).Onethen\ncomputesahashofthemessage.IntheDSAalgorithm,thisisdonewithe \u2190 H(m),whereas\nfor the Schnorr algorithm, one computes it via e \u2190 H(m(cid:107)r). Then the signature equation is\nappliedwhich,inthecaseofEC-DSA,is\ns \u2190 (e+x\u00b7r)\/k (mod q)\nand,inthecaseofSchnorr,is\ns \u2190 (k +e\u00b7x) (mod q).\nFinally,theoutputsignatureisgivenby(r,s)forEC-DSAand(e,s)forSchnorr.\nVerificationisdonebycheckingtheequation\nr = x\u2212coord([e\/s]\u00b7P +[r\/s]\u00b7Q)\ninthecaseofEC-DSA,andbychecking\ne = H(m(cid:107)x\u2212coord([s]\u00b7P \u2212e\u00b7Q))\nin the case of Schnorr. The key difference in the two algorithms is not the signing and verifi-\ncationequations(althoughthesedoaffectperformance),butthefactthat,withtheSchnorr\nscheme,thervalueisalsoenteredintothehashfunctiontoproducee.Thissmalldistinction\nresultsinthedifferentprovablesecuritypropertiesofthetwoalgorithms.\nAkeyaspectofbothEC-DSAandSchnorrsignaturesisthattheyareverybrittletoexposure\nof the per-message random nonce k. If only a small number of bits of k leak to the attacker\nwitheverysigningoperation,thentheattackercaneasilyrecoverthesecretkey.\nKACryptography |October2019 Page342 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n10.8 STANDARD PROTOCOLS\n[980,c18]\nCryptographicprotocolsareinteractiveoperationsconductedbetweentwoormorepartiesin\nordertorealizesomecryptographicgoal.Almostallcryptographicprotocolsmakeuseofthe\nprimitives we have already discussed (encryption, message authentication, secret sharing).\nInthissection,wediscussthetwomostbasicformsofprotocol,namelyauthenticationand\nkeyagreement.\n10.8.1 Authentication Protocols\nIn an authentication protocol, one entity (the Prover) convinces the other entity (the Verifier)\nthat they are who they claim to be, and that they are \u2018online\u2019; where \u2018online\u2019 means that the\nverifying party is assured that the proving party is actually responding and it is not a replay.\nThere are three basic types of protocol: Encryption based, Message Authentication based\nandZero-Knowledgebased.\n10.8.1.1 Encryption-BasedProtocols\nThesecanoperateinthesymmetricorpublickeysetting.Inthesymmetrickeysetting,both\ntheproverandtheverifierholdthesamesecretkey,whilstinthepublickeysetting,theprover\nholds the private key and the verifier holds the public key. In both settings, the verifier first\nencrypts a random nonce to the prover, the prover then decrypts this and returns it to the\nverifier,theverifierchecksthattherandomnonceandthereturnedvalueareequivalent.\nVerifier Prover\nN \u2190 M\nc\nc \u2190 Enc(N,pk;r) \u2212\u2212\u2192\nm\n\u2190\u2212\u2212 m \u2190 Dec(c,sk)\n?\nN = m\nThe encryption scheme needs to be IND-CCA secure for the above protocol to be secure\nagainstactiveattacks.ThenonceN isusedtopreventreplayattacks.\n10.8.1.2 MessageAuthentication-BasedProtocols\nThesealsooperateinthepublickeyorthesymmetricsetting.Intheseprotocols,theverifier\nsendsanonceinthecleartotheprover,theproverthenproducesadigitalsignature(oraMAC\ninthesymmetrickeysetting)onthisnonceandpassesitbacktotheverifier.Theverifierthen\nverifiesthedigitalsignature(orverifiestheMAC).Inthefollowingdiagramwegivethepublic\nkey\/digitalsignaturebasedvariant.\nVerifier Prover\nN\nN \u2190 M \u2212\u2212\u2192\n\u03c3\n\u2212\u2212\u2192 \u03c3 \u2190 Sign(N,sk)\n?\nVerify(N,\u03c3,pk) = true\nKACryptography |October2019 Page343 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n10.8.1.3 Zero-Knowledge-Based\nZero-knowledge-based authentication protocols are the simplest examples of zero-\nknowledge protocols (see Section 10.9.3) available. The basic protocol is a so-called \u03a3- (or\nSigma-) protocol consisting of three message flows; a commitment, a challenge and a re-\nsponse.ThesimplestexampleistheSchnorridentificationprotocol,basedonthehardness\nofcomputingdiscretelogarithms.Inthisprotocol,theProverisassumedtohavealong-term\nsecret x and an associated public key Q = [x]\u00b7P. One should note the similarity of this pro-\ntocoltotheSchnorrsignatureschemeabove.\nVerifier Prover\nk \u2190 Z\/qZ\nr\n\u2190\u2212\u2212 R \u2190 [k]\u00b7P\ne \u2190 Z\/qZ \u2212\u2212\u2192e\ns\n\u2190\u2212\u2212 s \u2190 (k +e\u00b7x) (mod q)\n?\nR = [s]\u00b7P \u2212e\u00b7Q\nIndeed, the conversion of the Schnorr authentication protocol into the Schnorr signature\nscheme is an example of the Fiat\u2013Shamir transform, which transforms any \u03a3-protocol into\nasignaturescheme.Iftheunderlying\u03a3-protocolissecure,inthesenseofazero-knowledge\nproofsofknowledge(seeSection10.9.3),thentheresultingsignatureschemeisUF-CMA.\n10.8.2 Key Agreement Protocols\nA key agreement protocol allows two parties to agree on a secret key for use in subsequent\nprotocols. The security requirements of key agreement protocols are very subtle, leading to\nvarious subtle security properties that many deployed protocols may or may not have. We\nrecaponbasicpropertiesofkeyagreementprotocolshere,butamorecompletediscussion\ncanbefoundin[994].Thebasicsecurityrequirementsare\n\u2022 The underlying key should be indistinguishable from random to the adversary, or that\nat least it should be able to be used in the subsequent protocol without the adversary\nbreakingthesubsequentprotocol.\n\u2022 Each party is assured that only the other party has access to the secret key. This is\nso-calledmutualauthentication.Inmanyapplicationscenarios(e.g.inthestandardap-\nplicationofTransportLayerSecurity(TLS)towebbrowsingprotocol),oneonlyrequires\nthis property of one-party, in which case we are said to only have one-way authentica-\ntion.\nKerberos is an example of a (usually) symmetric key-based key agreement system. This is\na protocol that requires trusted parties to relay and generate secret keys from one party to\nanother. It is most suited to closed corporate networks. On the public internet, protocols\nlike Kerberos are less useful. Thus, here one uses public key-based protocols such as TLS\nandIPSec.Moreadvancedpropertiesrequiredofmodernpublickey-basedprotocolsareas\nfollows.\n\u2022 Key Confirmation:Thepartiesknowthattheotherpartyhasreceivedthesamesecret\nkey.Sometimesthiscanbeeliminatedasthecorrectexecutionofthesubsequentpro-\ntocolusingthesecretkeyprovidesthisconfirmation.Thislaterprocessiscalledimplicit\nkeyconfirmation.\nKACryptography |October2019 Page344 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n\u2022 ForwardSecrecy:Thecompromiseofaparticipant\u2019slong-termsecretinthefuturedoes\nnot compromise the security of the secret key derived now, i.e. current conversations\narestillsecureinthefuture.\n\u2022 Unknown Key Share Security: This prevents one party (Alice) sharing a key with Bob,\nwhereasBobthinkshesharesakeywithCharlie,despitesharingitwithAlice.\nVariations on the theme of key agreement protocols include group key agreement, which\nenablesagroupofuserstoagreeonakey,orpasswordbasedkeyagreement,inwhichtwo\npartiesonlyagreeona(highentropy)keyiftheyalsoagreeonasharedpassword.\n10.8.2.1 KeyTransport\nThemostbasicformofkeyagreementprotocolisaformofkeytransportinwhichtheparties\nusepublickeyencryptiontoexchangearandomkey.Inthecaseofaone-wayauthenticated\nprotocol,thiswasthetraditionalmethodofTLSoperation(upuntilTLSversion1.2)between\naserverandaclient\nClient Server\npk\n\u2190\u2212\u2212\nk \u2190 K\nc\nc \u2190 Enc(k,pk;r) \u2212\u2212\u2192\nk \u2190 Dec(c,sk)\nThisprotocolproducedthepre-mastersecretinolderversionsofTLS(pre-TLS1.2).Toderive\nthe final secret in TLS, further nonces were exchanged between the parties (to ensure that\nboth parties were alive and the key was fresh). Then, a master secret was derived from the\npre-mastersecretandthenonces.Finally,keyconfirmationwasprovidedbytheentireproto-\ncol transcript being hashed and encrypted under the master secret (the so-called FINISHED\nmessage). In TLS, the resulting key is not indistinguishable from random as the encrypted\nFINISHEDmessageprovidestheadversarywithatrivialchecktodeterminewhetherakeyis\nreal or not. However, the protocol can be shown to be secure for the purposes of using the\nmastersecrettoproduceasecurebi-directionalchannelbetweentheserverandtheclient.\nAmorebasicissuewiththeaboveprotocolisthatitisnotforward-secure.Anyadversarywho\nrecords a session now, and in the future manages to obtain the server\u2019s long-term secret sk,\ncanobtainthepre-mastersecret,andhencedecrypttheentiresession.\n10.8.2.2 Diffie\u2013HellmanKeyAgreement\nToavoidtheissueswithforwardsecrecyofRSA-basedkeytransport,modernprotocolsmake\nuseofDiffie\u2013Hellmankeyexchange.Thisallowstwopartiestoagreeonauniformlyrandom\nkey,whichisindistinguishablefromrandomassumingtheDecisionDiffie\u2013Hellmanproblem\nishard\nAlice Bob\na \u2190 Z\/qZ b \u2190 Z\/qZ\nQ \u2190 [a]\u00b7P \u2212\u2212Q \u2192A\nA\n\u2190Q \u2212B\u2212 Q \u2190 [b]\u00b7P\nB\nK \u2190 [a]\u00b7Q K \u2190 [b]\u00b7Q\nB A\nThis protocol provides forward secrecy, but provides no form of authentication. Due to this,\nthe protocol suffers from a man-in-the-middle attack. To obtain mutual authentication, the\nmessage flow of Q is signed by Alice\u2019s public key and the message flow of Q is signed\nA B\nKACryptography |October2019 Page345 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nby Bob\u2019s public key. This prevents the man-in-the-middle attack. However, since the signa-\ntures are not bound into the message, the signed-Diffie\u2013Hellman protocol suffers from an\nunknown-key-shareattack;anadversary(Charlie)canstripAlice\u2019ssignaturefromQ andre-\nA\nplaceitwiththeirsignature.Theadversarydoesnotlearnthesecret,butdoesconvinceBob\nheistalkingtoanotherentity.\nTheone-wayauthenticatedversionofDiffie\u2013Hellmankeyagreementisthepreferredmethod\nof key agreement in modern TLS deployments, and is the only method of key agreement\nsupported by TLS 1.3. In TLS, the FINISHED message, which hashes the entire transcript,\nprevents the above unknown-key-share attack. However, it also prevents the protocol from\nproducingkeyswhichareindistinguishablefromrandom,asmentionedabove.\n10.8.2.3 Station-to-StationProtocol\nThe Station-to-Station (STS) protocol can be used to prevent unknown-key-share attacks\non signed Diffie\u2013Hellman and maintain key indistinguishability. In this protocol, the Diffie\u2013\nHellman derived key is used to encrypt the signatures, thus ensuring the signatures cannot\nbe stripped off the messages. In addition, the signatures are applied to the transcript so as\ntoconvincebothreceivingpartiesthattheotherpartyis\u2018alive\u2019.\nAlice Bob\na \u2190 Z\/qZ b \u2190 Z\/qZ\nQ \u2190 [a]\u00b7P \u2212\u2212Q \u2192A\nA\nQ \u2190 [b]\u00b7P\nB\nK \u2190 [b]\u00b7Q\nA\n\u03c3 \u2190 Sign({Q ,Q },sk )\nB B A B\n\u2190Q \u2212B\u2212,c \u2212B\u2212 c \u2190 Enc (\u03c3 )\nB K B\nK \u2190 [a]\u00b7Q\nB\n\u03c3 \u2190 Dec (c )\nB K B\n?\nVerify({Q ,Q },\u03c3 ,pk ) = true\nB A B B\n\u03c3 \u2190 Sign({Q ,Q },sk )\nA A B A\nc \u2190 Enc (\u03c3 ) \u2212\u2212c \u2192A\nA K A\n\u03c3 \u2190 Dec (c )\nA K A\n?\nVerify({Q ,Q },\u03c3 ,pk ) = true\nA B A A\n10.9 ADVANCED PROTOCOLS\n[980,c20\u2013c22]\nModern cryptography has examined a number of more complex protocols to achieve more\ncomplexends.Forexample,securee-votingschemes,secureauctions,datastorageandre-\ntrieval, etc. Most of these advanced protocols are either based on the simpler components\ndescribedinthissectionand\/orontheencryptionandsignatureschemeswithspecialprop-\nerties discussed in the next section. Here we restrict ourselves to discussing three widely\nneededprotocols:ObliviousTransfer,Zero-KnowledgeandMulti-PartyComputation.\nKACryptography |October2019 Page346 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n10.9.1 Oblivious Transfer\nWhile Oblivious Transfer (OT) is at the heart of many advanced protocols, it is a surprisingly\nsimple primitive which enables one to accomplish various more complex tasks. In the fol-\nlowing, we describe the basic 1-out-of-2 Oblivious Transfer, but extensions to n-out-of-m are\nimmediate.Inallcases,theprotocolisoneexecutedbetweenaSenderandaReceiver.\nIn a 1-out-of-2 Oblivious Transfer, the Sender has two messages m and m , whilst the Re-\n0 1\nceiver has an input bit b. The output of the protocol should be the message m for the Re-\nb\nceiver,andtheSenderobtainsnooutput.Inparticular,theReceiverlearnsnothingaboutthe\nmessagem ,whilsttheSenderlearnsnothingaboutthebitb.\n1\u2212b\nThispassivelysecureprotocolcanbeimplementedasfollows.WeassumetheSender\u2019smes-\nsagesaretwoelementsM andM inanellipticcurvegroupE(F )ofprimeorderq.\n0 1 p\nSender Receiver\nC \u2190 E(F ) \u2212C \u2192\np\nx \u2190 (Z\/qZ)\nQ \u2190 [x]\u00b7P\nb\nQ \u2190 C \u2212Q\n1\u2212b b\n\u2190Q \u22120\nQ \u2190 C \u2212Q\n1 0\nk \u2190 (Z\/qZ)\nC \u2190 [k]\u00b7P\n1\nE \u2190 M +[k]\u00b7Q\n0 0 0\nE \u2190 M +[k]\u00b7Q\n1 1 1\nC1\u2212,E \u21920,E1\nM \u2190 E \u2212[x]\u00b7C\nb b 1\nThe extension to an actively secure protocol is only a little more complex, but beyond the\nscopeofthisarticle.\n10.9.2 Private Information Retrieval and ORAM\nA Private Information Retrieval (PIR) protocol is one which enables a computer to retrieve\ndata from a server held database, without revealing the exact item which is retrieved. If the\nserver has n data items then this is related to a 1-out-of-n OT protocol. However, in PIR we\ndo not insist that the user does not learn anything else about the servers data, we only care\naboutprivacyoftheuserquery.InadditionprotocolsforPIRaremeanttoberunmanytimes,\nandweareinterestedinhidingthetotalsetofaccesspatterns,i.e.evenwhetheradataitem\nis retrieved multiple times. The goal of PIR protocols is to obtain greater efficiency than the\ntrivialsolutionoftheserversendingtheusertheentiredatabase.\nAnObliviousRandomAccessMemory(ORAM)protocolissimilarbutnowwenotonlyallow\ntheusertoobliviouslyreadfromtheserver\u2019sdatabase,wealsoallowtheusertowritetothe\ndatabase. So as to protect the write queries the server held database must now be held in\nan encrypted form (so what is written cannot be determined by the server). In addition the\nKACryptography |October2019 Page347 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\naccess patterns, i.e. where data is written to and read from, needs to be hidden from the\nserver.\n10.9.3 Zero-Knowledge\nA Zero-Knowledge protocol is a protocol executed between a Prover and a Verifier in which\nthe Prover demonstrates that a statement is true, without revealing why the statement is\ntrue. The concept is used in many places in cryptography, to construct signature schemes,\nto attest ones identity, and to construct more advanced protocols. An introduction to the\nmore theoretical aspects of zero-knowledge can be found in [982]. More formally, consider\nan NP language L (i.e. a set of statements x which can be verified to be true in polynomial\ntimegivenawitnessorproofw).AninteractiveproofsystemforLisasequenceofprotocol\nexecutions by an (infinitely powerful) Prover P and a (probabilistic polynomial time) Verifier\nV,whichonjointinputxproceedsasfollows:\nVerifier Prover\n\u2190p1\u2212 (p ,s(cid:48)) \u2190 P (x)\n1 1 1\n(v ,s ) \u2190 V (x,p ) \u2212v \u21921\n1 1 1 1\n\u2190p2\u2212 (p ,s(cid:48)) \u2190 P (s(cid:48),v )\n2 2 2 1 1\n(v ,s ) \u2190 V (s ,p ) \u2212v \u21922\n2 2 2 1 2\n\u2190p3\u2212 (p ,s(cid:48)) \u2190 P (s(cid:48),v )\n3 3 3 2 2\n. .\n. .\n. .\n\u2212p \u2192r (p ,s(cid:48)) \u2190 P (s ,v )\nr r r r1 r1\nBy the end of the protocol, the Verifier will output either true or false. An interactive proof\nsystemisonewhichisbothcompleteandsound\n\u2022 Completeness:Ifthestatementxistrue,i.e.x \u2208 L,theniftheProverishonestthenthe\nVerifierwilloutputtrue.\n\u2022 Soundness: If the statement is false, i.e. x (cid:54)\u2208 L, then no cheating Prover can convince\ntheVerifierwithprobabilitygreaterthanp.\nNote that even if p is large (say p = 0.5) then repeating the proof multiple times can reduce\nthesoundnessprobabilitytoanythingdesired.Ofcourse,protocolswithsmallptostartwith\naregoingtobemoreefficient.\nFor any NP statement, there is a trivial interactive proof system. Namely, the Prover simply\nsends over the witness w which the Verifier then verifies. However, this reveals the witness.\nIn a zero-knowledge proof, we obtain the same goal, but the Verifier learns nothing bar the\nfactthatx \u2208 L.Toformallydefinezero-knowledge,weinsistthatthereisa(probabilisticpoly-\nnomial time) simulator S which can produce protocol transcripts identical to the transcripts\nproduced between a Verifier and an honest Prover; except the simulator has no access to\nthe Prover. This implies that the Verifier cannot use the transcript to perform any other task,\nsincewhatitlearnedfromthetranscriptitcouldhaveproducedwithouttheProverbysimply\nrunningthesimulator.\nAzero-knowledgeproofissaidtobeperfectzero-knowledgeifthedistributionoftranscripts\nproduced by the simulator is identical to those produced between a valid prover and verifier.\nKACryptography |October2019 Page348 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nIfthetwodistributionsonlycannotbedistinguishedbyanefficientalgorithmwesaywehave\ncomputationalzero-knowledge.\nAzero-knowledgeproofissaidtobeaproofofknowledgeifaVerifiergivenrewindingaccess\nto the prover (i.e. the Verifier can keep resetting the Prover to a previous protocol state and\ncontinue executing) can extract the underlying witness w. This implies that the Prover must\n\u2018know\u2019w sincewecanextractw fromit.\nAnon-interactivezero-knowledgeproof isoneinwhichthereisnomessageflowingfromthe\nVerifier to the Prover, and only one message flowing from the Prover to the Verifier. Such\nnon-interactive proofs require additional setup assumptions, such as a Common Reference\nString (CRS), or they require one to assume the Random Oracle Model. Traditionally these\nare applied to specific number theoretic statements, such to show knowledge of a discrete\nlogarithm (see the next section on \u03a3-protocols), however recently so called Succinct Non-\nInteractiveArgumentsofKnowledge(SNARKs)havebeendevelopedwhichenablesuchnon-\ninteractiveargumentsformorecomplexstatements.SuchSNARKsarefindingapplications\ninsomeblockchainsystems.\n10.9.3.1 \u03a3-Protocols\nTheearlier\u03a3-protocolforidentificationisazero-knowledgeproofofknowledge.\nVerifier Prover\nk \u2190 Z\/qZ\nR\n\u2190\u2212\u2212 R \u2190 [k]\u00b7P\ne \u2190 Z\/qZ \u2212\u2212\u2192e\ns\n\u2190\u2212\u2212 s \u2190 (k +e\u00b7x) (mod q)\n?\nR = [s]\u00b7P \u2212e\u00b7Q\nThe protocol is obviously complete since Q = [x] \u00b7 P, and the soundness error is 1\/q. That\nit is zero-knowledge follows from the following simulation, which first samples e,s \u2190 Z\/qZ\nandthencomputesR = [s]P \u2212e\u00b7Q;theresultingsimulatedtranscriptbeing(R,e,s).Namely,\nthesimulatorcomputesthingsinthewrongorder.\nThe protocol is also a proof of knowledge since if we execute two protocol runs with the\nsame R value but different e-values (e and e ) then we obtain two s-values (s and s ). This\n1 2 1 2\nisdonebyrewindingtheprovertojustafterithassentitsfirstmessage.Ifthetwoobtained\ntranscripts(R,e ,s )and(R,e ,s )arebothvalidthenwehave\n1 1 2 2\nR = [s ]\u00b7P \u2212e \u00b7Q = [s ]\u00b7P \u2212e \u00b7Q\n1 1 2 2\nandso\n[s \u2212s ]\u00b7P = [e \u2212e ]\u00b7Q\n1 2 1 2\nandhence\n(cid:20) (cid:21)\ns \u2212s\n1 2\nQ = \u00b7P\ne \u2212e\n1 2\nandhencewe\u2018extract\u2019thesecretxfromx = (s \u2212s )\/(e \u2212e ) (mod q).\n1 2 1 2\nKACryptography |October2019 Page349 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n10.9.4 Secure Multi-Party Computation\nMulti-Party Computation (MPC) is a technique to enable a set of parties to compute on\ndata,withoutlearninganythingaboutthedata.ConsidernpartiesP ,...,P eachwithinput\n1 n\nx ,...,x . MPC allows these parties to compute any function f(x ,...,x ) of these inputs\n1 n 1 n\nwithout revealing any information about the x to each other, bar what can be deduced from\ni\nthe output of the function f. A general introduction to the theory of such protocols can be\nfoundin[983].\nInanMPCprotocol,weassumethatasubsetofthepartiesAiscorrupt.Instaticallysecure\nprotocols,thissetisdefinedatthestartoftheprotocol,butremainsunknowntothehonest\nparties. In an adaptively secure protocol, the set can be chosen by the adversary as the pro-\ntocol progresses. An MPC protocol is said to be passively secure if the parties in A follow\ntheprotocol,buttrytolearndataaboutthehonestparties\u2019inputsfromtheirjointview.Inan\nactivelysecureprotocol,thepartiesinAcanarbitrarilydeviatefromtheprotocol.\nAn MPC protocol should be correct, i.e. it outputs the correct answer if all parties follow\nthe protocol. It should also be secure, i.e. the dishonest parties should learn nothing about\nthe inputs of the honest parties. In the case of active adversaries, a protocol is said to be\nrobust if the honest parties will obtain the correct output, even when the dishonest parties\ndeviatefromtheprotocol.Aprotocolwhichisnotrobust,butwhichabortswithoverwhelming\nprobabilitywhenadishonestpartydeviates,issaidtobeanactivelysecureMPCprotocolwith\nabort.\nMPC protocols are catagorized by whether they utilize information-theoretic primitives\n(namelysecretsharing),ortheyutilizecomputationallysecureprimitives(suchassymmetric-\nkey and public-key encryption). They are also further characterized by the properties of the\nset A. Of particular interest is when the size t of A is bounded by a function of n (so-called\nthreshold schemes). The cases of particular interest are t < n, t < n\/2, and t < n\/3; the\nthreshold cases of t < n\/2 and t < n\/3 can be generalized to Q and Q access structures,\n2 3\nasdiscussedinSection10.3.2.\nIn the information-theoretic setting, one can achieve passively secure MPC in the case of\nt < n\/2(orQ accessstructures).ActivelysecurerobustMPCispossibleintheinformation-\n2\ntheoretic setting when we have t < n\/3 (or Q access structures). All of these protocols\n3\nare achieved using secret sharing schemes. A detailed study of secret sharing based MPC\nprotocolsisgivenin[995].\nIn the computational setting, one can achieve actively secure robust computation when t <\nn\/2, using Oblivious Transfer as the basic computational foundation. The interesting case\nof two party computation is done using the Yao protocol. This protocol has one party (the\nCircuit Creator, also called the Garbler) \u2018encrypting\u2019 a boolean function gate by gate using a\ncipher such as AES, the circuit is then sent to the other party (called the Circuit Evaluator).\nThe Evaluator then obtains the \u2018keys\u2019 for their input values from the Creator using Oblivious\nTransfer,andcanthenevaluatethecircuit.AdetailedstudyoftwopartyYaobasedprotocols\nisgivenin[996].\nModern MPC protocols have looked at active security with abort in the case of t < n. The\nmodernprotocolsaredividedintoafunction-dependentofflinephase,whichrequirespublic\nkeyfunctionalitybutwhichisfunctionindependent,thenafunction-dependentonlinephase\nwhich mainly uses information-theoretic primitives. Since information theoretic primitives\nare usually very fast, this means the time-critical online phase can be executed as fast as\npossible.\nKACryptography |October2019 Page350 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n10.10 PUBLIC KEY ENCRYPTION\/SIGNATURES WITH\nSPECIAL PROPERTIES\n[979,c13]\nA major part of modern cryptography over the last twenty years has been the construction\nofencryptionandsignaturealgorithmswithspecialpropertiesoradvancedfunctionalities.A\nnumberof thefollowinghavebeendeployedin specializedsystems(for example,U-PROVE,\nIDEMIX, attestation protocols and some crypto-currencies). We recap the main variants be-\nlow,givingforeachonethebasicideabehindtheirconstruction.\n10.10.1 Group Signatures\nA group signature scheme defined a group public key pk, associated to a number of secret\nkeyssk ,...,sk .ThepublickeyisusuallydeterminedbyanentitycalledaGroupManager,dur-\n1 n\ninganinteractionwiththegroupmembers.Givenagroupsignatures,onecannottellwhich\nsecretkeysignedit,althoughoneisguaranteedthatonedid.Thusgroupsignaturesprovide\nthe anonymity of a Signer. Most group signature algorithms have a special entity called an\nOpener who has some secret information which enables them to revoke the anonymity of a\nSigner. This last property ensures one can identify group members who act dishonestly in\nsomeway.\nA group signature scheme can either support static or dynamic groups. In a static group\nsignaturescheme,thegroupmembersarefixedatthestartoftheprotocol,whenthepublic\nkeyisfixed.Inadynamicgroupsignatureschemethegroupmanagercanaddmembersinto\nthegroupastheprotocolproceeds,and(often)revokemembersaswell.\nAnexampleofthistypeofsignatureschemewhichiscurrentlydeployedistheDirectAnony-\nmousAttestation(DAA)protocol;whichisessentiallyagroupsignatureschemeinwhichthe\nOpenerisreplacedwithaformofusercontrolledlinkability;i.e.asignercandecidewhether\ntwosignaturesoutputbythespecificsignercanbelinkedornot.\n10.10.2 Ring Signatures\nAringsignatureschemeismuchlikeagroupsignaturescheme,butinaringsignaturethereis\nnogroupmanager.Eachuserinaringsignatureschemehasapublic\/privatekeypair(pk ,sk ).\ni i\nAt the point of signing, the Signer selects a subset of the public keys (containing this own),\nwhichiscalledaringofpublickeys,andthenproducesasignature.TheReceiverknowsthe\nsignaturewasproducedbysomeoneinthering,butnotwhichmemberofthering.\nKACryptography |October2019 Page351 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n10.10.3 Blind Signatures\nA blind signature scheme is a two party protocol in which a one party (the User) wants to\nobtain the signature on a message by a second party (the Signer). However, the Signer is\nnotallowedtoknowwhichmessageisbeingsigned.Forexample,theSignermaybesimply\nnotarising that something happened, but does not need to know precisely what. Security\nrequiresthattheSignershouldnotlearnanythingaboutanymessagepassedtoitforsigning,\nandtheusershouldnotobtainthesignatureonanymessageotherthanthosetheysubmitted\nforsigning.\n10.10.4 Identity-Based Encryption\nInnormalpublickeyencryption,auserobtainsapublickeypk,alongwithacertificateC.The\ncertificateisproducedbyatrustedthirdparty,andbindsthepublickeytotheidentity.Usually,\nacertificateisadigitallysignedstatementcontainingthepublickeyandtheassociateduser\nidentity. So, when sending a message to Alice the Sender is sure that Alice is the legitimate\nholderofpublickeypk.\nIdentity Based Encryption (IBE) is an encryption scheme which dispenses with the need for\ncertificate authorities, and certificates. To encrypt to a user, say Alice, we simply use her\nidentity Alice as the public key, plus a global \u2018system\u2019 public key. However, to enable Alice to\ndecrypt,wemusthaveatrustedthirdparty,calledaKeyGenerationCentre,whichcanprovide\nAlicewithhersecretkey.Thisthirdpartyusesitsknowledgeofthe\u2018system\u2019secretkeytobe\nabletoderiveAlice\u2019ssecretkey.Whilstdispensingwithcertificates,anIBEsysteminherently\nhasanotionofkeyescrow;theKeyGenerationCentrecandecryptallmessages.\n10.10.5 Linearly Homomorphic Encryption\nIn a linearly homomorphic encryption scheme one can perform a number of linear opera-\ntionsonciphertexts,whichresultinaciphertextencryptingamessagehavinghadthesame\noperations performed on the plaintext. Thus, given two encryptions c \u2190 Enc(m ,pk;r ) and\n1 1 1\nc \u2190 Enc(m ,pk;r )onecanforma\u2018sum\u2019operationc \u2190 c \u2295c suchthatcdecryptstom +m .\n2 2 2 1 2 1 2\nThe standard example of such encryption schemes is the Paillier encryption scheme, which\nencrypts elements m \u2208 (Z\/NZ), for an RSA-modulus N by computing c \u2190 (1 + N)m \u00b7 rN\n(mod N2)wherer isselectedinZ\/NZ.\nSuchencryptionalgorithmscanneverbeIND-CCAsecure,asthehomomorphicpropertypro-\nducesatrivialmalleabilitywhichcanbeexploitedbyaCCAattacker.However,theycanhave\napplications in many interesting areas. For example, one can use a linearly homomorphic\nencryptionschemetoaddupvotesinadigitallyballotedelectionfortwocandidates,where\neachvoteisanencryptionofeitherthemessagezeroorone.\nKACryptography |October2019 Page352 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n10.10.6 Fully Homomorphic Encryption\nFullyHomomorphicEncryption(orFHE)isanextensiontolinearlyhomomorphicencryption,\ninthatonecannotonlyhomomorphicallyevaluatelinearfunctions,butalsonon-linearones.\nIn particular, the ability to homomorphically evaluate both addition and multiplication on en-\ncrypteddataenablesoneto(theoretically)evaluateanyfunction.ApplicationsofFHEwhich\nhave been envisioned are things such as performing complex search queries on encrypted\nmedicaldataetc.Thus,FHEisveryinterestinginacloudenvironment.\nAll existing FHE schemes are highly inefficient. Thus only very simple functions can be eval-\nuated in suitable time limits. A scheme which can perform homomorphic operations from\na restricted class of functions (for example, to homomorphically evaluate all multi-variate\npolynomials of total degree five) is called a Somewhat Homomorphic Encryption (or SHE)\nscheme. Obviously, if the set of functions are all multi-variate polynomials of degree one,\nthentheSHEschemeisalinearhomomorphicencryptionscheme.\n10.11 IMPLEMENTATION ASPECTS\nTherearetwoaspectsoneneedstobearinmindwithrespecttocryptographicimplementa-\ntion.Firstlysecurityandsecondlyperformance.\nIntermsofsecuritythemainconcernisoneofside-channelattacks.Thesecanbemounted\nagainstbothhardwareimplementations,forexamplecryptographiccircuitsimplementedon\nsmart-cards, or against software implementations running on commodity processors. Any\nmeasurabledifferencewhichoccurswhenrunninganalgorithmononesetofinputsversus\nanother can lead to an attack. Such measurements may involve timing differences, power\ncomsumption differences, differences in electromagnetic radiation, or even differences in\nthe sound produced by the fan on the processor. It is even possible to mount remote side-\nchannel attacks where one measures differences in response times from a remote server.\nA good survey of such attacks, focused on power analysis applied to symmetric algorithms\nsuchasAES,canbefoundin[997].\nTo protect against such side-channel attacks at the hardware level various techniques have\nbeenproposedincludingutilizingtechniquesbasedonsecret-sharing(calledmaskinginthe\nside-channelcommunity).Intheareaofsoftwareoneneedstoensurecodeisconstant-time\nattheleast(i.e.everyexecutionpathtakesthesameamountoftime),indeedhavingmultiple\nexecutionpathscanitselfleadtoattacksviapower-analysis.\nTo enable increased performance it is becoming increasingly common for processor manu-\nfacturerstosupplyspecialinstructionstoenableimprovementstocryptographicalgorithms.\nThisissimilartothemulti-mediaextensionswhichhavebeencommonplaceforotherappli-\ncationsforsomedecades.Anexampleofthisisspecialinstructionsonx86chipstoperform\noperationsrelatedtoAES,toperformGCM-modeandtoperformsomeECCoperations.\nPublic key, i.e. number theoretic constructions, are particularly expensive in terms of com-\nputationalresources.Thusitiscommonforthesespecificalgorithmstobeimplementedin\nlow level machine code, which is tuned to a specific architecture. However, this needs to be\ndonewithcaresoastotakeintoaccounttheearliermentionedside-channelattacks.\nFinally an implementation can also be prone to fault attacks. These are attacks in which an\nattackerinjectsfaults(eitherphysicalfaultsonhardware,ordatagramfaultsintoaprotocol).\nKACryptography |October2019 Page353 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nDefencesagainstsuchattacksneedtobeconsideredincludingstandardfaulttolerentcom-\nputing approaches in hardware, and full input validation in all protocols. Further details on\nfaultattackscanbefoundin[998].\nCROSS-REFERENCE OF TOPICS VS REFERENCE MATERIAL\nThe two main textbooks below we cross-reference against the main sections here. Further\ntopicspecificreadingisgivenbyreferencestothemainbibliography.\n10.1Mathematics c8\u2013c9,AppB c1\u2013c5 [981]\n10.2CryptographicSecurityModels c1\u2013c4 c11 [982,983,984,985]\n10.3Information-theoreticallySecure\nc2 c19 [986]\nConstructions\n10.4SymmetricPrimitives c3\u2013c6 c11\u2013c14 [987,988,989,990,991]\n10.5SymmetricEncryptionand\nc3\u2013c4 c13\u2013c14 [991,992]\nAuthentication\n10.6PublicKeyEncryption c11 c15\u2013c17 [981,993]\n10.7PublicKeySignatures c12 c16 [981,993]\n10.8StandardProtocols \u2013 c18 [994]\n10.9AdvancedProtocols \u2013 c20\u2013c22 [982,983,995,996]\n10.10PublicKeyEncryption\/Signatures\nc13 \u2013\nWithSpecialProperties\n10.11ImplementationAspects \u2013 \u2013 [997,998]\nFURTHER READING\nThe following two text books are recommended to obtain further information on the topics\ninthisknowledgearea.Furthertopicspecificreadingisgiveninthebibliography.\nKACryptography |October2019 Page354\n]979[lledniLztaK\n]089[tramS\nrehtO TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nIntroduction to Modern Cryptography (J. Katz and Y. Lindell) [979]\nAstandardmoderntextbookcoveringaspectsofthedesignofcryptographicschemesfrom\naprovablesecurityperspective.\nCryptography Made Simple (N.P. Smart) [980]\nAtextbookwithlessmathematicalrigourthanthepreviouslymentionedone,butwhichalso\ncoversawiderrangeofareas(includingzero-knowledgeandMPC),andtouchesonaspects\nrelatedtoimplementation.\nKACryptography |October2019 Page355 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nKACryptography |October2019 Page356 Chapter 11\nOperating Systems and\nVirtualisation\nHerbert Bos Vrije Universiteit Amsterdam\n357 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nINTRODUCTION\nInthisKnowledgeArea,weintroducetheprinciples,primitivesandpracticesforensuringse-\ncurityattheoperatingsystemandhypervisorlevels.Weshallseethatthechallengesrelated\nto operating system security have evolved over the past few decades, even if the principles\nhave stayed mostly the same. For instance, when few people had their own computers and\nmost computing was done on multi-user (often mainframe-based) computer systems with\nlimitedconnectivity,securitywasmostlyfocusedonisolatingusersorclassesofusersfrom\neachother1.Isolationisstillacoreprincipleofsecuritytoday.Eventheentitiestoisolatehave\nremained, by and large, the same. We will refer to them as security domains. Traditional se-\ncuritydomainsforoperatingsystemsareprocessesandkernels,andforhypervisors,Virtual\nMachines (VMs). Although we may have added trusted execution environments and a few\nothersecuritydomainsinrecentyears,westillhavethekernel,userprocessesandvirtualma-\nchinesasthemainsecuritydomainstoday.However,thethreatshaveevolvedtremendously,\nandinresponse,sohavethesecuritymechanisms.\nAsweshallsee,someoperatingsystems(e.g.,inembeddeddevices)donothaveanynotion\nof security domains whatsoever, but most distinguish between multiple security domains\nsuch as the kernel, user processes and trusted execution environments. In this Knowledge\nArea, we will assume the presence of multiple, mutually non-trusting security domains. Be-\ntween these security domains, operating systems manage a computer system\u2019s resources\nsuch as CPU time (through scheduling), memory (through allocations and address space\nmappings) and disk blocks (via file systems and permissions). However, we shall see that\nprotectingsuchtraditional,coarse-grainedresourcesisnotalwaysenoughanditmaybenec-\nessary to explicitly manage the more low-level resources as well. Examples include caches,\nTransaction Lookaside Buffers (TLBs), and a host of other shared resources. Recall that\nSaltzerandSchroeder\u2019sPrincipleofLeastCommonMechanism[8]statesthateverymecha-\nnismsharedbetweensecuritydomainsmaybecomeachannelthroughwhichsensitivedata\nmay leak. Indeed, all of the above shared resources have served as side channels to leak\nsensitiveinformationinattackscenarios.\nAs the most privileged components, operating systems and hypervisors play a critical role\ninmakingsystems(in)secure.Forbrevity,wemainlyusethetermoperatingsystemandpro-\ncesses in the remainder of this knowledge area and refer to hypervisors and VMs explicitly\nwherethedistinctionisimportant2.\nWhile security goes beyond the operating system, the lowest levels of the software stack\nformthebedrockonwhichsecurityisbuilt.Forinstance,theoperatingsystemmaybecapa-\nbleofexecutingprivilegedinstructionsnotavailabletoordinaryuserprogramsandtypically\noffers the means to authenticate users and to isolate the execution and files of different\nusers. While it is up to the application to enforce security beyond this point, the operating\nsystemguaranteesthatnon-authorisedprocessescannotaccessitsfiles,memory,CPUtime,\nor other resources. These security guarantees are limited by what the hardware can do. For\ninstance,ifaCPU\u2019sInstructionSetArchitecture(ISA)doesnothaveanotionofmultiplepriv-\nilege levels or address space isolation to begin with, shielding the security domains from\neachotherisdifficult\u2014althoughitmaystillbepossibleusinglanguage-basedprotection(as\nintheexperimentalSingularityoperatingsystem[1000]).\n1Asituation,incidentally,thatisnotunlikethatofsharedcloudstoday.\n2Targetedpublicationsaboutdevelopmentsinthreatsandsolutionsforvirtualisedenvironmentshaveap-\npearedelsewhere[999]\nKAOperatingSystemsandVirtualisation |October2019 Page358 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nThesecurityofferedby theoperatingsystemisalsothreatenedbyattacksthataimtoevade\nthe system\u2019s security mechanisms. For instance, if the operating system is responsible for\nthe separation between processes and the operating system itself gets compromised, the\nsecurityguaranteesarevoid.Thus,weadditionallyrequiresecurityof theoperatingsystem.\nAfter explaining the threat model for operating system security, we proceed by classifying\nthe different design choices for the underlying operating system structure (monolithic ver-\nsusmicrokernel-based,multi-serverversuslibraryOS,etc.),whichwethendiscussinrelation\ntofundamentalsecurityprinciplesandmodels.Next,wediscussthecoreprimitivesthatop-\nerating systems use to ensure different security domains are properly isolated and access\ntosensitiveresourcesismediated.Finally,wedescribeimportanttechniquesthatoperating\nsystemsemploytohardenthesystemagainstattacks.\n11.1 ATTACKER MODEL\n[1001,c1-c9][1002,c9][1003][999]\nWeassumethatattackersareinterestedinviolatingthesecurityguaranteesprovidedbythe\noperating system or hypervisor: leak confidential data (e.g., crypto keys), modify data that\nshouldnotbeaccessible(e.g.,toelevateprivileges)orlimittheavailabilityofthesystemand\nits services (e.g., by crashing the system or hogging its resources). In this knowledge area,\nwefocusonthetechnicalaspectsofsecurity,leavingasideinsiderthreats,humanbehaviour,\nphysical attacks, project management, company policies, etc. Not because they are not im-\nportant,butbecausetheyarebeyondOScontrolandwouldrequireaknowledgeareaoftheir\nown.Table11.1listssomeofthethreatsandattackmethodsthatwedoconsider.\nThesimplestwaytocompromisethesystemistoinjectamaliciousextensionintotheheart\nof the operating system. For instance, in monolithic systems such as Linux and Windows,\nthis could be a malicious driver or kernel module, perhaps inadvertently loaded as a Trojan,\nthathasaccesstoallprivilegedfunctionality[1004].Tomaintaintheirholdonthesystemina\nstealthymannerregardlessofwhattheoperatingsystemorhypervisormaydo,theattackers\nmay further infect the system\u2019s boot process (e.g., by overwriting the master boot record or\nthe Unified Extensible Firmware Interface (UEFI), firmware)\u2014giving the malicious code con-\ntrol over the boot process on every reboot, even before the operating system runs, allowing\nittobypassanyandalloperatingsystemleveldefenses[1005].\nBesides using Trojans, attackers frequently violate the security properties without any help\nfrom the user, by exploiting vulnerabilities. In fact, attackers may use a wide repertoire of\nmethods.Forinstance,theycommonlyabusevulnerabilitiesinthesoftware,suchasmemory\nerrors[1003]tochangecodepointersordataintheoperatingsystemandviolateitsintegrity,\nconfidentiality or availability. By corrupting a code pointer, they control where the program\nresumes execution after the call, jump or return instruction that uses the corrupted code\npointer. Changing data or data pointers opens up other possibilities, such as elevating the\nprivilege level of an unprivileged process to \u2018root\u2019 (giving all-powerful \u2019system\u2019 privileges) or\nmodifying the page tables to give a process access to arbitrary memory pages. Likewise,\nthey may use such bugs to leak information from the operating system by changing which\norhowmuchdataisreturnedforasystemcall,oranetworkrequest.\nAttackers may also abuse vulnerabilities in hardware, such as the Rowhammer bug present\nin many DRAM chips [1006]. Since bits in memory chips are organised in rows and packed\nvery closely together, accessing a bit in one row may cause the neighbouring bit in the ad-\nKAOperatingSystemsandVirtualisation |October2019 Page359 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nAttack Description\nMaliciousextensions Attackermanagestoconvincethesystemtoloadamaliciousdriver\norkernelmodule(e.g.,asaTrojan).\nBootkit Attackercompromisesthebootprocesstogaincontrolevenbefore\ntheoperatingsystemgetstorun.\nMemoryerrors(software) Spatialandtemporalmemoryerrorsallowattackers(localorremote)\ntodivertcontrolfloworleaksensitiveinformation.\nMemorycorruption(hardware) VulnerabilitiessuchasRowhammerinDRAMallowattackers(local\norremote)tomodifydatathattheyshouldnotbeabletoaccess.\nUninitaliseddataleakage Theoperatingsystemreturnsdatatouserprogramsthatisnotprop-\nerlyinitialisedandmaycontainsensitivedata.\nConcurrencybugsanddoublefetch Example: the operating system uses a value from userspace twice\n(e.g.,asizevalueisusedoncetoallocateabufferandlatertocopy\nintothatbuffer)andthevaluechangesbetweenthetwouses.\nSidechannels(hardware) Attackersuseaccesstimesofsharedresourcessuchascachesand\nTLBsstodetectthatanothersecuritydomainhasusedtheresource,\nallowingthemtoleaksensitivedata.\nSidechannels(speculative) Security checks are bypassed in speculative or out-of-order execu-\ntionandwhileresultsaresquashedtheyleaveameasurabletracein\nthemicro-architecturalstateofthemachine.\nSidechannels(software) Example: when operating systems \/ hypervisors use features such\nasmemorydeduplication,attackerscanmeasurethatanothersecu-\nritydomainhasthesamecontent.\nResourcedepletion(DoS) Byhoggingresources(memory,CPU,buses,etc.),attackersprevent\notherprogramsfrommakingprogress,leadingtoadenialofservice.\nDeadlocks\/hangs(DoS) Theattackerbringsthesystemtoastatewherenoprogresscanbe\nmadeforsomepartofthesoftware,e.g.,duetoadeadlock(DoS).\nTable11.1:Knownattackmethods\/threatstosecurityformodernoperatingsystems\nKAOperatingSystemsandVirtualisation |October2019 Page360 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\njacent row to leak a small amount of charge onto its capacitor\u2014even though that bit is in\na completely different page in memory. By repeatedly accessing the row at high frequency\n(\u2018hammering\u2019),theinterferenceaccumulatessothat,insomecases,theneighbouringbitmay\nflip.Wedonotknowinadvancewhich,ifany,ofthebitsinarowwillflip,butonceabitflips,\nit will flip again if we repeat the experiment. If attackers succeed in flipping bits in kernel\nmemory, they enable attacks similar to those based on software-based memory corruption.\nForinstance,corruptingpagetablestogainaccesstothememoryofotherdomains.\nAnotherclassofattacksisthatofconcurrencybugsanddoublefetch[1007,1008].Thedou-\nble fetch is an important problem for an operating system and occurs when it uses a value\nfrom userspace twice (e.g., a size value is used once to allocate a buffer and later to copy\nintothatbuffer).Securityissuessuchasmemorycorruptionariseifthereisaracebetween\nthe operating system and the attacker, and the attacker changes the userspace value in be-\ntween the two accesses and makes it smaller. It is similar to a Time Of Check Time Of Use\n(TOCTOU)attack,exceptthatthevaluemodifiedisused twice.\nInadditiontodirectattacks,adversariesmayusesidechannelstoleakinformationindirectly,\nforinstancebymeansofcachesidechannels[1009].Therearemanyvariants,butacommon\noneconsistsofattackersfillingacachesetwiththeirowndataorcodeandthenperiodically\naccessingtheseaddresses.Ifanyoftheaccessesissignificantlyslower,theywillknowthat\nsomeoneelse,presumablythevictim,alsoaccesseddata\/codethatfallsinthesamecache\nset.Nowassumethatthevictimcodecallsfunctionsinasecretdependentway.Forinstance,\nan encryption routine processes a secret key bit by bit and calls function foo if the bit is 0,\nandbarifitis1,wherefooandbarareindifferentcachesets.Bymonitoringwhichcache\nsetsareusedbythesidechannel,theattackersquicklylearnthekey.\nAnother famous family of hardware side channels abuses speculative and out-of-order exe-\ncution[1010,1011].Forperformance,modernCPUsmayexecuteinstructionsaheadoftime\u2014\nbefore the preceding instructions have been completed. For instance, while waiting for the\nconditionofaconditionalbranchtoberesolved,thebranchpredictormayspeculatethatthe\noutcomewillbe\u2018branchtaken\u2019(becausethatwastheoutcomeforthelastntimes),andspec-\nulativelyexecutetheinstructionscorrespondingtothetakenbranch.Ifitturnsoutthatitwas\nwrong, the CPU will squash all the results of the speculatively executed instructions, so that\nnone of the stores survive in registers or memory. However, there may still be traces of the\nexecution in the micro-architectural state (such as the content of caches, TLBs and branch\npredictors that are not directly visible in the instruction set architecture). For instance, if a\nspeculative instruction in a user program reads a sensitive and normally inaccessible byte\nfrommemoryinaregisterandsubsequentlyusesitasanoffsetinauserspacearray,thearray\nelement atthat offsetwill be inthe cache,eventhough the value inthe registeris squashed\nas soon as the CPU discovers that it should not have allowed the access. The attacker can\ntime the accesses to every element in the array and see if one is significantly faster (in the\ncache). The offset of that element will be the secret byte. In other words, the attacker can\nuseacachesidechanneltoextractthedatathatwasaccessedspeculatively.\nMore recent attacks show that the hardware vulnerabilities related to speculation and out-\nof-order execution may be more disastrous than we thought. The Foreshadow attack [1012]\nabuses the fact that Intel CPUs read from the Level 1 cache under speculative execution\nwheneveramemorypageismarkedasnotpresent\u2014withoutproperlycheckingtheownership\nof the data at that physical address. Worse, the vulnerability known as Rogue In-Flight Data\n(RIDL)[1013](thatattackerscanexploitwithoutprivileges,evenfromJavaScriptinbrowsers)\nand without caring about addresses, shows that Intel CPUs constantly feed speculatively\nKAOperatingSystemsandVirtualisation |October2019 Page361 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nexecutinginstructionswithdatafromarbitrarysecuritydomainsallthetime,viaavarietyof\ntemporarymicro-architecturalbuffers.\nMitigating these attacks require not just changes in the hardware but also deep and often\ncomplexinvolvementoftheoperatingsystem.Forinstance,theoperatingsystemmayneed\ntoflushcachesandbuffersthatcouldleakdata,provideguaranteesthatnospeculationtakes\nplaceacrosscertainbranches,orscheduledifferentsecuritydomainsonseparatecores,etc.\nBesides caches, hardware side channels can use all kinds of shared resources, including\nTLBs, MMUs, and many other components [1014]. Indeed, side channels need not be hard-\nwarerelatedatall.Forinstance,memorydeduplicationandpagecaches,bothimplemented\nin the operating system, are well-known sources for side channels. Focusing on the former\nfor illustration purposes, consider a system that aggressively deduplicates memory pages:\nwhenever it sees two pages with the same content, it adjusts the virtual memory layout so\nthat both virtual pages point to the same physical page. This way, it needs to keep only one\nof the physical pages to store the content, which it can share in a copy-on-write fashion. In\nthat case, a write to that page takes longer (because the operating system must copy the\npage again and adjust its page table mappings), which can be measured by an attacker. So,\nifawritetopagetakessignificantlylonger,theattackerknowsthatsomeotherprogramalso\nhasacopyofthatcontent\u2014asidechannelthattellstheattackersomethingaboutavictim\u2019s\ndata.Researchershaveshownthatattackersmayusesuchcoarse-grainedsidechannelsto\nleakevenveryfine-grainedsecrets[1015].Inmanyofthesidechannels,theissueisalackof\nisolationbetweensecuritydomainsinsoftwareandinhardware(e.g.,theremaybenoortoo\nlittleisolationduringhardware-implementedspeculativeexecution).Itisimportanttorealise\nthatdomainisolationissuesextendtothehardware\/softwareinterface.\nFor confidentiality in particular, information leaks may be subtle and seemingly innocuous,\nand still lead to serious security problems. For instance, the physical or even virtual ad-\ndresses of objects may not look like very sensitive information, until we take into account\ncode reuse [1016] or Rowhammer [1006] attacks that abuse knowledge of the addresses to\ndivertcontrolflowtospecificaddressesorflipspecificbits.\nAs for the origin of the attacks, they may be launched from local code running natively on\nthevictim\u2019smachineinuserspace,(malicious)operatingsystemextensions,scriptingcode\nfetched across the network and executed locally (such as JavaScript in a browser), mali-\ncious peripherals, or even remote systems (where attackers launch their exploit across the\nnetwork).Clearly,aremoteattackishardertocarryoutthanalocalone.\nIn some cases, we explicitly extend the attacker model to include malicious operating sys-\ntems or malicious hypervisors as well. These attackers may be relevant in cloud-based sys-\ntems, where the cloud provider is not trusted, or in cases where the operating system itself\nhas been compromised. In these cases, the goal is to protect the sensitive application (or a\nfragmentthereof),possiblyrunninginspecialhardware-protectedtrustedexecutionenviron-\nmentsorenclaves,fromthekernelorhypervisor.\nA useful metric for estimating the security of a system is the attack surface [1017]\u2014all the\ndifferent points that an attacker can reach and get data to or from in order to try and com-\npromisethesystem.Forinstance,fornativecoderunninglocally,theattacksurfaceincludes\nall the system calls the attacker can execute as well as the system call\u2019s arguments and re-\nturnvalues,togetherwithallthecodeimplementingthesystemcalls,whichtheattackercan\nreach. For remote attackers, the attack surface includes the network device drivers, part of\nthe network stack, and all the application code handling the request. For malicious devices,\nKAOperatingSystemsandVirtualisation |October2019 Page362 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntheattacksurfacemayincludeallthememorythedevicemayaccessusingDMAorthecode\nandhardwarefunctionswithwhichthedevicemayinteract.Note,however,thattheexposure\nof more code to attackers is only a proxy metric, as the quality of the code differs. In an ex-\ntreme case, the system is formally verified so that a wide range of common vulnerabilities\narenolongerpossible.\n11.2 THE ROLE OF OPERATING SYSTEMS AND THEIR\nDESIGN IN SECURITY\n[1002,c1,c7c9][1018,c1]\nAt a high level, operating systems and hypervisors are tasked with managing the resources\nofacomputersystemtoguaranteeafoundationonwhichitispossibletobuildsecureappli-\ncationswithrespecttoconfidentiality,integrityandavailability.\nThe main role of these lowest layers of the software stack with respect to security is to pro-\nvide isolation of security domains and mediation of all operations that may violate the iso-\nlation. In the ideal case, the operating system shields any individual process from all other\nprocesses. For instance, peripheral processes should not be able to access the memory al-\nlocated to the primary process, learn anything about the activities related to that primary\nprocess except those which the process chooses to reveal, or prevent the process from us-\ningitsallocatedresources,suchasCPUtimeindefinitely.Someoperatingsystemsmayeven\nregulatetheinformationflowssuchthattopsecretdatacanneverleaktoprocesseswithout\nthe appropriate clearance, or classified data cannot be modified by processes without the\nappropriateprivilegelevels.\nDigging a little deeper, we can distinguish between control and data plane operations and\nweseethatisolationinoperatingsystemsinvolvesboth.Inmemoryisolation,theoperating\nsystems operate at the control plane when it configures the MMU (memory management\nunit), which is then responsible for the isolation without much involvement by the operating\nsystem. In most other interactions, for instance when operating on arguments of system\ncallsprovidedbyunprivilegedsecuritydomains,anoperatingsystemoperatesatbothplanes.\nThe lack of separation between the planes may easily lead to vulnerabilities\u2014for instance,\nwhentheoperatingsystemdecidestoreusememorypagesthatpreviouslybelongedtoone\nsecurity domain (with access isolation enforced by the MMU) in another domain without\nproperlyoverwritingthe(possiblysensitive)dataonthatpage.\nTherearemanywaystodesignanoperatingsystem.Fig.11.1illustratesfourextremedesign\nchoices. In Fig. 11.1(a), the operating system and the application(s) run in a single security\ndomain and there is no isolation whatsoever. Early operating systems worked this way, but\nsodomanyembeddedsystemstoday.Inthiscase,thereislittletonoisolationbetweenthe\ndifferent components in the system and an application can corrupt the activities of the File\nSystem(FS),thenetworkstack,drivers,oranyothercomponentofthesystem.\nFig. 11.1(b) shows the configuration of most modern general-purpose operating systems,\nwhere most of the operating system resides in a single security domain, strictly isolated\nfromtheapplications,whileeachapplicationisalsoisolatedfromallotherapplications.For\ninstance, this is the structure of Windows Linux, OS X and many of the descendants of the\noriginalUNIX[1019].Sincealmosteverycomponentoftheoperatingsystemrunsinasingle\nsecuritydomain,themodelisveryefficientbecausethecomponentsinteractsimplybyfunc-\nKAOperatingSystemsandVirtualisation |October2019 Page363 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntioncallsandsharedmemory.Themodelisalsosafeaslongaseverycomponentisbenign.\nHowever, if attackers manage to compromise even a single component, such as a driver, all\nsecurityisvoid.Ingeneral,devicedriversandotheroperatingsystemextensions(e.g.,Linux\nKernel Modules) are important considerations for the security of a system. Often written by\nthirdpartiesandmorebuggythanthecoreoperatingsystemcode,extensionsrunninginthe\nsinglesecuritydomainoftheoperatingsystemmaycompromisethesecurityofthesystem\ncompletely.\nInterestingly,theboundarybetweenthekernelandothersecuritydomainsinsuchsystemsis\noftenabitfuzziernowthatoperatingsystemscanbypassthekernelfor,say,high-speednet-\nworking, or implement non performance critical operating system components as user pro-\ncesses. Examples include the File System in User Space (FUSE) in UNIX operating systems\nand the User Mode Driver Framework (UMDF) in Windows. Even so, most of the operating\nsystemfunctionalitystillformsasinglemonolithicsecuritydomain.\nFig. 11.1(c) shows the extreme breakup in separate processes of all the components that\nmakeuptheoperatingsysteminamulti-serveroperatingsystem[1020,1021].Theconfigura-\ntionispotentiallylessefficientthanthepreviousmodel,becausealltheinteractionsbetween\ndifferentcomponentsoftheoperatingsysteminvolveInter-ProcessCommunication(IPC).In\naddition, the operating system functions as a distributed system and anyone who has ever\nbuilt a distributed system knows how complicated the problems may get. However, the ad-\nvantage of a multi-server system is that a compromised driver, say, cannot so easily com-\npromise the rest of the system. Also, while from a conceptual perspective, the multi-server\nlooks like a distributed system, a lot of the complexity of a real distributed system is due to\nunreliablecommunicationandthisdoesnotexistinmulti-serversystems.Thecommonview\nis that microkernel-based multi-server designs have security and reliability advantages over\nmonolithic and single-domain designs, but incur somewhat higher overheads\u2014the price of\nsafety.\nFinally, Fig. 11.1(d) shows a situation that, at first glance, resembles that of Fig. 11.1(a): on\ntop of a minimal kernel that multiplexes the underlying resources, applications run together\nwith a minimal \u2018library operating system\u2019 (libOS [1022, 1023]). The libOS contains code that\nis typically part of the operating system, but is directly included with the application. This\nconfiguration allows applications to tailor the operating system exactly according to their\nneedsandleaveoutallthefunctionalitytheywerenotgoingtouseanyway.Libraryoperating\nsystems were first proposed in the 1990s (e.g., in MIT\u2019s Exokernel and Cambridge\u2019s Neme-\nsis projects). After spending a few years in relative obscurity, they are becoming popular\nagain\u2014especiallyinvirtualisedenvironmentswheretheyarecommonlyreferredtoasUniker-\nnels[1024].Intermsofsecurity,Unikernelsaredifficulttocompareagainst,say,microkernel-\nbased multi-server systems. On the one hand, they do not have the extreme separation of\noperating system components. On the other, they allow the (library) operating system code\nto be much smaller and less complex\u2014it only has to satisfy the needs of this one applica-\ntion.Moreover,thelibrarycannotcompromiseisolation:itispartofthisapplication\u2019strusted\ncomputingbaseandnoother.\nThe debate about which design is better goes back to the famous flame war between An-\ndrewS.TanenbaumandLinusTorvaldsin1992.Bythattime,MINIX[1025],asmallUNIX-like\noperating system developed by Tanenbaum, had been around for half a decade or so, and\nwas gaining traction as an education operating system around the world\u2014especially since\nBellLabs\u2019originalUNIXwassoldasacommercialproductwitharestrictivelicenseprohibit-\ning users from modifying it. One of MINIX\u2019s users was Torvalds, then a Finnish student who\nKAOperatingSystemsandVirtualisation |October2019 Page364 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nApplication Application Application Application\n1 2 1 2\nFS Network ... FS Network ... FS Network ...\nApp 1 App 2 App 3\nProcessMgr MemMgr ProcessMgr MemMgr ProcessMgr MemMgr\nlibOS libOS libOS\nScheduler Application Scheduler net disk ...\n(just bare (just bare (just bare\ndriver driver driver minimum) minimum) minimum)\nnet disk ... net disk ...\ndriver driver driver driver driver driver Scheduler Scheduler\nApplication(s) + OS Monolithic OS (Linux, Windows, ...) Microkernel-based multi-server OS Exokernel\/microkernel\/hypervisor\n(single domain) (multiple domains) (many domains) (many domains)\nHardware Hardware Hardware Hardware\n(a) (b) (c) (d)\nFigure 11.1: Extreme design choices for operating systems: (a) single domain (sometimes\nused in embedded systems), (b) monolithic OS (Linux, Windows, and many others), (c)\nmicrokernel-basedmulti-serverOS(e.g.,Minix-3)and(d)Unikernel\/LibraryOS\nannounced a new operating system kernel in a post in the comp.os.minix newsgroup on\nUsenet.InJanuary1992,Tanenbaumcriticisedthedesignforitslackofportability,andalso\ntookaimatLinux\u2019smonolithicdesign,claimingLinuxwasobsoletefromtheoutset.Torvalds\nrespondedwithhisowncriticismofMINIX.Thisheatedexchangecontainedincreasinglyso-\nphisticatedarguments,manyofwhichstillstandtoday,somuchsothatthequestionofwho\nwonthedebateremainsunanswered.\nThat said, Linux has become wildly popular and few people would consider it obsolete. It is\nalso clear that ideas from multi-server systems such as MINIX have been incorporated into\nexisting operating systems and hypervisor-based systems. Interestingly, at the time of writ-\ning even MINIX itself is running in hundreds of millions of Intel processors as a miniature\noperating system on a separate microprocessor known as the Management Engine. In ad-\ndition, now that the CPUs in modern systems are increasingly elaborate System on a Chips\n(SoCs),thehardwareitselfisstartingtolooklikeadistributedsystemandsomeresearchers\nexplicitly advocate designing the operating system accordingly, with a focus on message\npassingratherthanmemorysharingforcommunication[1026].\nThesituationforvirtualisedenvironments,ingeneral,iscomparabletothatofoperatingsys-\ntems.Wehavealreadyseenthatinoneextremecase,theentirevirtualmachinewiththeap-\nplicationandastripped-downoperatingsystemcanformasingledomain.Amorecommon\ncase is to have a hypervisor at the lowest level supporting one or more operating systems\nsuchasLinuxorWindowsinavirtualmachine.Inotherwords,thesehypervisorsprovideeach\nof the operating systems with the illusion that they run on dedicated hardware. At the other\nend of the spectrum, we find the entire system decomposed into separate, relatively small,\nvirtual machines. Indeed, some operating systems, such as QubesOS completely integrate\nthe concepts of virtualisation and operating systems by allowing individual user processes\nto be isolated in their own virtual machines. Finally, as we have already seen, Unikernels are\npopularinvirtualisedenvironments,ontopofhypervisors.\nIncidentally, one of the drawbacks of virtual machines is that each operating system image\nuses storage and adds redundancy, as every system will think that it is the king of the hard-\nwaremountain,whileinrealityitissharingresources.Moreover,eachoperatingsystemina\nvirtualmachineneedsseparatemaintenance:updates,configuration,testing,etc.Apopular\nalternativeis,therefore,tovirtualiseattheoperatingsystemlevel.Inthisapproach,multiple\nenvironments,knownascontainers,runontopofasinglesharedoperatingsystem.Thecon-\nKAOperatingSystemsandVirtualisation |October2019 Page365 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntainers are isolated from each other as much as possible and have their own kernel name\nspaces,resourcelimits,etc.,butultimatelysharetheunderlyingoperatingsystemkernel,and\noften binaries and libraries. Compared to virtual machines, containers are more lightweight.\nHowever,ifweignorethemanagementaspectsforamoment,virtualmachinesareoftenper-\nceived as more secure than containers, as they partition resources quite strictly and share\nonlythehypervisorasathinlayerbetweenthehardwareandthesoftware.Ontheotherhand,\nsome people believe that containers are more secure than virtual machines, because they\nare so lightweight that we can break applications into \u2018microservices\u2019 with well-defined in-\nterfacesincontainers.Moreover,havingfewerthingstokeepsecurereducestheattacksur-\nface overall. Early work on containers (or \u2018operating system level virtualisation\u201d is found in\nthe chroot call that was first added to Version 7 Unix in 1979 [1027]. In 2000, FreeBSD re-\nleased Jails [1028], which went much further in operating system virtualisation. Today, we\nhavemanycontainerimplementations.ApopularoneisDocker[1029].\nA final class of operating systems explicitly targets small and resource constrained devices\nsuch as those found in the Internet of Things (IoT). While everybody has a different opin-\nion on what IoT means and the devices to consider range from smartphones to smart dust,\nthereisacommonunderstandingthatthemostresourceconstraineddevicesshouldbepart\nof it. For such devices, even stripped down general-purpose operating systems may be too\nbulky and operating systems are expected to operate in just a few kilobytes. As an extreme\nexample, popular IoT operating systems such as RIOT can be less than 10 KB in size and\nrun on systems ranging from 8-bit microcontrollers to general-purpose 32-bit CPUs, with or\nwithoutadvancedfeaturessuchasMemoryManagementUnits(MMUs),etc.Theabundance\nof features and application isolation that we demand from operating systems such as Win-\ndowsandLinuxmaybeabsentintheseoperatingsystems,butinsteadtheremaybesupport\nforfunctionalitysuchasreal-timescheduleorlow-powernetworkingwhichareimportantin\nmanyembeddedsystems.\nSinceweareinterestedinthesecurityguaranteesofferedbytheoperatingsystem,wewillas-\nsumethattherearemultiplesecuritydomains.Inthenextsection,wewillelaborateonthead-\nvantages and disadvantages of the different designs from the viewpoint of well-established\nsecurity principles. Our focus will be on the security of the design and the way in which we\ncan stop attacks, but not before observing that there is more to security at this level. In par-\nticular,managementandmaintainabilityofthesystem\u2014withrespecttoupdates,extensions,\nconfiguration,etc.\u2014playanimportantrole.\n11.3 OPERATING SYSTEM SECURITY PRINCIPLES AND\nMODELS\n[1002,c9][1030,c4,c7][8][1031]\nSinceoperatingsystems(and\/orhypervisors)arethefoundationuponwhichreststhesecu-\nrityofallhigher-levelcomponentsinthesystem,itiscommontoheartheirdesignsdebated\nin terms of security principles such as those of Saltzer and Schroeder (see Table 11.2 ), and\nsecuritymodelssuchastheBell-LaPadula[23]andBiba[24]accessmodels\u2014thetopicofthe\nnextfewsubsections.WhileSaltzerandSchroeder\u2019ssecurityprinciplesarearguablythemost\nwell-known,weshouldmentionthatothershavesinceaddedtothelist.Forinstance,impor-\ntant additions that we discuss in this text include the Principle of Minimising the Amount of\nTrustedCode(theTrustedComputingBase)andthePrincipleofIntentionalUse[1032].\nKAOperatingSystemsandVirtualisation |October2019 Page366 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nPrincipleof...\nEconomyofmechanism\nFail-safedefaults\nCompletemediation\nOpendesign\nSeparationofprivilege\nLeastprivilege\/leastauthority\nLeastcommonmechanism\nPsychologicalacceptability\nTable11.2:Saltzer&Schroeder\u2019ssecurityprinciples[8].\n11.3.1 Security principles in operating systems\nFromasecurityperspective,thewallsbetweendifferentsecuritydomainsshouldbeashigh\nandasthickaspossible\u2014perfectisolation.Anyinteractionbetweendomainsshouldbesub-\nject to rigorous mediation, following the Principle of Complete Mediation, and security do-\nmains should have as few mechanisms (especially those involving a shared state such as\nglobalvariables)incommonaspossible,adheringtothePrincipleofLeastCommonMecha-\nnism.Forinstance,givenachoicebetweenaddingasharedprocedurewithglobalvariables\ntotheoperatingsystemkernelandmakingitavailableinauser-spacelibrarythatbehavesin\nan isolated manner for each process, we should choose the latter option, assuming it does\nnotincreasethecodesizetoomuchorviolateanyotherprinciplesorconstraints.Moreover,\nmediation should follow the Principle of Fail-Safe Defaults: the policy for deciding whether\ndomainscanaccesstheresourcesofotherdomainsshouldbe:\u2018No,unless\u2019.Inotherwords,\nonlyexplicitlyauthoriseddomainsshouldhaveaccesstoaresource.TheprinciplesofLeast\nCommon Mechanism and Economy of Mechanism also suggest that we should minimise\ntheamountofcodethatshouldbetrusted,theTrustedComputingBase(TCB).Sincestudies\nhave shown that even good programmers introduce between 1 and 6 bugs per 1000 lines of\ncode, assuming the complexity of the code is similar, a small TCB translates to fewer bugs,\na smaller attack surface and a better chance of automatically or manually verifying the cor-\nrectnessoftheTCBwithrespecttoaformalspecification.\nWithrespecttothedesignsinFig.11.1,wenotethatifthereisasingledomain,theTCBcom-\nprises all the software in the system, including the applications. All mechanisms are \u2018com-\nmon\u2019 and there is virtually no concept of fail-safe defaults or rigorously enforced mediation.\nForthemonolithicOSdesign,thesituationisalittlebetter,asatleasttheoperatingsystemis\nshieldedfromtheapplicationsandtheapplicationsfromeachother.However,theoperating\nsystemitselfisstillasinglesecuritydomain,inheritingthedisadvantagesofFig.11.1(a).The\nextremedecompositionofthemulti-serveroperatingsystemismoreamenabletoenforcing\nsecurity: we may enforce mediation between individual operating components in a minimal-\nsize microkernel with fail-safe defaults. Much of the code that is in the operating system\u2019s\nsecuritydomainintheotherdesigns,suchasdrivercode,isnolongerpartoftheTCB.Uniker-\nnels are an interesting alternative approach: in principle, the operating system code and the\napplication run in a single domain, but the libOS code is as small as possible (Economy of\nMechanism) and the mechanism common to different applications is minimised. Resource\npartitioning can also be mediated completely at the Unikernel level. For a Unikernel applica-\ntion, the TCB consists only of the underlying hypervisor\/Exokernel and the OS components\nit decides to use. Moreover, the library implementing the OS component is only in this appli-\ncation\u2019sTCB,asitisnotsharedbyothers.\nKAOperatingSystemsandVirtualisation |October2019 Page367 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nAnotherprinciple,thatofOpenDesign,isperhapsmorecontroversial.Inparticular,therehave\nbeen endless discussions about open source (which is one way to adhere to the principle)\nversus closed source and their merits and demerits with respect to security. The advantage\nof an open design is that anybody can study it, increasing the probability of finding bugs in\ngeneral and vulnerabilities in particular3. A similar observation was made by Auguste Kerck-\nhoffs about crypto systems and is often translated as that one should not rely on security\nbyobscurity.Afterall,theobscurityisunlikelytolastforeverandwhenthebadpeoplefinda\nvulnerabilitybeforethegoodpeopledo,youmayhavearealproblem.Thecounterargument\nisthatwithanopendesign,theprobabilityofthemfindingthebugishigher.\nIn contrast, there is little doubt that a design with a strict decomposition is more in linewith\nthePrincipleofLeastPrivilegeandthePrincipleofPrivilegeSeparationthanonewheremost\nofthecoderunsinasinglesecuritydomain.Specifically,amonolithicsystemhasnotruesep-\narationofprivilegesofthedifferentoperatingsystemcomponentsandtheoperatingsystem\nalways runs with all privileges. In other words, the operating system code responsible for\nobtaining the process identifier of the current process runs with the power to modify page\ntables,createrootaccounts,modifyanyfileondisk,readandwritearbitrarynetworkpackets,\nandcrashtheentiresystematanytimeitseesfit.Multi-serversystemsareverydifferentand\nmayrestrictwhatcallsindividualoperatingsystemcomponentscanmake,limitingtheirpow-\nerstojustthoseprivilegestheyneedtocompletetheirjob,adheringtothePrincipleOfLeast\nAuthority(POLA)withdifferentcomponentshavingdifferentprivileges(PrincipleofPrivilege\nSeparation).Unikernelsofferadifferentandinterestingpossibilityfordealingwiththisprob-\nlem.Whilemostofthecomponentsruninasingledomain(noprivilegeseparationorPOLA),\nthe operating system is stripped down to just the parts needed to run the application, and\ntheUnikernelitselfcouldrunwithjusttheprivilegesrequiredforthispurpose.\nOf course, however important security may be, the Principle of Psychological Acceptability\nsaysthatintheendthesystemshouldstillbeusable.Giventhecomplexityofoperatingsys-\ntem security, this is not trivial. While security hardened operating systems such as SELinux\nand QubesOS offer clear security advantages over many other operating systems, few ordi-\nnary users use them and even fewer feel confident to configure the security settings them-\nselves.\n11.3.2 Security models in operating systems\nAnimportantquestioninoperatingsystemsconcernstheflowofinformation:whocanread\nandwritewhatdata?Traditionally,wedescribesystem-widepoliciesinso-calledaccesscon-\ntrolmodels.\nFor instance, the Bell-LaPadula model [23] is a security access model to preserve the con-\nfidentiality of information, initially created for the US government. In the 1970s, the US mil-\nitary faced a situation where many users with different clearance levels would all be using\nthe same mainframe computers\u2014requiring a solution known as Multi-Level Security. How\ncould they ensure that sensitive information would never leak to non-authorised personnel?\nIf it adheres to the model designed by David Bell and Leonard LaPadula, a system can han-\ndlemultiplelevelsofsensitiveinformation(e.g.,unclassified,secret,topsecret)andmultiple\nclearancelevels(e.g.,theclearancetoaccessunclassifiedandsecret,butnottopsecretdata)\n3Ontheotherhand,researchershaveencounteredsecuritybugsthatareyearsorsometimesdecadesold,\neveninsecuritycriticalopensourcesoftwaresuchasOpenSSLortheLinuxkernel,suggestingthatthecommon\nbelief that \"given enough eyeballs, all bugs are shallow\u201d (also known as Linus\u2019 Law) does not always work\nflawlessly.\nKAOperatingSystemsandVirtualisation |October2019 Page368 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nandkeepcontrolovertheflowofsensitiveinformation.Bell-LaPadulaisoftencharacterised\nas \u2018read down, write up\u2019. In other words, a subject with clearance level secret may create\nsecret or top secret documents, but not unclassified ones, as that would risk leaking secret\ninformation. Likewise, a user can only read documents at their own security level, or below\nit.Declassification,orloweringofsecuritylevels(e.g.,copyingdatafromatopsecrettoase-\ncret document) can only be done explicitly by special, \u2018trusted\u2019 subjects. Strict enforcement\nofthismodelpreventstheleakageofsensitiveinformationtonon-authorisedusers.\nBell-LaPadulaonlyworriesaboutconfidentiality.Incontrast,theBibamodel[24]arrangesthe\naccess mode to ensure data integrity. Just like in Bell-LaPadula, objects and subjects have\na number of levels of integrity and the model ensures that subjects at lower levels cannot\nmodify data at higher levels. This is often characterised as \u2018read up, write down\u2019, the exact\noppositeofBell-LaPadula.\nBell-LaPadula and Biba are access control models that the operating system applies when\nmediatingaccesstoresourcessuchasdatainmemoryorfilesondisk.Specifically,theyare\nMandatory Access Control (MAC) models, where a system-wide policy determines which\nusers have the clearance level to read or write which specific documents, and users are not\nable to make information available to other users without the appropriate clearance level,\nno matter how convenient it would be. A less strict access control model is known as Dis-\ncretionary Access Control (DAC), where users with access to an object have some say over\nwhoelsehasaccesstoit.Forinstance,DACmayrestrictaccesstoobjectsbasedonauser\nor process identity or group membership. More importantly, DAC allows a user or process\nwith access rights to an object to transfer those rights to other users or processes. Having\nonly this group-based DAC makes it hard to control the flow of information in the system\nin a structured way. However, it is possible to combine DAC and MAC, by giving users and\nprogramsthefreedomtotransferaccessrightstoothers,withintheconstraintsimposedby\nMACpolicies.\nFor completeness, we also mention Role-Based Access Control (RBAC) [1033], which re-\nstricts access to objects on the basis of roles which may be based on job functions. While\nintuitivelysimple,RBACallowsonetoimplementbothDACandMACaccesscontrolpolicies.\n11.4 PRIMITIVES FOR ISOLATION AND MEDIATION\n[1002,c9][1034,c1-c9],[1031][1030,c4,c7][1035]\nIn the 1960s, Multics [1036] became the first major operating system designed from the\nground up with security in mind. While it never became very popular, many of its security\ninnovations can still be found in the most popular operating systems today. Even if some\nfeatureswerenotinventeddirectlybytheMulticsteam,theirintegrationinasingle,working,\nsecurity-oriented OS design was still novel. Multics offered rings of protection, virtual mem-\nory, segment-based protection, a hierarchical file system with support for Discretionary Ac-\ncessControl(DAC)andmandatoryaccesscontrol(MAC).Indeed,inmanyways,themanda-\ntory access control in Multics, added at the request of the military, is a direct software im-\nplementation of the Bell-LaPadula security model. Finally, Multics made sure that its many\nsmallsoftwarecomponentswerestronglyencapsulated,accessibleonlyviatheirpublished\ninterfaceswheremediationtookplace.\nIf any of this sounds familiar, this is not surprising, as Jerome Saltzer was one of the Mul-\ntics team leaders. The Trusted Computer System Evaluation Criteria (TCSEC), better known\nKAOperatingSystemsandVirtualisation |October2019 Page369 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nas the famous Orange Book [1031], describes requirements for evaluating the security of a\ncomputersystem,andisstronglybasedonMultics.ThereisnodoubtthatMulticswasvery\nadvancedandperhapsaheadevenofsomemodernoperatingsystems,butthiswasalsoits\ndownfall\u2014the system became so big and so complex that it arguably violated the Principle\nofPsychologicalAcceptabilityforatleastsomeofitsdevelopers.Frustrated,KenThomson\nandDennisRitchiedecidedtowriteanewandmuchsimpleroperatingsystem.Asapunand\nto contrast it with Multics, they called it \u2018Unics\u2019, later spelt UNIX. Like all major general pur-\nposeoperatingsystemsinusetoday,itreliedonasmallnumberofcoreprimitivestoisolate\nitsdifferentsecuritydomains.\nSo what are these major isolation primitives? First, the operating system has to have some\nway of authenticating users and security domains so it can decide whether or not they may\naccess certain resources. To isolate the different security domains, the operating system\nalsoneedssupportforaccesscontroltoobjects,suchasfiles.Inaddition,itneedsmemory\nprotection to ensure that a security domain cannot simply read data from another domain\u2019s\nmemory. Finally, it needs a way to distinguish between privileged code and non-privileged\ncode, so that only the privileged code can configure the desired isolation at the lowest level\nandguaranteemediationforalloperations.\n11.4.1 Authentication and identification\nSinceauthenticationisthetopicoftheAuthentication,Authorisation&Accountability(AAA)\nKnowledge Area (Chapter 13), we will just observe that to determine access rights, an op-\nerating system needs to authenticate its users and that there are many ways to do so. Tra-\nditionally, only usernames and passwords were used for this purpose, but more and more\nsystems nowadays use other methods (such as smartcards, fingerprints, iris scans, or face\nrecognition)\u2014eitherinsteadofpasswordsorasanadditionalfactor.Multi-factorauthentica-\ntionmakesitharderforattackerstomasqueradeasalegitimateuser,especiallyifthefactors\nareofadifferentnature,e.g.,somethingyouknow(likeapassword),somethingyouown(like\nasmartcard),andsomethingyou\u2018are\u2019(biometricdatasuchasfingerprints).\nFor every user thus authenticated, the operating system maintains a unique user id. More-\nover, it may also keep other information about users such as in which groups they reside\n(e.g.,student,faculty,and\/oradministrator).Similarly,mostoperatingsystemsattachsome\nidentity to each of the processes running on behalf of the user and track the ownership and\naccess rights of the files they use. For instance, it gives every running process a unique pro-\ncessidandalsoregisterstheidoftheusersonwhosebehalfitruns(andthusthegroupsin\nwhichtheuserresides).Finally,ittrackswhichuserownstheexecutingbinary.Notethatthe\nuser owning the binary and the user running the binary need not be the same. For instance,\ntheadministratorcancreateandownacollectionofsystemprogramsthatotherusersmay\nexecutebutnotmodify.\nIncidentally,storingcredentialsinasecuremanneriscrucial.Severalmodernoperatingsys-\ntemsresorttohardwaretoprotectsuchsensitivedata.Forinstance,theymayuseaTrusted\nPlatformModule(TPM)toensurecredentialssuchasdiskencryptionkeysarecryptograph-\nically sealed, or employ a separate VM for the credential store, so that even a compromised\nVMwillnotgetdirectaccesstothecredentials.\nKAOperatingSystemsandVirtualisation |October2019 Page370 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n11.4.2 Access control lists\nGiven these identities, the operating system is equipped to reason about which user and\nwhichprocessisallowedtoperformwhichoperationsonaspecificobject:accesscontrol.\nWhen Robert Daley and Peter Neumann first developed the Multics file system, they intro-\nduced an Access Control List (ACL) for every block of data in the system [1036, 1037]. Con-\nceptually, an ACL is a table containing users and data blocks that specifies for each data\nblock which users have which kind of access rights. Most modern operating systems have\nadopted some variant of ACLs, typically for the file system4. Let us look at an example. On\nUNIX-based systems [1019], the default access control is very simple. Every file is owned by\na user and a group. Moreover, every user can be in one or more groups. For instance, on a\nLinuxsystem,userherbertbisinninedifferentgroups:\nherbertb@nordkapp:~$ groups herbertb\nherbertb : herbertb adm cdrom sudo dip plugdev lpadmin sambashare cybok\nherbertb@nordkapp:~$\nPer file, a small number of permission bits indicates the access rights for the owning user,\nthe owning group, and everyone else. For instance, let us look at the ACL for a file called\nmyscriptonLinux:\nherbertb@nordkapp:~\/tmp$ getfacl myscript\n# file: home\/herbertb\/tmp\/myscript\n# owner: herbertb\n# group: cybok\nuser::rwx\ngroup::rwx\nother::r-x\nWeseethatmyscriptisownedbyuserherbertbandgroupcybok.Theowninguserand\nallusersingroupcybokhavepermissionstoread,write,andexecutethefile,whileallother\nuserscanreadandexecute(butnotwrite)it.\nThesebasicUNIXfilepermissionsarequitesimple,butmodernsystems(suchasLinuxand\nWindows) also allow for more extensive ACLs (e.g., with explicit access rights for multiple\nusers or groups). Whenever someone attempts to read, write or access a file, the operating\nsystem verifies whether the appropriate access rights are in the ACL. Moreover, the access\ncontrol policy in UNIX is typically discretionary, because the owning user is allowed to set\ntheserightsforothers.Forinstance,ontheaboveLinuxsystem,userherbertbcanhimself\ndecidetomakethefilemyscriptwritablebyalltheusers(\u2018chmod o+w myscript\u2019).\nBesidesDAC,MulticsalsoimplementedMACand,whileittookalongtimetoreachthisstage,\nthisisnowalsotrueformanyoftheoperatingsystemsthattooktheirinspirationfromMultics\n(namely most popular operating systems today). Linux even offers a framework to allow all\nsortsofaccesscontrolsolutionstobepluggedin,bymeansofso-called\u2018referencemonitors\u2019\nthat vet each attempt to execute a security sensitive operation and, indeed, several MAC\nsolutionsexist.ThebestknownoneisprobablySecurity-EnhancedLinux(SELinux[1038]),a\nsetofLinuxpatchesforsecurityoriginallydevelopedbytheNationalSecurityAgency(NSA)\nintheUSandderivedfromtheFluxAdvancedSecurityKernel(FLASK)[1039].\nSELinux gives users and processes a context of three strings: (username, role,\ndomain). While the tuple already (correctly) suggests that SELinux also supports RBAC,\nthere is significant flexibility in what to use and what to avoid. For instance, many deployed\nsystems use only the domain string for MAC and set username and role to the same\nvalueforallusers.Besidesprocesses,resourcessuchasfiles,networkports,andhardware\n4whichinmostcasesalsofollowsthehierarchicaldesignpioneeredinMultics.\nKAOperatingSystemsandVirtualisation |October2019 Page371 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nresources also have such SELinux contexts associated with them. Given this configuration,\nsystemadministratorsmaydefinesystem-widepoliciesforaccesscontrolontheirsystems.\nFor instance, they may define simply which domains a process have to perform specific op-\nerations (read, write, execute, connect) on a resource, but policies may also be much more\ncomplicated, with multiple levels of security and strict enforcement of information flow a la\nBell-LaPadula,Biba,orsomecustomaccess-controlmodel.\nMandatoryaccesscontrolinsystemssuchasSELinuxrevolvesaroundasinglesystem-wide\npolicythatissetbyacentraladministratoranddoesnotchange.Theydonotallowuntrusted\nprocesses to define and update their own information control policy. In contrast, research\noperating systems such as Asbestos [1040], HiStar [1041] and Flume [1042] provide exactly\nthat: distributed information flow control. In other words, any process can create security\nlabelsandclassifyanddeclassifydata.\n11.4.3 Capabilities\nSofar,wehaveassumedthataccesscontrolisimplementedbymeansofanACLoraccess\nmatrix,whereallinformationiskepttodecidewhetheraprocessP mayaccessaresourceR.\nAfterauthenticatingtheusersand\/orlookinguptheirrolesorclearancelevels,thereference\nmonitordecideswhetherornottograntaccess.However,thisisnottheonlyway.Apopular\nalternativeisknownascapability and,stemmingfrom1966,isalmostasold.\nIn1966,JackDennisandEarlVanHorn,researchersatMIT,proposedtheuseofcapabilities\nfor access control in an operating system [1043]. Unlike ACLs, capabilities do not require a\nper-objectadministrationwiththeexactdetailsofwhoisallowedtoperformwhatoperation.\nInstead, the users present a capability that in itself proves that the requested access is per-\nmitted. According to Dennis and Van Horn, a capability should have a unique identifier of\nthe object to which it pertains, as well as the set of access rights provided by the capability.\nMost textbooks use the intuitive definition by Henry Levy that a capability is a \u2018token, ticket,\nor key that gives the possessor permission to access an entity or object in a computer sys-\ntem\u2019 [1034]. Possession of the capability grants all the rights specified in it and whenever a\nprocesswantstoperformanoperationonanobject,itshouldpresenttheappropriatecapa-\nbility. Conversely, users do not have access to any resources other than the ones for which\ntheyhavecapabilities.\nMoreover,PeterNeumannarguesthattheaccesscontrolshouldbeexplicitandadheretothe\nPrincipleofIntentionalUse[1032],byexplicitlyauthorisingonlywhatisreallyintended,rather\nthansomethingthatisoverlybroadormerelyexpedient.Adherencetotheprinciplehelpsto\navoid the accidental or unintended use of rights that may lead to security violations in the\nformofa\u2019confuseddeputy\u2019(inwhichasecuritydomainunintentionallyexercisesaprivilege\nthatitholdslegitimately,onbehalfofanotherdomainthatdoesnotandshouldnot).\nOf course, it should be impossible to forge capabilities, lest users give themselves arbitrary\naccesstoanyobjecttheywant.Thus,anoperatingsystemshouldeitherstorethecapability\ninasafeplace(forinstance,thekernel),orprotectitfromforgeryusingdedicatedhardware\nor software-based encryption. For instance, in the former case, the operating system may\nstoreaprocess\u2019capabilitiesinatableinprotectedmemory,andwhenevertheprocesswants\nto perform an operation on a file, say, it will provide a reference to the capability (e.g., a file\ndescriptor) and never touch the capability directly. In the latter case, the capability may be\nhandledbytheprocessitself,butanyattempttomodifyitinaninappropriatemannerwillbe\ndetected[1044].\nKAOperatingSystemsandVirtualisation |October2019 Page372 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nCapabilitiesareveryflexibleandallowforconvenientdelegationpolicies.Forinstance,given\nfull ownership of a capability, a process may pass it on to another process, to give that pro-\ncess either the same access rights, or, alternatively, a subset of those rights. Thus, discre-\ntionary access control is easy. On the other hand, in some situations, it may not be desir-\nabletohavecapabilitiescopiedandspreadarbitrarily.Forthisreason,mostcapability-based\nsystems add a few bits to the capabilities to indicate such restrictions: whether copying is\npermitted,whetherthecapability\u2019slifetimeshouldbelimitedtoaprocedureinvocation,etc.\nComparingACLsandcapabilities,wefurtherobservethatACLsaretypicallybasedonusers\n(\u2018the user with id x is allowed to read and write\u2019), while capabilities can be extremely fine-\ngrained. For instance, we may use different capabilities for sending and receiving data. Fol-\nlowingthePrincipleofLeastAuthority,runningeveryprocesswiththefullpoweroftheuser,\ncompared to running a process with just the power of the capabilities it acquires, is less se-\ncure.Runningwiththeauthorityoftheuserwhostartedtheprogram,asisoftenthecasein\nmodern operating systems, is known as a form of ambient authority and much more likely\nto violate the Principle of Least Authority than fine-grained capabilities that equip a process\nonlywiththeprivilegesitneeds.Moreover,capabilitiesdonotevenallowaprocesstoname\nan object unless it has the appropriate capability, while ACLs should permit the naming of\nanyobjectbyeveryone,astheaccesscheckonlyoccurswhentheprocessattemptstheop-\neration. Finally, ACLs may become very large with growing numbers of users, access rights,\nandobjects.\nOn the other hand, revoking a particular access right for a particular user in an ACL is easy:\njustremoveapermissionintheappropriatetableentry.Withcapabilities,theprocessismore\ninvolved.Afterall,wemaynotevenknowwhichusers\/processeshavethecapability.Adding\nalevelofindirectionmayhelpsomewhat.Forinstance,wecouldmakethecapabilitiespoint\ntoanindirectobject,whichinturnpointstotherealobject.Toinvalidatethecapability(forall\nusers\/processes)theoperatingsystemcouldtheninvalidatethatindirectobject.Butwhatto\ndoifweonlywanttorevokethecapabilityinasubsetofprocesses?Whiletherearesolutions,\nrevocationofcapabilitiesremainsthemostdifficultpart.\nSince the 1960s, many capability-based systems have appeared\u2014initially all supported in\nhardware [1034] and typically more rigid than the more general capabilities discussed so\nfar. The first was the MIT PDP-1 Timesharing System [1045], followed shortly after by the\nChicagoMagicNumberMachineattheUniversityofChicago[1046],averyambitiousproject\nwithhardware-supportedcapabilities,which,asisnotuncommonforambitiousprojects,was\nnevercompleted.However,itdidhaveagreatimpactonsubsequentwork,asMauriceWilkes\noftheUniversityofCambridgelearnedaboutcapabilitiesduringseveralvisitstoChicagoand\nwroteaboutitinhisbookontime-sharingsystems.BackintheUK,thisbookwaspickedup\nby an engineer at Plessey which built the fully functional Plessey System 250 (with explicit\nhardwaresupportforcapability-basedaddressing).MauriceWilkeshimselfwentontobuild\ntheCambridgeCAPcomputertogetherwithRogerNeedhamandDavidWheeler[1047].CAP\nwasthefirstcomputertodemonstratetheuseofsecurecapabilities.Thismachineensured\nthat a process could only access a memory segment or other hardware if it possessed the\nrequired capabilities. Another noteworthy capability-based system of that time was CMU\u2019s\nHydra [1048]\u2014which added explicit support for restricting the use of capabilities or opera-\ntions on objects (allowing one to specify, for instance, that capabilities must not survive a\nprocedure invocation). Finally, in the 1980s, the Amoeba distributed operating systems ex-\nplored the use of cryptographically protected capabilities that could be stored and handled\nbyuserprocesses[1044].\nKAOperatingSystemsandVirtualisation |October2019 Page373 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nNowadays, many major operating systems also have at least some support for capabilities.\nFor instance, the L4 microkernel, which is present in many mobile devices today, embraced\ncapability-basedsecurityintheversionbyGernotHeiser\u2019sgroupatNICTAin20085.Aformally\nverified kernel called seL4 [1049] from the same group similarly relies on capabilities for ac-\ncesscontroltoresources.In1997,Linuxadoptedverylimitedcapabilitysupport(sometimes\nreferredtoas\u2018POSIXcapabilities\u2019),butthiswasdifferentfromthecapabilitiesdefinedbyDen-\nnis and Van Horn (with less support for copying and transferring capabilities). For instance,\nLinuxcapabilitiesreferonlytooperations,notobjects.RecognisingthatUNIXfiledescriptors\nandWindowshandlesarealmostcapabilitiesalready,aninterestingefforttomergecapabili-\ntiesandUNIXAPIsistheCapsicumproject[1050]bytheUniversityofCambridgeandGoogle,\nwhere the capabilities are extensions of UNIX file descriptors. FreeBSD adopted Capsicum\nin version 9.0 in 2012. An outgrowth of Capsicum is Capability Hardware Enhanced RISC\nInstructions (CHERI), a hardware-software project that transposes the Capsicum capability\nmodelintotheCPUarchitecture.\n11.4.4 Physical access and secure deletion\nItisimportanttoobservethataccessrestrictionsattheleveloftheoperatingsystemdonot\nnecessarily translate to the same restrictions at the physical level. For instance, the operat-\ning system may \u2018delete\u2019 a file simply by removing the corresponding metadata that makes it\nappear as a file (e.g., when listing the directory), without really removing the content of the\nfile on disk. Thus, an attacker that reads raw disk blocks with no regard for the file system\nmaystillbeabletoaccessthedata.\nIt turns out that securely deleting data on disk is not trivial. Naive deletion, for instance, by\noverwriting the original content with zeros, is not always sufficient. For instance, on some\nmagneticdisks,dataonthedisk\u2019stracksleaves(magnetic)tracesinareasclosetothetracks\nandacleverattackwithsufficienttimeandresourcesmayusethesetorecoverthecontent.\nMoreover, the operating system may have made copies of the file that are not immediately\nvisible to the user, for instance, as a backup or in a cache. All these copies need to be se-\ncurely deleted. The situation for Solid State Drives (SSDs) is no better, as SSDs have their\nown firmware that decides what to (over)write and when, beyond the control of the OS. For\nmost operating systems, truly secure deletion, in general, is beyond the operating system\u2019s\ncapabilities and we will not discuss it further in this knowledge area, except to say that full\ndisk encryption, a common feature of modern operating systems, helps a lot to prevent file\nrecoveryafterdeletion.\n11.4.5 Memory protection and address spaces\nAccesscontrolisonlymeaningfulifsecuritydomainsareotherwiseisolatedfromeachother.\nFor this, we need separation of the security domains\u2019 data according to access rights and a\nprivilegedentitythatisabletograntorrevokesuchaccessrights.Wewilllookattheisolation\nfirstandtalkabouttheprivilegeslater,whenweintroduceprotectionrings.\nA process should not normally be able to read another process\u2019 data without going through\nthe appropriate access control check. Multics and nearly all of the operating systems that\nfollowed (such as UNIX and Windows) isolate information in processes by giving each pro-\ncess (a) its own processor state (registers, program counter etc.) and (b) its own subset of\nmemory. Whenever the operating system decides to execute process P at the expense of\n2\n5OtherL4variants,suchastheL4FiascokernelfromDresden,alsosupportedcapabilities.\nKAOperatingSystemsandVirtualisation |October2019 Page374 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n9 bits 9 bits 9 bits 9 bits 12 bits\nVirtual address: 000000011000000010000000111000000110101101111000\nLevel 4\nPage Table\nLevel 3\nPage Table\nLevel 2\nPage Table\nLevel 1\nPage Table\n5\n4\n3\n2 5\nregister with addr 1 4 7\n0 3 66\nof top level PT 2 5\n1 4\n0 3 6\n2 5\n1 4\n0 3\n2\n1\nPage Table Entry: 0\nphysical address S\nremaining bits 12 bits ( ags)\nFigure 11.2: Address translation in modern processors. The MMU \u2018walks\u2019 the page tables to\nfindthephysicaladdressofthepage.Onlyifapageis\u2018mapped\u2019onaprocess\u2019pagetablescan\nthe process address it, assuming it is present and the process has the appropriate access\nrights.Specifically,auserprocesscannotaccessthepageforwhichthesupervisor(S)bitis\nsetinthepagetableentry.\nthe currently running process P (a so-called context switch), it first stops P and saves all\n1 1\nof its processor state in memory in an area inaccessible to other processes. Next, it loads\nP \u2019s processor states from memory into the CPU, adjusts the bookkeeping that determines\n2\nwhich parts of the physical memory are accessible, and starts executing P at the address\n2\nindicatedbytheprogramcounterthatitjustloadedaspartoftheprocessorstate.Sinceuser\nprocesses cannot directly manipulate the bookkeeping themselves, P2 cannot access any\nofP \u2019sdatainanon-mediatedform.\n1\nMost modern operating systems keep track of the memory bookkeeping by means of page\ntables, as illustrated in Fig. 11.2. For each process, they maintain a set of page tables (often\ncontaining multiple levels organised as a directed acyclic graph6), and store a pointer to the\ntop level page table in a register that is part of the processor state and that must be saved\nandrestoredonacontextswitch.\nThe main use for the page table structure is to give every process its own virtual address\nspace,rangingfromaddress0tosomemaximumaddress(e.g.,248),eventhoughtheamount\nofphysicalmemorymaybemuchless[1051,1052,1053].Sincetwoprocessesmaybothstore\ndata at address 0x10000, say, but should not be allowed to access each others\u2019 data, there\nhastobeamappingfromthevirtualaddresseseachprocessusestothephysicaladdresses\nusedbythehardware.Itislikeagameofbasketball,whereeachsidemayhaveaplayerwith\nthenumber23,butthatnumberismappedontoadifferentphysicalplayerforeachteam.\nThis is where the page tables comes in. We divide each of the virtual address spaces into\nfixed size pages and use the page table structure to map the address of the first byte of a\nvirtualpageontoaphysicaladdress.Theprocessoroftenusesmultiplelevelsoftranslation.\n6Whileitisoftenhelpfultothinkofpagetablestructuresastrees,differentbranchesmaypointtothesame\nleavenodes.\nKAOperatingSystemsandVirtualisation |October2019 Page375\n(cid:1) TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nIn the example in Fig. 11.2, it uses the first nine bits of the virtual address as an index in the\ntoplevelpagetable(indicatedbyacontrolregisterthatispartoftheprocessorstate)tofind\nanentrycontainingthephysicaladdressofthenextlevelpagetable,whichisindexedbythe\nnextninebits,andsoon,untilwereachthelastlevelpagetable,whichcontainsthephysical\naddress of the physical page that contains the virtual address. The last 12 bits of the virtual\naddressaresimplytheoffsetinthispageandpointtothedata.\nPaging allows the (total) size of the virtual address spaces of the processes to be much\nlarger than the physical memory available in the system. First, a process typically does not\nuse all of its possibly gigantic address space and only virtual pages that are in actual use\nneed backing by physical pages. Second, if a process needs more memory to store some\ndata and no physical pages are free at that moment (for instance, because they are already\ninusebyotherprocesses,ortheyarebackingsomeothervirtualpagesofthisprocess),the\noperatingsystemmayswapthecontentofthesepagestodiskandthenre-usethephysical\npagetostorethenewdata.\nA key consequence of this organisation is that a process can only access data in memory\nif there is a mapping for it in its page tables. Whether this is the case, is controlled by the\noperatingsystem,whichis,therefore,abletodecideexactlywhatmemoryshouldbeprivate\nand what memory should be shared and with whom. The protection itself is enforced by\nspecialised hardware known as the memory management unit (MMU7). If the mapping of\nvirtualtophysicalforaspecificaddressisnotinthesmallbutveryfastcacheknownasthe\nTransaction Lookaside Buffer (TLB), the MMU will look for it by walking the page tables and\nthentriggeringaninterruptifthepagecontainingtheaddressisnotmapped.\nTheMMUwillalsotriggerinterruptsifthepageiscurrentlynotinmemory(swappedtodisk),\nor, more relevant to security, if the user does not have the required privilege to access this\nmemory.Specifically,thelast12bitsofthePageTableEntry(PTE)containasetofflagsand\none of these flags, the S bit in Fig. 11.2, indicates whether this is a page for supervisor code\n(say, the operating system running at the highest privilege) or for ordinary user processes.\nWewillhavemoretosayaboutprivilegeslater.\nPage tables are the main way modern operating systems control access to memory. How-\never, some (mostly older) operating systems additionally use another trick: segmentation.\nNot surprisingly, one of the earliest operating systems using both segmentation and paging\nwas Multics [1036, 1053]. Unlike pages, segments have an arbitrary length and start at an\narbitrary address. However, both depend on hardware support: an MMU. For instance, pro-\ncessors such as Intel\u2019s 32 bits x86 have a set of dedicated registers known as segment se-\nlectors:oneforcode,onefordata,etc.Eachsegmenthasspecificpermissions,suchasread,\nwrite,orexecute.Givenavirtualaddress,theMMUusesthecurrentvalueinthecorrespond-\ning segment selector as an index in a so-called descriptor table. The entry in the descriptor\ntablecontainsthestartaddressandlengthofthesegment,aswellasprotectionbitstopre-\nventcodewithouttherequiredprivilegeleveltoaccessit.Incasethereisonlysegmentation\nand no paging, the resulting address is the original virtual address added to the start of the\nsegment and that will be the physical address, and we are done. However, both the GE-645\nmainframe computer used for Multics and the more modern x86-32 allow one to combine\nsegmentationandpaging.Inthatcase,thevirtualaddressisfirsttranslatedintoaso-called\nlinear address using the segment descriptor table and that linear address is then translated\nintoaphysicaladdressusingthepagetablestructure.\n7Asweshallseelater,notallprocessorshaveafull-fledgedMMUbutratherasimplermemoryprotection\nunit.\nKAOperatingSystemsandVirtualisation |October2019 Page376 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nThisisascomplicatedasitsounds;noneofthepopularmodernoperatingsystemsstilluse\nsegmentation. The best known examples of operating systems using segmentation were\nOS\/2 (an ill-fated collaboration between Microsoft and IBM that started in the mid-1980s\nand that never caught on) and IBM\u2019s AS\/400 (also launched in the 1980s8 and still running\nhappily today on a mainframe near you). The Xen hypervisor also used segmentation on 32\nbitx86,buton64bitsystemsthiswasnolongerpossible.Infact,the64-bitversionoftheIntel\nx86 no longer even supports full segmentation, although some vestiges of its functionality\nremain.Ontheotherhand,complicatedmulti-leveladdresstranslationisstillquitecommon\nin virtualised environments. Here, the hypervisor tries to give virtual machines the illusion\nthat they are running all by themselves on real hardware, so the MMU translates a virtual\naddressfirsttowhatisknownasaguestphysicaladdress(usingpagetables).However,this\nisnotarealphysicaladdressyet,asmanyvirtualmachinesmayhavethesameideaofusing,\nsay,physicaladdress0x10000.So,instead,theMMUusesasecondtranslationstage(using\nwhat Intel refers to as extended page tables, maintained by the hypervisor) to translate the\nguestphysicaladdresstoahostphysicaladdress(\u2018machineaddress\u2019).\n11.4.6 Modern hardware extensions for memory protection\nAlso, while segmentation is mostly dead, there are many other forms of hardware support\nfor memory protection beyond paging. For instance, many machines have had support for\nbuffer bounds checking and some date back a quarter of a century or more. To illustrate\nthe corresponding primitives, however, we will look at what is available in modern general\npurpose processors, focusing mostly on the Intel x86 family. The point here is not whether\nwe think this processor is more important or even that feature X or Y will be very important\ninthefuture(whichisdebatableandhardtopredict),butrathertoillustratethatthisisstilla\nveryactiveareaforhardwaredevelopmenttoday.\nAs a first example, consider the somewhat ill-fated Intel Memory Protection Extensions\n(MPX)thatenhanceIntel\u2019sworkhorseprocessorswithfunctionalitytoensurethatarraypoint-\ners cannot stray beyond the array boundaries (stopping vulnerabilities such as buffer over-\nflowsfrombeingexploited).Forthispurpose,asmallsetofnewregisterscanstorethelower\nandupperboundsofasmallnumberofarrays,whilepriortode-referencingthepointer,new\nMPX instructions check the value of the array pointer for boundary violations. Even in sys-\ntemsthatuseMPXonlyinuserspace,theoperatingsystemplaysarole,forinstance,tohan-\ndle the exception that the hardware throws when it encounters a buffer boundary violation.\nMPX was heavily criticised for having too few of these bounds registers, leading to much\nperformanceoverhead.Inaddition,MPXdoesnotsupportmulti-threading,whichmayresult\nin data races in legacy code. One might say that MPX is a good example of an attempt by a\nhardware vendor to add new features for memory safety to their CPUs that is unfortunately\nnotalwayssuccessful.\nMore recently, Intel added Memory Protection Keys (MPKs) to its processors9. Intel MPK al-\nlows one to set four previously unused bits in the PTE (Fig. 11.2) to one of 16 \u2018key\u2019 values.\nIn addition, it adds a new 32-bit register containing 2 bits for each key to indicate whether\nreadingandwritingisallowedforpagestaggedwiththatkey.MPKallowsdeveloperstopar-\ntition the memory in a small number (in this case 16) protection domain and, for instance,\nallowonlyaspecificcryptolibrarytoaccesscryptographickeys.Whileunprivilegeduserpro-\n8Oreventhe1970s,ifyouwanttocounttheSystem\/38.\n9Again, Intel was actually late to the party, as similar features existed in a variety of processors since the\n1960s.\nKAOperatingSystemsandVirtualisation |October2019 Page377 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ncesses may update the value of the register, only privileged operating system code can tag\nthememorypageswithkeys.\nSome processor designs support even more advanced memory protection in the form of\nwhat, using ARM terminology, we will refer to as memory tagging extensions (MTE10)[1055].\nThe idea is simple yet powerful. The processor assigns every aligned chunk of memory\n(whereachunkis,say,16bytes)aso-called\"tag\"inhardware.Similarly,everypointeralsoob-\ntainsatag.Tagsaregenerallynotverylarge,say4bits,sotheycanbestoredinthetop-most\nbyte of the 64-bit pointer value which we do not really use anyway (in fact, ARM supports a\ntop-byte-ignorefeaturethatmakesthehardwareexplicitlymaskoutthetopmostbyte).\nWhenever the program allocates N bytes of memory, the allocator rounds up the allocation\nto multiples of 16 bytes and assigns a random tag to it. It also assigns the same tag to the\npointertothememory.Fromnowon,dereferencingthepointerisonlypermittedifthetagin\nthepointermatchesthatofthememorytowhichitrefers\u2014effectivelystoppingmostspatial\nandtemporalmemoryerrors.\nMeanwhile,someprocessors,especiallyinlow-powerdevices,donotevenhaveafull-fledged\nMMU at all. Instead, they have a much simpler Memory Protection Unit (MPU) which serves\nonly to protect memory, in a way that resembles the MPK functionality discussed above. In\nMPUdesigns,theoperatingsystemsdefineanumberofmemoryregionswithspecificmem-\noryaccesspermissionsandmemoryattributes.Forinstance,theMPUonARMv8-Mproces-\nsors supports up to 16 regions. Meanwhile, the MPU monitors all the processor\u2019s memory\naccesses (including instruction fetches and data accesses) and triggers an exception on\ndetectinganaccessviolation.\nNote that in the above, we have assumed that the operating system needs protection from\nuntrusteduserapplications.Aspecialsituationariseswhentheoperatingitselfisnottrusted.\nPerhapsyouarerunningasecurity-sensitiveapplicationonacompromisedoperatingsystem,\norinthecloud,whereyouarenotsureyouwanttotrustthecloudprovider.Inthegeneralcase,\nyoumaywanttoprotectyourdataandapplicationswithouttrustinganyothersoftware.For\nthis purpose, processors may offer hardware support for running extremely sensitive code\ninasecure,isolatedenvironment,knownasatrustedexecutionenvironmentinARM\u2019s\u2018Trust-\nZone\u2019 or an enclave in Intel\u2019s Software Guard Extension (SGX). They offer slightly different\nprimitives. For instance, the code running in an SGX enclave is intended to be a part of a\nnormal user process. The memory it uses is always encrypted as soon as it leaves the pro-\ncessor. Moreover, SGX offers hardware support to perform attestation, so that a (possibly\nremote) party can verify that the code is running in an enclave and that it is the right code.\nARM TrustZone, on the other hand, isolates the \u2018normal world\u2019 that runs the normal operat-\ning system and user applications, from a \u2018secure world\u2019 that typically runs its own, smaller\noperating system as a well as a small number of security sensitive applications. Code in\nthe normal world can call code in the secure world in a way that resembles the way appli-\ncations call into an operating system. One interesting application of special environments\nsuch as ARM TrustZone (or Intel\u2019s SMM mode, discussed later) is to use it for runtime mon-\nitoring of the integrity of a regular operating system\u2014hopefully detecting whatever stealthy\nmalwareorrootkitcompromiseditbeforeitcandosomeseriousdamage.Althoughaspects\nof these trusted environments clearly overlap with operating system security, we consider\nthem mostly beyond the scope of this knowledge area. We should also note that in recent\nyears,thesecurityofferedbyhardwaretrustedexecutionenvironmentshasbeenrepeatedly\npiercedbyavarietyofsidechannels[1012,1013,1056]thatleakinformationfromsupposedly\n10AsimilarfeatureonSPARCprocessorsisknownasApplicationDataIntegrity(ADI)[1054]\nKAOperatingSystemsandVirtualisation |October2019 Page378 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nsecureworld.\nSwitchinggearsagain,itmaybethecasethattheoperatingsystemisfine,butthehardware\nis not. Malicious or faulty hardware may use the system\u2019s Direct Memory Access (DMA) to\nread or overwrite sensitive data in memory that should be inaccessible to them. Moreover,\nwith some standards (such as Thunderbolt over USB-C), a computer\u2019s PCIe links may be\ndirectly exposed to devices that a user plugs into a computer. Unfortunately for the user, it\nis hard to be sure that what looks like, say, a display cable or power adapter, does not also\ncontain some malicious circuitry designed to compromise the computer [1057]. As a partial\nremedy,mostarchitecturesnowadayscomewithaspecialMMUfordatatransferredtoand\nfrom devices. This hardware, called an IOMMU, serves to map device virtual addresses to\nphysical addresses, mimicking exactly the page-based protection illustrated in Fig. 11.2, but\nnow for DMA devices. In other words, devices may access a virtual memory address, which\ntheIOMMUtranslatestoanactualphysicaladdress,checksforpermissionsandstopsifthe\npageisnotmappedinforthedevice,ortheprotectionbitsdonotmatchtherequestedaccess.\nWhile doing so provides some measure of protection against malicious devices (or indeed\ndrivers), it is important to realise that the IOMMU was designed to facilitate virtualisation\nand really should not be seen as a proper security solution. There are many things that may\ngo wrong [1058]. For instance, perhaps the administrator wants to revoke a device\u2019s access\nrightstoamemorypage.SinceupdatingtheIOMMUpagetablesisaslowoperation,itisnot\nuncommon foroperatingsystems todelay thisoperationand batchit with otheroperations.\nTheresultisthattheremaybeasmallwindowoftimeduringwhichthedevicestillhasaccess\ntothememorypageeventhoughitappearsthattheserightshavealreadybeenrevoked.\nFinally, we can observe that the increasing number of transistors per surface area enables\na CPU vendor to place more and more hardware extensions onto their chips, and the ones\ndiscussed above are by no means the only security-related ones in modern processors. Ad-\nditionalexamplesincludecryptographicunits,memoryencryption,instructionstoswitchex-\ntendedpagetablesefficiently,andpointerauthentication(wherethehardwaredetectsmod-\nificationofpointervalues).Thereisnodoubtthatmorefeatureswillemergeinfuturegener-\nationsandoperatingsystemswillhavetoadaptinordertousetheminameaningfulway.A\nbroaderviewoftheseissuesisfoundintheHardwareSecurityKnowledgeArea(Chapter18).\n11.4.7 Protection rings\nAmong the most revolutionary ideas introduced by Multics was the notion of protection\nrings\u2014a hierarchical layering of privilege where the inner ring (ring 0) is the most privileged\nand the outer ring is the least privileged [1036]. Accordingly, untrusted user processes exe-\ncute in the outer ring, while the trusted and privileged kernel that interacts directly with the\nhardware executes in ring 0, and the other rings could be used for more or less privileged\nsystemprocesses.\nProtection rings typically assume hardware support, something most general purpose pro-\ncessors offer today, although the number of rings may differ. For instance, the Honeywell\n6180 supported as many as eight rings, Intel\u2019s x86 four, ARM v7 three (plus an extra one for\nTrustZone) and PowerPC two. However, as we shall see, the story becomes slightly confus-\ning, because some modern processors have also introduced more and different processor\nmodes.Fornow,wesimplyobservethatmostregularoperatingsystemsuseonlytworings:\nonefortheoperatingsystemandonefortheuserprocesses.\nWheneverlessprivilegedcodeneedsafunctionthatrequiresmoreprivileges,it\u2018callsinto\u2019the\nKAOperatingSystemsandVirtualisation |October2019 Page379 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nlowerringtorequesttheexecutionofthisfunctionasaservice.Thus,onlytrusted,privileged\ncode may execute the most sensitive instructions or manipulate the most sensitive data.\nUnlessaprocesswithfewerprivilegestricksmoreprivilegedcodeintodoingsomethingthat\nit should not be doing (as a confused deputy), the rings provide powerful protection. The\noriginalideainMulticswasthattransitioningbetweenringswouldoccurviaspecialcallgates\nthatenforcestrictcontrolandmediation.Forinstance,thecodeintheouterringcannotmake\na call to just any instruction in the inner ring, but only to predefined entry points where the\ncallisfirstvettedtoseeifitanditsargumentsdonotviolateanysecuritypolicy.\nWhileprocessorssuchasthex86stillsupportcallgates,fewoperatingsystemsusethem,as\ntheyarerelativelyslow.Instead,userprocessestransitionintotheoperatingsystemkernel(a\n\u2018systemcall\u2019)byexecutingasoftwareinterrupt(a\u2018trap\u2019)whichtheoperatingsystemhandles,\normorecommonly,bymeansofaspecial,highlyefficientsystemcallinstruction(withnames\nsuchasSYSCALL,SYSENTER,SVC,SCALLetc.,dependingonthearchitecture).Manyoperat-\ningsystemsplacetheargumentstothesystemcallinapredefinedsetofregisters.Likethe\ncallgates,thetrapsandsystemcallinstructionsalsoensurethattheexecutioncontinuesat\na predefined address in the operating system, where the code inspects the arguments and\nthencallstheappropriatesystemcallfunction.\nBesides the user process calling into the operating system, most operating systems also al-\nlowthekerneltocallintotheuserprocess.Forinstance,UNIX-basedsystemssupportsignals\nwhichtheoperatingsystemusestonotifytheuserprogramabout\u2018somethinginteresting\u2019:an\nerror,anexpiredtimer,aninterrupt,amessagefromanotherprocessetc.Iftheuserprocess\nregistered a handler for the signal, the operating system will stop the current execution of\ntheprocess,storingallitsprocessorstatesontheprocess\u2019stackinaso-calledsignalframe,\nand continue execution at the signal handler. When the signal handler returns, the process\nexecutes a sigreturn system call that makes the operating system take over, restore the\nprocessorstatethatisonthestackandcontinueexecutingtheprocess.\nTheboundarybetweensecuritydomains,suchastheoperatingsystemkernelanduserspace\nprocesses is a good place to check both the system calls themselves and their arguments\nfor security violations. For instance, in capability-based operating systems, the kernel will\nvalidate the capabilities [1049], and in operating systems such as MINIX 3 [1021], specific\nprocesses are only allowed to make specific calls, so that any attempt to make a call that\nis not on the pre-approved list is marked as a violation. Likewise, Windows and UNIX-based\noperatingsystemshavetochecktheargumentsofmanysystemcalls.Consider,forinstance,\nthe common read and write system calls, by which a user requests the reading of data\nfrom a file or socket into a buffer, or the writing of data from a buffer into a file or socket,\nrespectively.Beforedoingso,theoperatingsystemshouldcheckifthememorytowritefrom\norreadintoisactuallyownedbytheprocess.\nAfter executing the system call, the operating system returns control to the process. Here\nalso, the operating system must take care not to return results that jeopordise the system\u2019s\nsecurity. For instance, if a process uses the mmap system call to request the operating sys-\ntem to map more memory into its address space, the operating system should ensure that\nthememorypagesitreturnsnolongercontainsensitivedatafromanotherprocess(e.g.,by\ninitialisingeverybytetozerofirst[1059]).\nZero intialisation problems can be very subtle. For instance, compilers often introduce\npadding bytes for alignment purposes in data structures. Since these padding bytes are not\nvisible at the programming language level at all, the compiler may see no reason to zero ini-\ntialise them. However, a security violation occurs when the operating system returns such\nKAOperatingSystemsandVirtualisation |October2019 Page380 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\na data structure in response to a system call and the unitialised padding contains sensitive\ndatafromthekerneloranotherprocess.\nIncidentally, even the signalling subsystem in UNIX systems that we mentioned earlier is an\ninteresting case for security. Recall that the sigreturn takes whatever processor state is\non the stack and restores that. Now assume that attackers are able to corrupt the stack of\ntheprocessandstoreafakesignalframeonthestack.Iftheattackersarethenalsoableto\ntrigger a sigreturn, they can set the entire processor state (with all the register values) in\nonefellswoop.Doingsoprovidesapowerfulprimitiveinthehandsofaskilledattackerand\nisknownasSigreturn-OrientedProgramming(SROP)[1060].\n11.4.8 One ring to rule them all. And another. And another.\nAs also mentioned earlier, the situation regarding the protection rings is slightly more con-\nfusing these days, as recent CPUs offer virtualisation instructions for a hypervisor, allowing\nthem to control the hardware accesses at ring 0. To do so, they have added what, at first\nsight,lookslikeanextraringatthebottom.Sinceonx86processors,theterm\u2018ring0\u2019hasbe-\ncomesynomymouswith\u2018operatingsystemkernel\u2019(and\u2018ring\u201dwith\u2018userprocesses\u2019),thisnew\nhypervisor ring is commonly referred to as \u2018ring \u20131\u2019. It also indicates that operating systems\nintheirrespectivevirtualmachinescankeepexecutingring0instructionsnatively.However,\nstrictlyspeaking,itservesaverydifferentpurposefromtheoriginalrings,andwhilethename\nring\u20131hasstuck,itisperhapsabitofamisnomer.\nFor the sake of completeness, we should mention that things may get even more complex,\nas some modern processors still have other modes. For instance, x86 offers what is known\nas System Management Mode (SMM). When a system boots, the firmware is in control of\nthehardwareandpreparesthesystemfortheoperatingsystemtotakeover.However,when\nSMMisenabled,thefirmwareregainscontrolwhenaspecificinterruptissenttotheCPU.For\ninstance, the firmware can indicate that it wants to receive an interrupt whenever the power\nbutton is pressed. In that case, the regular execution stops, and the firmware takes over. It\nmay,forinstance,savetheprocessorstate,dowhateveritneedstodoandthenresumethe\noperatingsystemforanorderlyshutdown.Inaway,SMMissometimesseenasalevellower\nthantheotherrings(ring\u20132).\nFinally, Intel even added a ring \u20133 in the form of the Intel Management Engine (ME). ME is a\ncompletely autonomous system that is now in almost all of Intel\u2019s chipsets; it runs a secret\nand completely independent firmware on a separate microprocessor and is always active:\nduringthebootingprocess,whilethemachineisrunning,whileitisasleep,andevenwhenit\nispoweredoff.Aslongasthecomputerisconnectedtopower,itispossibletocommunicate\nwiththeMEoverthenetworkand,say,installupdates.Whileverypowerful,itsfunctionalityis\nlargelyunknownexceptthatitrunsitsownsmalloperatingsystem11 whichresearcherfound\ncontainedvulnerabilities.TheadditionalprocessorsthataccompanythemainCPU(beitthe\nME or related ones such as Apple\u2019s T2 and Google\u2019s Titan chips) raise an interesting point:\nis the operating system running on the main CPU even capable of meeting today\u2019s security\nrequirements?Atleast,thetrendappearstoaugmentitwithspecial-purposesystems(hard-\nwareandsoftware)forsecurity.\n11Version11oftheME,atthetimeofwriting,isbasedonMINIX-3.\nKAOperatingSystemsandVirtualisation |October2019 Page381 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n11.4.9 Low-end devices and the IoT\nManyofthefeaturesdescribedabovearefound,onewayoranother,inmostgeneral-purpose\nprocessor architectures. However, this is not necessarily true in the IoT, or embedded sys-\ntemsingeneral,andtailoredoperatingsystemsarecommonlyused[1061].Simplemicrocon-\ntrollers typically have no MMUs, and sometimes not even MPUs, protection rings, or any of\ntheadvancedfeatureswerelyonincommonoperatingsystems.Thesystemsaregenerally\nsmall (reducing attack surface) and the applications trusted (and possibly verified). Never-\ntheless,theembeddednatureofthedevicesmakesithardtocheckoreventesttheirsecurity\nand,wherevertheyplayaroleinsecuritysensitiveactivities,securitybymeansofisolation\/-\ncontainment and mediation should be enforced externally, by the environment. Wider IoT\nissuesareaddressedintheCyber-PhysicalSystemsSecurityKnowledgeArea(Chapter19).\n11.5 OPERATING SYSTEM HARDENING\n[1016,1030,1062,1063]\nThebestwaytosecureoperatingsystemsandvirtualmachinesistohavenovulnerabilities\nat all: security by design. For instance, we can use formal verification to ensure that certain\nclasses of bugs cannot be present in the software or hardware, and that the system is func-\ntionally correct [1049]. Scaling the verification to very large systems is still challenging, but\nthefieldisadvancingrapidlyandwehavenowreachedthestagethatimportantcomponents\nsuchasamicrokernel,filesystemsandcompilershavebeenverifiedagainstaformalspecifi-\ncation.Moreover,itisnotnecessarytoverifyallthecomponentsofasystem:guaranteeting\nisolation simply requires a verified microkernel\/hypervisor and a few more verified compo-\nnents. Verification of other components may be desirable, but is not essential for isolation.\nOfcourse,theverificationitselfisonlyasgoodastheunderlyingspecification.Ifyougetthat\nwrong,itdoesnotmatterifyouhaveverifiedit,youmaystillbevulnerable.\nDespite our best efforts, however, we have not been able to eradicate all security bugs from\nlarge,real-worldsystems.Toguardthemselvesagainstthetypesofattacksdescribedinthe\nthreats model, modern operating systems employ a variety of solutions to complement the\nabove isolation and mediation primitives. We distinguish between five different classes of\nprotection: information hiding, control flow restrictions, partitioning, code and data integrity\nchecks,andanomalydetection.\n11.5.1 Information hiding\nOneofthemainlinesofdefenseinmostcurrentoperatingsystemsconsistsofhidingwhat-\never the attackers may be interested in. Specifically, by randomising the location of all rel-\nevant memory areas (in code, heap, global data and stack), attackers will not know where\nto divert the control flow, nor will they be able to spot which addresses contain sensitive\ndata, etc. The term Address Space Layout Randomization (ASLR) was coined around the\nrelease of the PaX security patch, which implemented this randomisation for the Linux ker-\nnel in 2001 [1064]\u2014see also the discussion in the Software Security Knowledge Area (Sec-\ntion 14.4.2). Soon, similar efforts appeared in other operating systems and the first main-\nstreamoperatingsystemstohaveASLRenabledbydefaultwereOpenBSDin2003andLinux\nin 2005. Windows and MacOS followed in 2007. However, these early implementations only\nrandomisedtheaddressspaceinuserprogramsandrandomisationdidnotreachthekernel\nof major operating systems, under the name of Kernel ASLR (KASLR), until approximately a\nKAOperatingSystemsandVirtualisation |October2019 Page382 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ndecadeafteritwasenabledbydefaultinuserprograms.\nThe idea of KASLR is simple, but there are many non-trivial design decisions to make. For\ninstance,howrandomisrandom?Inparticular,whatportionoftheaddressdowerandomise?\nSay your Linux kernel has an address range of 1GB (=230) for the code, and the code should\nbe aligned to 2MB (=221) boundaries. The number of bits available for randomisation (the\nentropy) is 30\u221221 = 9 bits. In other words, we need at most 512 guesses to find the kernel\ncode.Ifattackersfindavulnerabilitytodivertthekernel\u2019scontrolflowtoaguessedaddress\nfrom a userspace program and each wrong guess leads to a system crash, it would suffice\nto have userspace access to a few hundred machines to get it right at least once with high\nprobability(althoughmanymachineswillcrashintheprocess).\nAnother important decision is what to randomise. Most implementations today employ\ncoarse-grained randomisation: they randomise the base location of the code, heap or stack,\nbutwithineachoftheseareas,eachelementisatafixedoffsetfromthebase.Thisissimple\nandveryfast.However,onceattackersmanagetogetholdofevenasinglecodepointervia\naninformationleak,theyknowtheaddressesforeveryinstruction.Thesameistrue,mutatis\nmutandis, for the heap, stack etc. It is no surprise that these information leaks are highly\nvaluedtargetsforattackerstoday.\nFiner-grainedrandomisationisalsopossible.Forinstance,itispossibletorandomiseatthe\npage level or the function level. If we shuffle the order of functions in a memory area, even\nknowingthebaseofthekernelcodeisnotsufficientforanattacker.Indeed,wecangomore\nfine-grained still, and shuffle basic blocks, instructions (possibly with junk instructions that\nneverexecuteorhavenoeffect)oreventheregisterallocations.Manyfine-grainedrandomi-\nsationtechniquescomeatthecostofspaceandtimeoverheads,forinstance,duetoreduced\nlocalityandfragmentation.\nBesidesthecode,fine-grainedrandomisationisalsopossiblefordata.Forinstance,research\nhas shown that heap allocations, globals and even variables on the stack can be scattered\naroundmemory.Ofcourse,doingsowillincuracostintermsofperformanceandmemory.\nConsideringKASLR,andespeciallycoarse-grainedKASLR,asourfirstlineofdefenseagainst\nmemoryerrorexploitswouldnotbefaroffthemark.Unfortunately,itisalsoaveryweakde-\nfense.NumerouspublicationshaveshownthatKASLRcanbebrokenfairlyeasily,byleaking\ndataand\/orcodepointersfrommemory,sidechannels,etc.\n11.5.2 Control-flow restrictions\nAnorthogonallineofdefenseistoregulatetheoperatingsystem\u2019scontrolflow.Byensuring\nthatattackerscannotdivertcontroltocodeoftheirchoosing,wemakeitmuchhardertoex-\nploit memory errors, even if we do not remove them. The best example is known as Control-\nFlow Integrity (CFI) [1063], which is now supported by many compiler toolchains (such as\nLLVMandMicrosoft\u2019sVisualStudio)andincorporatedintheWindowskernelunderthename\nof Control Flow Guard as of 2017 \u2014 see also the Software Security Knowledge Area (Chap-\nter14).\nConceptually,CFIisreallysimple:weensurethatthecontrolflowinthecodealwaysfollows\nthe static control flow graph. For instance, a function\u2019s return instruction should only be al-\nlowed to return to its callsite, and an indirect call using a function pointer in C, or a virtual\nfunction in C++, should only be able to target the entry point of the legitimate functions that\nitshouldbeabletocall.Toimplementthisprotection,wecanlabelallthelegitimatetargets\nKAOperatingSystemsandVirtualisation |October2019 Page383 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nforanindirectcontroltransferinstruction(returns,indirectcallsandindirectjumps)andadd\nthese labels to a set that is specific for this instruction. At runtime, we check whether the\ncontrol transfer the instruction is about to make is to a target that is in the set. If not, CFI\nraisesanalarmand\/orcrashestheprogram.\nLikeASLR,CFIcomesinmanyflavours,fromcoarse-grainedtofine-grained,andfromcontext\nsensitive to context insensitive. And just like in ASLR, most implementations today employ\nonly the simplest, most coarse-grained protection. Coarse-grained CFI means relaxing the\nrules a little, in the interest of performance. For instance, rather than restricting a function\u2019s\nreturn instruction to target-only legitimate call sites that could have called this function, it\nmay target any call site. While less secure than fine-grained CFI [1065], it still restricts the\nattackers\u2019wiggleroomtremendously,andhasamuchfasterruntimecheck.\nOn modern machines, some forms of CFI are (or will be) even supported by hardware. For\ninstance,IntelControl-FlowEnforcementTechnology(CET)supportsshadowstacksandin-\ndirectbranchtrackingtohelpenforcetheintegrityofreturnsandforward-edgecontroltrans-\nfers (in a very coarse-grained way), respectively. Not to be outdone, ARM provides pointer\nauthenticationtopreventillegitimatemodificationofpointervalues\u2014essentiallybyusingthe\nupper bits of a pointer to store a Pointer Authentication Code (PAC), which functions like a\ncryptographic signature on the pointer value (and unless you get the PAC right, your pointer\nisnotvalid).\nUnfortunately,CFIonlyhelpsagainstattacksthatchangethecontrolflow\u2014bycorruptingcon-\ntrol data such as return addresses, function pointers and jump targets\u2014but is powerless\nagainstnon-controldataattacks.Forinstance,itcannotstopamemorycorruptionthatover-\nwritestheprivilegelevelofthecurrentprocessandsetsitto\u2018root\u2019(e.g.,bysettingtheeffective\nuseridtothatoftherootuser).However,ifrestrictionsonthecontrolflowaresuchasuccess\ninpractice,youmaywonderifsimilarrestrictionsarealsopossibleondataflow.Indeedthey\nare, which is called Data-Flow Integrity (DFI) [1066]. In DFI, we determine statically for each\nload instruction (i.e., an instruction that reads from memory) which store instructions may\nlegitimately have produced the data, and we label these instructions and save these labels\ninaset.Atruntimeweremember,foreachbyteinmemory,thelabelofthelaststoretothat\nlocation. When we encounter a load instruction, we check if the last store to that address\nis in the set of legitimate stores, and if not, we raise an alarm. Unlike CFI, DFI has not been\nwidelyadoptedinpractice,presumablybecauseofthesignificantperformanceoverheads.\n11.5.3 Partitioning.\nBesides the structural decomposition of a system in different security domains (e.g, into\nprocessesandthekernel)protectedbyisolationprimitiveswithorwithouthardwaresupport,\nthere are many additional techniques that operating systems employ to make it harder for\nattackerstocompromisetheTCB.Inthissection,wediscussthemostprominentones.\nW\u2295X memory. To prevent code injection attacks, whereby the attackers transfer control to\na sequence of instructions they have stored in memory areas that are not meant to contain\ncodesuchasthestackortheheap,operatingsystemstodaydrawahardlinebetweencode\nanddata[1062].Everypageofmemoryiseitherexecutable(codepages)orwritable,butnot\nbothatthesametime.Thepolicy,frequentlyreferredtoasW\u2295X(\u2018writexorexecute\u2019),prevents\nthe execution of instructions in the data area, but also the modification of existing code. In\nthe absence of code injection, attackers interested in diverting the control flow of the pro-\ngramareforcedtoreusecodethatisalreadypresent.Similarmechanismsareusedtomake\nKAOperatingSystemsandVirtualisation |October2019 Page384 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nsensitive data in the kernel (such as the system call table, the interrupt vector table, etc.)\nread-only after initialisation. All major operating systems support this mechanism, typically\nrelying on hardware support (the NX bit in modern processors12)\u2014even if the details differ\nslightly, and the name may vary from operating system to operating system. For instance,\nMicrosoft refers to its implementation by the name Data Execution Prevention (DEP). Pre-\nventing the kernel from accessing userspace. We have already seen that operating systems\nusetheCPU\u2019sprotectionringstoensurethatuserprocessescannotaccessarbitrarydataor\nexecute code in the operating system, in accordance with the security principles by Saltzer\n& Schroeder, which prescribe that all such accesses be mediated. However, sometimes we\nalso need to protect the other direction and prevent the kernel from blindly accessing (or\nworse,executing)thingsinuserspace.\nTo see why this may be bad, consider an operating system where the kernel is mapped into\neveryprocess\u2019addressspaceandwheneveritexecutesasystemcall,itexecutesthekernel\ncodeusingtheprocess\u2019pagetables.ThisishowLinuxworkedfromitsinceptionin1991until\nDecember 2017. The reason is that doing so is efficient, as there is no need to switch page\ntables when executing a system call, while the kernel can efficiently access all the memory.\nAlso since the kernel pages have the supervisor (S) bit set, there is no risk that the user\nprocess willaccess thekernel memory.However, supposethe kernel hasa bugthat causes\nit to de-reference a function pointer that under specific circumstances happens to be NULL.\nThe most likely thing to happen is that the kernel crashes. After all, the kernel is trying to\nexecutecodeonapagethatisnotvalid.Butwhatifamaliciousprocessdeliberatelymapsa\npageataddress0,andfillsitwithcodethatchangestheprivilegesofthecurrentprocessto\nthatofroot?Inthatcase,thekernelwillexecutethecode,withkernelprivileges.Thisisbad.\nItshouldnowbeclearthatthekernelshouldprobablynotblindlyexecuteprocesscode.Nor\nshoulditreadblindlyfromuserdata.Afterall,anattackercoulduseittofeedmaliciousdata\nto the kernel instructions. To prevent such accesses, we need even more isolation than that\nprovided by the default rings. For this reason, many CPUs today provide Supervisor Mode\nExecution Protection (SMEP) and Supervisor Mode Access Protection (SMAP)13. SMEP and\nSMAP are enabled by setting the appropriate bits in a control register. As soon as they are\non, any attempt to access or transfer control to user memory will result in a page fault. Of\ncourse,thisalsomeansthatSMAPshouldbeturnedoffexplicitlywheneverthekernelneeds\ntoaccessusermemory.\nSomeoperatingsystems,includingLinux,gotSMEP-likerestrictions\u2018forfree\u2019onsystemsvul-\nnerabletotheMeltdownvulnerabilityin2017[1010],whichforcedthemtoadoptanalternative\ndesign,whichcamewithapricetag.Inparticular,theywereforcedtoabandonthesinglead-\ndressspace(wherethekernelexecutesintheaddressspaceoftheprocess),becauseofthe\nMeltdown out-of-order execution side channel from Table 11.1. To recap, the Meltdown (and\nrelatedSpectre)attacksconsistofattackersabusingtheCPU\u2019s(over-)optimismaboutwhat\nhappensintheinstructionsitexecutesout-of-orderorspeculatively.Forinstance,itwrongly\nassumesthatloadinstructionshavetheprivilegetoreadthedatatheyaccess,theoutcome\nofabranchisthesameastheprevioustimeabranchatasimilaraddresswasexecuted,or\nthedataneededforaloadinstructionisprobablythedatainthistemporaryCPUbufferthat\nwasjustwritten.However,evenifanyoftheseassumptionsarewrong,theCPUcanrecover\nbysquashingtheresultsofthecodethatwasexecutedout-of-orderorspeculatively.\n12NX(noexecute)ishowAMDoriginallycalledthefeatureinitsx86compatibleCPUs.IntelcallsitExecute\nDisable(XD)andARMExecuteNever(XN).\n13Again,thisisx86terminology.OnARMsimilarfeaturesarecalledPrivilegedAccessNever(PAN)andPriv-\nilegedExecuteNever(PXN).\nKAOperatingSystemsandVirtualisation |October2019 Page385 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nInaMeltdown-likeattack,theattackers\u2019processexecutesanout-of-orderinstructiontoread\na byte at a (supposedly inaccessible) kernel address, and the CPU optimistically assumes\nall is well and simply accesses the byte. Before the CPU realises things are not well after\nallandthisbyteshouldnotbeaccessible,theattackershavealreadyusedthebytetoreada\nparticularelementinalargearrayintheirownprocess\u2019addressspace.AlthoughtheCPUwill\neventuallysquashalltheresults,thedamageisalreadydone:eventhoughthebytecannotbe\nreaddirectly,theindexofthearrayelementthatisinthecache(andis,therefore,measurably\nfastertoaccessthantheotherelements)mustbethekernelbyte.\nTo remedy this problem on somewhat older processors that do not have a hardware fix for\nthis vulnerability, operating systems such as Linux use a design that completely separates\nthe page tables of the kernel from those of the processes. In other words, the kernel also\nrunsinitsownaddressspace,andanyattemptbyanout-of-orderinstructiontoreadakernel\naddress will fail. The kernel can still map in the pages of the user process and thus access\nthem if needed, but the permissions can be different. Specifically, if they are mapped in as\nnon-executable,webasicallygetSMEPfunctionalityforfree.\nForothervulnerabilitiesbasedonspeculativeexecution(suchasSpectreandRIDL),thefixis\nmoreproblematic.Often,multipledifferentspotsolutionsareusedtopatchthemostserious\nissues. For instance, after a bounds check that could be influenced by untrusted users, we\nmay want to insert special instructions to stop speculation completely. Likewise, operating\nsystemssuchasWindowstryto\"gangschedule\"onlycodethatbelongstothesamesecurity\ndomain on the same core (so that leaking from on thread to another on the same core is\nless of an issue), while others such as OpenBSD disable hyperthreading altogether on Intel\nprocessors. However, it is unclear how complete the set of patches will be, while we are\nwaitingforthehardwaretobefixed.\nPartitioningmicro-architecturalstatesSophisticatedsidechannelattacksbuildontheaggres-\nsive resource sharing in modern computer systems. Multiple security domains share the\nsame cache, the same TLB, the same branch predictor state, the same arithmetic units, etc.\nSharing is good for efficiency, but, as indicated by the Principle of Least Common Mecha-\nnism, they also give rise to side channels. To prevent such attacks, operating systems may\nneed to sacrifice some of the efficiency and partition resources even at fine granularity. For\ninstance,bymeansofpagecolouringinsoftwareorhardware-basedcacheallocationtechnol-\nogy, an operating system may give different processes access to wholly disjointed portions\nof the cache (e.g., separating the cache sets or separating the ways within a cache set). Un-\nfortunately, partitioning is not always straightforward and currently not supported for many\nlow-levelresources.\n11.5.4 Code and data integrity checks\nOne way to reduce the exploitability of code in an operating system, is to ensure that the\ncode and\/or data is unmodified and provided by a trusted vendor. For instance, for many\nyears Windows has embraced driver signing. Some newer versions have taken this a step\nfurtheranduseacombinationofhardwareandsoftwaresecurityfeaturestolockamachine\ndown, ensuring that it runs only trusted code\/apps\u2014a process referred to by Microsoft as\n\u2018DeviceGuard\u2019.Evenprivilegedmalwarecannoteasilygetnon-authorisedappstorun,asthe\nmachinery to check whether to allow an app to run sits in a hardware-assisted virtualised\nenvironment. Most code signing solutions associate digital signatures associated with the\noperatingsystemextensionsallowtheoperatingsystemtocheckwhetherthecode\u2019sintegrity\nisintactandthevendorislegitimate.Asimilarprocessispopularlyusedforupdates.\nKAOperatingSystemsandVirtualisation |October2019 Page386 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nHowever, what about the code that checks the signature and, indeed, the operating system\nitself\u2014arewesurethatthishasnotbeentamperedwithbyamaliciousbootkit?Ensuringthe\nintegrityofthesystemsoftwarethatisloadedduringthebootinginvolvesanumberofsteps,\nmostlyrelatedtothemultiplestepsinthebootprocessitself.Fromtheearliestcommercial\ncomputersonward,bootinginvolved multiplestages.EventheIBM701,a popularcomputer\nin the early 1950s with as many as 19 installations, already had such a multi-stage booting\nprocedurethatstartedwithpressingaspecial\u2018Load\u2019buttontomakethesystemloadasingle\n36-bit word from, typically, a punched card. It would execute (part of) this word to load even\nmoreinstructions,andthenstartexecutingtheseinstructionsasthe\"bootprogram\".\nIn general, securely booting devices starts with an initial \u2018root of trust\u2019 which initiates the\nbootingprocessandistypicallybasedinhardware,forinstance,amicrocontrollerthatstarts\nexecuting software from internal, immutable memory, or from internal flash memory that\ncannot be reprogrammed at all, or only with strict authentication and authorisation checks.\nAs an example, modern Apple computers use a separate processor, the T2 Security Chip, to\nprovidethehardwarerootoftrustforsecurebootamongotherthings,whileGooglehasalso\ndevelopedacustomprocessorforthiscalledtheTitan.Wewillnowdiscusshowahardware-\nrootoftrusthelpstoverifythatasystembootedsecurely.\nBooting general-purpose computers typically starts with the firmware which initiates a se-\nquence of stages that ends with a fully booted system. For instance, the firmware may load\naspecialbootloaderprogramwhichthenloadstheoperatingsystemkernelwhichinturnmay\nload additional boot drivers until finally the operating system is fully initialised and ready to\ninteract with the user or applications. All of these stages need protection. For instance,the\nUnifiedExtensibleFirmwareInterface(UEFI)canprotectthefirststage(i.e.,verifytheintegrity\nof the bootloader), by means of Secure Boot. Secure boot verifies whether the boot loaders\nweresignedwiththeappropriatekey,i.e.,usingkeysthatagreewiththekeyinformationthat\nisstoredinthefirmware.Thiswillpreventloadersanddriverswithouttheappropriatesigna-\nturesfromgainingcontrolofthesystem.Thebootloadercannowverifythedigitalsignature\nof the operating system kernel before loading it. Next, the kernel verifies all other compo-\nnents of the operating system (such as boot drivers and possibly integrated anti-malware\nsoftware)beforestartingthem.Bystartingtheanti-malwareprogrambeforeotherdrivers,it\ncan subsequently check all these later components, and extend the chain of trust to a fully\ninitialisedoperatingsystem.\nThenextproblemis:howdoweknow thatthisisthecase?Inotherwords,howdoweknow\nthatthesystemreallydidbootsecurelyandwecantrustwhateverisdisplayedonthescreen?\nThe trick here is to use attestation, whereby a (remote) party can detect any changes that\nhavebeenmadetooursystem.Remoteattestationtypicallyusesspecialhardwaresuchas\na Trusted Platform Module (TPM) that serves as a root of trust and consists of verifying, in\nsteps, whether the system was loaded with the \u2018right\u2019 kind of software. In particular, a TPM\nis a cryptograhic hardware module that supports a range of cryptographic functions, key\ngeneration and management, secure storage (e.g., for keys and other security-sensitive in-\nformation),andimportantly,integritymeasurements.SeetheHardwareSecurityKnowledge\nArea(Chapter18)forfurtherdiscussion.\nFortheintegritymeasurements,TPMshaveasetofPlatformConfigurationRegisterscalled\nPCR-0, PCR-1, ..., that are set to a known value on every boot. These registers are not for\nwriting to directly, but rather for extending. So, if the current value of the PCR-0 register is X\nand we want to extend it with Y, the TPM calculates hash(X,Y) and stores the outcome in\nPCR-0.Now,ifwewanttoextenditfurther,saywithZ,theTPMagaincalculatesthehashof\nKAOperatingSystemsandVirtualisation |October2019 Page387 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nZ and the value currently in PCR-0 and stores the outcome in PCR-0. In other words, it will\ncalculatehash(Z,hash(X,Y)).Wecannowextendthisfurtherandcreateanarbitrarilylong\n\u201chashchain\".\nThevaluesinthePCRscanserveasevidencethatthesystemisinatrustworthystate.Specif-\nically, the first code that executes when you boot your system is firmware boot code that is\nsometimes referred to as the Core Root of Trust for Measurements (CRTM) or BIOS boot\nblock. This code will \u2018measure\u2019 the full firmware by generating a hash of its content which it\nsendstotheTPMtoextendPCR-0,beforeitstartsexecutingit.Next,thefirmwarethatisnow\nexecuting will measure the next component of the boot process and again store the value\nin a PCR of the TPM (e.g., by extending PCR-0), before executing it. After a number of these\nstages, the PCR register(s) contain a hash chain of all steps that the system took to boot.\nA remote party can now verify whether the system booted securely by asking the TPM for\na \u2018quote\u2019: a report of a set of PCR values currently in PCRs (together with a nonce supplied\nbytheremoteparty),thatissignedwiththeTPM\u2019sprivateAttestationIdentityKeythatnever\nleavestheTPM(andderivesfromahardcodedkeythatwascreatedatmanufacturingtime).\nAs the public key is well-known, anyone can verify that the quote came from the TPM. Upon\nreceiving the quote and after verifying that it came from the TPM and that it was fresh, the\nremotepartyknowsthatthebootingprocesscouldonlyhavefollowedthestepsthatcreated\nthese hashes in the PCRs. If they correspond to the hashes of known and trusted code, the\nremotepartyknowsthatthesystembootedsecurely.\nCode and data integrity checking may well continue at runtime. For instance, the hypervisor\nmay provide functionality to perform introspection of its virtual machines: is the code still\nthe same, do the data structures still make sense? This technique is known as Virtual Ma-\nchineIntrospection(VMI).TheVMIfunctionalitymayresideinthehypervisoritself,although\nitcouldbeinaseparateapplication.Besidesthecode,commonthingstocheckinVMIsolu-\ntionsincludetheprocesslist(isanyrootkittryingtohide?),thesystemcalltable(isanybody\nhijackingspecificsystemcalls?),theinterruptvectortable,etc.\n11.5.5 Anomaly detection\nAmonitor,beitinthehypervisororintheoperatingsystem,canalsobeusedtomonitorthe\nsystem for unusual events\u2014anomaly detection [1067]. For instance, a system that crashes\nhundreds of times in a row could be under attack by someone who is trying to break the\nsystem\u2019s address spacelayoutrandomisation. Ofcourse, there isno hard evidenceandjust\nbecauseananomalyoccurreddoesnotmeanthereisanattack.Anomalydetectionsystems\nmust strike a balance between raising too many false alarms, which are costly to process,\nandraisingtoofew,whichmeansitmissedanactualattack.\n11.6 OPERATING SYSTEMS, HYPERVISORS\u2014WHAT ABOUT\nRELATED AREAS?\n[1030,c4,c7]\nThe problems that we encounter at the operating system and hypervisor levels resurface in\nother systems areas and the solutions are sometimes similar. In this section, we briefly dis-\ncussdatabasesasanexampleofhowoperatingsystemsecurityprinciples,issuesandsolu-\ntionsareappliedtootherdomains[1068].Securityindatabasesystemsfollowssimilarprin-\nciplesasthoseinoperatingsystemswithauthentication,privileges,accesscontrolandsoon\nKAOperatingSystemsandVirtualisation |October2019 Page388 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nasprimeconcerns.Thesameistrueforaccesscontrol,wheremanydatabasesofferdiscre-\ntionary access control by default, and role-based and mandatory access control for stricter\ncontrol to more sensitive data. Representing each user as a security domain, the questions\nweneedtoanswerconcern,forinstance,theuser\u2019sprivileges,theoperationsthatshouldbe\nlogged for auditing, and the resource limits such as disk quota, CPU processing time, etc. A\nuser\u2019s privileges consist of the right to connect to the database, create tables, insert rows\nin tables, or retrieve information from other users\u2019 tables, and so on. Note that sometimes\nusers who do not have access to a database except by means of a specific SQL query may\ncraftmaliciousinputstoelevatetheirprivilegesinso-calledSQLinjectionattacks[1069].\nWhiledatabase-levelaccesscontrollimitswhogetsaccesstowhichelementsofadatabase,\nitdoesnotpreventaccessesattheoperatingsystemleveltothedataondisk.Forthisreason,\nmany databases support transparent data encryption of sensitive table columns on disk\u2014\noften storing the encryption keys in a module outside the database. In an extreme case, the\ndatainthedatabasemaybeencryptedwhileonlytheclientsholdthekeys.\nQueryingsuchencrypteddataisnottrivial[471].Whilesophisticatedcryptographicsolutions\n(such as homomorphic encryption) exist, they are quite expensive and simpler solutions\nare commonly used. For instance, sometimes it is sufficient to store the hash of a credit\ncard number, say, instead of the actual number and then query the database for the hash.\nOf course, in that case, only exact matches are possible\u2014as we cannot query to see if the\nvalue in the database is greater than, smaller than, or similar to some other value (nor are\naggregated values such as averages or sums possible). The problem of querying encrypted\ndatabasesisanactivefieldofresearchandbeyondthescopeofthisKnowledgeArea.\nWhilesecurityandaccesscontrolinregulardatabasesisnon-trivialalready,thingsgeteven\nmorecomplexinthecaseofOutsourcedDatabases(ODBs),whereorganisationsoutsource\ntheir data management to external service providers [1070]. Specifically, the data owner cre-\natesandupdatesthedataatanexternaldatabaseprovider,whichthendealswiththeclient\u2019s\nqueries. In addition to our earlier concerns about confidentiality and encryption, questions\nthat arise concern the amount of trust to place in the provider. Can the data owner or the\nqueryingclienttrusttheprovidertoprovidedatathatwascreatedbytheoriginaldataowner\n(authenticity),unmodified(integrity),andfreshresultstothequeries?Conceptually,itispos-\nsible to guarantee integrity and authenticity by means of signatures. For instance, the data\nowner may sign entire tables, rows\/records in a table, or even individual attributes in a row,\ndepending on the desired granularity and overhead. More advanced solutions based on au-\nthenticated data structures are also commonly advocated, such as Merkle hash trees. In\nMerkle hash trees, originally used to distribute authenticated public keys, leaf nodes in the\ntree contain a hash of their data value (the database record), each non-leaf node contains a\nhashofthehashesofitschildren,andtherootnode\u2019shashissignedandpublished.Allthat\nisneededtoverifyifavalueinaleafnodeisindeedpartoftheoriginalsignedhashtreeisthe\nhashesoftheintermediatenodes,whichtheclientcanquicklyverifywithanumberofhashes\nproportionaltothelogarithmofthesizeofthetree.Ofcourse,rangequeriesandaggregation\naremoreinvolvedandresearchershaveproposedmuchmorecomplexschemesthanMerkle\nhashtrees,butthesearebeyondthescopeofthisknowledgearea.Thetake-awaymessage\nisthatwithsomeeffortwecanguaranteeauthenticity,integrityandfreshness,eveninODBs.\nKAOperatingSystemsandVirtualisation |October2019 Page389 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n11.7 EMBRACING SECURITY\n[1002,c9][1030,c1-c21]\nIncreasingly advanced attacks are leading to increasingly advanced defenses. Interestingly,\nmanyoftheseinnovationsinsecuritydonotoriginallycomefromtheoperatingsystemven-\ndorsorlargeopensourcekernelteams,butrather\u2018fromtheoutside\u2019\u2014sometimesacademic\nresearchers,butinthecaseofoperatingsystemsecurity,alsooftenfromindependentgroups\nsuchasGRSecurity andthePaXTeam.Forinstance,thePaXTeamintroducedASLRasearly\nas 2001, played a pioneering role in making data areas non-executable and executable sec-\ntions non-writable, as well as in ensuring the kernel cannot access\/execute user memory.\nSurprisingly, where you might think that the major operating systems would embrace these\ninnovations enthusiastically, the opposite is often true and security measures are adopted\ninconsistently.\nThe main reason is that nothing is free and a slow-down or increase in power consumption\nbecause of a security measure is not very popular. The Linux kernel developers in particu-\nlar have been accused of being obsessed with performance and having too little regard for\nsecurity. However, when the situation is sufficiently pressing, there is no other way than to\ndealwiththeproblem,evenifitiscostly.Inoperatingsystems,thisperformanceversussecu-\nrity trade-off has become increasingly important. Research often focuses on methods that\nsignificantlyraisethebarforattackers,atanacceptableoverhead.\nCONCLUSION\nIn this Knowledge Area, we addressed security issues at the lowest levels of the software\nstack: the operating system and the hypervisor. Operating system \/ hypervisor security in-\nvolves both the security of the operating system \/ hypervisor and the security guarantees\nofferedby theoperatingsystem\/hypervisor.Asthemostprivilegedcomponents,operating\nsystemsandhypervisorsplayacriticalroleinmakingsystems(in)secure.Unfortunately,the\nattack surface of a modern operating system or hypervisor is often large and threats of in-\ncreasing sophistication involving both software and hardware call for increasingly powerful\ndefensesalsoinvolvingsoftwareandhardware.Startingfromsecurityprinciplesandfunda-\nmentals,weshowedthatthesystem\u2019ssecurityisinfluencedbythedesignofthesystem(e.g.,\nin the isolation of security domains), and the available security primitives and mechanisms\nto enforce the principles (e.g., memory isolation, capabilities, protection rings). Many of the\nprinciples of operating system design are useful across many application domains and are\ncommonlyappliedinotherareas,suchasdatabasemanagementsystems.Aswithmostdo-\nmains,wesawthatdesigndecisionsattheoperatingsystem\/hypervisorlevelareatrade-off\nbetween security and performance\u2014a balancing act that often slows down the adoption of\nsecuritymeasures.\nKAOperatingSystemsandVirtualisation |October2019 Page390 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nCROSS-REFERENCE OF TOPICS VS REFERENCE MATERIAL\n11.1Attackermodel c9 c1-c9 [1003] [999] c1\n11.2OSdesignandsecurity c1-c12 [999] c1 [8] [1031] [1035]\n11.3Principlesandmodels c9 c4,c7 [8] [1031]\n11.4primitives c3,c9 c4,c7 [8] [1031] c1-c9 [1035]\n11.5OShardening c9 c1-c9 [1003]\n11.6Securityindatabases c4,c6 [1003]\n11.7EmbracingSecurity c9 c1-c21 [1003]\nKAOperatingSystemsandVirtualisation |October2019 Page391\n]2001[nredom5102muabnenat\n]0301[ytiruces8002nosredna\n]1001[4031491:EKG:0102:alreP\n]3001[2102-yromem-neev-red-nav\n]999[6216582.9416582:TAE:6102:arrudnagS\n]8101[6042051:SSO:8002:regeaJ\n]8[noitcetorpeht57reztlaS\n]1301[58:koobegnaro\n]4301[ytilibapac4102yvel\n]5301[497487.295487:LYT:2002:regraK TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nKAOperatingSystemsandVirtualisation |October2019 Page392 Chapter 12\nDistributed Systems\nSecurity\nNeeraj Suri Lancaster University\n393 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nINTRODUCTION\nA distributed system is typically a composition of geo-dispersed resources (computing and\ncommunication) that collectively (a) provides services that link dispersed data producers\nand consumers, (b) provides on-demand, highly reliable, highly available, and consistent re-\nsourceaccess,oftenusingreplicationschemastohandleresourcefailures,and(c)enables\nacollectiveaggregatedcapability(computationalorservices)fromthedistributedresources\ntoprovide(anillusionof)alogicallycentralised\/coordinatedresourceorservice.\nExpanding on the above, the distributed resources are typically dispersed (for example, in\nan Azure or Amazon Cloud, in Peer-to-Peer Systems such as Gnutella or BitTorrent, or in a\nBlockchain implementation such as Bitcoin or Ethereum) to provide various features to the\nusers. These include geo-proximate and low-latency access to computing elements, high-\nbandwidth and high-performance resource access, and especially highly-available uninter-\nrupted services in the case of resource failure or deliberate breaches. The overall technical\nneeds in a distributed system consequently relate to the orchestration of the distributed re-\nsourcessuchthattheusercantransparentlyaccesstheenhancedservicesarisingfromthe\ndistributionofresourceswithouthavingtodealwiththetechnicalmechanismsprovidingthe\nvariedformsofdistributedresourceandserviceorchestrations.\nTo support these functionalities, a distributed system commonly entails a progression of\nfourelements.Theseinclude(a)dataflowsacrossthecollectionofauthorisedinputs(regu-\nlatedviaAccess\/AdmissionControl),(b)transportationofthedatato\/acrossthedistributed\nresources (Data Transport functionality), (c) a resource coordination schema (Coordination\nServices), and (d) property based (e.g., time or event based ordering, consensus, virtualisa-\ntion)datamanagementtosupportthedesiredapplicationssuchastransactions,databases,\nstorage,control,andcomputing.\nConsequently, distributed systems security addresses the threats arising from the exploita-\ntion of vulnerabilities in the attack surfaces created across the resource structure and func-\ntionalities of the distributed system. This covers the risks to the data flows that can com-\npromise the integrity of the distributed system\u2019s resources\/structure, access control mech-\nanisms (for resource and data accesses), the data transport mechanisms, the middleware\nresourcecoordinationservicescharacterisingthedistributedsystemmodel(replication,fail-\nure handling, transactional processing, and data consistency), and finally the distributed ap-\nplicationsbasedonthem(e.g.,webservices,storage,databasesandledgers).\nThis Knowledge Area first introduces the different classes of distributed systems categoris-\ning them into two broad categories of decentralised distributed systems (without central\ncoordination) and the coordinated resource\/services type of distributed systems. Subse-\nquently,eachofthesedistributedsystemcategoriesisexpoundedfortheconceptualmech-\nanisms providing their characteristic functionalities prior to discussing the security issues\npertinenttothesesystems.Assecuritybreachesinadistributedsystemtypicallyarisefrom\nbreachesintheelementsrelatedtodistribution(dispersion,access,communication,coordi-\nnation, etc.), the KA emphasises the conceptual underpinnings of how distributed systems\nfunction. The better one understands how functionality is distributed, the better one can un-\nderstandhowsystemscanbecompromisedandhowtomitigatethebreaches.TheKAalso\ndiscusses some technology aspects as appropriate along with providing references for fol-\nlowingupthetopicsingreaterdepth.\nKADistributedSystemsSecurity |October2019 Page394 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nCONTENT\n12.1 CLASSES OF DISTRIBUTED SYSTEMS AND\nVULNERABILITIES\n[1071,c2][1072,c5][1073,c18]\n12.1.1 Classes of Distributed Systems\nA diversity of viewpoints, models, and deployments exist for characterising distributed sys-\ntems. These include defining a distributed system at the level of the aggregation of physi-\ncal resources (e.g., Peer to Peer or Cloud systems), defining it at the Middleware level (e.g.,\nPublish-Subscribe, distributed object platforms, or Web services), or defining it in terms of\ntheservicesadistributedsystemprovides(e.g.,DatabasesorLedgers).Whileaspectrumof\ndefinitionsexistsinliterature,distributedsystemscanbebroadlyclassifiedbythecoordina-\ntion schema linking the resources or by the specification of the services utilising them. One\nbroad class is of decentralised control where the individual resources primarily interact with\ntheir \u201cneighbouring\u201d resources. The other broad category links the distributed resources via\ncommunication processes, such as message passing, to realise varied forms of virtual cen-\ntralised\/coordinatedcontrol.Thus,basedonsuchcommunicationandcoordinationmodels,\ndistributedsystemscanbecategorisedintothefollowingtwobroadclasses.\n1. Decentralisedpoint-to-pointinteractionsacrossdistributedentitieswithoutacentralised\ncoordination service: Peer to Peer (P2P) systems represent this class of distributed\nsystems.Decentralisedun-timedcontrolisaprominentcharacteristicofsuchsystems.\nForexample,systemssuchasKademlia,Napster,Gnutella,andmanyotherdistributed\nfile and music sharing\/storage systems, wireless sensor networks as well as online\ngamingsystemsfallinthiscategory.\n2. Coordinatedclusteringacross distributedresources andservices: This is a broad class\nthatisbestunderstoodwhensub-dividedintotwocoordinationsub-classes,namely(a)\nthecoordinationofresourcesand(b)thecoordinationofservices.Wewillutilisethese\ntwocoordinationabstractionsthroughoutthischapter.Thespectrumofdistributedsys-\ntems includes Client-Server models, n-Tier Multi-tenancy Models, elastic on-demand\ngeo-dispersed aggregation of resources (Clouds \u2013 public, private, hybrid, multi-Cloud,\nBig Data services, High Performance Computing), and transactional services such as\nDatabases, Ledgers, Storage Systems, or Key Value Store (KVS). The Google File Sys-\ntem,AmazonWebServices,Azure,andApacheCassandraaresimpleexamplesofthis\nclass. While this class may appear to be both broad and diverse, the coordination ab-\nstraction(foreitherresourcesorservices)directlycharacterisesthetypeofdistributed\nsystem into these two sub-classes. In both cases, these systems are typically coordi-\nnated via communication exchanges and coordination services with the intended out-\ncome of providing a \u201cvirtually centralised system\u201d where properties such as causality,\norderingoftasks,replicationhandling,andconsistencyareensured.Therearediscrete\ndefinitionsintheliteratureforClient-Serversystems,CloudComputing,MobileComput-\ning, Distributed Databases, etc., though the provisioning of virtual \u201ccentralised\/coordi-\nnated\u201dbehaviourisacommoncharacteristicacrossthem.\nKADistributedSystemsSecurity |October2019 Page395 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nNotes: Therearemanynuancesofsecurityindistributedsystems.Oneviewpointfocuses\non the concepts and mechanisms to provide security in a distributed system where the re-\nsources and services are dispersed. The other viewpoint considers using distribution as a\nmeans of providing security, e.g., the dispersal of keys versus a centralised key store or the\nuse of Virtual Machines (VMs) to partition and isolate resources and applications. This KA\nfocuses on the former category of \u201csecurity in a distributed system\u201d. However, it also dis-\ncussesthelatterviewpointsgiventhatthedispersedsecuritymechanismstypicallyexecute\non dispersed resources logically resulting in the need for the above mentioned classes of\nDecentralisedorCoordinatedclustering.\nItisworthhighlightingthatadistributedsystemarchitectureisoftenanaggregationofmul-\ntiple layers where each layer builds upon the services provided by the layer below and co-\nordinated services offered across the distribution. At the lowest level, resources within a\nparticulardevice(memory,computation,storage,communication)areaccessedthroughthe\nOperatingSystemprimitivesprovidedonthatdevice.Distributedservicese.g.,naming,time\nsynchronisation, distributed file systems are assembled through the interaction of different\ncomponents and services running on individual devices. Higher layers build upon the lower\nlayersandservicestoprovideadditionalfunctionalitiesandapplications.Interactionsacross\nthedifferentcomponentsofthedistributedsystemateachlevelareprovidedbymiddleware\nframeworks that support many different communication styles: message passing, Remote\nProcedure Calls(RPCs), distributedobject platforms, publish-subscribearchitectures,enter-\nprise service bus. Distributed applications are thus realised in a layered (or tiered) fashion\nthrough the interactions and coordination of distributed components and services. Within\nthese architectures, decentralisation and coordination at each layer may differ resulting in\nhybrid compositions of decentralisation and coordination patterns. We refer the reader to\nthe Operating Systems & Virtualisation Knowledge Area (Chapter 11) for issues concerning\naccesstobasicresourcesandthebooks[1030,1073,1074,1075,1076]forfurtherreadingon\ndistributedsystemsarchitecturesandmiddleware.\n12.1.2 Classes of Vulnerabilities & Threats\nVulnerabilitiesrefertodesignoroperationalweaknessesthatallowasystemtobepotentially\ncompromised by an attacker. Analogously, a threat reflects the potential or likelihood of an\nattacker causing damage or compromising the system. Furthermore, security is an end-to-\nend systems property. Consequently, the vulnerabilities of a distributed system are broadly\ngrouped based on the functional blocks therein defining the distributed system. Logically,\nthesefunctionalblocksandtheiroperationsalsoconstitutethethreat\/attacksurfaceforthe\nsystems where an attacker\/adversary can exploit a vulnerability to compromise the system.\nAt a high level, the attack surface relates to the compromises of the physical resources, the\ncommunication schema, the coordination mechanisms, the provided services themselves,\nandtheusagepoliciesonthedataunderlyingtheservices.\nThe following outlines the general functionalities that will be progressively detailed in the\nsubsequentsectionsasrelevanttothespecificdistributedsystemmodel.\nKADistributedSystemsSecurity |October2019 Page396 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n12.1.2.1 Access\/AdmissionControl&IDManagement\nAccess or Admission control determines the authorised participation of a resource, a user,\nor a service within a distributed system. This can include the sourcing of data and the ac-\ncess rights to read\/write and use data over the lifetime of a service. The potential threats\nand consequent attacks include masquerading or spoofing of identity to gain access rights\ntothedata.TheycanalsoinvolveDenialofService(DoS)attacksthatdetrimentallylimitac-\ncess (e.g., depletion of computing resources and communication channels) leading to the\ninaccessibilityandunavailabilityofthedistributedresources\/services.Itisworthemphasis-\ning that resource distribution often entails more points for access control, and also more\ninformation transported in the system to support access control thus increasing the attack\nsurface of the system (see the Authentication, Authorisation & Accountability (AAA) Knowl-\nedge Area (Chapter 13) for a discussion of authentication and authorisation in distributed\nsystems).\nA distributed system entity (resource, service, user, or data element) participates in a dis-\ntributed system with a physical or logical identity. The identity, statically or dynamically allo-\ncated,canbearesourceidentifiersuchasanIDnameoranumber1.Here,authorisationmay\nbe specified in terms of the user and\/or resource identity including the use of login names\nandpasswords.Thus,anactivitythatinvolvestamperingwiththeidentityconstitutesalikely\nthreat.\n12.1.2.2 DataTransportation\nThe network level threats span routing, message passing, the publish-subscribe modalities\nofresourceinteraction,eventbasedresponsetriggering,andthreatsacrossthemiddleware\nstack.Moreover,thesecanbepassive(eavesdropping)oractiveattacks(datamodification).\nA typical example is the Man In The Middle (MITM) attack where the attacker inserts itself\nbetween the victim\u2019s browser and the web server to establish two separate connections be-\ntweenthem.Thisenablestheattackertoactivelyrecordallmessagesandselectivelymodify\ndata without triggering a suspicious activity alarm if the system does not enforce endpoint\nauthentication.Wereferthereaderto [1074,1075]fordetailedcoverageofthesetopics,and\ntotheNetworkSecurityKnowledgeArea(Chapter17).\n1[1030]providesanexcellentdiscourseonnamingissuesinChapter6.\nKADistributedSystemsSecurity |October2019 Page397 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n12.1.2.3 ResourceManagementandCoordinationServices\nThis critical group encompasses the spectrum of threats to the mechanisms (typically mid-\ndleware protocols) that provide the coordination of resources. This includes, among others,\ntheaspectsofsynchronisation,replicationmanagement,viewchanges,time\/eventordering,\nlinearisability,consensus,andtransactionalcommit.\n12.1.2.4 DataSecurity\nAs a distributed system essentially operates on data (at rest or in motion) over the facets\nofdata-sourcing,data-distribution,data-storage,ordata-usageinservices,theclassicalCIA\n(Confidentiality,IntegrityandAvailability)propertiesdirectlyapplytoeachelement(andinter-\nfaces) of this data chain. The threats to confidentiality include information leakage threats\nsuchasSideChannelAttacksorCovertChannelAttacks.Anydelayordenialofdataaccess\nconstitutesathreattoAvailability.Integrityaspectsconcernanycompromiseofdatacorrect-\nness such as the violation of data consistency as observed by the distributed participants.\nThis includes the different types of consistency (strong, weak, relaxed, eventual, etc.) over\nstorage and transactional services. Consequently, addressing the security of the data ele-\nmentsofadistributedsystemrequiresconsiderationofthethreatsmentionedaboveacross\nresources, access control, data transportation, and coordination services as well as data\nthreats in the form of malicious applications, code, and viruses (see the Malware & Attack\nTechnologyKnowledgeArea(Chapter6)).\nSection Organisation Based on this overview, the subsequent sections progressively out-\nline the security approaches for distributed systems as split into the above mentioned\nclassesofdecentralisedandcoordinationbasedsystems.Inordertounderstandthesecurity\nissues relevant to each class, the sections also provide a basic overview of the underlying\ndistributed system concepts along with pointers for further reading. Section 12.2 presents\nthe commonly used models for decentralised P2P systems. Section 12.3 then elaborates\nthe corresponding security threats for the P2P systems. This is followed by the exposition\nof coordinated distributed system models in Section 12.4, and by a discussion of the corre-\nspondingsecurityaspectsinSection12.5.\n12.2 DISTRIBUTED SYSTEMS: DECENTRALISED P2P\nMODELS\n[1077,c11-12][1072,c25]\nPeer to Peer (P2P) systems constitute a decentralised variant of distributed systems. Their\npopularity is driven by the characteristic P2P features of scalability, decentralised coordina-\ntion, and low cost. Scalability implies that no changes to the protocol design are needed\nwith increasing numbers of peers. Whereas a Client-Server architecture typically entails in-\ncreasing back-end (Server) resources with increasing numbers of (Client) requests, this is\nnot the case in P2P systems due to their inherent decentralised architecture. Furthermore,\nthe decentralised P2P system designs promote inherent resilience against individual peer\nfailures or other disruptions. The peer population itself represents the service provisioning\ninfrastructure of the system. Thereby, potential service consumers are required to partake\nin resource provisioning avoiding the need for dedicated data centres. Over the past two\nKADistributedSystemsSecurity |October2019 Page398 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ndecades, a multitude of P2P models have emerged. Regardless of their specific realisation,\nthey usually combine the following five principles: (1) symmetry of interfaces as peers can\ntake inter-changeable duties as both servers and clients, (2) resilience to perturbations in\nthe underlying communication network substrate and to peer failures, (3) data and service\nsurvivabilitythroughreplicationschemes,(4)usageofpeerresourcesatthenetwork\u2019sedge,\nimposing potentially low infrastructure costs and fostering scalability as well as decentrali-\nsation,and(5)addressvarianceofresourceprovisioningamongpeers.\nThesefiveprinciplesmakeP2Pavitalfoundationforadiversesetofapplications.Originally,\nP2P systems were (in)famous for their support of file sharing applications such as eMule\nor KaZaA, though their usage is now common in applications such as social networks, mul-\ntimedia content distribution, online games, internet telephony services, instant messaging,\nthe Internet of Things, Car-to-Car communication, Supervisory Control and Data Acquisition\n(SCADA) systems, and wide area monitoring systems. As discussed in later sections, dis-\ntributedledgersalsoutilisesomeaspectsofP2Poperations.\nP2P Protocol Categories The two major P2P paradigms are unstructured and structured\nsystems.Thesesystemdesignsdirectlycorrelatewiththeapplicationcategoriesintroduced\nin the previous section, i.e., unstructured protocols are mostly suitable for (large scale and\nscalable) data dissemination, whereas structured ones are usually applied for efficiency of\ndata discovery. The emergent hybrid P2P protocol designs combine aspects from both un-\nstructuredandstructuredoneswithinanintegratedP2Psystem.\nAdditionally,hierarchicalP2Psystemsalsoexist.ThesepartlycontradicttheconceptualP2P\nprinciple that considers all peers as equal in the sense of service provisioning. These hierar-\nchicalsystemscanbeconsideredaslayeredsystems,e.g.,compositionofmultipleoverlays\nconsistingoffront-endandback-endpeers.\nRegardless of the type of P2P system, it is important to note that the basic P2P operations\nare based on three elements, namely (a) identification or naming of peer nodes, (b) routing\nschemasacrosspeers,and(c)discoveryofpeersasafunctionoftheiridentifiersandrouting.\nIn order to support the discussion of security in P2P systems, the next subsections provide\nanintroductoryleveltechnicaloverviewonP2Pprotocols.Weprovideabriefoverviewofthe\nP2Pprotocolcategoriesinregardoftheoverlaytopology,resourcesdiscovery,andmessage\npassing.Thereaderisreferredto[1078]foracomprehensivediscussiononP2Poperations.\n12.2.1 Unstructured P2P Protocols\nRepresentatives of the unstructured P2P protocol class such as Freenet2 or Gnutella [1079,\n1080] are mainly used for data dissemination applications such as censorship-free3 com-\nmunication or file sharing. While the set of peers do not have any characteristic topology\nlinkingthem,theirimplicittopologyisusuallyembeddedwithinthephysicalcommunication\nunderlay network topology and often unveils tree or mesh like sub-graphs, which allow for\nlowlatencymessageexchange,e.g.,toaddresstimelinessrequirementsofdatadissemina-\ntion applications. Tree topologies can be found, e.g., in single source streaming media data\ndisseminationwithvariousconsumersasleafnodes.Meshesarethemoregenericcase,for\nexample,inapplicationswithmultiplesourcesandsinkssuchasinfilesharingapplications.\n2https:\/\/freenetproject.org\/\n3Inthesensethatdataandinformationisstoredandexchangedwithintegrityandprivacypreservingtech-\nniquestoaddressfreedomofexpressionandspeechconcerns.\nKADistributedSystemsSecurity |October2019 Page399 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nUnstructured P2P protocols typically search for resources (i.e., peers and data) by name\nor labels, and do not use a structured addressing scheme. This feature supports scalable\ndissemination but scales poorly for resource discovery or reproducible routing paths. Peers\nnevertheless maintain an identifier to allow independence of the underlay network address.\nResourcesarediscoveredusingsearchalgorithmsontheoverlaygraph.Examplesofsearch\nalgorithms include breadth-first search, depth-first search, random walks, or expanding ring\nsearches. These options are often combined according to the requirements of the applica-\ntion.\nThecommunicationacrosspeersisviamessages.Messagepassingmaybedirect,i.e.,using\nan underlay network connection between two peers, but this usually requires that the peers\nexplicitlyknowthepeeraddressandroute.Whenthedestinationpeerforthemessagetobe\nsentisunknown,messagesarepiggybackedalongsidearesourcediscoveryoperation.\nAllpeersmaintainlists(directroutingtableswithaddressesorhashedaddresses)withcon-\ntactinformationaboutotherpeers.Hence,messagingworksefficientlyandthenetworkdoes\nnot suffocate from address-search messages. The efficiency of such lists depends on the\nlivenessofthepeers.Hence,thelistedpeersareperiodicallypingedforlivenessandremoved\nwhennoreplyisreceived.Theperiodicityisdynamicallyadjustedbasedontherelevantchurn,\ni.e.,therateofpeerjoinsanddepartures.\n12.2.2 Structured P2P Protocols\nStructured P2P protocols such as Chord, Pastry, Tapestry, Kademlia, CAN etc. [1081, 1082,\n1083,1084]aretypicallyusedfordatadiscoveryapplicationswherethestructureofthetopol-\nogy aids efficient searches. Their topology graphs usually show small-world properties, i.e.,\nthereexistsapathbetweenanytwopeerswitharelativelysmallnumberofedges.Structured\ntopologies often appear as ring structures with shortcuts, which forms a basis for scalable\nand efficient operations such as resource discovery and message passing. Some protocols\nhavemoreexotictopologies,e.g.,butterflygraphs,fixed-degreegraphs,oramulti-torus.The\nsalient characteristics are efficiency of node discovery and efficiency of routing that uses\ninformation on the P2P structure and topology. As this aspect has security implications, we\nbrieflydetailtheseoperations.\nUnlike unstructured P2P\u2019s open addressing schemas, in structured P2P protocols, pointers\nto resources such as peers or data are stored in a distributed data structure which is called\naDistributedHashTable(DHT).Theoverlay\u2019saddressspaceisusuallyanintegerscaleinthe\nrangeof[0,...,2w \u22121]withw being128or160ingeneral.Usually,adistancefunctiond(a,b)\nisdefinedwhichallowsdistancecomputationsbetweenanytwoidentifiersaandbinthead-\ndressspace.Distancecomputationsarecrucialforthelookupmechanismanddatastorage\nresponsibilities.Thedistancefunctionanditspropertiesdifferamongprotocolimplementa-\ntions.Datadiscoveryisrealisedbycomputingthekeyofaneasy-to-graspresourceidentifier\nsuch as a distinctive name\/key and subsequently requesting that key and its data from one\noftheresponsiblepeers.\nMessages \u2013 for example to request the data for a given key \u2013 are exchanged in most struc-\ntured protocols directly, i.e., using an underlay network connection between two peers. If\npeers do not know each other, then no direct connection can be set up and the destination\npeer\u2019s location needs to be determined to conduct routing. To this end, an overlay lookup\nmechanism aims to steadily decrease the address space distance towards the destination\non each iteration of the lookup algorithm until the identifier can be resolved. This design\nKADistributedSystemsSecurity |October2019 Page400 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\napproach turns out to be very efficient and promotes scalability. Once the lookup has suc-\ncessfullyretrievedthedestination\u2019sunderlaynetworkaddress,messagescanbeexchanged.\nLookup variants include iterative or recursive algorithms as well as parallelised queries to a\nsetofclosestneighbourpeers.\nRoutingtablesusuallystorek\u00b7w entrieswithk beingaprotocolspecificconstant.Moreover,\nfor the ith portion of k entries with i \u2208 [0...w], the peer stores contact information of peers\nthat share i common prefix bits of the peer\u2019s key. In other words, routing tables usually pro-\nvide more storage for closer peers than more distant ones. Moreover, routing tables keep\nonly information about live and reachable peers, therefore peers are periodically pinged. In\nstructured protocols, maintenance is more expensive as the topological structure needs to\nberetained,e.g.,newlyjoinedpeershavetobeputintotheappropriatepeer\u2019sroutingtables\norleaving\/unresponsivepeershavetobereplacedbyliveonesinmanypeers\u2019routingtables.\n12.2.3 Hybrid P2P Protocols\nHybrid variants of P2P protocols integrate elements from unstructured and structured\nschemas, as their principal intent is data discovery and data dissemination. Prominent hy-\nbrid protocol examples include file sharing services such as Napster and BitTorrent [1085].\nBitTorrent was originally a classical unstructured protocol but now has been extended with\nstructured P2P features to provide a fully decentralised data discovery mechanism. Conse-\nquently, BitTorrent could abandon the concept of so called \u201ctracker servers\u201d (that facilitated\npeerdiscovery)andimproveitsavailability.Ontheotherhand,architecturalrequirementsof-\nten need to be considered to fully utilise the capacity of hybrid P2P protocols. An example\nwould be establishing how the data discovery is transmitted among the servers and how it\nis reported back to the user [1086]. Similar considerations apply to other streaming overlay\napproaches.\n12.2.4 Hierarchical P2P Protocols\nTypically,allthepeersinaP2Psystemareconsideredtobeequalintermsoftheclient-server\nservices they can provide. Yet, for some application scenarios it turns out that a hierarchi-\ncal P2P design can be advantageous. These can include a layered design of structured and\nunstructured overlays. In hierarchical designs, peers are further categorised based on their\nbandwidth,latency,storage,orcomputationcyclesprovisioningwithsome(super)peerstak-\ningacoordinatingrole.Usually,thecategorywithfewerpeersrepresentedtheback-endpart\nof the hierarchical system, whereas the multitude of peers act as front-end peers that pro-\ncess service requests at the first level and only forward requests to the back-end when they\ncannotfulfilltheservicerequestinthefirstplace.Thisimprovesthelook-upperformanceand\nalsogeneratesfewermessagesinthenetwork.Furthermore,popularcontentcanbecached\nlocallytoreducedownloaddelays[1087].Thisdesignhasprovensuccessful,forexample,in\nthe eDonkey file sharing system or in Super P2P models such as KaZaA where a selected\npeeractsasaservertoasubsetofclients.\nKADistributedSystemsSecurity |October2019 Page401 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n12.3 DISTRIBUTED SYSTEMS: ATTACKING P2P SYSTEMS\n[1073,c16][1088,c5]\nWepresentsecurityattackscorrespondingtotheabovementionedclassesofP2Psystems.\nTo facilitate this discussion, we outline the functional elements of a P2P system that help\nthe reader relate the security implications for specific systems or application cases. Subse-\nquently,weassesstherisksstemmingfromattackstoplantherequisitemitigation.TheP2P\nfunctionalelementsthatneedprotectionbroadlyinclude:\n1. P2POperations(P-OP)suchasdiscovery,query,routing,download,etc.thatareacces-\nsiblethroughtheserviceinterfaceoftheP2Pprotocol.Thisfunctionalityrelatestothe\nnetworklevel.\n2. P2PDataStructures(P-DS),e.g.,datastoredinapeer\u2019sroutingtableorresourcesthat\nare shared with other peers of the overlay network. This functional element may be\naccessibleateitherthenetworklevelorlocallyonthepeer\u2019shostmachine.\nWe will refer to these two elements as P-OP and P-DS, in the following subsections where\nwe discuss the specific P2P attacks. We use the established security notions of [1089] for\nConfidentiality, Integrity and Availability. Whenever a definition refers to authentication, we\nassumethatpeersareimplicitlyauthenticatedonjoiningtheoverlaynetwork.P2Pprotocols\nmaymayuseadmissioncontrolsystemsormaybeopentoarbitrarypeers.\nNote that we focus on attacks against P2P systems (e.g., denial of service or routing dis-\nruptions) and do not consider attacks that are prepared or conducted using P2P systems in\nordertoharmnon-P2Psystems(e.g.,usingaP2Psystemtocoordinatedistributeddenialof\nserviceattacks).\n12.3.1 Attack Types\nWe now present the different attacks that are specific to P2P systems. Broadly, the attacks\ncorrespondtoattackingthefunctionalelements,P-OPandP-DS,eitherby(a)disruptingtheir\nconnectivity or access to other nodes for dissemination\/discovery\/routing or (b) corrupting\ntheir data structures. Besides the well known (distributed) denial of service attacks which\napply to P2P as well as to other systems, most attacks exploit fundamental P2P features\nsuchasmessageexchangebaseddecentralisedcoordinationandespeciallythateachpeer\nhasonlyapartial(local)viewoftheentiresystem.Consequently,attackersaimtotrickother\npeersbyprovidingincorrectdataorcolludetocreatepartitionsthathideviewsofthesystem\nfromgoodnodes.Thisincludesexamplescenariossuchas(a)tomisleadpeersintermsof\nrouting, (b) to take advantage of access to resources, (c) to overcome limitations in voting\nsystemsorgames,or(d)tohideinformationintheoverlayamongothers.Wereferthereader\ntothesurveyarticles [1090,1091]forafullerexpositionofP2Psecurity.Wenowenumerate\nsomerepresentativesecurityattacksandrelatethemtotheircorrespondingimpactonCon-\nfidentiality, Integrity and Availability (CIA). Some examples of attacks are further discussed\ninSection12.3.2alongwithcorrespondingmitigationapproaches.\n-Denialofserviceattacks(DoS)[1089],DistributedDenialofService(DDoS),ordisruptionat-\ntacks [1092] manifest as resource exhaustion by limiting access to a node or a communica-\ntion route. In P2P architectures, the attacker aims to decrease the overlay network\u2019s service\navailability by excessively sending messages to a specific set of peers and thereby nega-\ntively affecting the P-OP functionality. This could affect the peer join\/leave mechanism, or\nKADistributedSystemsSecurity |October2019 Page402 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nother arbitrary P2P service aspects, e.g., damaging the routing put\/get operations in a DHT.\nFor example, benign peers may be impaired by an excessive maintenance workload. More-\nover, DoS and DDoS attacks can have a negative impact on bandwidth usage and resource\nprovisioningwhichmayresultindegradedservices.Forinstance,GitHubwashitwithasud-\ndenonslaughtoftrafficthatreached1.35terabitspersecond4.Thetrafficwastracedbackto\n\u201cover a thousand different Autonmous Systems (ASNs) across tens of thousands of unique\nendpoints\u201dparticipatingintheattack.\n- Collusion attacks [1093] aim to compromise the availability, integrity, or confidentiality of\nP2P networks. Collusion refers to the fact that a sufficiently large subset of peers colludes\nto carry out a strategy which targets the P2P services and thereby negatively affects the P-\nOP functionality. The typical attack aims to override control mechanisms such as those for\nreputation or trust management, or bandwidth provisioning. The Sybil and Eclipse attacks,\ndiscussedlateron,arebasedonattackerscolludingtocreatenetworkpartitionstohidesys-\ntemstateinformationfromgoodnodes.\n- Pollution attacks [1094, 1095] or index poisoning [1096] aim to compromise the P2P sys-\ntem\u2019s integrity and its P-DS functionality by adding incorrect information. Consequences of\npollution attacks are the proliferation of polluted content resulting in service impairments.\nAnexampleisthetyphoidad-wareattackwheretheattackerpartiallyaltersthecontent,e.g.,\nadding advertisement at a single peer that subsequently spreads this polluted content to\notherpeers.\n- White washing [1095] or censorship attacks aim to compromise the availability or integrity\nofP2Psystems.Thisincludeseitherillicitchangingof,deletionofordenyingaccesstodata.\nTherefore, these attacks endanger the P-DS functionality. White washing attacks are espe-\nciallydangerousforP2Psystemsthatusereputationbasedsystemssincetheyallowapeer\nwithabadreputationtoleavethesystem,andsubsequentlyre-joinasabenignuser.\n-Routingattacks[1092,1097]aimtocompromisetheavailabilityorintegrityofP2Pnetworks.\nRoutingattacksplayanimportantroleincompositeattacks,suchastheEclipseattackwhich\nobstructs a good node\u2019s view of the rest of the system. In routing attacks, a malicious peer\nundermines the message passing mechanism, e.g., by dropping or delaying messages. An-\notherroutingattackvariantisRoutingTablePoisoning(RTP)[1097].Inthisattack,anattacker\ndeliberately modifies its own or other peers\u2019 routing tables, e.g., by returning bogus informa-\ntion to benign peer lookup requests. Attraction and repulsion [1092] are specific variants of\nrouting attacks which either increase (attraction) or decrease (repulsion) the attractiveness\nofpeers,e.g.,duringpathselectionorroutingtablemaintenancetasks.Theseattacksnega-\ntivelyaffecttheP-DSfunctionality.ThecompromiseoftheroutingtableinPastry,oftenused\ninonlinesocialnetworks,isatypicalroutingattack.\n-Buffermapcheatingattacks[1098]aimtodecreasetheavailabilityofP2Pnetworks,partic-\nularlythoseusedformediastreamingapplications.Throughthisattack,adversariesreduce\nthe outgoing traffic load of their peers by lying about their data provisioning. This is also\naninfringementonintegrityandaffectstheP-OPfunctionality.Thisattackisespeciallyrele-\nvantinstreamingmediaP2Papplicationswhichrelyonthecollaborationofpeers.Omission,\nFake Reporting, Fake Blocks, incorrect Neighbour Selection are related implications of such\nattacks.\n- Sybil attacks [1099] aim to compromise the availability or confidentiality (via spoofing) of\nP2Pnetworksandcanberegardedasaspecificversionofnode\/peerinsertionattacks.They\n4https:\/\/www.wired.com\/story\/github-ddos-memcached\nKADistributedSystemsSecurity |October2019 Page403 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nconsider the insertion into the overlay of peers that are controlled by one or several adver-\nsaries.Thiscouldhappenatspecificorarbitrarylocationsoftheoverlay\u2019stopology,depend-\ningontheattacker\u2019saim.Furthermore,P2Papplicationsmayconsidersystemusersaslegal\nentities and consequently restrict the amount of peers per user to the amount of allowed\nvotes for that entity. Hence, an imbalance results in terms of the expected amount of peers\nperuser.Sybilattacksmaybeaprecursorformanyofthepreviouslydescribedattacks.Sybil\nattacksaffecttheP-OPfunctionalityofthesystem.ProminentSybilattacksincludethecom-\npromiseoftheBitTorrentDHTandtheSybilattackontheToranonymisationnetwork.\n-Eclipseattacks[1100]aimtodecreasetheavailability,integrityandconfidentialityofP2Pnet-\nworks. Essentially, a good peer is surrounded by a colluding group of malicious peers that\neitherpartiallyorfullyblockthepeer\u2019sviewoftherestofthesystem.Theconsequenceisthat\nthemaliciousnodescaneithermaskorspoofthenode\u2019sexternalinteractions.Thisisacom-\nposite attack that may involve routing table poisoning, DoS\/DDoS, Sybil attacks, collusion,\nwhitewashing,orcensorship.Consequently,theseattackshaveanimpactonboththeP-OP\nand P-DS functionality. Variants of Eclipse attacks include Localised Eclipse Attacks (LEA),\nTopology Aware Localised Eclipse Attacks (taLEA) and Outgoing Eclipse Attacks (OEA) at-\ntacksamongothers.AnexampleofanEclipseattackonBitcoinisdiscussedinSection5.\nAttack Availability Integrity Confidentiality Functionality\nDoS\/DDoS (cid:51) (cid:55) (cid:55) P-OP\nCollusion (cid:51) (cid:51) (cid:51) P-OP\nPollution (cid:55) (cid:51) (cid:55) P-DS\nWhitewashing&censorship (cid:51) (cid:51) (cid:55) P-DS\nRouting (cid:51) (cid:51) (cid:55) P-DS\nBuffermapcheating (cid:51) (cid:51) (cid:55) P-OP\nSybil (cid:51) (cid:55) (cid:51) P-OP\nEclipse (cid:51) (cid:51) (cid:51) P-DS,P-OP\nTable12.1:P2PAttacks,SecurityGoalsandAffectedFunctionality\n12.3.1.1 Summary\nTable 12.1 summarises attacks on the P2P functional elements that entail modifications of\nthe P2P system to either degrade or compromise the P2P operations. The adversarial col-\nlusion of malicious peers is a key factor to launch these attacks resulting in significant dis-\nruption.Inmanycases,theinherentdesignchoicesofP2P,whichfosterscalabilityandfault\ntolerance,areexploited.AttacksagainstP2Psystemsusuallyshowanimpactintermsofthe\nsystem\u2019s confidentiality, integrity, or availability. Several of the observed attacks are known\nfrom other system architectures such as client-server models while others are new ones or\ncompositionsofvariousattacks.Thedifferencefromcomparableattacksinclient-serversys-\ntemarchitecturesisthatP2Poverlaynetworksmaygrowverylargeandadversarieshaveto\ncorrespondinglyadapttheirefforts,i.e.,theyneedtoscaleupthefractionofmaliciouspeers\naccordingly, thereby requiring a substantial amount of coordination to execute an effective\ncollusion strategy. These attacks vary depending upon whether the attacker has direct or\nindirect network access via a P2P overlay. The latter requires attackers to properly join the\nnetwork prior to the attack. Thus, this may entail malicious peers making, e.g., a proper an-\nnouncementintheoverlaynetwork,beforetheycanlaunchtheiradversarialbehaviour.\nSupplementalObservations:\n- Denial of service attacks degrade or prevent a system from correct service delivery [1101,\nKADistributedSystemsSecurity |October2019 Page404 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n1102]. The more sophisticated Sybil attack [1102, 1103, 1104] can be used as a potential pre-\ncursorforanEclipseattack[1102,1103].\n- If either secure storage, secure routing, or authentication mechanisms cannot be provided,\nasetofattacksincludingomission,contentforgery,contentpollution,censorship,orrouting\ntablepoisoningmaybetheconsequence[1102,1104].\n-Churnrelatestotheeffectsofpeersjoiningandleavinginanoverlay.Churnattacksconsider\nartificially induced churn with potentially high peer join\/leave rates to cause bandwidth con-\nsumption due to the effort needed to maintain the overlay structure. This can lead to partial\norcompletedenialofservice[1104].\n- Varied cheating attack strategies exist (for observing or corrupting player information and\nactivities)inMassiveMultiplayerOnlineGames(MMOG)builtuponP2Parchitectures[1104].\n12.3.2 Attacks and their Mitigation\nWe present some example attacks along with the approaches used to mitigate them. For a\ncomprehensivecoverage,wereferthereadertothesurveysof[1090,1091].\nBasic PoS and P-DS Based Scenarios: The prominent P2P protocol security mechanisms\nare authentication mechanisms, secure storage, and secure routing. These three mecha-\nnismsallowtheimplementationofvariousdownstreammechanisms.Authenticationmech-\nanisms [1102, 1105] help to maintain a benign peer population and provide the technical ba-\nsis for downstream mechanisms like secure admission, secure storage, or secure routing.\nSecure storage is vital for data centric applications in order to prevent attackers from con-\nductingillicitdatamodifications[1101,1103,1105,1106].Inabroadersense,illicitdatamodifi-\ncationinonlinegamesisconsideredascheating[1104].Theuseofsecureroutingistypically\nadvocated as an approach to facilitate the identification of peers conducting improper mes-\nsage forwarding [1103, 1105, 1106]. Limiting the number of routing paths and\/or protecting\nthepathsusing(highoverhead)cryptographicapproachesarealternateapproachestomiti-\ngatingroutingattacks.\nSybil and Eclipse Scenarios: Sybil attacks occur where the attacker could launch an attack\nwith a small set of malicious peers and subsequently gather multiple addresses, which al-\nlows malicious peers to fake being a larger set of peers. Using Sybil attacks, a LEA can be\nlaunchedviaachainofSybil\/maliciousnodes.However,theattackreliesontheassumption\noftheexistenceofasinglepathtowardsthevictimthatcanbemanipulatedbytheattacker.\nAlternately,aLEAcanbelaunchedusingSybilpeers.\nIn such attacks, mitigation relies on using a centralised authority that handles peer enrol-\nmentsoradmission.Extendingthisconcept,addingcertificates(issuedbyacommonCertifi-\ncateAuthority)topeers\u2019networkIDswhilejoiningthenetworkisanotherpossibility.Othermit-\nigation techniques to prevent malicious entities from selecting their own network IDs could\nentailasigningentityusingpublickeycryptography.\nBuffer Map Cheating Scenarios: Other disruptions could be used to attack the KAD P2P net-\nwork [1084], which is a Kademlia based network, through flooding peer index tables close\nto the victim with false information as a simplistic taLEA variant. A KAD network crawler is\nintroducedtomonitorthenetworkstatusanddetectmaliciouspeersduringaLEA.However,\nahighoverheadisincurredifeachpeerusessuchamechanismtodetectmaliciousentities.\nThisbecomesimpracticalastheoverlaysizeincreases.\nKADistributedSystemsSecurity |October2019 Page405 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nDivergentlookupshavebeenproposedasanalternatetaLEAmitigationtechniquewherethe\ndisjoint path lookups avoid searching the destination peer\u2019s proximity to skip the wasteful\nqueryingofmaliciouspeersundertaLEAassumptions.\nRoutingScenarios:Mitigationmechanismstohandleroutingattacksconsiderassigningmul-\ntiplepathsforeachlookupusingdisjointpathsthoughatthecostofhighmessageoverhead.\nAlternativesincludetheuseofcryptographicschemestoprotectthepaths.However,P2Pis\na decentralised coordination environment where implementing a centralised service to sup-\nportthecoordinationofsystemwidecryptographicsignaturesishardtorealise.\nThe aforementioned security mechanisms increase the resilience of P2P systems against\nthe various attacks. Naturally, these mechanisms are resilient only until a critical mass of\ncolludingmaliciouspeersisreached.Inaddition,someofthesemechanismsrequirecrypto-\ngraphic support or the identification of peers. These requirements may interfere with appli-\ncationrequirementssuchasanonymity,heterogeneity,orresourcefrugality.\n12.4 DISTRIBUTED SYSTEMS: COORDINATED RESOURCE\nCLUSTERING\n[1077,c5,7,12,25][1071,3][1072,c5,c14][1073,c16-17,c19]\nContrasting with the decentralised-control of P2P systems, a multitude of distributed sys-\ntems exist where the interactions across the distributed resources and services are orches-\ntrated using varied coordination mechanisms that provide the illusion of a logically cen-\ntralised and coordinated system or service. The coordination can simply be a scheduler\/re-\nsourcemanager,adiscretecoordinatororacoordinationgroup,andincludeorderingintime\n(causality) or varied precedence orders across distributed transactions. While it is tempting\ntodefineeachtypeofdistributedsystemdiscretely(i.e.,differingfromdecentralisedcontrol\nin P2P), the large and diverse group of distributed systems\/services share a common ab-\nstraction of \u201ccoordination\u201d although its realisation and resultant properties for each system\nwillvary.\nFirstly,thereisthecasewhereaserviceisreplicatedonadistributedresourcesplatform(or\ninfrastructure) to enable geo-dispersed access to users while sustaining the required type\nof consistency specifications on the service. The Cloud and many distributed Client-Server\nsystemsfallinthiscategory.\nThe alternate approach addresses distributed services (versus platforms) where the dis-\npersed service participants interact to yield the collective distributed service for given con-\nsistency requirements. For example, transactional databases and distributed ledgers fall in\nsuchacategoryofstrongconsistency.Webcrawlers,searches,orlogisticsapplicationsmay\nwellworkwithweakconsistencyspecifications.\nOverall,theseconstitutethetwobroadclassesofdistributedsystemsinthecoordinatedre-\nsourcepoolingmode,namelytheclassesofresource-coordinationandservice-coordination,\nasbasedontheircharacteristiccoordinationschemaalthoughtheirfunctionalityanddefini-\ntionsoftenoverlap.\nIn the subsequent subsections, in order to contextualise distributed systems security, we\nfirstdetailthebasicdistributedconceptsalongwiththecoordinationschemabasedonthem.\nThisisfollowedbyoutliningthecharacteristicsystemsineachoftheresourceandserviceco-\nKADistributedSystemsSecurity |October2019 Page406 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nordinationmodels.Thisformsthebasisbehindthegeneralsetofdisruptions\/vulnerabilities\nrelevanttobothclassesofcoordinateddistributedsystems.Wethenoutlinethethreatsand\nsecurity implications specific to each class of systems. We refer the reader to the excellent\ntextsof[1071,1072,1077]foracomprehensiveandrigoroustreatiseoftheseissues.\nA Note on Technologies Underlying Distributed Platforms: The introduction emphasised\nthatthefocusofthisKAisonsecurityindistributedsystemsratherthantheuseofdistribu-\ntiontowardsprovidingsecurity.Expandingonthistopic,itisworthcommentingonalternate\nperspectives related to the \u201cdesign and realisation\u201d of distributed platforms and services.\nThisdesignorientedperspectivetendstoemphasisethearchitectureofdistributedsystems,\ndistributed services and their construction. This perspective typically focuses on (a) estab-\nlishing security requirements, (b) realisation approaches on how to meet given security re-\nquirements at each level of abstraction, and (c) considers a distributed system as a layered\narchitecturewhereeachlayerbuildsupontheprimitivesofferedatthelayerbelowandfrom\ndistributedservices.Inthisperspective,centralised(coordinated)anddecentralisedpatterns\nareoftencombined,differentlyandatdifferentlayers.Alsofromthisperspective,thesecurity\nrequirements of the applications must be met by complementing and building upon what is\nofferedatthelowerlayersandservices.\nThis is a construction and compositional approach where the security properties (require-\nments) at the application level, or at a given layer, drive the selection of solutions and sub-\nsystems that must be assembled (e.g., authentication, authorisation, accountability, non-\nrepudiationetc.).Thecompositionofsuchsubsystems\/solutionsisoftenachievedthrough\nthe use of trade-offs (and also threat) analysis that tend to cover some and not all of\nthe requirements and thus determining relative strengths and weaknesses. For example,\nblockchainapplications,furtherdiscussedinSection12.5.2,emphasisenon-repudiationand\ndecentralisationastheirmainproperties.\nThislayeredandcompositionalapproachcanoftenbeencounteredintheliteraturesuchas\n[999, 1072, 1073, 1074, 1075, 1076, 1107] and many others. As the architectures and realisa-\ntion fundamentally underlie the KA premise of providing security in distributed systems, the\nreader is encouraged to refer to this literature. The following section returns the focus back\non distributed system concepts, and especially the fundamental concepts of the coordina-\ntionclassofdistributedsystems.\nDistributed Concepts, Classes of Coordination\nAs mentioned in the introduction, a distributed system is a collation of geo-dispersed com-\nputing resources that collectively interact to provide (a) services linking dispersed data pro-\nducers and consumers, (b) high-availability via fault tolerant replication to cover resource\n(computing and communication) failures, or (c) a collective aggregated capability (compu-\ntationalorservices)fromthedistributedresourcestoprovide(anillusionof)alogicallycen-\ntralised\/coordinatedresourceorservice.\nDistributedsystemsareoftenstructuredintermsofservicestobedeliveredtoclients.Each\nservice comprises and executes on one or more servers and exports operations that the\nclientsinvokebymakingrequests.Althoughusingasingle,centralisedserverappearstempt-\ning,theresultingserviceresidentonaservercanonlybeasfaulttolerantastheserverhost-\ning it. Typically, in order to accommodate server failures, the servers are replicated, either\nphysically or logically, to ensure some degree of independence across server failures with\nsuch isolation. Subsequently, replica management protocols are used to coordinate client\nKADistributedSystemsSecurity |October2019 Page407 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ninteractions across these server replicas. Naturally, the handling of client failures or client\ncompromises (including their role in launching attacks via malicious code or viruses) also\nneedstobeconsidered.\nWe now outline a basic set of distributed system concepts that also constitute the basis\nof the security considerations therein. The concepts are presented at an informal level to\ncommunicate the intuitions, and the reader is referred to [1071, 1072, 1073, 1077] for a com-\nprehensivetreatiseonthetopics.\n12.4.1 Systems Coordination Styles\nIn order for the distributed resources and services to meaningfully interact, the synchroni-\nsation basis across them, in physical time or in logical order, needs to be specified. The\nsynchronisation applies at both the network and process levels. We refer the reader to\n[1071, 1072, 1073, 1077] for more details. At a high level, the synchronisation types include\nthefollowing:\n1. Synchronous:Allcomponentsofadistributedsystemarecoordinatedintime(aslock\nsteporrounds)tobesynchronisedwitheachother.Causalityisexplicitlyobtained.Ex-\namplesincludetypicalsafety-criticalsystemssuchasaircraftfly-by-wirecontrolwhere\npredictabilityandguaranteedreal-timeresponsivenessisdesired.\n2. Asynchronous: Separate entities take steps in arbitrary order and operate at different\nspeeds. The ordering of events needs to be ensured through collective interactions.\nTypicalexamplesaretransactionalsystems,databases,webcrawlers,etc.\n3. Partiallysynchronous:Somerestrictionsapplyonorderingofactionsbutnolock-step\nsynchronisationispresent.TypicalexamplesareSCADAcontrolsystemsorhigh-value\ntransactional stock systems where timeliness has implications on the service correct-\nness.\n12.4.2 Reliable and Secure Group Communication\nGroupcommunicationaddressesthecommunicationschemaavailabletoensurereliablede-\nliveryofmessagesacrossthedistributedentities.Thesecanbesimplepoint-to-pointdirect\nmessagingsupportedbyappropriateacknowledgements(ACKSandNACKS)forreliablede-\nlivery.Alternately,reliableandsecuremulticast(atomic,best-effort,regular,uniform,logged,\nstubborn,probabilistic,causal,etc.)toprovideredundantchannelsororderingofmessages\ncan be used along with the more sophisticated publish-subscribe forms of group communi-\ncation [1072, 1073]. In these approaches, the channels and messages can be encrypted or\ncryptographically signed though this entails higher transmission and processing overheads.\nThe range of credential management, symmetric\/asymmetric cryptography techniques, PKI\ncryptosystems,securekeydistribution[1108]alsofallinthiscategory.Thereaderisreferred\nto[1071,1072,1073,1109]foracomprehensivecoverageofgroupcommunicationprimitives.\nKADistributedSystemsSecurity |October2019 Page408 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n12.4.3 Coordination Properties\nThe utility of a distributed system comes from a coordinated orchestration of the dispersed\nresourcestoyieldacollectivelymeaningfulcapability.Priortodiscussingthevarietyofcom-\nmonly used coordination schemas in Section 12.4.4, we first present the base definitions of\nConsensus,GroupMembershipandConsistency.\nConsensus\nInformally,consensuspertainstoachievinganagreementonvalues.Forexample,thevalues\ncouldbedataorprocessIDs.Consensusrequiresthefollowingpropertiestohold:\n1. Agreement:Allgoodprocessesagreeonthesamevalue.\n2. Validity:Theagreeduponvalueisagood\/validvalue.\n3. Termination:Adecisioniseventuallyachieved.\nThe specific type of consensus depends upon the semantics of the faults (crash, omission,\nByzantine,etc.)tobeaddressed.ThefaultstypesarediscussedinSection12.5.\nGroupMembershipandConsistency:\nMembership is a key \u201cservice\u201d property in distributed systems that determines the set of\nconstituentresourcesandalsothenatureoftheagreementachievedonthesetofvalidpar-\nticipants (static, dynamic, quorum membership) and the data. From a security perspective,\nthisoftenrelatestotheintegritypropertyfortheservice.Consistencyhasvariednuancesand\nthe prominent types are listed below with fuller details presented in [1071, 1072, 1073, 1077,\n1109, 1110]. Note that the underlying assumption is always that the constituent processes\ncan be modelled as deterministic state machines. That is, performing a specific sequence\nofactionsalwaysleadstothesamestate.\n\u2022 Strongconsistencymodels:Inthesemodelstheparticipantsmustagreeononeconsis-\ntentorderofactionstotake.Hence,theprocessesareguaranteedtoreachaconsistent\nstateundertheassumptionofdeterminism.\n1. Strict Consistency: In strict consistency there are no constraints on the observed\norderofactionsaslongasitisconsistentacrossalltheparticipants.\n2. Linearisability: The linearisability model is essentially strict consistency with the\nadditional constraint that the observed order of actions corresponds to their real\ntimeorder.\nStrong consistency models are widely used in high risk contexts where any inconsis-\ntencies in the data may lead to dire consequences. In these situations, consistency is\nmore valued than availability and enforcing strong consistency constraints results in\nmore delays in the systems due to the frequent synchronisation. Traditional relational\ndatabasesystemssuchasMySQL[1111]orMicrosoft\u2019sSQLServer[1112]butalsomod-\nern NoSQL databases such as MongoDB [1113] or Google\u2019s Chubby lock service [1114]\narepopularexamplesthatimplementthesestrongconsistencymodels.\n\u2022 Weak Consistency Models: In these models, the participants do not necessarily ob-\nservethesameorderofactions.Thiscanleadtoinconsistentstatesdependingonthe\nnature of the additional constraints that the observed orders have to satisfy. Naturally,\nKADistributedSystemsSecurity |October2019 Page409 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nthis can lead to inconsistent states that can be dealt with through conflict resolution\nmechanisms[1115].\n1. Sequential Consistency: Sequential consistency is met if the order in which the\nactions are performed by a certain process corresponds to their original order. In\norderwords,thesequentialexecutionorderofeveryprocessispreserved.\n2. Causal Consistency: Causal consistency is achieved by categorising actions into\nthosecausallyrelated\/dependentandthosethatarenot.Inthiscaseonlytheorder\nofcausallyrelatedactionshastobepreserved.Twoeventsarecausallyrelatedif\ntheybothaccessthesamedataobjectandatleastoneofthemisawriteevent.\n3. EventualConsistency:Ineventualconsistencytherearenospecialconstraintsthat\nhavetobesatisfiedbytheorderofobserveractions.Theideabehindthisconcept\nis that the participants will eventually converge to a consistent state either by ob-\nserving equivalent orders of actions or by resorting to costly conflict resolution\nmechanisms.\nSystemswithweakerconsistencymodelsbecamepopularwiththeadventoftheInter-\nnet where wide scale web servers had to accommodate a large number of users. To\nachieve this, such systems sacrifice strong consistency guarantees to achieve higher\navailability for their user base. Systems like Amazon\u2019s Dynamo [1116], Facebook\u2019s Cas-\nsandra [1117] are widely known examples of systems with weak consistency guaran-\ntees.\n12.4.4 Replication Management and Coordination Schema: The Basis\nBehind Attack Mitigation\nAfundamentalchallengefordevelopingreliabledistributedsystemsistosupportthecooper-\nationofthedispersedentitiesrequiredtoexecuteacommontask,evenwhensomeofthese\nentities, or the communication across them, fails. There is a need to ensure ordering of the\nservice actions and to avoid partitions of the distributed resources in order to result in an\noverall\u201ccoordinated\u201dgroupofresources.\nThe state machine replication or state machine approach [1118] is a general method for im-\nplementingafault-tolerantservicebyreplicatingserversandcoordinatingclientinteractions\nwithserverreplicas.Theapproachalsoprovidesaframeworkforunderstandinganddesign-\ning replication management protocols. The essential system abstraction is that of a state\nmachinesuchthattheoutputsofthestatemachinearefullydeterminedbythesequenceof\nrequestsitprocessesindependentoftimeorotheractivityinthesystem.Replicationcanbe\nactive,semi-active,passive,orlazy[1073].\nItshouldbenotedthatideallyonewouldliketocollectivelyattainhighavailability,consistency\nand also full coordination to eliminate any partitioning of the set of distributed resources.\nHowever,theCAPassertioncomesintoplayas:\nKADistributedSystemsSecurity |October2019 Page410 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nCAP\nAny network shared data system (e.g. Web) can provide only 2 of the 3 possible proper-\nties[1119]as:\n1. Consistency (C): equivalent to having a single up-to-date copy of the data, i.e., each\nserverreturnstherightresponsetoeachrequest.\n2. Availability(A):ofthedatawhereeachrequesteventuallyreceivesaresponse.\n3. Partition(P):Networkpartitiontolerancesuchthatserverscannotgetpartitionedinto\nnon-communicatinggroups.\nNaturally,securityattacksattempttocompromisetheseelementsofCAP.\nReplicationandCoordination\nIn order to provide coherent and consistent behaviour (in value and order), distributed re-\nsources use various types of replica management, i.e., the coordination schema. This is a\nkey coordination mechanism that characterises the functionality of any distributed system.\nThefactorsdeterminingthespecificmechanismdependonthetypeofsystemsynchronisa-\ntion model, the type of group communication and especially the nature of the perturbations\n(faults or attacks) being considered. The mechanisms can be simple voting or leader elec-\ntionprocesses(e.g.,RingAlgorithms,Bully)ormorecomplexconsensusapproachestodeal\nwith crashes or Byzantine5 behaviour. The commit protocols for database transactions are\nrelevanthereasaretheschemesforcredentialmanagementandPKIinfrastructuresprovid-\ning verified access control. We briefly describe a set of widely used schema, and the reader\nis referred to [1071, 1072, 1077] for complete coverage. Authorisation and Authentication in\ndistributedsystemsarealsodiscussedintheAuthentication,Authorisation&Accountability\n(AAA)KnowledgeArea(Chapter13).\nPaxos\nTo avoid the situation of distributed entities conducting uncoordinated actions or failing to\nrespond,Paxos[1120],agroupofimplicitleader-electionprotocolsforsolvingconsensusin\nanasynchronoussetup,hasbeendeveloped.Paxossolvestheconsensusproblembygiving\nalltheparticipantsthepossibilitytoproposeavaluetoagreeuponinaninitialphase.Inthe\nsecondphase,ifamajorityagreesonacertainvalue,theprocessthathadproposedthevalue\nimplicitlybecomestheleader,andagreementisachieved.Thesameprocessisrepeatedfor\nthenextvaluetoachieveconsensusonasequenceofvalues.\nThe protocol is known not to provide liveness only under very specific circumstances as de-\nscribed in [1120]. In this case, processes continue to propose values indefinitely and remain\nblocked in the initial phase as no majority can be formed and progress is never made. How-\never, this situation rarely occurs in practice and Paxos remains one of most widely used co-\nordinationprotocols.\nSince only a majority is necessary in the second phase to reach consensus, the protocol is\nadditionallytoleranttocrasheseveninthecaseofrecovery.Thisisremarkablesince,aslong\nasthemajorityoftheprocesseshasnotfailed,consensuscanbereached.Thepaper[1121]\n5Byzantinebehaviourhappenswhenanentity\/attackersendsdifferent(albeitvalid)informationtodifferent\nrecipients.\nKADistributedSystemsSecurity |October2019 Page411 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nis an excellent read of the experiences of implementing Paxos at Google for the Chubby file\nsystem.\nWhilethereexistsavarietyofimplementationsofthePaxosprotocol,itisnotoriouslyknown\nfor being hard to implement and build middleware upon it due to its inherent complexity.\nFor this purpose, RAFT, a protocol similar to Paxos that provides the same guarantees, has\nbeenproposed.RAFThasrecentlygainedinpopularityduetoitssimplerdesign.Paper[1122]\nexplains the motivation behind the development of the RAFT protocol and how it works by\ncomparingitwithPaxos.\nByzantineFaultTolerance(BFT)\nAttacks and other deliberate disruptions do not necessarily follow the semantics of benign\nomissions, timing or crashes. In order to tolerate arbitrarily malicious behavior, Byzantine\nFault Tolerance (BFT) protocols use coordinated replication to guarantee the correct exe-\ncution of operations as long as at most a third of processes is compromised and exhibits\narbitrary(i.e.,Byzantine,cf.Section12.5)behavior.\nIn BFT, processes exchange the values they have received from each other in rounds. The\nnumber of rounds necessary to reach consensus is determined by the number of compro-\nmised participants there are in the system [1123]. Note that since the protocol operates in\nrounds, it is classified as a synchronous coordination protocol. It has been shown in [1124]\nas the FLP impossibility result that it is impossible to reach consensus in the case of asyn-\nchronous communication. Due to the necessity of synchronous communication and the\nrather higher overhead of message exchange required to deal with Byzantine failures, BFT\nprotocols are applied mostly in specific critical applications. However, there are multiple on-\ngoingattemptsforpracticalBFToptimisationsbystrengtheningsomebasicassumptionson\nsynchronisation, determinism, and number of compromises [1125, 1126, 1127]. The Google\nFile System (Chubby) and Amazon Web Services (AWS) implement Paxos and also partial\nBFT functionality. It is also important to emphasize that BFT is expensive not only for the\nmessagecomplexityoverthenumberofroundsneeded.Itisalsoexpensiveforthenumber\nof nodes needed (> 3f) to handle f malicious failures, i.e., f being the number of nodes\ncontrolled by an adversary. The generalisation of adversarial structures to quorum systems\nisdiscussedin [1109].\nFromasecurityviewpoint,foritsabilitytotoleratearbitrarymaliciousbehaviors,theBFTpro-\ntocols constitute an appealing building block for the construction of intrusion tolerant sys-\ntems. It is worth making the observation that these protocols consider the number of com-\npromised entities. When faced with a malicious attacker identical replicas are not sufficient\nbecause they exhibit the same vulnerabilities. A malicious adversary who can compromise\none replica can easily compromise the others if they are identical. Replication and diversity\n(or distinct protection methodologies) are needed. We refer the reader to the discussions\nin[1071,1072,1077,1109,1123,1128,1129].\nKADistributedSystemsSecurity |October2019 Page412 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nCommitProtocols\nA number of applications, e.g., databases, require ordering across replicated data or oper-\nations where either all participants agree on conducting the same correct result (i.e., com-\nmit) or do nothing \u2013 the atomicity property. Hence, as a specialised form of consensus, a\ndistributed coordinator directed algorithm is required to coordinate all the processes that\nparticipate in a distributed atomic transaction on whether to commit or abort (roll back) the\ntransaction.\nThe Two-Phase Commit (2PC) is a straightforward example of such atomic commitment\nprotocols. The protocol proceeds with a broadcast query from a leader to all the clients to\ncommit. This is followed by an acknowledgment (commit or abort) from each client. On re-\nceiving all responses, the leader notifies all clients on an atomic decision to either commit\nor abort [1072, 1074, 1075]. The protocol achieves its goal even in many cases of failure (in-\nvolvingeither process,network node,or communicationfailuresamong others),andis thus\nwidelyused.Anapproachbasedonloggingprotocolstatesisusedtosupportrecovery.The\nclassical 2PC protocol provides limited support for the coordinator failure that can lead to\ninconsistencies.\nTosolvethisproblemthethree-phasecommit(3PC)protocolhasbeendeveloped.The3PC\nprotocol is essentially an extension of the BFT protocol and adds a third communication\nphase to assist the leader with the decision for an abort. This entails a higher messaging\nand logging overhead to support recovery. While 3PC is a more robust protocol compared\nto BFT, it is not widely used due to the messaging overhead and its sensitivity to network\npartitioning (i.e., the P in CAP). In practice, systems use either BFT for its simplicity or the\nPaxosprotocolforitsrobustness.\n12.5 DISTRIBUTED SYSTEMS: COORDINATION CLASSES\nAND ATTACKABILITY\n[1077,c3][1071,c5,c6][1072,c19][1073,c18][1088,c3]\nThe General Class of Disruptions\nThe attack surface [1088, 1130] in distributed systems involves the disruption of the re-\nsources,communication,interfaces,and\/ordatathateitherimpairstheresourceavailability\nor disrupts the communication layer interconnecting the resources to impact Confidential-\nity, Availability, or Integrity of the overall system and its services. The disruptions can be\nfrom improper design, arising from operational conditions or deliberate attacks. Resource\ncompromises or disruptions form the basic attack targets. However, the functionality of a\ndistributed system emerges from the interactions across the distributed resources. As ref-\nerencedinSection12.1.2,theresourcesandservices(includingreplicationmanagement)in\nadistributedsystemareprimarilylinkedviacommunicationinfrastructures.Thesespanthe\nrangeofdirectmessageexchangesorviamiddlewarearchitecturessuchaspub-suborevent\nbasedtriggeringamongothers.\nA number of varied terminologies exist to cover the range of operational and deliberate per-\nturbations from crashes, omissions, timing, value disruptions, spoofing, viruses, trapdoors,\nandmanyothers.Wereferthereaderto[1089]foracomprehensivediscussiononthetopic.\nKADistributedSystemsSecurity |October2019 Page413 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nAs the distributed systems primarily rely on message passing for both data transportation\nand coordination, we group the perturbations at the level of message delivery6. The term\n\u201cperturbation or disruption\u201d is deliberately used as the anomalous operation can result from\noperationalissues(dependability)orfromamaliciousintent(security).Themanifestationof\ntheseperturbationsonthesystemoperationsresultsindeviationsfromthespecifiedbehav-\nior of the system. Complementing the vulnerabilities mentioned in Section 12.1.2 of access\ncontrol, data distribution, interfaces, the communication level perturbations can be broadly\ngroupedas:\n1. Timing Based: This spans the omission of messages, early, delayed, or out-of-order\nmessaging.Crashesanddenial-of-servicealsofallinthisgroupastheytypicallymani-\nfestasdisruptionsofthepropertemporaldeliveryofmessagesbyobstructingaccess\ntothecommunicationchannelsorresources.\n2. Value\/Information Based: Spoofing attacks, mimicking, duplication, information leak-\nage such as a Covert Channel Attack or Side Channel Attack, and content manipula-\ntionattacksbroadlyfallinthiscategory.Themanipulationofthecontentofmessages\nmanifestsasByzantinebehavior.Thisattackisonlyviableifasetofresourcesusethe\nexchange messages to build their global view of the system. A malicious entity can\nsend deliberately modulated information (e.g., a mixture of correct and incorrect val-\nues)todifferentgroupsofresourcestoresultinpartitionsofsystemstateviews.Thus,\nbased on different values received by different nodes, the individual nodes are unable\ntoconstitutea\u201cconsistent\u201dandcorrectviewofthesystemstate.Thedegreeofbreach\nofconsistency(strong\u2013fullagreementbyallonvalueandorder\u2013weak,partial,even-\ntual) constitutes the degree of disruption. The nature of the underlying transactional\nservice (e.g., distributed ledgers in Blockchains) determines the type of breach of the\nfunctionality.Relatingtothegroupsofvulnerabilities,aByzantineattackcanabuseac-\ncess control, message delivery and coordination services, or the data itself (viruses,\ncompromisedmobilecode,worms)tocompromisethesystem.\nIt should be noted that a perturbation also includes the property of persistence, i.e., the du-\nration of a perturbation can be transient, episodic, intermittent, or permanent in nature. Fur-\nthermore,attacksoftenentailmultiplesimultaneousoccurrencesthatinvolveacombination\nof timing, value, persistence, and dispersed locations, potentially due to collusion between\nmultipleattackingentities.\nAttacks and Implications\nOnthisgeneralbackground,wenowdetailthetwoprominentclassesofdistributedsystems\nas based on the coordination schema (resource- and service-coordination). This will also\nformthesystemgroupingforconsideringthesecuritymanifestationsofattacks.\nWe use the classical CIA (Confidentiality, Integrity, and Availability) terminology though the\nimplications of these terms often differ according to the type of system and services. For\neach class, the specification of its functionality determines the type of attack and the resul-\ntantcompromisethatdetrimentallyaffectsthedeliveryofservices.\nAs mentioned in Section 12.1.2, the threat surfaces of a distributed system comprise at-\ntacks on the resources, admission control, the communication architectures, the coordina-\n6Theprovisioningofmessageintegritybytechniquessuchascoding,cryptographicprimitives,messageac-\nknowledgements,retries,securegroupcommunication,etc.arediscussedin[1072,1073]andtheCryptography\nKnowledgeArea(Chapter10).\nKADistributedSystemsSecurity |October2019 Page414 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntionmechanisms,andthedata.Similarly,attacksaimtosubverttheassumptionsbehindthe\nfunctionalityofresources,theservices,andtheunderlyingcoordinationschema.\nIn the following subsection, we enumerate some attack scenarios for the resources\/infras-\ntructure and services\/application classes of coordination. Given the immense diversity of\ntypesofresourceandservicesbaseddistributedsystems,thepurposeoftheseexamplesis\nonlytoillustratesomepotentialscenarios.Itisalsoworthhighlightingthatoftenaresource\nattack does not harm the resource per se but primarily affects the service executing on the\nresource.\n12.5.1 The Resource Coordination Class \u2013 Infrastructure View\nThisclassof\u201cvirtualisedresourceaccess\u201dprimarilydealswiththecoordinationofagroupof\ncomputingandcommunicationresourcestoprovideanensembleofhighly-available,highly-\nreliable\u201cplatform\u201dofdiversesharedresourcestotheuser.Thisisaninfrastructure(vsappli-\ncations) view where the user specifies the operational requirements for the desired service\n(e.g.,computationalcapabilities,numberofVirtualMachines(VMs),storage,bandwidthcon-\nstraints, etc.) but is agnostic to the actual mechanisms providing the on-demand access to\ntheresources,scalability,physicalcharacteristics,andgeo-location\/distributionoftheunder-\nlyingresources.\nOverall,thekeycharacteristicofthiscoordinationmodelistheprovisioningofhigh-reliability,\nhigh-availability access to resources. The basic resource replication simply provides a pool\nof resources to support high-availability access. However, the resource replication schema\nprovides only the \u201ccapabilities\u201d to support the services executing on it. Integrity is relevant\ncorrespondingtotheservicespecifications.Forinstance,VMsneedtoprovidethespecified\nlevel of isolation without information leakage. Similarly, a web server is typically replicated\nacrossmachinesbothforreliabilityandforlow-latencylocalisedgeo-dispersedaccess.Each\nreplicatedserverhasthesamesetofdata,andanytimethedataisupdated,acopyisupdated\nacross the replicated servers to provide consistency on data. It is the nature of the service\n(as executing on the resources platform) that determines the type of desired coordination,\nperhapsasconsistency(strong,weak,eventual,causal).ThiswillbethebasisoftheService\nCoordinationclassdiscussedlateron.\nWe briefly present the Cloud and Client-Server models that constitute prominent examples\noftheclassofdistributedresources.\nTheCloudModel\nThe Cloud, in all its manifestations, is representative of the resource coordination model\nas essentially a \u201cresources platform\u201d for services to execute on. There are multiple types\nof Clouds offering varied types of services ranging across emphasis on high-performance,\nlow-latency access or high-availability amongst many other properties. It is the specific re-\nsourcecoordinationschemadictatedbythespecificationsofthedesiredservicesbasedon\nwhich the Cloud \u201cplatform\u201d provides structured access to the Cloud resources. The chosen\ncoordination schema correspondingly supports the type of desired capabilities, for exam-\nple,accesstospecialisedcomputingresourcesand\/orresourcecontainerssuchasphysical\nor virtual machines each offering differing isolation guarantees across the containers. The\nuser specified services execute on the Cloud resources, which are managed by the Cloud\nserviceprovider.Thecoordinationschema,asacentralisedordistributedresourcemanager,\nhandles the mapping and scheduling of tasks to resources, invoking VMs, health monitor-\ning of resources, fault-handling of failed resources such that the user transparently obtains\nKADistributedSystemsSecurity |October2019 Page415 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nsustained access to the resources as per the contractual Service Level Agreements (SLAs)\nspecified on the Cloud resources. The ENISA [1131], NIST [70], and ISO [1132] specifications\nofInfrastructureasaService(IaaS)andPlatformasaService(PaaS)arerepresentationsof\n\u201cresources\/platforms\/infrastructuressupporting theservices\u201d. The multitude ofCloud mod-\nels,architectures,andservicesexistinginpracticemakesitdifficulttoprojectasinglenotion\nof Cloud security. Each specific resource coordination model is characterized by the types\nof resource types in the Cloud model, the type of computing architecture as well as the de-\nsired functionalities within the Cloud. These include, as a non-exhaustive list, the desired\ntypes of resource fault handling, the chosen approach for handling of service bursts, the\ntype of schemas implemented for resource federation and migration, for task orchestration,\nscheduling, the desired degree of concurrent access, the supported levels of multi-tenancy\netc.\nHowever, from a security perspective, it is useful to de-construct the Cloud into its architec-\ntural and functional components that result in the Cloud\u2019s attack surface to consider. Anal-\nogous to the infrastructure view of a data center being an aggregation of computing and\nstorageresources,theCloudisanaggregationofgeo-dispersedresourcesthatareavailable\non-demand to the user. The user has resource-location and resource-composition agnostic\ntransparent access to highly-scalable, highly-available, highly-reliable resource and service\nvirtualisation. The user specifies the operational attributes of interest (termed as Service\nLevel Objectives) as (a) performance specifications, (b) reliability, (c) replication and isola-\ntioncharacteristicsastypesandnumberofVMs,(d)latency,(e)securityasthelevel\/degree\nof encryption and other mechanisms at the computing or communication level and (f) cost\nparameters for delivery or non-delivery of services in the form of contracts known as Ser-\nviceLevelAgreements.Theexactcompositionoftheresources,theirlocationorthemecha-\nnismscollatingtheaggregatedresourcesistransparenttotheuser.Thefunctionalblocksof\ntheCloudincludeauthentication,accesscontrol,admissioncontrol,resourcebrokering,VM\ninvocation, schedulers, monitors, reconfiguration mechanisms, load balancers, communica-\ntion infrastructures, user interfaces, storage, and many other functions under the PaaS and\nIaaSparadigms[70,1131,1132].Thesefunctionalblocks,thephysicalCloudresourcesalong\nwiththeinterfacesacrossthemdirectlyconstitutetheattacksurfaceoftheCloud.\nTheClient-ServerModel\nResource groups where a set of dedicated entities (servers \u2013 service providers) provide a\nspecified service (e.g., Web services \u2013 file system servers, name servers, databases, data\nminers,webcrawlers,etc.)toasetofdataconsumers(clients).Acommunicationinfrastruc-\nture, such as the public Internet, a local network, or a combination thereof, links the servers\nto the clients. This can be monolithic, layered, or hierarchical. Both servers and clients are\nreplicatedtoeitherprovideacharacteristiccollectivedistributedserviceorforfaulttolerance.\nNotethatwearereferringtoClient-Serverarchitectureasaresourcesplatformorinfrastruc-\nture and not the Client-Server services per se. The functionality of a Client-Server infrastruc-\ntureisderivedfromthespecificationsoftheservicesusingtheClient-Servermodelandfrom\ntherequisitecoordinationschemaunderlyingit.\nKADistributedSystemsSecurity |October2019 Page416 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nAttackability Implications (and Mitigation Approaches) on Resource Coor-\ndination\nWenowoutlinesomeexamplescenariosfortheCloudthoughtheyanalogouslyapplytothe\nClient-Serverandotherresourcemodelsaswell.Thereaderisreferredto [1133,1134]foran\ninsightfuldiscussionrelatingsecurityandfunctionalityissuesintheCloud.\n-CompromiseofResources:SuchattacksimpacttheAvailabilityofthebasicresources.\nMitigation:Protectioncanbeobtainedbyusingaccesscontrolschemes(includingFirewalls)\nto limit external access to services and network resources. Authorisation processes are set\nup for granting of rights along with access control mechanisms that verify the actual rights\nofaccess[1135].Otherapproachestoresourceprotectionincludethesandboxingresources\norhavingatamper-resistantTrustedComputingBase(TCB)thatconductscoordinationhan-\ndling[1072,1073]andenforcesresourceaccesses.Whiletheresourceclassprimarilyconsid-\ners attacks on the infrastructure, data at-rest or in-motion (as in a data storage facility) can\nalso be considered as a resource. Consequently, it can be protected using techniques such\nasencryption.Asthespecificationofadistributedserviceincludesthespecificationofboth\nnormalandanomalousbehaviorontheuseofthedataprovidingtheservice,thisprotection\nisconsideredundertheservicesclass.\nOther manifestation of resource attacks, including on communication channels, aim to par-\ntition resources (and overlying services). The implication here is on Availability for the re-\nsourcesandonIntegrityfortheservices.\n- Compromise of Access\/Admission Control: This comprises the broad categories of Mas-\nquerading, Spoofing, and ID management attacks. The implication on the resources is on\nAvailability, though both the Integrity and Confidentiality of the data\/service are affected. In\ncaseofaDoSattack,theconsequenceisonresourceAvailability.\nMitigation:IntrusionDetectionSystem(IDS)constitutetypicalmitigationapproaches.These\nare complemented by periodic or random ID authentication queries. The periodic checking\nofsystemstateisusedtoestablishthesanityofIDs.\n- Compromise of VM: The typical manifestation is of information leakage from the VM via\na Covert Channel Attack or Side Channel Attack or similar attacks. The consequence is the\nviolationofIntegrityandConfidentialityoftheservicesprovisionedbytheVM.\nMitigation: A variety of schemes for VM\u2019s protection are detailed in [999] (also see the Oper-\nating Systems & Virtualisation Knowledge Area (Chapter 11)). There are three aspects to be\nconsidered here as the detection of leakage, the system level where the leakage transpires,\nand the handling of leakage. Taint analysis is a powerful technique for data level detection.\nAs covert\/side-channel attacks often happen at the hardware level and are influenced by\nthe schedulers, the use of detectors employing hardware performance counters is a gener-\nallyusedtechniqueasadvocatedin[1136].SystemlevelhandlingofVMcompromisesoften\nstartsfromtheleveloftighteningthespecificationoftrustassumptionsandvalidatingthem\nbeing upheld using analytical, formal, or experimental stress techniques. Hypervisors are\ncommonlyusedfortheenforcementofVMoperations.\n- Compromise of Scheduler: There are two manifestations of such attacks. When the sched-\nulerisaffectedandthisresultsinananomaloustaskorresourceallocation,suchadeviation\n(onanincorrectresourceallocation)canbedetectedthroughAccessControl.Inthecaseof\namalicioustakeoverofthescheduler,thelikelyresultantinconsistenciesacrossthesystem\nKADistributedSystemsSecurity |October2019 Page417 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nstate or resource-task bindings can be filtered by the coordination schema whose job is to\nmaintainaconsistentstate.SuchattackstypicallyimpactAvailabilityandIntegrity.Confiden-\ntialityisnotbreached.\nMitigation: As mentioned in the attack description, Access Control and coordination con-\nstructsareusedtochecktheconsistencyofthesystemstateforanyobservedmis-matchto\nthe legitimate or allowed set of resource allocations. This can be used identify corruptions\nofthescheduler.\n-CompromiseofBroker:Thisoccurrence,withinaCloudresourcemanager\/brokeroraninter-\nCloudbroker,primarilyimpactsresourceAvailability.\nMitigation:Approachessimilartoschedulercompromisemitigationareusedhere.Ifbackup\nbrokers are part of the design, that is a typical fall back, otherwise, system stops are often\nthesolution.\n- Compromise on Communication: As communication is a core functionality to achieve re-\nsource coordination, this has strong implications on the resources to stay coordinated and\ndirectlyimpactsAvailability.Theconsequentinabilitytosupportreplication,resourcetotask\nallocation,etc.fundamentallycompromisesthefunctionalityofthesystem.\nMitigation: A variety of communication protection techniques are presented in the Network\nSecurity Knowledge Area (Chapter 17). These include retries, ACK\/NACK based schemes,\ncryptographicallysecuredchannelsamongothers.\n- Compromise on Monitoring and Accounting: With incorrect information on the state of the\nsystem and\/or services, this can lead to compromise of Confidentiality, Integrity, and Avail-\nability.\nMitigation: State consistency schemes are the typical mechanism utilised here. It is worth\nmentioning that the replication and coordination concepts presented in Sections 12.4 and\n12.4.4formthebasisofthemitigationapproaches.Theverypurposeofthereplicationman-\nagementistoobtainconsistentsystemstatestocircumventdisruptions.\n12.5.2 The Services Coordination Class \u2013 Applications View\nThe service coordination model focuses on the specific characteristics of the services that\ndetermine the degree\/type of coordination relevant to supporting that service. For example,\na database hosted on a Cloud necessarily requires the provision of integrity in the form of\nACID7 properties along with liveness. Distributed storage, such as KVS (Key Value Store) or\ntransactional database services, may require varied levels of consistency or linearisability\nwhere the desired level of integrity may depend on the level of data-access latency feasi-\nble in the system. The broad class of Web services to include Web crawlers and search en-\ngines may require weak or partial consistency as per CAP. On the other hand, Blockchains\norledgerqueries,thatprovidedistributedcryptobasedconsensus,havestrongconsistency\n(andtraceableauditing)asakeyrequirementwithlesserdemandsonlatency.Thus,itisthe\nspecification of the service (KVS, Database, Blockchain) that determines the nature of the\ncoordinationschemaforthedistributedresourcesplatform.\nWepresentsomecharacteristicexamplesoftheservicesclassas:\nWeb Services: These cover the spectrum of data mining, web crawlers, information servers,\n7Astandsforatomic,Cforconsistent,IforisolatedandDfordurable.\nKADistributedSystemsSecurity |October2019 Page418 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nsupport for e-transactions, etc. This is a fairly broad, and generic, category, which encom-\npasses a wide variety of services. It is useful to note that many of these services utilise the\nClient-Serverparadigmthoughourinteresthereisattheserviceslevel.\nKey Distribution: This is a broad class of (Authorisation & Authentication) services such as\nKerberos, PKI, etc. Such services typically enable authentication (either proving server au-\nthenticity to a client, or mutually authenticating both client and server) over insecure net-\nworks, based on various cryptographic protocols. Authentication services commonly act as\ntrusted third party for interacting entities in a distributed system. For further details see the\nAuthentication,Authorisation&Accountability(AAA)KnowledgeArea(Chapter13).\nStorage\/KVS\nThisisadiversesetofservicesstartingfromregisterleveldistributedread-writesthatentail\nstrong consistency with very low latency. Another general model is Key Value Store (KVS)\nwhere data is accessed via keys\/pointers\/maps with simple read, write, delete types of se-\nmantics. In KVS, the data is represented as a collection of key-value pairs, such that each\npossiblekeyappearsatmostonceinthecollectionwithafocusonfastaccesstimes(upto\naconstantaccesstime).Thekey-valuemodelisoneofthesimplestnon-trivialdatamodels,\nand richer data models are often implemented as extensions with specified properties. For\nexample, an ordered model can be developed that maintains the keys in a lexicographic or-\ndertoefficientlyretrieveselectivekeyranges.Key-valuestorescanuseconsistencymodels\nrangingfromeventualconsistencytostrictconsistency.Thesecurityissuesrequiresdealing\nwithdata-at-rest(staticstorage)anddata-in-transit(dynamicR\/Wops).\nTransactionalServices,Databases\nThis is a wide class of services covering databases and general transactional services (re-\ntrieval, informational data mining, banking and stock transactions, etc.). The requirements\nare consistency as in banking where all the debit and credit transactions are (strongly or\nweakly) serializable for consistency. More generally, a database adheres to all of the stipu-\nlatedACIDproperties.\nOntheotherhand,anumberofdataminingandinformationlookuptransactionsonlyrequire\nweaker nuances of consistency. For example, an information lookup process can work with\nphysically partitioned data centers resulting in stale or inconsistent information as long as\nthey are eventually reconcilable within some specification of the service requirements. The\nspecificationofthetypeanddegreeofperturbationsandlevelofconsistencytheservicesare\ndesignedtoberesilienttodeterminesthespecificcoordinationschematouse.Additionally,\nin the case of weaker consistency models, the user is required to deal with any stale data\nthatmighthavebeenretrievedfromthedatabase.\nBlockchains\/Cryptocurrencies\nThe concept of a ledger provides for consistent bookkeeping on transactions. This is prob-\nlematic to achieve in a distributed system where the participating entities do not trust each\notherandarepotentiallyuntrustworthy.Blockchainsprovideadecentralised,distributed,and\npublic ledger that is used to record transactions across many computers so that the record\ncannot be altered retroactively without also altering all subsequent blocks. Such alterations\nrequire the consensus of the network and can therefore not be performed unilaterally by\nan attacker. This also allows the participants to verify and audit transactions inexpensively.\nBlockchainsformthefoundationfornumerouscryptocurrencies,mostnotableBitcoin.\nIntechnicalterms,aBlockchainisalistofrecordsorblocks.Theaforementionedproperties\nKADistributedSystemsSecurity |October2019 Page419 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\narise from the fact that each block incorporates a cryptographic hash of the previous block\nandatimestamp.Ifablockinthechainisalteredwithoutalsoalteringallsubsequentblocks,\nthehashofthefollowingblockwillnolongermatch,makingthetamperingontheBlockchain\ndetectable.\nWhen used as distributed ledgers, Blockchains are typically managed by peer-to-peer net-\nworks. Peers in such a network participate in a protocol for validating newly submitted\nblocks.Blockchainsarealsoexamplesofwidelydeployedsystemsexhibitinghightolerance\ntoByzantinefailures.\nThegenericBlockchainconceptallowsparticipationbyanyentity(permission-lesssystems,\npublic blockhains) and does not include any access restrictions. This is the case for the\nblockchainsunderlyingmanywidelyusedcryptocurrenciessuchasBitcoin.However,amore\nrestrictiveparticipationmodel(permissionedsystems,privateblockchains)isalsopossible,\nwherea\u201cvalidatingauthority\u201dgrantspermissionforparticipation.\nIn order to deter denial of service attacks and other service abuses such as spam on a net-\nwork,theconceptofProof-of-Work(PoW)(i.e.,spendingprocessingtimetoperformcompu-\ntationallyexpensivetasks)isspecifiedasarequirementforparticipation.Thisiseffectiveas\nameansofpreventingserviceabusessuchasspamsincetherequiredworkistypicallyhard\nto perform but easy to verify, leading to asymmetric requirements for service requester and\nprovider.However,PoWschemesalsoleadtohighenergyusageand,dependingonthecho-\nsen work requirement, may lead to unreasonably high barriers of entry. This is the case, for\ninstance, in certain cryptocurrencies, where meaningful participation requires custom hard-\nware designed for the specific type of work required. To avoid these shortcomings, alterna-\ntive approaches relying on Proof-of-Stake (PoS) are in development but not as mature as\nPoW-basedschemesandnotwidelydeployed.\nA comprehensive discussion on Blockchain issues appears in [1137, 1138]. As a note,\nBlockchainsrepresentaninterestingcombinationofdecentralisedresourcesusingtheP2P\nmodel for the resource coordination and the coordination schema of consensus for its ser-\nvicefunctionality.\nOverall,serviceintegrity,intermsofconsensusassupportedbyrequisiteliveness,isthekey\ncharacteristic of the service coordination model. This contrasts with the resource coordina-\ntion class where resource accessibility and availability were the dominant drivers\/consider-\nations.\nAttackability Implications (and Mitigation Approaches) on Service Coordi-\nnation\nThe services and applications constitute a very broad class to cover, both for the type of\nattacks and the diversity of services where the functional specification of the service deter-\nmines the type and degree of the impact on security. In most cases the breach on Integrity,\nalongwithonConfidentiality,isthefirstclassimpactwithimpactonAvailabilityfollowingas\naconsequence.Someexamplesofbreachesforthecoordinationschemaandservicetypes\narementionedbelow.\nNote: The mitigation schemes applicable here are the same as described in Section 12.5.1\nthat essentially result from the basic replication management and coordination concepts\npresented in Sections 12.4 and 12.4.4. The very purpose of replication based coordination,\nat the resource or the service level, is to prevent compromises by discrete attacks up to the\nKADistributedSystemsSecurity |October2019 Page420 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nthresholdofseveritytypeandthenumberofdisruptionsthereplicationschemaisdesigned\ntohandle.\nCompromiseofKeydistributioninPKI:Theauthenticationprocessessupportingthedistribu-\ntionofpublickeysiscompromisedaffectingserviceIntegrityandConfidentiality.\nCompromise of Data at Rest: This is analogous to the breach of resources in the resource\ncoordinationmodelasapplicabletostoragesystems.\nCompromise of Data in Motion: This has varied consistency and latency consequences that\ncompromisetheIntegritydependingonthespecificationsoftheservices.Wepresentavery\nsimplisticenumerationusingtransactionsclassesas:\nShort transactions:(Storage\/KVS,etc.)Themajordriverforthisclassisbothconsistency\nandlowlatency(e.g.,linearisability).Asbothlivenessandsafetyareviolated,theIntegrityof\nthe transaction is compromised. It is worth noting that a DoS attack may not affect consis-\ntency.However,aslatencyisaffected,theserviceIntegrityislost.\nLarge transactions: Ledgers (Blockchain, etc.) lie in this category where, although latency\nis important, it is the Integrity (as defined by the consistency of the ledger) that is the pri-\nmarypropertytopreserve.AsLedgersconstituteapopularservice,wediscussittoillustrate\naspectsofbothattacksurfacesandassumptions.\nTorecapitulatefromSection12.5.2,Blockchainsconstitutealedgerofinformationthatisdis-\npersedacrossadistributedsystem.Blockchainsensurethesecurityofdatabynotproviding\na single point of attack. The ledger is stored in multiple copies on a network of computers.\nEachtimeanauthorisedparticipant(forexampleinapermissionedsystem)submitsatrans-\naction to the ledger, the other participants conduct checks to ensure that the transaction is\nvalid, and such valid transactions (as blocks) are added to the ledger chain. Consensus en-\nsuresaconsistentviewofthesequenceoftransactionsandthecollatedoutcome.Thecryp-\ntographicbasisofthehash,oneachblock,isexpectedtoavoidtampering,andtheProofof\nWorknotionisdesignedtomitigatetheeffectofDoSattacks.\nWhatmakesthissystemtheoreticallytamperproofaretwoaspects:(a)anunforgeablecryp-\ntographichashlinkingtheblocks,and(b)attack-resilientconsensusbywhichthedistributed\nparticipantsagreeonasharedhistoryoftransactions.\nCompromising these involves the compromise of stored cryptographic keys and the hash.\nWhile theoretically safe, such systems may turn out to be vulnerable to emergent technolo-\ngies such as quantum computing. Moreover, while Proof of Work requirements (i.e., \u201cto\ndemonstrate\u201d a greater than 50% participant agreement) can make collusion attacks pro-\nhibitivelyexpensiveinsufficientlylargesystems,theycanbefeasibleonsystemswithfewer\nparticipants.\nSimilarly,theconsensuspropertycanbecompromisedviaanEclipseattack[1139]forBitcoin,\nand also in general cases where there exists the potential to trick nodes into wasting com-\nputing power. Nodes on the Blockchain must remain in constant communication in order to\ncomparedata.Anattackerthatcantakecontrolofanode\u2019scommunicationandspoofother\nnodes into accepting false data to result in wasted computing or confirming fake transac-\ntions can potentially breach consensus. The work in [1138] provides useful reading on such\ncompromises.\nMixedtransactions:Asimpliedinthelabel,thiscombinesshortandlargetransactions.The\nsecurityimplicationsdependonthetypeofservices.Asanexample,weoutlinetwoservice\nKADistributedSystemsSecurity |October2019 Page421 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ngroups,namely:\n- E-commerce supporting transactions: The core requirements here are ACID properties\nthatentailstrongconsistencyandnopartitions.AnycompromisesaffecttheIntegrityofthe\nservice.\n- Informational systems: Services such as Webcrawlers, Data Retrieval for applications\nsuchasUberorinformationalqueriesforshoppingcanhandle(bothnetworkanddata)par-\ntitions of data to operate on stale cached data. The attack may lead to redundant compu-\ntations on the searches or slightly stale information but Integrity is not violated as long as\nthesemanticsofWeak,Relaxed,orEventualconsistency,asapplicablefortheservicespec-\nification,aresustained.Alsoinformationalquerieshavemixedlatencyrequirements.Forex-\nample, the small latency within a local data center and higher-tolerable latency across geo-\ndispersed data centers may define the degree of attack tolerance until both Availability and\nIntegrityarecompromised.\nCONCLUSIONS\nThe intent of this chapter has been to outline how distributed systems work, and how the\nmechanisms supporting the operations of such systems open security issues in them. Very\noften the expectation is that classical security techniques will directly apply in a distributed\nsystemscontextaswell.However,thisisoftennotthecaseandthebetteroneunderstands\nthe conceptual basis of a distributed system, the better one can understand and provide\nfor its security. The KA discussed the functional categorisation of distributed systems into\ntwo major classes: decentralised and coordinated control. The operations for each class\nwere elaborated leading to the security implications resulting from the different specifics\nunderlyingdistributedsystems.\nCROSS-REFERENCE OF TOPICS VS REFERENCE MATERIAL\n12.1ClassesofDistributedSystemsandVulnerabilities c2 c5 c18\n12.2DistributedSystems:DecentralisedP2PModels c25\nc11,c12\n12.3DistributedSystems:AttackingP2PSystems c16 c5\nc5-7, c16,\n12.4DistributedSystems:CoordinatedResourceClustering c12, c3 c17,\nc5,c14\nc25 c19\n12.5DistributedSystems:CoordinationClassesandAttackability c3 c5-6 c19 c18 c3\nKADistributedSystemsSecurity |October2019 Page422\n]7701[hcnyL ]1701[dihcaR ]2701[namriB\n]3701[VJP\n]8801[redynS TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nFURTHER READING\nThefollowingbooksarerecommendedforadeepercoverageofthedistributedsystemand\nsecurityconcepts.\nDistributedAlgorithmsConcepts Lynch[1077]\u2014Thebooklaysouttheessentialconcepts\nofdistributedsystems.Thefocusisonsynchronisationandconsensusthoughitprovidesa\ncomprehensiveandmathematicallyrigorouscoverageofdistributedsystemsconceptsfrom\nanalgorithmsviewpoint.\nReliable&SecureDistributedProgramming Cachin,Guerraoui,Rodrigues[1071]\u2014Coming\nfrom a distributed programming viewpoint, this is another rigorous book that covers both\nfaulttoleranceandsecurity.Italsoprovidesanexcellentcoverageofcryptographicprimitives.\nAlthough it predates the development of Ledgers, most of the concepts behind them are\ncoveredinthisbook.\nGroup Communication & Replication Birman [1072] \u2014 This is an excellent book that com-\nbines concepts with an emphasis on the actual development of distributed systems. The\ncasestudiesprovidevaluableinsightsonpracticalissuesandsolutions.Aninsightfulcover-\nageofP2Psystemsalsoappearsinthisbook.\nSecurityEngineering Anderson[1030]\u2014Thisbookmakesforexcellentreadingonthereal-\nisationofdistributedsystemfromasecurityperspectiveespeciallyfornamingservicesand\nmulti-level security. The reader is also encouraged to read the texts [1076, 1107] that detail\ncomplementarycoverageonCORBAandWebservices.\nThreat Modeling Swiderski, Snyder [1088] \u2014 The coverage is on the basics of threat mod-\neling from a software life cycle and application security viewpoint. While not a distributed\nsystemsbook,itstillprovidesvaluableinsightsonhowthreatmodelingisconductedinprac-\ntice.\nKADistributedSystemsSecurity |October2019 Page423 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nKADistributedSystemsSecurity |October2019 Page424 Chapter 13\nAuthentication,\nAuthorisation &\nAccountability (AAA)\nDieter Gollmann Hamburg University of Technology\n& Nanyang Technological\nUniversity Singapore\n425 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nAbstract\nAccess control builds on authorisation and authentication. This KA will present the general\nfoundations of access control and some significant instantiations that have emerged as IT\nkeptspreadingintonewapplicationareas.Itwillsurveymodesofuserauthenticationandthe\nway they are currently deployed, authentication protocols for the web, noting how new use\ncaseshaveledtoashiftfromauthenticationtoauthorisationprotocols,andtheformalisation\nofauthenticationpropertiesasusedintoday\u2019sprotocolanalysistools.Onaccountability,the\nfocusisonthemanagementandprotectionofauditlogs.Thesurveillanceoflogstodetect\nattacks or inappropriate behaviour is described in the Security Operations & Incident Man-\nagementKnowledgeArea(Chapter8)whiletheexaminationofevidencefollowingabreach\nof policy or attack is covered in the Forensics Knowledge Area (Chapter 9). Throughout the\nKA, we will flag technical terms that appear in more than one meaning in the academic and\nthetradeliterature.\n13.1 INTRODUCTION\n\u201cAllscienceiseitherphysicsorstampcollecting.\u201d[ErnestRutherford]\nIn some cases, IT systems may guarantee \u2013 by design \u2013 that no undesirable behaviour is\npossible. In other cases, IT systems exhibit such a degree of flexibility \u2013 also by design \u2013\nthatadditionalmeasuresneedtobetakentolimitundesirablebehaviourinaccordancewith\nthe given circumstances. As noted by Lessig, this can be done by code in the system that\nexcludesbehaviour,whichwillviolatecertainrules,oritcanbedonebycodesofconductthat\ntheusersofthesystemareexpectedtoadhereto[1140].Inthelattercase,disciplinaryorlegal\nprocesses deal with those that had broken the rules. This is the context for authentication,\nauthorisation,andaccountability.\nReadersacquaintedwiththemoresofacademicwritingmaynowexpectdefinitionsofcore\nterms,maybesomerefinementofterminology,andthenanoverviewofthelatestapproaches\ninachievingauthentication,authorisation,andaccountability.Aswillbeshown,thisapproach\nfails at the first hurdle. These three terms are overloaded to an extent that provides ample\nspace for confusion and dispute. For example, authorisation stands both for the setting of\nrules and for checking compliance with those very rules. Readers should thus be cautious\nwhenstudyingtheliteratureonthisKnowledgeArea.\nChangesinthewayITisbeingusedcreatetheirownchallengesfortaxonomies.Howclosely\nshould terms be tied to the environment in which they first emerged? There is a habit in the\ntrade and research literature of linking terms exclusively to a notional \u2018traditional\u2019 instantia-\ntion of some generic concept, and inventing new fashionable terms for new environments,\neventhoughtheunderlyingconceptshavenotchanged.\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page426 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n13.2 CONTENT\nThisKAfirstaddressesauthorisationinthecontextofaccesscontrolandpresentsthemain\nflavours of access control in use today. The section on access control in distributed sys-\ntemsexplainsconceptsusedwhenimplementingaccesscontrolacrossdifferentsites.The\nKA then moves to authentication, touching on user authentication and on authentication in\ndistributed systems, and concludes with a discussion of logging services that support ac-\ncountability.\n13.3 AUTHORISATION\n[1141,1142,1143,1144,1145]\nIntheirseminalpaper[1142],Lampsonetal.postulateaccesscontrol=authentication+autho-\nrisation. We will follow this lead and present authorisation in the context of access control,\nstarting with an introduction to the concepts fundamental for this domain, followed by an\noverview of different policy types. Libicki\u2019s dictum, \u201cconnotation, not denotation, is the prob-\nlem\u201d [1146] also applies here, so we will pay particular attention to the attributes used when\nsettingaccessrules,andtothenatureoftheentitiesgovernedbythoserules.Code-basedac-\ncess control, mobile security, and Digital Rights Management will introduce new paradigms\nto access control, without changing its substance. We will then present design options for\npolicy enforcement and discuss delegation and some important theoretical foundations of\naccesscontrol.\n13.3.1 Access Control\nAccess control is \u201cthe process of granting or denying specific requests ...\u201d [1147]. This pro-\ncessneedsthefollowinginputs\n\u2022 Whoissuedtherequest?\n\u2022 Whatisrequested?\n\u2022 Whichrulesareapplicablewhendecidingontherequest?\n\u201cWho\u201dinthefirstquestionisdangerous.Thewordsuggeststhatrequestsalwayscomefrom\naperson.Thisisinaccuratefortworeasons.First,thesourceofarequestcouldbeaparticu-\nlarmachine,amachineinaparticularconfiguration,oraparticularprogram,e.g.aparticular\nAndroid app. Secondly, at a technical level, requests in a machine are issued by a process,\nnotbyaperson.Thequestionthusbecomes,\u201cforwhomorwhatistheprocessspeakingfor\nwhen making the request?\u201d \u201cWhat is requested\u201d is frequently given as a combination of an\naction to be performed and the object on which the action is to be performed. The rules are\nlogicalexpressionsthatevaluatetoadecision.Intheelementarycase,thedecisionispermit\nordeny.Whenpoliciesgetmoreelaborate,theremaybereasonsforaddinganindeterminate\ndecision. A decision may also prescribe further actions to be performed, sometimes called\nobligations.\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page427 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n13.3.1.1 CoreConcepts\nTheterm\u2019securitypolicy\u2019isusedbothforthegeneralruleswithinanorganisationthatstipu-\nlate how sensitive resources should be protected, and for the rules enforced by IT systems\non the resources they manage. Sterne had coined the terms organisational policies and au-\ntomatedpoliciestodistinguishthesetwolevelsofdiscourse[1141].\nWhen setting security policies, principal stands for the active entity in an access request.\nWhen policies directly refer to users, as was the case in the early stages of IT security, user\nidentities serve as principals. Access control based on user identities is known as Identity-\nBased Access Control (IBAC). In security policies that refer to concepts such as roles or to\nthe program that issues a request, the principal is a role or a program. Principal may then\ngenerally stand for any security attribute associated with the issuer of a request. With this\ngeneralisation, any flavour of access control is by definition attribute-based access control\n(seeSection13.3.1.4).\nSubject stands for the active entity making a request when a system executes some pro-\ngram.Asubjectspeaksforaprincipalwhentheruntimeenvironmentassociatesthesubject\nwiththeprincipalinanunforgeablemanner.Theoriginalexampleforcreatingasubjectthat\nspeaks for a principal is user log-in, spawning a process running under the user identity of\nthe person that had been authenticated. The research literature does not always maintain\nthisdistinctionbetweenprincipalsandsubjectsandonemayfindsecuritypoliciesreferring\ntosubjects.Whenpoliciesrefertoattributesofauserbutnottotheuser\u2019sidentity,useriden-\ntitiesbecomealayerofindirectionbetweenprincipalsandsubjects[1148].\nAsubjectiscreated,e.g.,atlog-in,andcanbeterminated,e.g.atlog-out.Similarly,useriden-\ntitiesarecreatedthroughsomeadministrativeactionandcanbeterminated,e.g.,bydeleting\nauseraccount.Inpractice,subjectshaveconsiderablyshorterlifetimesthanuseridentities.\nProcessesthatcontrolindustrialplantsarearareexampleofsubjectsthatcouldliveforever,\nbutcouldbekilledbysystemcrashes.\nObjectisthepassiveentityinanaccessrequest.Accessoperationsdefinehowanobjectmay\nbe accessed by a subject. Access operations can be as elementary as read, write, execute\nin Linux, they can be programs such as setuid programs in Linux, and they can be entire\nworkflowsasinsomeflavoursofUCON(Section13.3.1.8).\nAccess rights express how a principal may access an object. In situations where there is a\ndirect match between access operations and access rights, the conceptual distinction be-\ntweenaccessoperationsandaccessrightsmaynotbemaintained.Permissionisfrequently\nused as a synonym for access right. Privilege may also be used as a synonym for access\nright,e.g.,Oracle9iDatabaseConceptsRelease2(9.2)states:\n\u201cAprivilegeispermissiontoaccessanamedobjectinaprescribedmanner...\u201d\nOther systems, such as Windows, make a distinction between access rights and privileges,\nusing privilege specifically for the right to access system resources and to perform system-\nrelatedtasks.Operatingsystemsanddatabasesoftenhavearangeofsystemprivilegesthat\narerequiredforsystemadministration.\nThe reference monitor (more details in Section 13.3.2.2) is the component that decides on\naccessrequestsaccordingtothegivenpolicy.\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page428 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n13.3.1.2 SecurityPolicies\nAutomated security policies are a collection of rules. The rules specify the access rights a\nprincipalhasonanobject.Conceptually,apolicycouldthenbeexpressedasanAccessCon-\ntrol Matrix with rows indexed by principals and columns indexed by objects [1135]. Access\nControl Lists (ACLs) stored with the objects correspond to the columns of this matrix; capa-\nbilities stored with principals correspond to the rows of this matrix (also see the Operating\nSystems&VirtualisationKnowledgeArea(Chapter11)).\nDiscretionary Access Control (DAC) and Mandatory Access Control (MAC) are two core poli-\ncies formulated in the 1970s in the context of the US defence sector. Discretionary access\ncontrol policies assign the right to access protected resources to individual user identities,\natthediscretionoftheresourceowner.Intheliterature,DACmaygenericallyrefertopolicies\nsetbyresourceownersbutalsotopoliciesreferringdirectlytouseridentities,i.e.,toIBAC.\nMandatory access control policies label subjects and objects with security levels. The set\nof security levels is partially ordered, with a least upper bound and a greatest lower bound\noperator.Thesecuritylevelsthusformalattice.Intheliterature,MACmaygenericallyreferto\npolicies mandated by the system as, e.g., in Security-Enhanced Linux (SELinux) [1149, 1150]\nandinSecurity-Enhanced(SE)Android[1151],ortopoliciesbasedonsecuritylevelsasinpast\nproducts such as Trusted Xenix or Trusted Oracle. Policies of the latter type are also known\nasmulti-levelsecuritypoliciesandaslattice-basedpolicies.\n13.3.1.3 Role-basedAccessControl\nIn Role-BasedAccessControl(RBAC), roles are an intermediate layer between users and the\npermissionstoexecutecertainoperations.Operationscanbewell-formedtransactionswith\nbuilt-inintegritychecksthatmediatetheaccesstoobjects.Usersareassignedrolesandare\nauthorised to execute the operations linked to their active role. Separation of Duties (SoD)\nrefers to policies that stop single users from becoming too powerful. Examples for SoD are\nrules stating that more than one user must be involved to complete some transaction, rules\nstating that a user permitted to perform one set of transactions is not permitted to perform\nsome other set of transactions, the separation between front office and back office in finan-\ncial trading firms is an example, or rules stating that policy administrators may not assign\npermissionstothemselves.StaticSoDrulesareconsideredduringuser-roleassignment,dy-\nnamic SoD must be enforced when a role is activated. The NIST RBAC model [1144] distin-\nguishesbetween:\n\u2022 Flat RBAC: users are assigned to roles and roles to permissions to operations; users\ngetpermissionstoexecuteproceduresviarolemembership;user-rolereviewsaresup-\nported.\n\u2022 HierarchicalRBAC:addssupportforrolehierarchies.\n\u2022 ConstrainedRBAC:addsseparationofduties.\n\u2022 Symmetric RBAC: adds support for permission-role reviews, which may be difficult to\nachieveinlargedistributedsystems.\nMany commercial systems support some flavour of role-based access control, without nec-\nessarily adhering to the formal specifications of RBAC published in the research literature.\nRBAC is an elegant and intuitive concept, but may become quite messy in deployment as\nsuggestedbycommentsinanempiricalstudyontheuseofRBAC[1152].Practitionersnote\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page429 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nthatRBACworksaslongaseveryuserhasonlyonerole,orthat\u201ctheenormouseffortrequired\nfordesigningtherolestructureandpopulatingroledata\u201dconstitutesaninhibitorforRBAC.\n13.3.1.4 Attribute-basedAccessControl\nAttribute-BasedAccessControl(ABAC)isdefinedin[1153]asa\u201clogicalaccesscontrolmethod-\nologywhereauthorisationtoperformasetofoperationsisdeterminedbyevaluatingattributes\nassociated with the subject, object, requested operations, and, in some cases, environment\nconditions against policy, rules, or relationships that describe the allowable operations for a\ngivensetofattributes\u201d. This is a generic definition of access control that no longer reserves\na special place to the user or to the user\u2019s role, reflecting how the use of IT systems has\nchangedovertime.\nAccess control may be performed in an application or in the infrastructure supporting the\napplication. Access control in an infrastructure uses generic attributes and operations. The\nLinuxaccesscontrolsystemmayserveasanexample.Accesscontrolinanapplicationuses\napplication-specific attributes and operations. In this distinction, ABAC can be viewed as a\nsynonymforapplication-levelaccesscontrol.\n13.3.1.5 Code-basedAccessControl\nCode-BasedAccessControl(CBAC)assignsaccessrightstoexecutables.Policiesmayrefer\ntocodeorigin,tocodeidentity(e.g.,thehashofanexecutable),ortootherpropertiesofthe\nexecutable, rather than to the identity of the user who had launched the executable. Origin\ncansubsumethedomainthecodewasobtainedfrom,theidentityofthecodesigner,aspe-\ncificnamespace(.NEThadexperimentedwithstrongnames,i.e.barepublickeysservingas\nnames for name spaces), and more. CBAC can be found in the Java security model [1154]\nandinMicrosoft\u2019s.NETarchitecture[1155].\nThereferencemonitorinCBACtypicallyperformsastackwalktocheckthatallcallershave\nbeengrantedtherequiredaccessrights.Thestackwalkaddressestheconfuseddeputyprob-\nlem[1156],whereanunprivilegedattackermanipulatesasystemviacallstoprivilegedcode\n(the confused deputy). Controlled invocation is implemented through assert statements; a\nstackwalkforanaccessrightwillstopatacallerthatassertsthisright.\n13.3.1.6 MobileSecurity\nSmartphonestypicallyhaveasingleowner,holdprivateuserdata,offercommunicationfunc-\ntionsrangingfromcellphonetoNFC,canobservetheirsurroundingsviacameraandmicro-\nphone, and can determine their location, e.g., via GPS. On smartphones, apps are the prin-\ncipals for access control. The objects of access control are the sensitive data stored on a\nphoneandthesensitivedevicefunctionsonaphone.\nAccess control on a smartphone addresses the privacy requirements of the owner and the\nintegrityrequirementsoftheplatform.Android,forexample,dividespermissiongroupsinto\nnormal, dangerous, and signature permissions. Normal permissions do not raise privacy or\nplatform integrity concerns; apps do not need approval when asserting such permissions.\nDangerouspermissionscanimpactprivacyandneeduserapproval.UptoAndroid6.0,users\nhadtodecidewhethertoauthorisearequestedpermissionwheninstallinganapp.Userstud-\niesshowedthatpermissionswereauthorisedtoofreelyduetoagenerallackofunderstand-\ningandriskawareness,seee.g.[1157].SinceAndroid6.0,usersareaskedtoauthoriseaper-\nmission when it is first needed. Signature permissions have an impact on platform integrity\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page430 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nandcanonlybeusedbyappsauthorisedbytheplatformprovider;appandpermissionhave\ntobesignedbythesameprivatekey.ForfurtherdetailsseetheWeb&MobileSecurityKnowl-\nedgeArea(Chapter15).\n13.3.1.7 DigitalRightsManagement\nDigital Rights Management (DRM) has its origin in the entertainment sector. Uncontrolled\ncopying of digital content such as games, movies or music would seriously impair the busi-\nness models of content producers and distributors. These parties hence have an interest in\ncontrolling how their content can be accessed and used on their customers\u2019 devices. Poli-\ncies can regulate the number of times content can be accessed, how long content can be\nsampled for free, the number of devices it can be accessed from, or the pricing of content\naccess.\nDRMturnsthefamiliaraccesscontrolparadigmonitshead.DRMimposesthesecuritypolicy\nofanexternalpartyonthesystemownerratherthanprotectingthesystemownerfromexter-\nnal parties. Superdistribution captures the scenario where data are distributed in protected\ncontainersandcanbefreelyredistributed.Labelsspecifyingthetermsofuseareattachedto\nthecontainers.Thedatacanonlybeusedonmachinesequippedwithaso-calledSuperdistri-\nbution Label Reader that can unpack the container and track (and report) the usage of data,\nand enforce the terms of use [1158]. The search for such a tamper resistant enforcement\nmechanismwasoneofthedrivingforcesofTrustedComputing.\nTheleveloftamperresistancerequireddependsontheanticipatedthreats.TrustedPlatform\nModulesareahardwaresolutiongivingahighdegreeofassurance.EnclavesinIntelSGXare\nasolutioninsystemsoftware.Documentreadersthatdonotpermitcopyingimplementthis\nconceptwithinanapplication.Stickypoliciespursuearelatedidea[1159];policiessticktoan\nobjectandareevaluatedwhenevertheobjectisaccessed.\nAttestation provides trustworthy information about a platform\u2019s configuration. Direct anony-\nmousattestationimplementsthisservicein away thatprotectsuserprivacy[1160]. Remote\nattestationcanbeusedwithsecuritypoliciesthatarepredicatedonthesoftwarerunningon\naremotemachine.Forexample,acontentownercouldcheckthesoftwareconfigurationata\ndestinationbeforereleasingcontent.IntheFIDOUniversalAuthenticationFramework(FIDO\nUAF)justthemodeloftheauthenticatordeviceisattested.Alldevicesofagivenmodelhold\nthesameprivateattestationkey[1161].\nFor a brief period, it was fashionable to use Digital Rights Management as the generic term\nsubsuming\u2018traditional\u2019accesscontrolasaspecialcase.\n13.3.1.8 UsageControl\nUsageControl(UCON)wasproposedasaframeworkencompassingauthorisationsbasedon\nthe attributes of subject and object, obligations, and conditions [1143]. In [1143], obligations\nare additional actions a user has to perform to be granted access, e.g., clicking on a link\nto agree to the terms of use. In today\u2019s use of the term, obligations may also be actions\nthe system has to perform, e.g., logging an access request. Such actions may have to be\nperformed before, during or after an access happens. Conditions are aspects independent\nofsubjectandobject,e.g.,timeofdaywhenapolicypermitsaccessonlyduringofficehours\northelocationofthemachineaccessisrequestedfrom.Examplesforthelatterarepolicies\npermitting certain requests only when issued from the system console, giving access only\nfrommachinesinthelocalnetwork,orpoliciesthatconsiderthecountryattributedtotheIP\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page431 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\naddressarequestcomesfrom.ManyconceptsfromUCONhavebeenadoptedintheXACML\n3.0standard[1162].\nUsagecontrolmayalsoincludeprovisionsforwhathappensafteranobjectisaccessed,e.g.,\nthat a document can be read but its content cannot be copied or adjustment of attributes\nafteranaccesshasbeenperformed,e.g.,decrementingthecounteroffreearticlesavisitor\nmay access. In another interpretation, \u2018traditional\u2019 access control deals with the elementary\naccessoperationsfoundataninfrastructurelevelwhileusagecontroladdressesentirework\nflows at the application level. In telecom services, usage control may put limits on traffic\nvolume.\n13.3.2 Enforcing Access Control\nToenforceasecuritypolicy,thispolicyfirsthastobeset.Foragivenrequest,adecisionhas\nto be made about whether the request complies with the policy, which may need additional\ninformation from other sources. Finally, the decision has to be conveyed to the component\nthatmanagestheresourcerequested.IntheterminologyofXACML,thisinvolves\n\u2022 PolicyAdministrationPointswherepoliciesareset,\n\u2022 PolicyDecisionPointswheredecisionsaremade,\n\u2022 Policy Information Points that can be queried for further inputs to the decision algo-\nrithm,\n\u2022 PolicyEnforcementPointsthatexecutethedecision.\n13.3.2.1 DelegationandRevocation\nDelegation and granting of access rights both refer to situations where a principal, or a sub-\nject, gets an access right from someone else. The research literature does not have firm\ndefinitions for those terms, and the trade literature even less so. Granting tends to be used\ninagenericsense;grantedaccessrightsoftenrefertothecurrentaccessrightsofasubject\nthatdeliversarequesttoareferencemonitor.Delegationissometimes,butnotalways,used\nmore narrowly for granting short-lived access rights during the execution of a process. For\nexample, XACML distinguishes between policy administration and dynamic delegation that\n\u201cpermits some users to create policies of limited duration to delegate certain capabilities to\nothers\u201d[1163].\nAsecondpossibledistinctionletsdelegationreferonlytothegrantingofaccessrightsheld\nbythe delegator, while granting access also includessituations where amanaging principal\nassignsaccessrightstoothersbutisnotpermittedtoexercisethoserightsitself.\nRights may not always be granted in perpetuity. The grantor may set an expiry date on the\ndelegation, a right may be valid only for the current session, or there may be a revocation\nmechanismsuchastheOnlineCertificateStatusProtocol(OCSP)forX.509certificates(see\nSection13.4.1).OCSPissupportedbyallmajorbrowsers.Revocationlistsaresuitablewhen\nonlinechecksarenotfeasibleandwhenitisknowninadvancewhereagrantedrightmaybe\nconsumed.\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page432 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n13.3.2.2 ReferenceMonitor\nauthorisation\n(cid:63)\nauthentication\nACL\n(cid:63)(cid:63) (cid:63)\n............................. ... ... .... ... ... ... ... .... ... .... .... ..... .... ... .... ...... .. ....... ...... .. ... .... .. .... ..... .. ... ..\n.\n...\n.\n........ .... .... .. ..... .. .. .. .. ... ................. (cid:45) requ(cid:63) est (cid:45)re mfe or ne in toc re (cid:45) object\nprincipal\nFigure13.1:AccessControl=Authentication+Authorisation.\nIn its original definition, the reference monitor was the abstract machine mediating all ac-\ncesses by subjects to objects. The security kernel was a trustworthy implementation of the\nreference monitor. The Trusted Computing Base (TCB) was the totality of protection mecha-\nnismswithinacomputersystemresponsibleforenforcingasecuritypolicy(definitionsfollow\n[1164]). There has been some interpretation creep since. The reference monitor component\nincurrentoperatingsystems,e.g.,theSecurityReferenceMonitorinWindows,wouldactually\nbe the security kernel from above, and TCB is today sometimes used in a limited sense to\nstandonlyforthesecuritykernel.Areferencemonitorperformstwotasks.\n\u2022 Itauthenticatesanyevidencesuppliedbythesubjectwithanaccessrequest.Tradition-\nally,theuseridentitythesubjectwasspeakingforwasauthenticated.\n\u2022 It evaluates the request with respect to the given policy. The early literature on access\ncontrolreferstothistaskasauthorisation(oftherequest),seee.g.,[1142].\nHowever, authorisation also stands for the process of setting a security policy; principals\nare authorised to access certain resources. This overloads the term authorisation, applying\nit both to principals and to requests, but with different meanings. A convention that refers\nto \u201cauthorised principals\u201d and \u201capproved requests\u201d would resolve this issue. Figure 13.1 rep-\nresents the view of access control adopted in operating systems research around 1990. In\nSection13.5.3.4,authorisationwillstandforthegrantingofaccessrightstoprincipals.\nThedecisionalgorithm executed bythe referencemonitorhas to identify the applicablepoli-\ncies and rules, and try to collect the evidence those rules refer to from Policy Information\nPoints. For situations where more than one rule is applicable for a given request, rule com-\nbiningalgorithmsspecifythefinaldecision.\n13.3.2.3 TypesofReferenceMonitors\nSchneiderdescribesthreetypesofreferencemonitors[1145]:\n\u2022 Reference monitors that only see the system calls to protected resources, but not the\nentire program executed. This type of reference monitor, called execution monitor in\n[1145],isimplementedinmanyoperatingsystems.\n\u2022 Reference monitors that can see the entire program and analyse its future behaviour\nbeforemakinganaccesscontroldecision.\n\u2022 Instructions guarding all security relevant operations are in-lined into the program; in\nallotherrespectsthein-linedprogramshouldbehaveasbefore.Thistypeofreference\nmonitor, called in-line reference monitor in [1145], is mostly used to deal with software\nsecurityissues,seee.g.[1165].\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page433 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n13.3.3 Theory\n13.3.3.1 SecurityModels\nSecuritymodelsarehigh-levelspecificationsofsystemsintendedtoenforcecertainsecurity\npolicies. Such models can be used in a formal security analysis to show that a lower-level\nspecificationfaithfullyimplementsthemodel.\nThe Bell-LaPadula (BLP) model [23] is a state machine model for discretionary and manda-\ntoryaccesscontrolpoliciesthatadaptedexistingrulesgoverningaccesstoclassifieddatato\nITsystems.Themandatoryaccesscontrolpoliciesstatethatasubjectcanonlyreadobjects\nat its own or at a lower level (no read up). To prevent unauthorised declassification of data,\nasubjectmayonlywritetoobjectsatitsownoratahigherlevel(\u2217-property,nowritedown).\nTheSeaViewmodelextendstheBLPpoliciestomulti-levelsecurerelationaldatabases[1166].\nPolyinstantiation of database entries, i.e., keeping separate entries at the different security\nlevels, is used to prevent integrity checks from causing information leaks. BLP was highly\ninfluentialincomputersecurityintothe1990s.\nTheBibamodelcapturesintegritypoliciesbasedonintegritylevels[24].Theaccessrulesare\nthe dual of the BLP model, no read down and no write up, but have no predecessors in the\nworld of paper documents. The low watermark policies in Biba introduce dynamic policies\n(mutable in the terminology of UCON, Section 13.3.1.8) that adapt the integrity level of an\nobjectdependingontheintegritylevelofthesubjectperformingtheaccessoperation.\nThe Clark-Wilson model [25] places well-formed transactions as an intermediate layer be-\ntween principals and objects; constrained data items can only be accessed via those trans-\nactions;users(principals)are\u2018labelled\u2019withthetransactionstheyareauthorisedtoexecute.\nThis model captures the way data are processed in enterprise systems. The Chinese Wall\nmodel [1167] formalises dynamic conflict of interest policies that apply in financial consul-\ntancybusinesseswhenworkingforclientsthatarecommercialcompetitors.Hence,theact\nofaccessingdataforoneclientdynamicallyremovespermissionstoaccessdatafromother\nclientsintherelevantconflict-of-interestclass.\nThe Harrison, Ruzo, and Ullman model (HRU) [1168] provides a context for examining a core\nquestion in policy management: is it possible to decide whether an access right may leak\ntoasubjectthroughsomesequenceofcommands?Thisproblemisundecidableingeneral,\nbutmaybedecidableundercertainrestrictions.\n13.3.3.2 EnforceablePolicies\nSchneider has examined the relationship between different kinds of security policies and\ndifferent kinds of reference monitors [1145]. Security policies are defined as predicates over\nexecutiontraces,takingabroaderviewthanSection13.3.1.2whererulesappliedtoindividual\naccessoperations.Policiesthatonlyconsiderthegivenexecutiontracearecalledproperties.\nInformation flow policies that require an execution trace to be indistinguishable from some\nbenignexecutiontracearethusnotproperties.Itisshownthatonlysafetypropertiescanbe\nenforcedbyexecutionmonitors(seeSection13.3.2.3).\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page434 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n13.3.3.3 AccessControlLogics\nAccess control and delegation logics [1169] specify calculi for reasoning about composite\nprincipals in distributed systems. The calculus for access control in distributed systems\n[1170] was developed as a formal specification for parts of the Digital Distributed Systems\nSecurityArchitecture.Insuchanarchitecture,cryptographicallysecuredsessionscanbees-\ntablished between parties. For example, when a session is established with a principal on\nsome other machine, the session key can be treated as a subject for access control that\nspeaksforthatprincipal.\n13.4 ACCESS CONTROL IN DISTRIBUTED SYSTEMS\n[1171,1172,1173,1174]\nAccess control in distributed systems deals with technology issues and with organisational\nissues.Anydistributedsystemneedsmechanismsforsecurelytransmittingaccessrequests,\nattributes, policies, and decisions between nodes. These mechanisms are largely based on\ncryptography.Therequirementformechanismsthatidentifyandretrieveallpoliciesrelevant\nforagivenrequestmaybecomemorepronouncedthanincentralisedsettings.\nInfederatedsystemswhereseveralorganisationscollaborate,securitypoliciescanbesetby\ndifferentparties.Thisdemandssomecommonunderstandingofthenamesofprincipals,at-\ntributes,andattributevaluessothatpoliciesissuedbyonepartycanbeusedindecisionsby\nsomeotherparty.Arrivingatsuchacommonunderstandingaddstothepracticalchallenges\nforRBAClistedinSection13.3.1.3.\nWefirstintroducecoreconceptsforthisdomain.Wewillthencoverorigin-basedaccesscon-\ntrol, examining cross-site scripting from the viewpoint of access control. Federated Access\nControlandtheuseofcryptographyinaccesscontrolareexploredfurther.\n13.4.1 Core Concepts\nTheliteratureonaccesscontrolindistributedsystemsusesthefollowingrelatedterms,but\nthedistinctionbetweenthosetermsisfluid.\n\u2022 A certificate is a digitally signed data structure, created by an issuer, binding a sub-\nject (not to be confused with the term subject as introduced earlier) to some further\nattributes.Theemphasisisonprotectionbyadigitalsignature.\n\u2022 Acredentialissomethingpresentedtogainaccess.Examplesforcredentialsarepass-\nwords or fingerprints. In distributed systems, a credential can be a data structure con-\ntainingattributesofthesubject.Theemphasisisonevidencesubmittedtothedecision\nalgorithm.\n\u2022 A token records (\u2018encapsulates\u2019) the result of some authorisation decision. For exam-\nple,inoperatingsystemstheaccesstokencontainsthesecuritycredentialsforalogin\nsession. The emphasis is on conveying the result of an access decision to some en-\nforcement point. So-called bearer tokens are not tied to a specific subject and can be\nusedbyanyoneinpossessionofthetoken.\nX.509 certificates [1175] can be used for implementing user-centric access control. Identity\ncertificates bind user identities to public verification keys. Attribute certificates bind user\nidentitiestoaccessrights.AttributecertificatescorrespondcloselytoACLentries.\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page435 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n13.4.2 Origin-based Policies\nIn web applications, clients and servers communicate via the HTTP protocol. The client\nbrowser sends HTTP requests; the server returns result pages. The browser represents the\npage internally in the document object in the Document Object Model (DOM). Security poli-\nciesspecifywhichresourcesascriptinawebpageisallowedtoaccess,orwhichserversan\nXMLHttpRequest may refer to. Web applications are thus the principals in access control.\nBy convention, principal names are the domain names of the server hosting an application;\nthepolicydecisionpoint(cf.Section13.3.2)attheclientsideislocatedinthebrowser.\nTheprototypepolicyforwebapplicationsistheSame-Origin-Policy(SOP),statingthatascript\nmay only connect back to the origin it came from or that an HTTP cookie is only included\nin requests to the domain that had placed the cookie. Two pages have the same origin if\nthey share protocol, host name and port number. Certain actions may be exempt from the\nsameoriginpolicy.Forexample,awebpagemaycontainlinkstoimagesfromotherdomains,\nreflecting a view that images are innocuous data without malign side effects. There exist\nvariationsoftheSOP,e.g.,policiesforcookiesthatalsoconsiderthedirectorypath.Thereis\nalso the option to set the HttpOnly flag in a Set-Cookie HTTP response header so that\nthecookiecannotbeaccessedbyclientsidescripts.\nSender Policy Framework (SPF) [1176] implements origin-based access control in the email\nsystem as a measure against spoofing the sending domain of an email. Domain owners\npublish SPF policies in their DNS zone. An SMTP server can then use the domain part of\ntheMAILFROMidentitytolookupthepolicyandconsultthispolicytocheckwhethertheIP\naddressoftheSMTPclientisauthorisedtosendmailfromthatdomain.\n13.4.2.1 Cross-siteScripting\nCross-site scripting attacks on web applications can be treated as cases of failed authenti-\ncation in access control. The browser lets all scripts that arrive in a web page speak for the\noriginofthatpage.Abrowserwouldthenrunascriptinjectedbytheattackerinthecontext\nof an origin other than the attacker\u2019s. Content Security Policy (CSP) refines SOP-based ac-\ncess control. The web server conveys a policy to the browser that characterises the scripts\nauthorisedtospeakforthatserver[1173].Typically,thisisdonebyspecifyingadirectorypath\nonthewebserverwhereauthorisedscripts(andotherwebelements)willbeplaced.\nTheuseofCSPinpracticehasbeenexaminedin[1177],observingthattheunsafe-inline\ndirective disabling CSP for all pages from a given domain was widely used. This is a famil-\niar policy management issue. A new security mechanism is deployed but quickly disabled\nbecause it interferes too much with established practices. Moreover, CSP had an inherent\nvulnerability related to callbacks. Callbacks are names of scripts passed as arguments to\nother (authorised) scripts, but arguments are not covered by CSP. In strict CSP policies, the\nserver declares a nonce in the CSP policy it sends to the client as the script source. The\nserveralsoincludesthisnonceasanattributeinallscriptsfetchedbytheclient.Theclient\u2019s\nbrowser only accepts scripts that contain this nonce as an attribute. Nonces must only be\nusedonceandmustbeunpredictable.\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page436 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n13.4.2.2 Cross-originResourceSharing\nWhen mashups of web applications became popular, this exposed another limitation of\nthe same origin policy: there was no built-in mechanism for specifying exceptions to the\nSOP. Mashup designers initially had to find ways of circumventing the SOP enforced by the\nbrowsers. The Cross-Origin Resource Sharing (CORS) protocol was then introduced to sup-\nport policies for sharing resources cross-origin [1178]. When a script requests a connection\ntoatargetotherthanitsownorigin,thebrowserasksthetargettoauthorisetheconnection\nrequest. The decision at the target considers evidence supplied by the browser, such as the\noriginofthescriptorusercredentialsassociatedwiththerequest.\nCORS specifies a set of HTTP headers to facilitate this exchange. Preflight Requests in-\nclude an Access-Control-Request-Method header that informs the target about the\naccess intended. The response lists methods and headers the target grants to the given\norigin. CORS requests are by default sent without user credentials. The target can set the\nAccess-Control-Allow-Credentials: true header to indicate that user credentials\nmay be provided with requests to access a resource. The target must also specify an origin\nin the Access-Control-Allow-Origin header. Otherwise, the browser will not pass on\nthetarget\u2019sresponsetothescriptthathadmadetherequest.\n13.4.3 Federated Access Control\nWhen organisations join to form a federated security domain, the import of identities, cre-\ndentials, policy rules, and decisions from different contexts (name spaces) becomes an im-\nportantsecurityissue.AfederationmayhaveseveralPolicyAdministrationPointswherepoli-\nciesaredefined,PolicyDecisionPointswheredecisionsonaccessrequestsaremade,Policy\nEnforcement Points where the decisions are enforced, and Policy Information Points where\nadditionalevidencerequiredforevaluatinganaccessrequestcanbeobtained.\nTrustmanagementasoriginallyconceivedinPolicyMaker[1171]referstoaccesscontrolsys-\ntemsforsuchscenarios.Federatedidentitymanagementdealswiththemanagementofdig-\nital identities in a federation, and in particular with single sign-on in a federation. In Web\nServices, related standards for authentication (SAML, Section 13.5.3.3) and access control\n(XACML) have been defined. OAuth 2.0 and OpenID Connect (Section 13.5.3.4) provide user\nauthenticationandauthorisationviaaccesstokens.\nBinderisaninstanceofafederatedaccesscontrolsystem[1172].TheBinderpolicylanguage\nisbasedonDatalog.Policiesarelogicalclauses.Bindercontextsareidentifiedbypublickeys\nand export statements by signing them with the corresponding private key. The decision\nalgorithmismonotonic;presentingmoreevidencecannotreducetheaccessrightsgranted.\n13.4.4 Cryptography and Access Control\nAccess control mechanisms in an operating system implement a logical defence. Access\nrequests passed via the reference monitor will be policed. This includes requests for direct\nmemoryaccess.However,dataarestoredintheclearandapartywithphysicalaccesstothe\nstoragemediumcanretrievethedataandthusbypasslogicalaccesscontrol.Whensolutions\nfortheprotectionofunclassifiedbutsensitivedatawereevaluatedintheU.S.inthe1970s,it\nwas decided that encrypting the data was the best way forward. Access control would then\nbeappliedtothekeysneededtounlockthedata.\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page437 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n13.4.4.1 Attribute-BasedEncryption\nCloud computing has raised the interest in access control on encrypted data over the past\ndecade. Storing data in encrypted form protects their confidentiality but creates a key man-\nagementchallenge.Attribute-BasedEncryption(ABE)addressesthischallengebyconstruct-\ningencryptionschemesthatenforceattribute-baseddecryptionpolicies.Policiesarelogical\npredicatesoverattributes,representedasaccessstructures.TheKeyGeneratorisaTrusted\nThird Party that generates private keys and has to check a user\u2019s policy \/ attributes before\nissuingaprivatekey.TheKeyGeneratoristhusinapositiontorecreateprivatekeys.\nKey-Policy Attribute-Based Encryption (KP-ABE) works with policies that define a user\u2019s ac-\ncessrights[1174].Fromthecorrespondingaccessstructure,theKeyGeneratorcreatesapri-\nvatedecryptionkey.Documentsareencryptedunderasetofattributes.InCiphertext-Policy\nAttribute-BasedEncryption(CP-ABE)[1179],thepolicyreferstothedocumentandtheaccess\nstructureisusedforencryption.Theuser\u2019sprivatekeycreatedbytheKeyGeneratordepends\non the user\u2019s attribute set. In both variants, decryption is possible if and only if the given at-\ntributesetsatisfiesthegivenaccessstructure.\nA study of the feasibility of ABE in realistic dynamic settings had concluded that the over-\nheads incurred by those schemes were still prohibitive [1180]. Efficient encryption and de-\ncryptiondonotnecessarilyimplyanefficientaccesscontrolsystem.\n13.4.4.2 Key-centricAccessControl\nIn distributed systems, access requests may be digitally signed. Access rights could then\nbe granted directly to the public verification key without the need to bind the public key to\nsomeotherprincipal.SPKI\/SDSIusesauthorisationcertificatesforimplementingkeycentric\naccess control, where (names of) public keys are bound to access rights [1181]. The right to\nfurtherdelegateanaccessrightiscontrolledbyadelegationflag.\nCryptographic keys are rarely suitable principals for access control, however. They would\nneed to have an obvious meaning in the application domain that provides the context for a\ngivensecuritypolicy.Inmostcases,cryptographickeyswouldbesubjectsspeakingforsome\nprincipal. Constrained delegation refines the basic delegation mechanism of SPKI\/SDSI so\nthatseparationofdutiespoliciescanbeenforced[1182].\n13.5 AUTHENTICATION\n[1183,1184,1185,1186,1187,1188]\nAuthenticationinanarrowsenseverifiestheidentityofauserloggingin\u2013locallyorremotely\n\u2013andbindsthecorrespondinguseridentitytoasubject.Userauthenticationbasedonpass-\nwords is a common method. Some applications have adopted biometric authentication as\nan alternative. Authentication in distributed systems often entails key establishment. Some\nsecuritytaxonomiesthusreduceauthenticationtoa\u2018heartbeat\u2019propertytoseparateauthen-\ntication from key establishment. The design of authentication protocols is a mature area in\nsecurity research with good tool support for formal analysis. Standard protocols such as\nKerberos,SAML,orOAutharedeployedwidelytoday.\nWewillgiveabriefoverviewofidentitymanagementbeforemovingtopassword-basedand\nbiometric user authentication. We then cover authentication protocols from the Needham-\nSchroeder protocol via Kerberos and SAML to OAuth 2.0, observing that OAuth 2.0 is more\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page438 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nof an authorisation protocol than an authentication protocol. We conclude with an overview\nof formalisations of authentication properties that serve as the basis for a formal analysis\nofauthenticationprotocols.\n13.5.1 Identity Management\nFollowing NIST, \u201cidentity management systems are responsible for the creation, use, and ter-\nminationofelectronicidentities\u201d.Thisincludesoperationalaspectswhencreatinganddelet-\ningelectronicidentities.Oncreation,onequestionishowstronglyelectronicidentitiesmust\nbe linked to persons. In some sensitive areas, strong links have to be established and doc-\numented. For example, money laundering rules may demand a thorough verification of an\naccountholder\u2019s identity.Inother areas, electronicidentitiesneed notto betiedtoaperson.\nPrivacybydesignimpliesthatsuchapplicationsshoulduseelectronicidentitiesthatcannot\nbelinkedtopersons.Identitymanagementmayalsolinkaccessrightstoanelectroniciden-\ntity,eitherdirectlyorviasomelayerofindirectionsuchasarole.Electronicidentitiesshould\nbe terminated when they are no longer required, e.g. when a person leaves an organisation.\nCarehastobetakenthatthisisdoneonallsystemswherethisidentityhadbeenregistered.\nElectronicidentitiesexistatdifferentlayers.Thereareidentitiesforinternalsystempurposes,\nsuch as user identities in an operating system. These identities must be locally unique and\ncouldbecreatedbysystemadministrators(Linux).Thiscanleadtoproblemswhenaniden-\ntity is taken out of use and re-assigned later. The new user may get unintended access to\nresources the predecessor had access to. When organisations merge, collisions between\nidentities may arise that identity management then must address. Alternatively, identities\ncould be long random strings (Windows). The probability for one of the problems just men-\ntionedtoariseisthennegligible,butwhenauseraccountisre-created,anewrandomidentity\nisassignedsoaccessrightshavetobereassignedfromscratch.\nElectronic identities such as user names and email addresses could be random strings, but\nitisoftenpreferabletoassignunderstandableidentities.Thereis,forexample,meritincom-\nmunicating with meaningful email addresses. Email addresses can be taken out of use and\nre-assignedlater,butausermaythenreceiveemailsintendedforitspreviousowner.\nWeb applications often use email addresses as electronic identities. This is convenient for\ncontacting the user, and it is convenient for users as they do not have to remember a new\nidentity. There are alternatives, such as FIDO UAF (Section 13.5.2.3), where electronic iden-\ntities are randomly created public keys and a back channel for resetting passwords is not\nrequiredasnopasswordsareused.\nIdentitymanagementcanalsobeviewedfromaperson\u2019sperspective.Apersonusingdiffer-\nent identities with different organisations may want to manage how identities are revealed\ntootherparties.\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page439 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n13.5.2 User Authentication\nAccessrequestsareissuedbysubjects.Subjectscanbeassociatedwithsecurityattributes\nwhen they are created or during their lifetime. Authentication can then be viewed as the ser-\nvice that validates the security attributes of a subject when it is created. When subjects are\ncreated due to some user action, and when their security attributes depend on the corre-\nspondinguseridentity,userauthenticationhastogiveareasonabledegreeofassurancethat\nthe user identity linked to the subject belongs to the user who had triggered the creation of\nthesubject.Thedegreeofassurance(strengthofauthentication)shouldbecommensurate\nwith the severity of the risk one wants to mitigate. The term risk-based authentication thus\nstatestheobvious.\nUser authentication can also support accountability, as further elaborated in Section 13.6.\nAuthenticationceremonyreferstothestepsauserhastogothroughtobeauthenticated.\nThereareaccess control systemswherethe securityattributes ofa subjectpersist through-\noutthelifetimeofthatsubject.Manyoperatingsystemsadoptthisapproach.Policychanges\ndonotaffectactiveprocesses,butthelifetimeofsubjectsislimited,whichlimitstheperiod\nwhen the new policy is not applied consistently. Alternatively, the attributes of a subject are\nchecked each time it issues a request. For example, a user already logged in to a banking\napplicationisauthenticatedagainwhenrequestingafundstransfer.Whenthefocusmoves\nfrom the subject to individual requests, authentication can be viewed as the service that\nchecksthevalidityofthesecurityattributessubmittedwiththerequesttothedecisionalgo-\nrithm.\n13.5.2.1 Passwords\nWhen passwords are employed for user authentication, protective measures at the system\nsideincludethestoringofhashed(Unix,Linux)orencrypted(Windows)passwords,thesalt-\ningofpasswords,andshadowpasswordfilesthatmovesensitivedataoutofworld-readable\npassword files. Protective measures at the user side include guidance on the proper choice\nandhandlingofpasswords,andsecurityawarenessprogramsthattrytoinstilbehaviourthat\nassuresthelinkbetweenapersonandaprincipal.Recommendationsinthisareaarechang-\ning.TheDigitalIdentityGuidelinespublishedbyNISTbuildonassessmentsoftheobserved\neffectiveness of previous password rules and reflect the fact that users today have to man-\nagepasswordsformultipleaccounts[1188].Thenewrecommendationsadvise\n\u2022 against automatic password expiry; passwords should only be changed when there is\nareason;\n\u2022 againstrulesforcomplexpasswords;passwordlengthmattersmorethancomplexity;\n\u2022 againstpasswordhintsorknowledge-basedauthentication;inaneraofsocialnetworks\ntoomuchinformationaboutapersoncanbefoundinpublicsources;\n\u2022 toenable\u201cshowpasswordwhiletyping\u201dandtoallowpaste-inpasswordfields.\nPassword-basedprotocolsforremoteauthenticationareRADIUS,DIAMETER(bothcovered\nin the Network Security Knowledge Area (Chapter 17)), HTTP Digest Authentication, and to\nsomeextentKerberos(Section13.5.3.2).PasswordguidanceisfurtherdiscussedintheHu-\nmanFactorsKnowledgeArea(Chapter4).\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page440 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n13.5.2.2 BiometricsforAuthentication\nNumerouswell-rehearsedargumentsexplainwhypasswordsworkpoorlyinpractice.Biomet-\nricsareanalternativethatavoidsthecognitiveloadattachedtopassword-basedauthentica-\ntion.Fingerprintandfacerecognitionarethetwomainmethodsdeployedforbiometricuser\nauthentication,knownasverificationinthatdomain.\nBiometricfeaturesmustbesufficientlyuniquetodistinguishbetweenusers,butfingerprints\nor faces cannot be considered as secrets. Fingerprints are left in many places, for example.\nBiometric features are thus better treated as public information when conducting a security\nanalysisandtheprocessofcapturingthefeaturesduringauthenticationhastoofferanade-\nquateleveloflivenessdetection,beitthroughsupervisionofthatprocessorthroughdevice\nfeatures.Employingbiometricsforuserauthenticationmakesthefollowingassumptions:\n\u2022 The biometric features uniquely identify a person; face, fingerprints, and iris patterns\nmayserveasexamples.\n\u2022 Thefeaturesarestable;theeffectsofagingonfingerprintrecognitionaresurveyed,e.g.,\nin[1189].\n\u2022 Thefeaturescanbeconvenientlycapturedinoperationalsettings.\n\u2022 Thefeaturescannotbespoofedduringuserauthentication.\nUser authentication, known as verification in biometrics, starts from a template captured by\nadevice.Fromthetemplate,afeaturevectorisextracted.Forexample,thetemplatemaybe\ntheimageofafingerprint,thefeaturesarethepositionsofso-calledminutiae(ridgeendings,\nbifurcations, whorls, etc.). Users initially register a reference feature vector. During authenti-\ncation, a new template is captured, features are extracted and compared with the reference\nvalues.Auserisauthenticatedifthenumberofmatchingfeaturesexceedsagiventhreshold.\nThisprocessmayfailforvariousreasons:\n\u2022 Failure to capture: this may happen at registration when it is not possible to extract a\nsufficientnumberoffeatures,orduringauthentication.\n\u2022 False rejects: the genuine user is rejected because the number of matches between\nreferencefeaturesandextractedfeaturesisinsufficient.\n\u2022 Falseaccepts:awronguserisacceptedasthematchingthresholdisexceeded.\n\u2022 Spoofing:todeceivethedevicecapturingthetemplate,someobjectcarryingtheuser\u2019s\nfeatures is presented. Liveness detection tries to ensure that templates are captured\nfromtheverypersonthatisbeingauthenticated[1190].\nBiometric authentication based on face recognition or fingerprints is used increasingly at\nautomated border control gates [1191]. It has also become a feature on mobile devices, see\ne.g.[1192].Asurveyofthecurrentstate-of-the-artapproachestobiometricauthenticationis\ngivenin[1193].\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page441 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n13.5.2.3 AuthenticationTokens\nAuthenticationbypasswordrelieson\u201csomethingyouknow\u201d.Biometricauthenticationbuilds\non\u201cwhoyouare\u201d.Inafurtheralternative,usersareissuedwithadevice(a.k.a.tokenorsecu-\nritykey,nottobeconfusedwithacryptographickey)thatcomputesaOTPsynchronisedwith\nthe authenticator, or a response to a challenge set by the authenticator. Possession of the\ndevice is then necessary for successful authentication, which is thus based on \u201csomething\nyouhave\u201d.\nA token could be a small hand-held device with an LED display for showing an OTP that\nthe user enters in a log-in form; RSA SecureID and YubiKey are examples for this type of\ntoken. A token could come with a numeric keypad in addition to the LED display and with a\n\u2018sign\u2019button.Theholdercouldthenreceiveachallenge,e.g.,an8-digitnumber,enteritatthe\nkeypad, press \u2018sign\u2019 to ask the token to compute and display the response, and then enter\nthe response in a log-in form. Some e-banking services use this type of token for account\nholder authentication. With PhotoTAN devices, the challenge is sent as a QR code to the\nuser\u2019scomputerandscannedfromthescreenbythePhotoTANdevice.Whenauthentication\nis based on a secret shared between token and server, different tokens must be used for\ndifferentservers.\nThe FIDO authenticator is a token that can create public key \/ private key pairs; public keys\nserve as identifiers, private keys are used for generating digital signatures [1161]. In FIDO\nUAF, users register a public key with a server. The same token can be used for different\nservers,butwithdifferentkeys.Userauthenticationisbasedonachallenge-responsepattern\n(Section 13.5.4.1), where the user\u2019s authenticator digitally signs the response to the server\u2019s\nchallenge.Theresponseisverifiedusingthepublickeyregisteredwiththeserver.\nIn some applications, possession of the token is sufficient for user authentication. In other\napplications, authentication is a two-stage process. First, the token authenticates the user,\ne.g.,basedonaPINorafingerprint.Inasecondstage,theserverauthenticatesthetoken.It\nwill depend on the threat model whether \u2018weak\u2019 authentication in the first stage and \u2018strong\u2019\nauthenticationinthesecondstagecanprovideadequatesecurity.\nAppsonsmartphonescanprovidethesamefunctionalityasauthenticationtokens,butsmart-\nphones are not dedicated security devices. User authentication may then be compromised\nviaattacksonthesmartphone.Thismaybecomeeveneasierwhensmartphonescomewith\nasecondaryauthenticationmechanismforusewhenadeviceispartiallylocked,withaless\nonerous but also less secure authentication ceremony. This creates a conflict between the\ninterestsofsmartphonemanufacturerswhovalueease-of-useofacommunicationsdevice,\nandtheinterestsoftheprovidersofsensitiveapplicationssearchingforasecuritytoken.\n13.5.2.4 BehaviouralAuthentication\nBehavioural authentication analyses \u201cwhat you do\u201d, lending itself naturally to continuous au-\nthentication.Keystrokedynamics[1194,1195]canbecapturedwithoutdedicatedequipment.\nCharacteristic features of hand writing are writing speed and pen pressure [1196]. Here,spe-\ncialpensorwritingpadsneedtobedeployed.Voicerecognitionneedsamicrophone.Smart-\nphones come with various sensors such as touch screens and microphones that are being\nutilisedforbehaviouralauthenticationtoday.Therequirementsonbehaviouralauthentication\narethesameasthoselistedinSection13.5.2.2:\n\u2022 Thebehaviouralfeaturesuniquelyidentifyaperson.\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page442 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n\u2022 Thefeaturesarestableandunaffectedbytemporaryimpairments.\n\u2022 Thefeaturescanbeconvenientlycapturedinoperationalsettings.\n\u2022 Thefeaturescannotbespoofedduringuserauthentication.\nAdvocates of continuous authentication promise minimum friction, maximum security. Be-\nhavioural authentication does not inconvenience the user with authentication ceremonies,\nbutvariationsinuserbehaviourmaycausefalserejects.Forexample,howwillaseverecold\naffect voice recognition? There needs to be a smooth fall-back when behavioural authenti-\ncation fails. Security depends on the strength of liveness detection. For example, will voice\nrecognition detect synthesised speech or a very proficient human voice imitator? Without\na precise threat model, behavioural authentication can only offer uncertain security guaran-\ntees.Thereisagrowingresearchliteratureondifferentmodesofbehaviouralauthentication.\nCriteriaforassessingtheactualcontributionsofthisresearchincludesamplesizeandcom-\nposition,whetherlongitudinalstudieshavebeenperformed,theexistenceofanexplicitthreat\nmodelandresistancetotargetedimpersonationattempts.\n13.5.2.5 Two-factorAuthentication2FA\nMulti-factor authentication combines several user authentication methods for increased se-\ncurity.TheEuropeanPaymentServicesDirective2(PSD2,Directive(EU)2015\/2366),written\nfor the regulation of financial service providers, prescribes 2FA for online payments (with a\nfewexceptions).PSD2thusisacasestudyonrollingoutlargescale2FAsolutions.\nThetwofactorscouldbeapasswordandanauthenticationtokenforcomputingTransaction\nAuthenticationNumbers(TANs)uniquelytiedtothecontentofatransaction.Thetokencould\nbeaseparatedevice;ifthedeviceistiedtoonepaymentserviceonly,customerswouldhave\ntocarrymultipledeviceswiththem.Fordevicesthatcanbeusedwithseveralservices,some\nlevelofpriorstandardisationisrequired.TheFIDOalliancehasbeenpromotingitsstandards\nforPSD2complianttwo-factorauthentication.\nThe token could be a smartphone registered with the service; customers could then install\napps for several services on the same device. This approach has been favoured by many\nbanks. However, when passwords (or PINs) and TANs are handled by the same device, the\ntwomechanismsarenolongerindependent,reducingthesecuritygainsclaimedfor2FA.\nIncontrasttotheEuropeanTrustServicesandElectronicidentificationregulation(eIDDirec-\ntive-Regulation(EU)No910\/2014)thatspecifiesrequirementsonsecuresignaturecreation\ndevices, PSD2 does not impose security requirements on the devices used for user authen-\nticationbutwants\u201ctoallowfortheuseofallcommontypesofdevices(suchascomputers,\ntablets and mobile phones) for carrying out different payment services\u201d. PSD2 and the eID\nDirective thus strike different balances between ease-of-use and security, a trade-off notori-\nouslydifficulttogetright.\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page443 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n13.5.3 Authentication in Distributed Systems\nWhenmethodsforuserauthenticationindistributedsystemswerefirstdesigned,anauthen-\nticated session took the place of a process speaking for the user. Authenticated sessions\nwere constructed on the basis of cryptographic keys. In the terminology of Section 13.3.1,\nthosesessionkeysbecamethesubjectsofaccesscontrol,andkeyestablishmentbecamea\ncorefeatureoftheuserauthenticationprocess.\n13.5.3.1 Needham-SchroederProtocol\nThe Needham-Schroeder protocol is a key establishment protocol that employsan authenti-\ncationserverasanintermediarybetweenaclientandaserver[1183].Clientandservershare\nsecret keys with the authentication server respectively. Nonces, values that are used only\nonce, are used as a defence against replay attacks. The client does not have to share indi-\nvidual long term secrets with all servers it wants to access, it needs just one shared secret\nwith the authentication server. The authentication server issues a session key to client and\nserver,andhastobetrustedtoproperlyauthenticatetheclientandtheserver.\n13.5.3.2 Kerberos\nThe Kerberos protocol [1184] adapted the Needham-Schroeder protocol for user authentica-\ntion at the MIT campus. Most major operating systems have since adopted (variations of)\nKerberosforuserauthentication.\nUsersshareapasswordwithaKerberosAuthenticationServer(KAS)theyareregisteredwith.\nFromthispassword,theclientandtheKASderiveasymmetricencryptionkey.Initsresponse\nto a client request 1 the KAS sends an encrypted session key to the client, together with a\nticket containing that session key encrypted under a key shared between the KAS and the\nserver 2 . If the correct password is entered at the client, the session key can be decrypted.\nTheticketisforwardedtotheserver 3 .Clientandservernowsharethesessionkey,andthe\nservercanreturnanauthenticatorconstructedwiththesessionkey 4 .\nA Ticket Granting Server (TGS) may provide a further layer of indirection between client and\nserver.TheKASwouldissueasessionkeyfortheTGSandaTicketGrantingTicket(TGT)to\ntheclient.WiththesessionkeyandtheTGT,theclientthenrequestsaticketfortheresource\nserver. The TGS checks the TGT and can apply an access control policy to decide whether\nto issue a ticket for use with the server. If the request is approved, the TGS issues another\nsessionkeyandaticketencryptedunderasecretkeysharedbetweenTGSandserver.\n............................. ... ... .... ... ... ... ... .... ... .... .... ..... .... ... . ... ...... .\n.\n....... ... ... .. ... .....\n.\n.... .. ... ... .. ...\n. ...\n........ ..\n.\n..... ... .... ... ... ... . ..................\nuser\n1.UID,SID,nonce (cid:63) 4.authenticator\n(cid:27)\n(cid:45) client\n2.eKUID(Kses),ticket 3.ticket\n(cid:63) (cid:63)\nKAS server\nFigure13.2:MessageflowintheKerberosprotocol.\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page444 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n13.5.3.3 SAML\nThe Security Assertion Markup Language (SAML) v2.0 defines meta-protocols for authenti-\ncation in web services [1185]. Meta-protocols specify high-level message flows that can be\nboundtovariousunderlyingprotocolssuchasKerberos.ApplicationsthatuseSAMLforau-\nthentication then need not be aware of the underlying protocol used. Many cloud service\nproviders,e.g.,AWS,Azure,IBM,areusingSAMLforuserauthenticationviaabrowser.\nSecuritytokenscontainingassertionsareusedtopassinformationaboutaprincipal(usually\nanenduser)betweenaSAMLauthority(a.k.a.IdentityProvider(IdP)orassertingparty),and\na SAML consumer (a.k.a. Service Provider (SP) or relying party). Assertions can be passed\nviatheclienttotherelyingparty(browserPOSTprofile,Figure13.3)orbepulledbytherelying\npartyfromtheassertingpartyviaahandle(artefact)passedviatheclient(browserartefact\nprofile,Figure13.4).ThespecificationofSAMLmessagesandassertionsisbasedonXML.\nAn authentication assertion has to include the name of the identity provider and the user\nidentity, but this is insufficient. This was shown to be the case by an attack against the im-\nplementation of Service Provider-initiated single sign-on with Redirect\/POST Bindings used\nat that time in Google Applications [1197]. In this implementation, authentication assertions\nincluded just the two aforementioned fields. A malicious Service Provider could ask a user\nfor authentication at a specific Identity Provider (step 0 in Figure 13.3) and then re-use the\nassertion to impersonate the user with another Service Provider that relied on the chosen\nIdentity Provider and where the user was known by the same user identity, e.g., an email\naddress.\nThe specification of SAML Redirect\/POST Bindings includes the Service Provider\u2019s ID and a\nrequest ID issued by the Service Provider in the authentication assertion. Hence, a Service\nProvider would only accept an assertion issued in reaction to a pending authentication re-\nquest.\n............................. ... ... .... ... ... ... ... .... ... .... .... ..... .... ... . ... ...... .\n.\n....... ... ... .. . .. .....\n.\n.... .. ... ... .. ...\n. ...\n........ ..\n.\n..... ... .... ... ... ... . ..................\nuser\n1.UID,SID,logincredential (cid:63)\n(cid:45) client\n3.assertion\n2.assertion\n(cid:54)\n(cid:63) 0.requesttoauthenticate (cid:63)\nIdP (cid:45) SP\n-1.connectionrequest\nFigure13.3:MessageflowintheSAMLPOSTprofile.\n............................. ... ... .... ... ... ... ... .... ... .... .... ..... .... ... . ... ...... .\n.\n....... ... ... .. . .. .....\n.\n.... .. ... ... .. ...\n. ...\n........ ..\n.\n..... ... .... ... ... ... . ..................\nuser\n1.UID,SID,logincredential (cid:63)\n(cid:45) client\n2.artefact 3.artefact\n(cid:63) 4.artefact (cid:63)\n(cid:27)\nIdP (cid:45) RP\n5.assertion\nFigure13.4:MessageflowintheSAMLartefactprofile.\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page445 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nSAML was introduced as a meta-protocol to isolate web services from underlying authenti-\ncation protocols and from different underlying communication protocols. It was conceived\nasafederatedsinglesign-onprotocolwheretherelyingpartydecideshowtouseassertions\nwhenmakingdecisionsaccordingtoitsownsecuritypolicy.\nInthe practicaldeploymentof SAML,parsingXMLdocuments \u2013thepricetobepaidfor em-\nployingameta-protocol\u2013cancreatenon-trivialoverheadsandcanintroducesecurityvulner-\nabilities. Furthermore, the advent of smartphones has made it easier to access the internet\nfrom mobile user devices, removing one of the reasons for introducing a meta-protocol be-\ntweenwebservicesandtheunderlyingITsystems.\n13.5.3.4 OAuth2\u2013OpenIDConnect\nNewerprotocolssuchasOAuth2.0[1186]andOpenIDConnect[1198]rundirectlyoverHTTP\nandprovideauthenticationandauthorisation.Thepartiesinvolvedincludeauserwhoowns\nresources,theresourceowner,aresourceserverthatstorestheuser\u2019sresources,aso-called\nclient application that wants to be granted access to those resources, and an Authorisation\nServer(AS)thatcanauthenticateusersandclientapplications.\nClients have to be registered with the AS. They will receive a public client ID and a client\nsecretsharedwiththeAS.Thissecretisusedforestablishingsecuresessionsbetweenthe\nclient and the AS. The client also registers redirect_URIs with the AS. The AS will redirect a\nuser agent only to those registered redirect_URIs. Proper definition of the redirect_URIs is\nprimarilyamatterfortheclient,andcanalsobeenforcedbytheAS.Weaksettingsareopen\ntoexploitationbyattackers.\nIn an OAuth protocol run (a high level overview is given in Figure 13.5), the user agent\n(browser) has opened a window for the client application. In the client window, an authori-\nsation request can be triggered 1 ; the request also contains a redirect_URI. The user agent\nthentypicallyconveystheauthorisationrequestandtheuser\u2019sauthorisationtotheAS 2 .A\nsecure session between the user agent and the AS is required, and may already exist if the\nuser has logged in previously at the AS. If authorisation is granted, an authorisation grant is\nreturned to the user agent 3 , which will pass it on to the redirect_URI given by the client 4 .\nThe client then posts the authorisation grant and a redirect URI to the AS 5 . It is assumed\nthat the AS can authenticate this message as coming from the client. If the request is valid,\nthe AS returns an access token to the redirect URI provided, where the token can be used to\nretrievetheresourcefromtheresourceserver 6 .\nAuthorisation requests and authorisation grants are linked via a request ID, called state in\nOAuth. Omitting the request ID or using a fixed value had introduced vulnerabilities in appli-\ncationsusingOAuth,seee.g.[1199,1200].\nu................. s............ ... ... .... ... ... ... ... .... ... .... .... ..... .... ... . ... ... e... .\n.\n....... ... ... .. . .. .....\n.\n.... .. ... ... .. ...\n. ...\n........ ..\n.\n..... .. ..... ... ... ... . ..................\nr\n2.authrequest+approval (cid:63) 1.authorisationrequest\nuser (cid:27)\n(cid:45) agent\n3.authorisationgrant 4.authorisationgrant\n(cid:63) (cid:63)\n5.authorisationgrant\nauthor.(cid:27) client\n(cid:45)\nserver (app)\n6.accesstoken\nFigure13.5:MessageflowinOAuth2.0.\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page446 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nThere is a fundamental switch in focus compared to SSO protocols such as Kerberos and\nSAMLdespiteaconsiderabledegreeofsimilarityinthemessageflows.InanOAuth2.0pro-\ntocolruntheuserisnolongerthepartyrequestingaccesstoaresourceownedbysomeone\nelse, but the party granting access to resources owned by the user. OAuth 2.0 has thus be-\ncome an authorisation protocol. Several assumptions about pre-existing trust relationships\nbetween parties have to be met for OAuth to be secure. Conversely, one cannot take for\ngranted that the OAuth security properties still hold when the protocol is deployed in a new\nsetting.\nOpenID Connect puts user authentication back into the OAuth 2.0 message flow. The client\napplicationnowdoublesasarelyingparty,andtheauthorisationserverbecomesanauthenti-\ncation&authorisationserverthatissuesdigitallysignedidtokens(authenticationassertions\ninSAMLdiction).Anidtokencontainsthenameoftheissuer,thenameoftheauthenticated\nuser (called subject), the intended relying party (called audience), the nonce that had been\nsentwiththeauthenticationrequest,anindicatorofauthenticationstrength,andotherfields.\n13.5.4 Facets of Authentication\nWe have sketched how user authentication in distributed systems first integrated session\nand key establishment with the process of verifying a user\u2019s identity, and later established\nauthorisation practices to access a user\u2019s resources. In communication security, peer entity\nauthentication refers to the process of verifying the identity of the peer in a connection and\ndataoriginauthenticationtotheprocessofverifyingtheoriginofindividualdataitems.\nUser authentication, whether relating to a local system or to a remote system, entails three\naspects:\n\u2022 creatinganewsubject,e.g.anewprocessoranewsessionwithafreshsessionkey,\n\u2022 linkinganinternalentity,e.g.auserID,tothesubject,\n\u2022 linkinganexternalentity,e.g.aperson,toaninternalidentity.\nTo differentiate between these aspects, the term key establishment was introduced in com-\nmunication security towards the end of the 1980s for the first aspect. Entity authentication\nstood for what was left. Quoting ISO\/IEC 9798, \u201centity authentication mechanisms allow the\nverification, of an entity\u2019s claimed identity, by another entity. The authenticity of the entity can\nbe ascertained only for the instance of the authentication exchange\u201d. This property is related\ntodeadpeerdetectionandtotheheartbeatextensioninRFC6250[1201].Notethatthisdefi-\nnitiondoesnotdistinguishbetweeninternalandexternalentities.\n13.5.4.1 PatternsforEntityAuthentication\nEntity authentication according to the definition in ISO\/IEC 9798 can be implemented with\nchallenge response-mechanisms. When prover and verifier share a secret, the verifier sends\nan unpredictable challenge to the prover who constructs its response as a function of the\nchallenge and the shared secret. For example, HTTP digest authentication uses the hash of\nthe challenge, a password, and further data that binds authentication to a particular HTTP\nrequest.\nWhen public key cryptography is used, the verifier needs the prover\u2019s public key. With a digi-\ntal signature scheme, the verifier could send the challenge in the clear and the prover could\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page447 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nrespondwiththesignedchallenge.Withapublickeyencryptionscheme,theverifiercoulden-\ncryptthechallengeundertheprover\u2019spublickey;aresponseconstructedfromthedecrypted\nchallengewouldauthenticatetheprover.ThelattermechanismisusedwithTrustedPlatform\nModules (TPMs) where successful decryption of data encrypted under the public endorse-\nmentkeyofaTPMauthenticatestheTPM.Inbothcases,theverifierneedsanauthenticcopy\nof the prover\u2019s public verification key. When users are identified by arbitrary public keys, no\nPublic Key Infrastructure is required and the public key could be set directly in a registration\nphase.\n13.5.4.2 CorrespondenceProperties\nThe Public-Key Needham-Schroeder protocol uses public key encryption with its challenge-\nresponse mechanism [1183]. In this protocol, a malicious prover could decrypt a challenge\nandreuseitinaprotocolrunwithathirdpartypretendingtobetheoriginalverifier;thethird\nparty would then respond to the verifier although the verifier is not engaged in a protocol\nrun with the third party [1187]. This scenario would amount to an attack if the mismatch in\nthe assumptions about a protocol run is security relevant. The attack would be detected if\ntheidentitiesofproverandverifierareincludedinallmessages.Notethatinthis\u2018attack\u2019the\nverifierstillcorrectlyconcludesthattheproverisalive.\nMatchesintheassumptionsaboutaspectsofaprotocolrunheldbythepeersoncompletion\nof a run can be captured by correspondence properties, as proposed in [1202] and further\nelaboratedin[1203]:\n\u2022 Aliveness:whenevertheverifier(initiator)concludesaprotocolrun,theproverhadalso\nbeenengagedinaprotocolrun.\n\u2022 Weak agreement: whenever the verifier (initiator) concludes a protocol run apparently\nwithagivenprover,theproverhadalsobeenengagedinaprotocolrun,apparentlywith\nthatverifier.\n\u2022 Non-injective agreement: whenever the verifier (initiator) concludes a protocol run ap-\nparently with a given prover, the prover had also been engaged in a protocol run, ap-\nparently with that verifier, and responder and receiver agree on a specified set of data\nitemspertainingtoaprotocolrun.\n\u2022 Agreement: whenever the verifier (initiator) concludes a protocol run apparently with a\ngiven prover, the prover had also been engaged in a protocol run, apparently with that\nverifier,andresponderandreceiveragreeonaspecifiedsetofdataitemspertainingto\na protocol run, and each protocol run of the verifier corresponds to a unique protocol\nrunoftheprover.\nInthevulnerableRedirect\/POSTBindinginGoogleApplicationsthereisnoagreementonthe\nserviceprovideranauthenticationassertionisintendedfor([1197],Section13.5.3.3).Flawed\nimplementationsofOAuththatuseafixedvalueforthestatevariabledonotevenguarantee\naliveness([1199],Section13.5.3.4).\nCorrespondence properties are intensional properties well suited for protocol analysis us-\ning model checking. This line of research had reversed the earlier decision to separate pure\nentity authentication from agreeing on session keys and again added agreement on certain\ndataitemstoauthentication.TAMARIN[1204]andProVerif[1205]areexamplesfortoolsthat\nsupporttheautomatedanalysisofauthenticationprotocols.\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page448 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n13.5.4.3 AuthenticationasVerifiedAssociation\nReturningtoaholisticviewonauthentication,onecouldusethisasageneraltermformecha-\nnismsthatcreateanewsubjectandassociateitwithevidencerelevantforaccessdecisions.\nIf this route is taken, verifying the identity of a user becomes just a special case of authenti-\ncation.\nThere would, furthermore, be merit in distinguishing between association with internal and\nexternal entities. The latter case is an instance of the \u2018difficult and error prone\u2019 problem of\nfaithfullyrepresentingaspectsofthephysicalworldwithinanITsystem.Theveracityofsuch\nrepresentationscannotbeguaranteedbycryptographicmeansalone.\nForexample,accesscontrolindistributedsystemsmaymakeuseofpublickeycryptography\n(Section13.4.4.2).Publickeyscanthenbeinterpretedassubjectsforthepurposeofaccess\ncontrol. The checks performed by a certificate authority before it issues a certificate would\nthenamounttoauthenticationofanexternalentity.\n13.5.4.4 AuthenticationforCreditorforResponsibility\nAuthenticationmayservethepurposeofgivingcredittoanentityforactionsithasperformed,\nor of establishing which entity is responsible for an action [1206]. In the first case, an attack\namountstoearningundeservedcreditsandauthenticationisbrokeniftheattackersucceeds\nin making a victim perform actions under the attacker\u2019s identity. In the second case, an at-\ntackamountstodeflectingresponsibilitytosomeoneelseandauthenticationisbrokenifthe\nattackersucceedsinperformingactionsunderthevictim\u2019sidentity.\n13.6 ACCOUNTABILITY\n[1207,ch.24],[1208,ch.18]\nAccountability has been defined as \u201cthe security goal that generates the requirement for ac-\ntionsofanentitytobetraceduniquelytothatentity.Thissupportsnon-repudiation,deterrence,\nfault isolation, intrusion detection and prevention, and after-action recovery and legal action\u201d\n[1147].\nThis definition invites investigations into psychology to determine what makes an effective\ndeterrent,investigationsintolegalmatterstodeterminethestandardofevidencedemanded\nin a court of law, and technical investigations into the collection, protection, and analysis of\nevidence.ThisKnowledgeAreawillfocusonthosetechnicalaspects.\nWe will cover the technical prerequisites for accountability. We will briefly explore potential\nconflictsbetweenprivacyandaccountability,describecurrentactivitiesindistributedlogging\nofevents,andrefertosomerelatedtermsthatoverlapwithaccountability.\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page449 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n13.6.1 Technical Aspects\nAccountabilitysupportsprocessesthatarelaunchedaftereventshaveoccurred.Suchapro-\ncessmaybearegularauditthatcheckswhetheranorganisationcomplieswithexistingreg-\nulations. It might represent a technical audit that scans logs in search for signs of a cyber\nattack. It may also be an investigation triggered by an incident that tries to identify the vul-\nnerabilities exploited, or an investigation that tries to identify the parties responsible. In all\ncases,thequalityoftheevidenceisdecisive.\nThe aforementioned processes make use of logs of events. Such logs may be kept by the\noperating system, by networking devices, or by applications (Section 13.6.2 will give an ex-\nample).Thenatureoftheeventsdependsontheactivitythatisbeingmonitored.\n13.6.1.1 AuditPolicies\nAccountability is only as strong as the quality of evidence collected during operations. Sys-\ntemadministratorsmaysetauditpoliciesthatdefinewhicheventswillbelogged.Examples\nforsucheventsaresuccessfulandfailedauthenticationattempts,anddecisionsonsensitive\naccess requests. Operating systems and audit tools provide menus to guide administrators\nthrough this task. Access control policies that specify as obligations that certain requests\nmustbeloggedalsoinfluencewhichevidenceiscollected.\n13.6.1.2 PreservingtheEvidence\nAccountabilityisonlyasstrongastheprotectionoftheevidencecollectedduringoperations.\nAttackers could try to hide their traces by deleting incriminating log entries once they have\nacquired sufficient privileges. They could then modify audit policies so that future actions\narenotrecorded,butshouldnotbeabletotamperwiththeevidencealreadycollected.\nTamperresistancecouldrelyonphysicalmeasureslikeprintingthelogonanendlesspaper\nreelorwritingthelogtoWORM(Write-Once,Read-Many)memorylikeanopticaldisk.Tamper\nresistance could be supported by cryptography. Storing the log as a hash chain [1209, 1210]\nmakesitevidentwhenentrieshavebeenremoved,butdoesnotguaranteethatentriescannot\nbelost.\nAudit policies have to address situations where logging is disrupted, e.g., because the log\nfile has run out of space. Is it then acceptable to overwrite old entries or should the system\nbe stopped until proper auditing is again enabled? This conflict between availability and ac-\ncountabilityhastoberesolved.\n13.6.1.3 AnalysingtheEvidence\nAuditlogscancreatelargevolumesofdataandmanyentriesarenotsecurityrelevantsothat\nautomatedprocessingisrequired.Knownattackpatternscanbedetectedbytheirsignatures.\nMachine learning techniques can help to detect anomalies. Lessons learned when applying\nthisapproachtonetworkintrusiondetectionarediscussedin[1211].Visualisationtechniques\ntrytodrawtheadministrators\u2019attentiontothemostrelevantevents.\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page450 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n13.6.1.4 AssessingtheEvidence\nAccountability is only as strong as the method of user authentication when legal or disci-\nplinary actions are to be supported. This relates to technical aspects of the authentication\nmechanism and also to user resilience to phishing and social engineering attacks. Telling\nusers not to fall for obvious phishing attacks is easy, but a well-designed spear phishing at-\ntackwillnotbeobvious.\nAccountabilityisonlyasstrongastheorganisationalsecuritypoliciesonconnectingdevices,\ne.g. USB tokens, to internal systems, and policies on access to external web sites. Account-\nabilityisonlyasstrongasthedefencesagainstsoftwarevulnerabilitiesthatcanbeexploited\ntoruncodeunderauseridentitywithouttheuserbeingawareofthatfact,e.g.so-calleddrive-\nby-downloads.\n13.6.2 Privacy and Accountability\nPrivacyrulescanhaveanimpactontheeventsthatmaybelogged.Employmentlawmay,for\nexample,limithowcloselyacompanymonitorsitsemployees,whichmightmakeitdifficult\ntoachieveaccountabilitywhenruleshavebeenbroken.\nSometimes, there are technical resolutions to such conflicts between legal goals. Take the\nexample of a company that is not permitted to log which external websites employees con-\nnect to: when an external site is attacked from within the company network, it is desirable\nthat the perpetrator can be held accountable. To achieve both goals, the company gateway\nwould log for outgoing requests only the internal IP address and the port number used with\nthe global IP address. There is thus no record of visited websites. If an attack is reported,\nthewebsiteaffectedcanprovidetheportnumbertheattackcamefrom,establishingthelink\nbetweentheinternalIPaddressandthevisitedsite.\nConversely, logging may have unintended privacy impacts. Take Certificate Transparency\n[RFC 6962] as an example. Certificate Transparency is a logging service for the issuers of\nTLScertificates.ParticipatingCertificateAuthoritiesrecordtheissuanceofcertificateswith\nthis service. Domain owners can scan the log for certificates for their domain that they had\nnot asked for, i.e., detect authentication failures at issuers. This service was introduced in\nreaction to attacks where such misissued certificates had been used to impersonate the\ndomainaffected,andmakesissuersaccountabletodomainowners.\nPrivatesubdomainsaresubdomainscreatedforinternaluseonly.Whenacertificateforapri-\nvatesubdomainisrequested,thecertificatewillberecordedintheCertificateTransparency\nlogdisclosingtheexistenceoftheprivatesubdomaintothepublic[1212].\n13.6.3 Distributed Logs\nLogs may be kept to hold the users of a system accountable. Logs may be kept to hold\nthe owner of a system accountable. In the latter case, auditors may require that the logging\ndevice is sealed, i.e., rely on a physical root of trust. Alternatively, logs could be kept in a\ndistributed system run by independent nodes where there are sufficient barriers to forming\nalliancesthatcantakeoverthesystem.\nThe nodes maintaining the log need to synchronise their versions of the log. The overheads\nfor synchronisation, or consensus, depend on the failure model for the nodes and for the\ncommunicationnetwork,andontherulesforjoiningthedistributedsystem.Systemsmaybe\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page451 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nopenforanyone,orbegovernedbyamembershipservice.Therecentinterestinblockchains\nextendstothistypeofloggingsolutions.\n13.6.4 Related Concepts\nThe definition at the start of Section 13.6 refers to non-repudiation and intrusion detection.\nNon-repudiation has a specific meaning in communication security, viz. providing unforge-\nable evidence that a specific action occurred. This goal is not necessarily achieved by log-\nging mechanisms; they may protect the entries recorded, but may record entries that have\nalreadybeenmanipulated.\nIntrusion detection (see the Security Operations & Incident Management Knowledge Area\n(Chapter 8)) is an area of its own with overlapping goals. Intrusion detection does not have\nthe requirement for actions of an entity to be traced uniquely to that entity. The focus will be\nmoreondetectingattacksthandetectingtheattacker.\nThe definition given subsumes both the accountability of legal persons and technical inves-\ntigations into security breaches. The standards of evidence may be higher in the first case.\nTracing actions uniquely to an entity leads to cyber attribution, the process of tracking and\nidentifying the perpetrators of a cyber attack. Circumstantial evidence such as similarity in\nmalware may be used in this process, and mis-attribution due to false flag operations is an\nissue. Calling for DRM to protect the intellectual property of content owners, because digi-\ntal content can be copied so easily, but assuming that malware cannot be copied would be\nincongruous.\nAPPLYING THE KNOWLEDGE\nITsecuritymechanismsshouldnotbedeployedfortheirownsakebutforareason.Therea-\nson has to come from an application in need of protection. An organisational policy would\ncapturetheprotectionrequirementsandthenbeimplementedbyanautomatedpolicy(Sec-\ntion13.3.1.1).Sometimes,thisprocesscanstartfromaclearlydefinedorganisationalpolicy.\nThe policies governing access to classified paper documents are an example. There, the\ntranslation into automated policies did not have to bridge a wide conceptual gap, although\ntherewereunanticipatedtwists,e.g.,thenowrite-uppolicyoftheBLPmodel.Thesespecific\ncircumstancesmayhaveraisedtheunwarrantedexpectationthatthisapproachwouldwork\nin general. The fact that these policies were applied in highly hierarchical organisations and\nwerefairlystablearefurtherpointsworthnoting.\nSinclair et al. paint a picture of a very different world [1213]. Their observations can be sum-\nmarized under the headings of translation (from organisational to automated policies) and\nautomation. Any translation has to start from a source document, in our case an organisa-\ntionalpolicy.Thetranslatorwillfaceproblemswhenthesourceisambiguousorinconsistent.\nThissituationismorelikelytoariseinorganisationswithamatrixedstructure,whereseveral\nentitiesaresettingpolicies,thaninstrictlyhierarchicalorganisations.Moreover,thewiderthe\nlanguagegapbetweenthesourcedocumentandthedestinationdocument,themoredifficult\ntranslation becomes, and the more difficult it is to ascertain that the translation meets the\nspiritofthesource.Thelatterstepisaprerequisiteforpolicycertification,i.e.,management\napprovalofagivenautomatedpolicy.\nOrganisational policies may intentionally leave decisions at the discretion of caseworkers,\ne.g., for handling situations where none of the existing rules is directly applicable or where\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page452 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ncompeting rules apply. It is a purpose of automation to remove discretion. Removing dis-\ncretion adds rules that do not have a counterpart in the organisational policy. Creating an\nautomated policy is then more than translation, it becomes an exercise in creative writing\nin the spirit of the organisational policy. To do this job well, the writer needs a good under-\nstandingoftheapplicationsandtheirworkflows,ontopofproficiencyinthetargetlanguage\n(the domain of IT experts). Automated policies based on na\u00efve assumptions easily become\ndenial-of-serviceattacksontheuser.Asarelatedpoint,thereisatensionbetweenthecom-\npeting goals of keeping a policy simple \u2013 which may be feasible in an organisational policy\nthatleavesroomfordiscretion\u2013andofrequiringthe(automated)policytocaterforavariety\nof different contexts. This explains why in many cases the number of rules created to cater\nfor exceptions to the general rules ends up being overwhelming. Points that span organisa-\ntional and automated policies are the handling of dynamic policy changes and the analysis\noftheside-effectsofpolicyrulesinhighlycomplexsystems.\nThe literature on security operations has to say more about the points raised in this section\nthan the research literature on IT security, which has a habit of abstracting problems to a\npoint where much of the awkward issues encountered in real life have disappeared [1213],\nandthenconfusingitssimplifiedmodelswithreality.\nSimilar disconnects between application experts and infrastructure experts exist within the\nIT domain. Dynamically configurable applications are running foul of well-intended policies\nsuchasSOP(Section13.4.2)andCSP(Section13.4.2.1).Organisationsmaythenoptforopen\npoliciesthatprovidenoprotectionbutallowthedynamicapplicationstorun,orapplications\nwriters may explore workarounds accepted by the automated policy but still defeating its\nspirit.\nCONCLUSIONS\nAccesscontrolhaskeptadaptingtothechangingapplicationsofITsystems.Accesscontrol\nwas originally conceived for the protection of sensitive data in multi-user and multi-level se-\ncure systems. Access control without user identities was literally unthinkable. Applications\nhavesincechangedandsomerequirenewmodesofaccesscontrol.Onecouldthenreserve\n\u2018accesscontrol\u2019fortheoriginalsettingandinventnewtermsforeachnewflavourofaccess\ncontrol.DRMmayserveasanexample.ThisKAhasnottakenthisroutebutapplied\u2018access\ncontrol\u2019, \u2018authentication\u2019, and \u2018authorisation\u2019 more generally while staying true to the generic\nmeanings of these terms. User identities have lost their prominence along this way. Code\n(apps)andwebdomainshavetakentheirplace.\nAuthenticationoriginallystoodfortheservicethatlinksexternalentitieslikehumanusersto\ninternal actions in the IT system; today, it may also denote the service that verifies evidence\nassociated with access requests that are submitted for evaluation by a decision algorithm.\nDesign and analysis of cryptographic authentication protocols for distributed systems is a\nmature knowledge area. Cryptographic solutions for other aspects of access control are of-\ntenmoreofacademicthanofpracticalinterest.\nAccountability services build on tamper resistant records of events. The evidence collected\nmay serve as input for technical investigations that try to establish how an attack was con-\nducted and to identify its effects. The evidence collected may also be used in disciplinary\nprocesses that deal with situations where rules were broken at the level of the persons im-\nplicated. Privacy rules may put limits on the events that are recorded, and the nature of the\neventsrecordedmayreduceprivacyinwaysnotanticipated.\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page453 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nCROSS-REFERENCE OF TOPICS VS REFERENCE MATERIAL\nSection Cites\n13.3Authorisation [1141,1142,1143,1144,1145]\n13.3.1AccessControl [1141,1143,1144],\n13.3.2EnforcingAccessControl [1142]\n13.3.3Theory [1145]\n13.4AccessControlinDistributedSystems [1171,1172,1173,1174]\n13.4.1CoreConcepts\n13.4.2Origin-basedPolicies [1173]\n13.4.3FederatedAccessControl [1171,1172]\n13.4.4CryptographyandAccessControl [1174]\n13.5Authentication [1183,1184,1185,1186,1187,1188]\n13.5.1IdentityManagement [1188]\n13.5.3AuthenticationinDistributedSystems [1183,1184,1185,1186]\n13.5.4FacetsofAuthentication [1187]\n13.6Accountability [1207,ch.24],[1208,ch.18]\n13.6.1TechnicalAspects [1207,ch.24],[1208,ch.18]\n13.6.2PrivacyandAccountability\n13.6.3DistributedLogs\n13.6.4RelatedConcepts\nKAAuthentication,Authorisation&Accountability(AAA) |October2019 Page454 IV Software Platform\nSecurity\n455  Chapter 14\nSoftware Security\nFrank Piessens KU Leuven\n457 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nINTRODUCTION\nThe purpose of this Software Security chapter is to provide a structured overview of known\ncategories of software implementation vulnerabilities, and of techniques that can be used\nto prevent or detect such vulnerabilities, or to mitigate their exploitation. This overview is\nintendedtobeusefultoacademicstaffforcourseandcurriculadesignintheareaofsoftware\nsecurity,aswellastoindustryprofessionalsfortheverificationofskillsandthedesignofjob\ndescriptionsinthisarea.\nLet us start by defining some terms and concepts, and by defining the scope of this chap-\nter. A first key issue is what it means for software to be secure? One possible definition is\nthat a software system is secure if it satisfies a specified or implied security objective. This\nsecurityobjectivespecifiesconfidentiality,integrityandavailabilityrequirements1 forthesys-\ntem\u2019sdataandfunctionality.Consider,forinstance,asocialnetworkingservice.Thesecurity\nobjectiveofsuchasystemcouldincludethefollowingrequirements:\n\u2022 Picturespostedbyausercanonlybeseenbythatuser\u2019sfriends(confidentiality)\n\u2022 Ausercanlikeanygivenpostatmostonce(integrity)\n\u2022 Theserviceisoperationalmorethan99.9%ofthetimeonaverage(availability)\nDifferentsecurityrequirementscanbeatoddswitheachother,forinstance,lockingdowna\nsystemontheappearanceofanattackisgoodforconfidentialityandintegrityofthesystem,\nbutbadforavailability.\nA security failure is a scenario where the software system does not achieve its security ob-\njective, and a vulnerability is the underlying cause of such a failure. The determination of an\nunderlying cause is usually not absolute: there are no objective criteria to determine what\nvulnerability is responsible for a given security failure or where it is located in the code. One\nmight say that the vulnerability is in the part of the code that has to be fixed to avoid this\nspecific security failure, but fixes can be required in multiple places, and often multiple mit-\nigation strategies are possible where each mitigation strategy requires a different fix or set\noffixes.\nThedefinitionsof\u201csecurity\u201dand\u201cvulnerability\u201daboveassumetheexistenceofasecurityob-\njective. In practice however, most software systems do not have precise explicit security\nobjectives, and even if they do, these objectives are not absolute and have to be traded off\nagainst other objectives such as performance or usability of the software system. Hence,\nsoftwaresecurityisoftenaboutavoidingknownclassesofbugsthatenablespecificattack\ntechniques.Therearewell-understoodclassesofsoftwareimplementationbugsthat,when\ntriggered by an attacker, can lead to a substantial disruption in the behaviour of the soft-\nware,andarethuslikelytobreakwhateversecurityobjectivethesoftwaremighthave.These\nbugs are called implementation vulnerabilities even if they are relatively independent from\napplication-ordomain-specificsecurityobjectivesliketheexampleobjectivesabove.\nThisdocument,theSoftwareSecurityKA,coverssuchimplementationvulnerabilities,aswell\nas countermeasures for them. Many other aspects are relevant for the security of software\nbasedsystems,includinghumanfactors,physicalsecurity,securedeploymentandprocedu-\nral aspects, but they are not covered in this chapter. The impact of security on the various\n1Othercommoninformationsecurityrequirementslikenon-repudiationordataauthenticationcanbeseen\nasinstancesorrefinementsofintegrityfromasoftwareperspective.Butfromotherperspectives,forinstance\nfromalegalperspective,thesemanticsoftheserequirementscanbemoreinvolved.\nKASoftwareSecurity |October2019 Page458 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nphases of the software lifecycle is discussed in the Secure Software Lifecycle Knowledge\nArea (Chapter 16). Security issues specific to software running on the web or mobile plat-\nformsarediscussedintheWeb&MobileSecurityKnowledgeArea(Chapter15).\nThe remainder of this chapter is structured as follows. Topic 14.1 (Categories) discusses\nwidely relevant categories of implementation vulnerabilities, but without the ambition of de-\nscribingacompletetaxonomy.Instead,thetopicdiscusseshowcategoriesofvulnerabilities\ncan often be defined as violations of a partial specification of the software system, and it\nis unlikely that a useful complete taxonomy of such partial specifications would exist. The\ndiscussion of countermeasures for implementation vulnerabilities is structured in terms of\nwhereinthelifecycleofthesoftwaresystemtheyareapplicable.Topic14.2(Prevention)dis-\ncusses how programming language and Application Programing Interface (API) design can\nprevent vulnerabilities from being introduced during development in software programmed\ninthatlanguageandusingthatAPI.Inaddition,defensivecodingpracticescancontributeto\nthe prevention of vulnerabilities. Topic 14.3 (Detection) covers techniques to detect vulnera-\nbilitiesinexistingsourcecode,forinstance,duringdevelopmentandtesting.Topic14.4(Mit-\nigation) discusses how the impact of remaining vulnerabilities can be mitigated at runtime.\nItisimportanttonote,however,thatsomecountermeasuretechniquescouldinprinciplebe\nappliedinallthreephases,sothisisnotanorthogonalclassification.Forinstance,aspecific\ndynamic check (say, an array bounds check) could be mandated by the language specifica-\ntion (Prevention, the countermeasure is built in by the language designer), could be used as\na testing oracle (Detection, the countermeasure is used by the software tester) or could be\ninlinedintheprogramtoblockattacksatrun-time(Mitigation,thecountermeasureisapplied\nondeployment).\nCONTENT\n14.1 CATEGORIES OF VULNERABILITIES\n[1214][1215,c4,c5,c6,c7,c10,c11][1216,c6,c9][1030,c17][1217,c5,c9,c11,c13,c17]\nAs discussed in the Introduction, we use the term implementation vulnerability (sometimes\nalso called a security bug) both for bugs that make it possible for an attacker to violate a\nsecurityobjective,aswellasforclassesofbugsthatenablespecificattacktechniques.\nImplementation vulnerabilities play an important role in cybersecurity and come in many\nforms. The Common Vulnerabilities and Exposures (CVE) is a publicly available list of en-\ntries in a standardised form describing vulnerabilities in widely-used software components,\nanditlistsclosetoahundredthousandsuchvulnerabilitiesatthetimeofwriting.Implemen-\ntationvulnerabilitiesareoftencausedbyinsecureprogrammingpracticesandinfluencedby\nthe programming language or APIs used by the developer. This first topic covers important\ncategoriesofimplementationvulnerabilitiesthatcanbeattributedtosuchinsecureprogram-\nmingpractices.\nExisting classifications of vulnerabilities, such as the Common Weakness Enumeration\n(CWE), a community-developed list of vulnerability categories, are useful as a baseline for\nvulnerabilityidentification,mitigationandprevention,butnoneoftheexistingclassifications\nhave succeeded in coming up with a complete taxonomy. Hence, the categories discussed\nin this first topic should be seen as examples of important classes of vulnerabilities, and\nnot as an exhaustive list. They were selected with the intention to cover the most common\nKASoftwareSecurity |October2019 Page459 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nimplementationvulnerabilities,butthisselectionisatleasttosomeextentsubjective.\nSpecificcategoriesofimplementationvulnerabilitiescanoftenbedescribedasviolationsof\na (formal or informal) specification of some sub-component of the software system. Such\naspecificationtakestheformofacontractthatmakesexplicitwhatthesub-componentex-\npects of, and provides to its clients. On violation of such a contract, the software system\nentersanerror-state,andthefurtherbehaviourofthesoftwaresystemistypicallybehaviour\nthat has not been considered by the system developers and is dependent on system imple-\nmentationdetails.Attackersofthesystemcanstudytheimplementationdetailsandexploit\nthemtomakethesystembehaveinawaythatisdesirablefortheattacker.\n14.1.1 Memory Management Vulnerabilities\nImperative programming languages support mutable state, i.e., these languages have con-\nstructs for allocating memory cells that can subsequently be assigned to, or read from by\nthe program, and then deallocated again. The programming language definition specifies\nhow to use these constructs correctly: for instance, allocation of n memory cells will return\na reference to an array of cells that can then be accessed with indices 0 to n \u2212 1 until the\nreference is deallocated (freed) again. This specification can be seen as a contract for the\nmemory management sub-component. Some programming languages implement this con-\ntractdefensively,andwillthrowanexceptionifaclientprogramaccessesmemoryincorrectly.\nOtherprogramminglanguages(mostnotably,CandC++)leavetheresponsibilityforcorrectly\nallocating,accessinganddeallocatingmemoryinthehandsoftheprogrammer,andsaythat\nthe behaviour of programs that access or manage memory incorrectly is undefined. Such\nlanguages are sometimes called memory unsafe languages, and bugs related to memory\nmanagement (memory management vulnerabilities) are a notorious source of security bugs\nintheselanguages.\n\u2022 A spatial vulnerability is a bug where the program is indexing into a valid contiguous\nrange of memory cells, but the index is out-of-bounds. The archetypical example is a\nbuffer overflow vulnerability where the program accesses an array (a buffer) with an\nout-of-boundsindex.\n\u2022 A temporal vulnerability is a bug where the program accesses memory that was once\nallocatedtotheprogram,buthassincebeendeallocated.Atypicalexampleisderefer-\nencingadanglingpointer.\nThe C and C++ language specifications leave the behaviour of a program with a memory\nmanagement vulnerability undefined. As such, the observed behaviour of a program with a\nvulnerabilitywilldependontheactualimplementationofthelanguage.Memorymanagement\nvulnerabilities are particularly dangerous from a security point of view, because in many im-\nplementationsmutablememorycellsallocatedtotheprogramarepartofthesamememory\naddress space where also compiled program code, and runtime metadata such as the call\nstack are stored. In such implementations, a memory access by the program that violates\nthememorymanagementcontractcanresultinanaccesstocompiledprogramcodeorrun-\ntimemetadata,andhencecancausecorruptionofprogramcode,programcontrolflowand\nprogram data. There exists a wide range of powerful attack techniques to exploit memory\nmanagementvulnerabilities[1214].\nAnattackconsistsofprovidinginputtotheprogramtotriggerthevulnerability,whichmakes\ntheprogramviolatethememorymanagementcontract.Theattackerchoosestheinputsuch\nthattheprogramaccessesamemorycellofinteresttotheattacker:\nKASoftwareSecurity |October2019 Page460 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n\u2022 Inacodecorruptionattack,theinvalidmemoryaccessmodifiescompiledprogramcode\ntoattackerspecifiedcode.\n\u2022 In a control-flow hijack attack, the invalid memory access modifies a code pointer (for\ninstance, a return address on the stack, or a function pointer) to make the processor\nexecute attacker-provided code (a direct code injection attack), or to make the proces-\nsor reuse existing code of the program in unexpected ways (a code-reuse attack, also\nknown as an indirect code injection attack, such as a return-to-libc attack, or a return-\noriented-programmingattack).\n\u2022 In a data-only attack, the invalid memory access modifies other data variables of the\nprogram,possiblyresultinginincreasedprivilegesfortheattacker.\n\u2022 In an information leak attack, the invalid memory access is a read access, possibly\nresulting in the exfiltration of information, either application secrets such as crypto-\ngraphic keys, or runtime metadata such as addresses which assist prediction of the\nexactlayoutofmemoryandhencemayenableotherattacks.\nBecauseofthepracticalimportanceoftheseclassesofattacks,mitigationtechniqueshave\nbeendevelopedthatcounterspecificattacktechniques,andwediscusstheseinTopic14.4.\n14.1.2 Structured Output Generation Vulnerabilities\nProgramsoftenhavetodynamicallyconstructstructuredoutputthatwillthenbeconsumed\nby another program. Examples include: the construction of SQL queries to be consumed by\nadatabase,ortheconstructionofHTMLpagestobeconsumedbyawebbrowser.Onecan\nthink of the code that generates the structured output as a sub-component. The intended\nstructureoftheoutput,andhowinputtothesub-componentshouldbeusedwithintheoutput,\ncan be thought of as a contract to which that sub-component should adhere. For instance,\nwhen provided with a name and password as input, the intended output is a SQL query that\nselectstheuserwiththegivennameandpasswordfromtheusersdatabasetable.\nAcommoninsecureprogrammingpracticeistoconstructsuchstructuredoutputbymeans\nofstringmanipulation.Theoutputisconstructedasaconcatenationofstringswheresome\nof these strings are derived (directly or indirectly) from input to the program. This practice\nisdangerous,becauseitleavestheintendedstructureoftheoutputstringimplicit,andmali-\nciouslychosenvaluesforinputstringscancausetheprogramtogenerateunintendedoutput.\nForinstance,aprogrammercanconstructaSQLqueryas:\nquery = \"select * from users where name=\u2019\" + name\n+ \"\u2019\" and pw = \u2019\" + password + \"\u2019\"\nwith the intention of constructing a SQL query that checks for name and password in the\nwhere clause. However, if the name string is provided by an attacker, the attacker can set\nnameto\"John\u2019 --\",andthiswouldremovethepasswordcheckfromthequery(notethat\n--startsacommentinSQL).\nAstructuredoutputgenerationvulnerabilityisabugwheretheprogramconstructssuchunin-\ntended output. This is particularly dangerous in the case where the structured output repre-\nsentscode that is intended to include provided input asdata. Maliciously chosen input data\ncan then influence the generated output code in unintended ways. These vulnerabilities are\nalsoknownasinjectionvulnerabilities(e.g.,SQLinjection,orscriptinjection).Thename\u2018injec-\ntion\u2019 refers to the fact that exploitation of these vulnerabilities will often provide data inputs\nKASoftwareSecurity |October2019 Page461 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nthat cause the structured output to contain additional code statements, i.e. exploitation in-\njects unintended new statements in the output. Structured output generation vulnerabilities\narerelevantformanydifferentkindsofstructuredoutputs:\n\u2022 A SQL injection vulnerability is a structured output generation vulnerability where the\nstructured output consists of SQL code. These vulnerabilities are particularly relevant\nforserver-sidewebapplicationsoftware,whereitiscommonfortheapplicationtointer-\nactwithaback-enddatabasebyconstructingqueriespartiallybasedoninputprovided\nthroughwebforms.\n\u2022 Acommandinjectionvulnerabilityisastructuredoutputgenerationvulnerabilitywhere\nthe structured output is a shell command sent by the application to the operating sys-\ntemshell.\n\u2022 A script injection vulnerability, sometimes also called a Cross-Site Scripting (XSS) vul-\nnerability is a structured output generation vulnerability where the structured output is\nJavaScriptcodesenttoawebbrowserforclient-sideexecution.\nThislistisbynomeansexhaustive.Otherexamplesinclude:XPathinjection,HTMLinjections,\nCSSinjection,PostScriptinjectionandmanymore.\nSeveral factors can contribute to the difficulty of avoiding structured output generation vul-\nnerabilities:\n\u2022 The structured output can be in a language that supports sublanguages with a signifi-\ncantly different syntactic structure. An important example of such a problematic case\nisHTML,thatsupportssublanguagessuchasJavaScript,CSSandSVG.\n\u2022 Thecomputationofthestructuredoutputcanhappenindifferentphaseswithoutputs\nofonephasebeingstoredandlaterretrievedasinputforalaterphase.Structuredout-\nput generation vulnerabilities that go through multiple phases are sometimes referred\ntoasstoredinjectionvulnerabilities,ormoregenerallyashigher-orderinjectionvulnera-\nbilities.ExamplesincludestoredXSSandhigher-orderSQLinjection.\nAttack techniques for exploiting structured output generation vulnerabilities generally de-\npendonthenatureofthestructuredoutputlanguage,butawiderangeofattacktechniques\nforexploitingSQLinjectionorscriptinjectionareknownanddocumented.\nTheWeb&MobileSecurityKnowledgeArea(Chapter15)providesamoredetaileddiscussion\nofsuchattacktechniques.\n14.1.3 Race Condition Vulnerabilities\nWhen a program accesses resources (such as memory, files or databases) that it shares\nwith other concurrent actors (other threads in the same process, or other processes), the\nprogramoftenmakesassumptionsaboutwhattheseconcurrentactorswilldo(ornotdo)to\nthesesharedresources.\nSuch assumptions can again be thought of as part of a specification of the program. This\nspecification is no longer a contract between two sub-components of the program (a caller\nand a callee), but it is a contract between the actor executing the program and its environ-\nment(allconcurrentactors),wherethecontractspecifiestheassumptionsmadeonhowthe\nenvironment will interact with the program\u2019s resources. For instance, the specification can\nsaythattheprogramreliesonexclusiveaccesstoasetofresourcesforaspecificintervalof\nKASoftwareSecurity |October2019 Page462 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nits execution: only the actor executing the program will have access to the set of resources\nforthespecifiedinterval.\nViolations of such a specification are concurrency bugs, also commonly referred to as race\nconditions, because a consequence of these bugs is that the behaviour of the program may\ndependonwhichconcurrentactoraccessesaresourcefirst(\u2018winsarace\u2019).Concurrency,and\nthe corresponding issues of getting programs correct in the presence of concurrency, is an\nimportantsub-areaofcomputersciencewithimportancewellbeyondtheareaofcybersecu-\nrity[1218].\nBut concurrency bugs can be security bugs, too. Concurrency bugs often introduce non-\ndeterminism: the behaviour of a program will depend on the exact timing or interleaving of\ntheactionsofallconcurrentactors.Inadversarialsettings,whereanattackercontrolssome\noftheconcurrentactors,theattackermayhavesufficientcontrolonthetimingofactionsto\ninfluencethebehaviouroftheprogramsuchthatasecurityobjectiveisviolated.Aracecon-\ndition vulnerability is a concurrency bug with such security consequences. A very common\ninstanceisthecasewheretheprogramchecksaconditiononaresource,andthenrelieson\nthat condition when using the resource. If an attacker can interleave his\/her own actions to\ninvalidatetheconditionbetweenthecheckandthetimeofuse,thisiscalledaTimeOfCheck\nTimeOfUse(TOCTOU)vulnerability.\nRace condition vulnerabilities are relevant for many different types of software. Two impor-\ntantareaswheretheyoccurare:\n\u2022 Race conditions on the file system: privileged programs (i.e., programs that run with\nmore privileges than their callers, for instance, operating system services) often need\ntochecksomeconditiononafile,beforeperforminganactiononthatfileonbehalfof\nalessprivilegeduser.Failingtoperformcheckandactionatomically(suchthatnocon-\ncurrentactorcanintervene)isaraceconditionvulnerability:anattackercaninvalidate\ntheconditionbetweenthecheckandtheaction.\n\u2022 Races on the session state in web applications: web servers are often multi-threaded\nforperformancepurposes,andconsecutiveHTTPrequestsmaybehandledbydifferent\nthreads. Hence, two HTTP requests belonging to the same HTTP session may access\nthesessionstateconcurrently.Failingtoaccountforthisisaraceconditionvulnerability\nthatmayleadtocorruptionofthesessionstate.\n14.1.4 API Vulnerabilities\nAn Application Programming Interface, or API, is the interface through which one software\ncomponent communicates with another component, such as a software library, operating\nsystem, web service, and so forth. Almost all software is programmed against one or more\npre-existingAPIs.AnAPIcomeswithan(explicitorimplicit)specification\/contractofhowit\nshould be used and what services it offers, and just like the contracts we considered in pre-\nvious subsections, violations of these contracts can often have significant consequences\nfor security. If the client of the API violates the contract, the software system again enters\nanerror-state,andthefurtherbehaviourofthesoftwaresystemwilldependonimplementa-\ntion details of the API, and this may allow an attacker to break the security objective of the\noverall software system. This is essentially a generalisation of the idea of implementation\nvulnerabilitiesascontractviolationsfromsubsections14.1.1,14.1.2and14.1.3toarbitraryAPI\ncontracts.\nKASoftwareSecurity |October2019 Page463 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nOfcourse,someAPIsaremoresecuritysensitivethanothers.AbroadclassofAPIsthatare\nsecuritysensitiveareAPIstolibrariesthatimplementsecurityfunctionalitylikecryptography\nor access control logic. Generally speaking, a software system must use all the \u2018security\ncomponents\u2019 that it relies on in a functionally correct way, or it is likely to violate a security\nobjective.Thisisparticularlychallengingforcryptographiclibraries:ifacryptographiclibrary\noffersaflexibleAPI,thencorrectuseofthatAPI(inthesensethatagivensecurityobjectiveis\nachieved)isknowntobehard.Thereissubstantialempiricalevidence[1219]thatdevelopers\nfrequentlymakemistakesintheuseofcryptographicAPIs,thusintroducingvulnerabilities.\nAn orthogonal concern to secure use is the secure implementation of the cryptographic API.\nSecure implementations of cryptography are covered in the Cryptography Knowledge Area\n(Chapter10).\n14.1.5 Side-channel Vulnerabilities\nThe execution of a program is ultimately a physical process, typically involving digital elec-\ntroniccircuitrythatconsumespower,emitselectro-magneticradiation,andtakestimetoex-\necute to completion. It is common, however, in computer science to model the execution of\nprogramsabstractly,intermsoftheexecutionofcodeonanabstractmachinewhoseseman-\ntics is defined mathematically (with varying levels of rigour). In fact, it is common to model\nexecutionofprogramsatmanydifferentlevelsofabstraction,including,forinstance,execu-\ntion of assembly code on a specified Instruction Set Architecture (ISA), execution of Java\nbytecode on the Java Virtual Machine, or execution of Java source code according to the\nJava language specification. Each subsequent layer of abstraction is implemented in terms\nofalowerlayer,butabstractsfromsomeoftheeffectsorbehavioursofthatlowerlayer.For\ninstance, an ISA makes abstraction from some physical effects such as electro-magnetic\nradiation or power consumption, and the Java Virtual Machine abstracts from the details of\nmemorymanagement.\nA side-channel is an information channel that communicates information about the execu-\ntion of a software program by means of such effects from which the program\u2019s code ab-\nstracts.Someside-channelsrequirephysicalaccesstothehardwareexecutingthesoftware\nprogram. Other side-channels, sometimes called software-based side-channels can be used\nfromsoftwarerunningonthesamehardwareasthesoftwareprogramunderattack.\nCloselyrelatedtoside-channelsarecovertchannels.Acovertchannelisaninformationchan-\nnelwheretheattackeralsocontrolstheprogramthatisleakinginformationthroughtheside-\nchannel,i.e.,theattackerusesaside-channeltopurposefullyexfiltrateinformation.\nSide-channels play an important role in the field of cryptography, where the abstraction gap\nbetween(1)themathematical(orsourcecodelevel)descriptionofacryptographicalgorithm\nand(2)thephysicalimplementationofthatalgorithm,hasbeenshowntoberelevantforse-\ncurity [1220]. It was demonstrated that, unless an implementation carefully guards against\nthis, side-channels based on power consumption or execution time can easily leak the cryp-\ntographickeyusedduringtheexecutionofanencryptionalgorithm.Thisbreaksthesecurity\nobjectives of encryption for an attacker model where the attacker can physically monitor\nthe encryption process. Side-channel attacks against cryptographic implementations (and\ncorrespondingcountermeasures)arediscussedintheCryptographyKnowledgeArea(Chap-\nter10).\nButside-channelsarebroadlyrelevanttosoftwaresecurityingeneral.Side-channelscanbe\nstudiedforanyscenariowheresoftwareisimplementedintermsofalower-layerabstraction,\nKASoftwareSecurity |October2019 Page464 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\neven if that lower-layer abstraction is itself not yet a physical implementation. An important\nexample is the implementation of a processor\u2019s Instruction Set Architecture (ISA) in terms\nof a micro-architecture. The execution of assembly code written in the ISA will have effects\nonthemicro-architecturalstate;forinstance,aneffectcouldbethatsomevaluesarecopied\nfrommainmemorytoacache.TheISAmakesabstractionoftheseeffects,butunderattacker\nmodels where the attacker can observe or influence these micro-architectural effects, they\nconstituteaside-channel.\nSide-channels, and in particular software-based side-channels, are most commonly a con-\nfidentiality threat: they leak information about the software\u2019s execution to an attacker mon-\nitoring effects at the lower abstraction layer. But side-channels can also constitute an in-\ntegrity threat in case the attacker can modify the software\u2019s execution state by relying on\nlower layer effects. Such attacks are more commonly referred to as fault injection attacks.\nPhysical fault-injection attacks can use voltage or clock glitching, extreme temperatures, or\nelectromagnetic radiation to induce faults. Software-based fault-injection uses software to\ndrive hardware components of the system outside their specification range with the objec-\ntive of inducing faults in these components. A famous example is the Rowhammer attack\nthat uses maliciously crafted memory access patterns to trigger an unintended interaction\nbetweenhigh-densityDRAMmemorycellsthatcausesmemorybitstoflip.\n14.1.6 Discussion\n14.1.6.1 Betterconnectionwithoverallsecurityobjectivesneedsmorecomplexspecifica-\ntions\nWe have categorised implementation vulnerabilities as violations of specific partial specifi-\ncations of software components. However, the connection to the security objective of the\noverallsoftwaresystemisweak.Itisperfectlypossiblethatasoftwaresystemhasanimple-\nmentationvulnerability,butthatitisnotexploitabletobreakasecurityobjectiveofthesystem,\nfor instance, because there are redundant countermeasures elsewhere in the system. Even\nmore so, if a software system does not have any of the implementation vulnerabilities we\ndiscussed,itmaystillfailitssecurityobjective.\nTo have stronger assurance that the software system satisfies a security objective, one\ncan formalise the security objective as a specification. During the design phase, on decom-\nposition of the system in sub-components, one should specify the behaviour of the sub-\ncomponentssuchthattheyjointlyimplythespecificationoftheoverallsystem.Withsucha\ndesign,theconnectionbetweenanimplementationvulnerabilityasaviolationofaspecifica-\ntion on the one hand, and the overall security objective of the system on the other, is much\nstronger.\nIt is important to note, however, that specifications would become more complex and more\ndomain-specificinsuchascenario.Wediscussoneillustrationofadditionalcomplexity.For\nthe vulnerability categories we discussed (memory management, structured output genera-\ntion,raceconditionsandAPIvulnerabilities),thecorrespondingspecificationsexpressprop-\nerties of single executions of the software: a given execution either satisfies or violates the\nspecification, and the software has a vulnerability as soon as there exists an execution that\nviolatesthespecification.\nThere are, however, software security objectives that cannot be expressed as properties of\nindividualexecutiontraces.Awidelystudiedexampleofsuchasecurityobjectiveisinforma-\ntionflowsecurity.Abaselinespecificationofthissecurityobjectivefordeterministicsequen-\nKASoftwareSecurity |October2019 Page465 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntial programs goes as follows: label the inputs and outputs of a program as either public or\nconfidential,andthenrequirethatnotwoexecutionsofthesoftwarewiththesamepublicin-\nputs(butdifferentconfidentialinputs)havedifferentpublicoutputs.Theintuitionforlooking\nat pairs of executions is the following: it might be that the program does not leak confiden-\ntialdatadirectlybutinsteadleakssomepartialinformationaboutthisdata.Ifcollectedalong\nmultiple runs, the attacker can gather so much information that eventually relevant parts of\ntheconfidentialoriginaldataare,infact,leaked.Theabovespecificationeffectivelyrequires\nthatconfidentialinputscanneverinfluencepublicoutputsinanyway,andhencecannotleak\nevenpartialinformation.Inadualway,onecanexpressintegrityobjectivesbyrequiringthat\nlow-integrityinputscannotinfluencehigh-integrityoutputs.\nButaninformationflowspecificationismorecomplexthanthespecificationsweconsidered\ninprevioussectionsbecauseoneneedstwoexecutionstoshowaviolationofthespecifica-\ntion. Information leak vulnerabilities are violations of a (confidentiality-oriented) information\nflow policy. They can also be understood as violations of a specification, but this is now\na specification that talks about multiple executions of the software system. This has pro-\nfound consequences for the development of countermeasures to address these vulnerabili-\nties[1145].\n14.1.6.2 Sidechannelvulnerabilitiesaredifferent\nSide channel vulnerabilities are by definition not violations of a specification at the abstrac-\ntion level of the software source code: they intrinsically use effects from which the source\ncodeabstracts.However,ifonedevelopsamodeloftheexecutioninfrastructureofthesoft-\nwarethatisdetailedenoughtomodelsidechannelattacks,thensidechannelvulnerabilities\ncan again be understood as violations of a partial specification. One can choose to locate\nthevulnerabilityintheexecutioninfrastructurebyprovidingaspecificationfortheexecution\ninfrastructurethatsaysthatitshouldnotintroduceadditionalcommunicationmechanisms.\nThis is essentially what the theory of full abstraction [1221] requires. Alternatively, one can\nrefine the model of the source code language to expose the effects used in particular side\nchannelattacks,thusmakingitpossibletoexpressside-channelvulnerabilitiesatthesource\ncode level. Dealing with general software side-channel vulnerabilities is not yet well under-\nstood,andnogenerallyapplicablerealisticcountermeasuresareknown.Onecan,ofcourse,\nisolatetheexecution,i.e.,preventconcurrentexecutionsonthesamehardware,butthatthen\ncontradictsothergoalssuchasoptimisedhardwareutilisation.\n14.1.6.3 Vulnerabilitiesasfaults\nThe classification of vulnerabilities by means of the specification they violate is useful for\nunderstandingrelevantclassesofvulnerabilities,butisnotintendedasacompletetaxonomy:\nthere are a very large number of partial specifications of software systems that contribute\ntoachievingsomesecurityobjective.Vulnerabilitiescan,however,beseenasaninstanceof\ntheconceptoffaults,studiedinthefieldofdependablecomputing,andagoodtaxonomyof\nfaultshasbeendevelopedinthatfield[1089].\nKASoftwareSecurity |October2019 Page466 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n14.2 PREVENTION OF VULNERABILITIES\n[1222,1223,1224][1225,c3]\nOnceacategoryofvulnerabilitiesiswellunderstood,animportantquestionishowtheintro-\nduction of such vulnerabilities in software can be prevented or at least be made less likely.\nThe most effective approaches eradicate categories of vulnerabilities by design of the pro-\ngramminglanguageorAPI.\nThe general idea is the following. We have seen in Topic 14.1 that many categories of im-\nplementation vulnerabilities can be described as violations of a specification of some sub-\ncomponent. Let us call an execution of the software system that violates this specification,\nanerroneousexecution,oranexecutionwithanerror.Fromasecuritypointofview,itisuseful\ntodistinguishbetweenerrorsthatcausetheimmediateterminationoftheexecution(trapped\nerrors),anderrorsthatmaygounnoticedforawhile(untrappederrors)[1223].Untrappeder-\nrors are particularly dangerous, because the further behaviour of the software system after\nan untrapped error can be arbitrary, and an attacker might be able to steer the software sys-\ntem to behaviour that violates a security objective. Hence, designing a language or API to\navoid errors, and in particular untrapped errors, is a powerful approach to prevent the pres-\nence of vulnerabilities. For instance, languages like Java effectively make it impossible to\nintroducememorymanagementvulnerabilities:acombinationofstaticanddynamicchecks\nensures that no untrapped memory management errors can occur. This effectively protects\nagainst the attack techniques discussed in 14.1.1. It is, however, important to note that this\ndoesnotpreventthepresenceofmemory-managementbugs:aprogramcanstillaccessan\narray out of bounds. But the bug is no longer a vulnerability, as execution is terminated im-\nmediatelywhensuchanaccessoccurs.Onecouldarguethatthebugisstillavulnerabilityif\noneofthesecurityobjectivesofthesoftwaresystemisavailability,includingtheabsenceof\nunexpectedprogramtermination.\nIn cases where choice or redesign of the programming language or API itself is not an op-\ntion, specific categories of vulnerabilities can be made less likely by imposing safe coding\npractices.\nThistopicprovidesanoverviewofthesetechniquesthatcanpreventtheintroductionofvul-\nnerabilities.\n14.2.1 Language Design and Type Systems\nA programming language can prevent categories of implementation vulnerabilities that can\nbedescribedasviolationsofaspecificationby:\n1. makingitpossibletoexpressthespecificationwithinthelanguage,and\n2. ensuringthattherecanbenountrappedexecutionerrorswithrespecttotheexpressed\nspecification.\nKASoftwareSecurity |October2019 Page467 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n14.2.1.1 Memorymanagementvulnerabilities\nAprogramminglanguagespecificationinherentlyincludesaspecificationofallthememory\nallocation, access and deallocation features provided by that language. Hence, the specifi-\ncationofthememorymanagementsub-componentisalwaysavailable.Aprogramminglan-\nguageiscalledmemory-safeifthelanguagedefinitionimpliesthattherecanbenountrapped\nmemorymanagementerrors.LanguageslikeCorC++arenotmemory-safebecausethelan-\nguage definition allows for implementations of the language that can have untrapped mem-\norymanagementerrors,butevenforsuchlanguagesonecanbuildspecificimplementations\nthatarememory-safe(usuallyatthecostofperformance).\nAlanguagecanbemadememory-safethroughacombinationof:\n1. thecarefulselectionofthefeaturesitsupports:forinstance,languagescanchooseto\navoidmutablestate,orcanchoosetoavoiddynamicmemoryallocation,orcanchoose\ntoavoidmanualdeallocationbyrelyingongarbagecollection,\n2. imposing dynamic checks: for instance, imposing that every array access must be\nbounds-checked,and\n3. imposingstaticchecks,typicallyintheformofastatictypesystem:forinstance,object-\nfieldaccesscanbeguaranteedsafebymeansofatypesystem.\nProgramming languages vary widely in how they combine features, dynamic and static\nchecks. Pure functional languages like Haskell avoid mutable memory and rely heavily on\nstaticchecksandgarbagecollection.DynamiclanguageslikePythonrelyheavilyondynamic\nchecks and garbage collection. Statically typed object-oriented languages like Java and C#\nsit between these two extremes. Innovative languages like SPARK (a subset of Ada) [1226]\nand Rust achieve memory safety without relying on garbage collection. Rust, for instance,\nusesatypesystemthatallowsthecompilertoreasonaboutpointersstatically,thusenabling\nittoinsertcodetofreememoryatplaceswhereitisknowntonolongerbeaccessible.This\ncomes at the expense of some decreased flexibility when it comes to structuring program\ncode.\n14.2.1.2 Structuredoutputgenerationvulnerabilities\nAn important cause for structured output generation vulnerabilities is that the programmer\nleaves the intended structure of the output implicit, and computes the structured output by\nstringmanipulation.Aprogramminglanguagecanhelppreventsuchvulnerabilitiesbyprovid-\ninglanguagefeaturesthatallowtheprogrammertomaketheintendedstructureexplicit,thus\nproviding a specification. The language implementation can then ensure that no untrapped\nerrorswithrespecttothatspecificationarepossible.\nAfirstapproachistoprovideatypesystemthatsupportsthedescriptionofstructureddata.\nThisapproachhasbeenworkedoutrigorouslyforXMLdata:theprogramminglanguagesup-\nports XML documents as first class values, and regular expression types [1227] support the\ndescriptionofthestructureofXMLdocumentsusingthestandardregularexpressionopera-\ntors.Atype-correctprogramthatoutputsanXMLdocumentofagiventypeisguaranteedto\ngenerateXMLoutputofthestructuredescribedbythetype.\nA second approach is to provide primitive language features for some of the common use\ncasesofstructuredoutputgeneration.LanguageIntegratedQuery(LINQ)isanextensionof\ntheC#languagewithsyntaxforwritingqueryexpressions.Bywritingthequeryasanexpres-\nsion(asopposedtobuildingaSQLquerybyconcatenatingstrings),theintendedstructureof\nKASoftwareSecurity |October2019 Page468 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nthequeryisexplicit,andtheLINQproviderthatcompilesthequerytoSQLcanprovidestrong\nguaranteesthatthegeneratedqueryhastheintendedstructure.\n14.2.1.3 Raceconditionvulnerabilities\nRaceconditionvulnerabilitiesonheapallocatedmemoryareoftenenabledbyaliasing,theex-\nistenceofmultiplepointerstothesamememorycell.Iftwoconcurrentthreadsbothholdan\naliastothesamecell,thereisthepotentialofaraceconditiononthatcell.Theexistenceof\naliasing also leads to temporal memory-management vulnerabilities, when memory is deal-\nlocatedthroughonealiasbutthenaccessedthroughanotheralias.Thenotionofownership\nhelps mitigate the complications that arise because of aliasing. The essence of the idea is\nthat, while multiple aliases to a resource can exist, only one of these aliases is the owner\nof the resource, and some operations can only be performed through the owner. An owner-\nshipregimeputsconstraintsonhowaliasescanbecreated,andwhatoperationsareallowed\nthrough these aliases. By doing so, an ownership regime can prevent race condition vulner-\nabilities, or it can support automatic memory management without a garbage collector. For\ninstance,asimpleownershipregimeforheapallocatedmemorycellsmightimposethecon-\nstraintsthat:(1)aliasescanonlybecreatediftheyareguaranteedtogooutofscopebefore\ntheownerdoes,(2)aliasescanonlybeusedforreading,and(3)theownercanwritetoacell\nonly if no aliases currently exist. This simple regime avoids data races: there can never be\na concurrent read and write on the same cell. It also supports automatic memory manage-\nmentwithoutgarbagecollection:aheapcellcanbedeallocatedassoonastheownergoes\nout of scope. Of course, this simple regime is still quite restrictive, and a significant body of\nresearch exists on designing less restrictive ownership regimes that can still provide useful\nguarantees.\nAn ownership regime can be enforced by the programming language by means of a type\nsystem,andseveralresearchlanguageshavedonethiswiththeobjectiveofpreventingdata\nracesormemorymanagementvulnerabilities.TheRustprogramminglanguage,arecentsys-\ntems programming language, is the first mainstream language to incorporate an ownership\ntypesystem.\n14.2.1.4 Othervulnerabilities\nManyothercategoriesofvulnerabilitiescan,inprinciple,beaddressedbymeansofprogram-\nming language design and static type checking. There is, for instance, a wide body of re-\nsearch on language-based approaches to enforce information flow security [1228]. These\napproaches have until now mainly been integrated in research prototype languages. SPARK\nisanexampleofareal-worldlanguagethathasimplementedinformationflowanalysisinthe\ncompiler.Language-basedinformationflowsecuritytechniqueshavealsohadaprofoundin-\nfluenceonthestaticdetectiontechniquesforvulnerabilities(Topic14.3).\nKASoftwareSecurity |October2019 Page469 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n14.2.2 API Design\nThe development of software not only relies on a programming language, it also relies on\nAPIs, implemented by libraries or frameworks. Just like language design impacts the likeli-\nhood of introducing vulnerabilities, so does API design. The base principle is the same: the\nAPIshouldbedesignedtoavoidexecutionerrors(wherenow,executionerrorsareviolations\nof the API specification), and in particular untrapped execution errors. It should be difficult\nfor the programmer to violate an API contract, and if the contract is violated, that should be\ntrapped, leading, for instance, to program termination or to well-defined error-handling be-\nhaviour.\nWheretheprogramminglanguageitselfdoesnotpreventacertaincategoryofvulnerabilities\n(e.g. C does not prevent memory-management vulnerabilities, Java does not prevent race\nconditionsorstructuredoutputgenerationvulnerabilities),thelikelihoodofintroducingthese\nvulnerabilitiescanbereducedbyofferingahigher-levelAPI:\n\u2022 Several libraries providing less error-prone APIs for memory management in C or C++\nhavebeenproposed.Theselibrariesofferfatpointers(wherepointersmaintainbounds\ninformationandcheckwhetheraccessesareinbound),garbagecollection(whereman-\nual deallocation is no longer required), or smart pointers (that support an ownership-\nregimetosafelyautomatedeallocation).\n\u2022 Several libraries providing less error-prone APIs to do structured output generation for\nvarious types of structured output and for various programming languages have been\nproposed.ExamplesincludePreparedStatementAPIsthatallowaprogrammertosep-\naratethestructureofaSQLstatementfromtheuserinputthatneedstobepluggedinto\nthatstructure,orlibraryimplementationsoflanguageintegratedquery,wherequeryex-\npressionsareconstructedusingAPIcallsinsteadofusinglanguagesyntax.\n\u2022 Several libraries providing less error-prone APIs to cryptography have been proposed.\nTheselibrariesusesimplification(atthecostofflexibility),securedefaults,betterdoc-\numentationandtheimplementationofmorecompleteuse-cases(forinstance,include\nsupport for auxiliary tasks such as key storage) to make it less likely that a developer\nwillmakemistakes.\nTheuseofassertions,contractsanddefensiveprogramming[1225,c3]isageneralapproach\nto construct software with high reliability, and it is a highly useful approach to avoid API\nvulnerabilities. Design by contract makes the contract of an API explicit by providing pre-\nconditions and post-conditions, and in defensive programming these preconditions will be\nchecked,thusavoidingtheoccurrenceofuntrappederrors.\nA programming language API also determines the interface between programs in the lan-\nguage and the surrounding system. For instance, JavaScript in a browser does not expose\nanAPItothelocalfilesystem.Asaconsequence,JavaScriptprogramsrunninginthebrowser\ncannotpossiblyaccessthefilesystem.SuchlessprivilegedAPIscanbeusedtocontainor\nsandboxuntrustedcode(seeSection14.4.3),buttheycanalsopreventvulnerabilities.Object\ncapabilitysystems[1229]takethisideafurtherbyprovidingalanguageandAPIthatsupports\nstructuringcodesuchthateachpartofthecodeonlyhastheprivilegesitreallyneeds(thus\nsupportingtheprincipleofleastprivilege).\nThe design of cryptographic APIs that keep cryptographic key material in a separate protec-\ntion domain, for instance in a Hardware Security Module (HSM) comes with its own chal-\nlenges. Such APIs have a security objective themselves: the API to a HSM has the objective\nKASoftwareSecurity |October2019 Page470 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nof keeping the encryption keys it uses confidential \u2013 it should not be possible to extract the\nkeyfromtheHSM.Researchhasshown[1030,c18]thatmaintainingsuchasecurityobjective\nisextremelychallenging.TheHSMAPIhasanAPI-levelvulnerabilityifthereisasequenceof\nAPIcallsthatextractsconfidentialkeysfromtheHSM.NotethatthisisanAPIdesigndefect\nasopposedtotheimplementationdefectsconsideredinTopic1.\n14.2.3 Coding Practices\nThelikelihoodofintroducingthevariouscategoriesofvulnerabilitiesdiscussedinTopic14.1\ncan be substantially reduced by adopting secure coding practices. Coding guidelines can\nalso help against vulnerabilities of a more generic nature that can not be addressed by lan-\nguageorAPIdesign,suchas,forinstance,theguidelinetonothard-codepasswords.Secure\ncoding practices can be formalised as collections of rules and recommendations that de-\nscribeandillustrategoodandbadcodepatterns.\nA first approach to design such coding guidelines is heuristic and pragmatic: the program-\nmingcommunityissolicitedtoprovidecandidatesecurecodingrulesandrecommendations\nbasedonexperienceinhowthingshavegonewronginthepast.Theseproposedrulesarevet-\ntedanddiscussedbythecommunityuntilaconsensusisreachedthattheruleissufficiently\nappropriate to be included in a coding standard. Influential standards for general purpose\nsoftwaredevelopmentincludetheSEICERTcodingstandardsforC[1224]andJava[1230].\nFor critical systems development, more rigorous and stricter coding standards have been\ndeveloped.TheMISRAguidelines[1231]haveseenwidespreadrecognitionandadoptionfor\ndevelopmentofcriticalsystemsinC.TheSPARKsubsetofAda[1226]wasdesignedtosup-\nportcodingtoenableformalverificationoftheabsenceofclassesofvulnerabilities.\nRulescantakemanyforms,including:\n\u2022 the avoidance of dangerous language provided API functions (e.g., do not use the sys-\ntem()functioninC),\n\u2022 attempting to avoid undefined behaviour or untrapped execution errors (e.g., do not\naccessfreedmemoryinC),\n\u2022 mitigations against certain vulnerabilities caused by the language runtime (e.g., not\nstoring secrets in Java Strings, as the Java runtime can keep those Strings stored on\ntheheapindefinitely),or,\n\u2022 proactive, defensive rules that make it less likely to run into undefined behaviour (e.g.,\nexcludeuserinputfromformatstrings).\nAlso, specific side-channel vulnerabilities can be addressed by coding rules, for instance\navoidingcontrolflowormemoryaccessesthatdependonsecretscanpreventthesesecrets\nfromleakingthroughcache-basedorbranch-predictorbasedside-channels.\nWhen they are not enforced by a type system, ownership regimes for safely managing re-\nsources such as dynamically allocated memory can also be the basis for programming id-\nioms and coding guidelines. For instance, the Resource Acquisition Is Initialisation (RAII)\nidiom,movesemanticsandsmartpointersessentiallysupportanownershipregimeforC++,\nbutwithoutcompilerenforcedguarantees.\nAnimportantchallengewithsecurecodingguidelinesisthattheirnumbertendstogrowover\ntime, and hence programmers are likely to deviate from the secure practices codified in the\nKASoftwareSecurity |October2019 Page471 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nguidelines. Hence, it is important to provide tool support to check compliance of software\nwith the coding rules. Topic 14.3.1 discusses how static analysis tools can automatically\ndetectviolationsagainstsecurecodingrules.\n14.3 DETECTION OF VULNERABILITIES\n[1216,1232][1225,c4]\nForexistingsourcecodewherefullpreventionoftheintroductionofaclassofvulnerabilities\nwas not possible, for instance, because the choice of programming language and\/or APIs\nwas determined by other factors, it is useful to apply techniques to detect the presence of\nvulnerabilitiesinthecodeduringthedevelopment,testingand\/ormaintenancephaseofthe\nsoftware.\nTechniques to detect vulnerabilities must make trade-offs between the following two good\npropertiesthatadetectiontechniquecanhave:\n\u2022 A detection technique is sound for a given category of vulnerabilities if it can correctly\nconclude that a given program has no vulnerabilities of that category. An unsound de-\ntectiontechniqueontheotherhandmayhavefalsenegatives,i.e.,actualvulnerabilities\nthatthedetectiontechniquefailstofind.\n\u2022 Adetectiontechniqueiscompleteforagivencategoryofvulnerabilities,ifanyvulnera-\nbility it finds is an actual vulnerability. An incomplete detection technique on the other\nhandmayhavefalsepositives,i.e.itmaydetectissuesthatdonotturnouttobeactual\nvulnerabilities.\nTrade-offs are necessary, because it follows from Rice\u2019s theorem that (for non-trivial cate-\ngoriesofvulnerabilities)nodetectiontechniquecanbebothsoundandcomplete.\nAchievingsoundnessrequiresreasoningaboutallexecutionsofaprogram(usuallyaninfinite\nnumber).Thisistypicallydonebystaticcheckingoftheprogramcodewhilemakingsuitable\nabstractionsoftheexecutionstomaketheanalysisterminate.\nAchievingcompletenesscanbedonebyperformingactual,concreteexecutionsofaprogram\nthat are witnesses to any vulnerability reported. This is typically done by dynamic detection\nwheretheanalysistechniquehastocomeupwithconcreteinputsfortheprogramthattrigger\navulnerability.Averycommondynamicapproachissoftwaretestingwherethetesterwrites\ntestcaseswithconcreteinputs,andspecificchecksforthecorrespondingoutputs.\nInpractice,detectiontoolscanuseahybridcombinationofstaticanddynamicanalysistech-\nniquestoachieveagoodtrade-offbetweensoundnessandcompleteness.\nIt is important to note, however, that some detection techniques are heuristic in nature, and\nhence the notions of soundness and completeness are not precisely defined for them. For\ninstance,heuristictechniquesthatdetectviolationsofsecurecodingpracticesasdescribed\nin14.2.3arecheckingcompliancewithinformallydefinedrulesandrecommendations,andit\nis not always possible to unambiguously define the false positives or false negatives. More-\nover,theseapproachesmighthighlight\u2018vulnerabilities\u2019thataremaybenotexploitableatthis\npoint in time, but should be fixed nonetheless because they are \u2018near misses\u2019, i.e., might be-\ncomeeasilyexploitablebyfuturemaintenancemistakes.\nStatic and dynamic program analysis techniques are widely studied in other areas of com-\nKASoftwareSecurity |October2019 Page472 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nputerscience.ThisTopichighlightstheanalysistechniquesmostrelevanttosoftwaresecu-\nrity.\nAnotherimportantapproachtodetectionofvulnerabilitiesistoperformmanualcodereview\nandauditing.ThesetechniquesarecoveredintheSecureSoftwareLifecycleKnowledgeArea\n(Chapter16).Whenusingtool-supportedstaticdetection,itmakessensetoadjustsuchsub-\nsequentcodereviewandotherverificationactivities.Forinstance,ifstaticdetectionissound\nfor a given category of vulnerabilities, then one might consider not to review or test for that\ncategoryofvulnerabilitiesinlaterphases.\n14.3.1 Static Detection\nStaticdetectiontechniquesanalyseprogramcode(eithersourcecodeorbinarycode)tofind\nvulnerabilities.Opposedtodynamictechniques,thestaticoneshavetheadvantagethatthey\ncanoperateonincompletecodethatisnot(yet)executable,andthatinasingleanalysisrun\ntheyattempttocoverallpossibleprogramexecutions.Roughlyspeaking,onecandistinguish\ntwoimportantclassesoftechniques,thatdifferintheirmainobjective.\n14.3.1.1 Heuristicstaticdetection\nFirst, there are static analysis techniques that detect violations of rules that are formal en-\ncodings of secure programming-practice heuristics. The static analysis technique builds a\nsemanticmodeloftheprogram,including,forinstance,anabstractsyntaxtree,andabstrac-\ntions of the data flow and control flow in the program. Based on this model, the technique\ncanflagviolationsofsimplesyntacticrulessuchas,donotusethisdangerousAPIfunction,\noronlyusethisAPIfunctionwithaconstantstringasfirstparameter.\nAnimportantindicatorforthepresenceofvulnerabilitiesisthefactthat(possiblymalicious)\nprogram input can influence a value used in a risky operation (for instance, indexing into an\narray,orconcatenatingstringstocreateaSQLquery).Taintanalysis(sometimesalsocalled\nflowanalysis)isananalysistechniquethatdetermineswhethervaluescomingfromprogram\ninputs (or more generally from designated taint sources) can influence values used in such\nariskyoperation(ormoregenerally,valuesflowingintoarestrictedsink).Thesameanalysis\ncanalsobeusedtodetectcaseswhereconfidentialorsensitiveinformationintheprogram\nflowstopublicoutputchannels.\nMany variants of static taint analysis exist. Important variations include (1) how much ab-\nstractionismadeofthecode,forinstance,path-sensitiveversuspath-insensitive,orcontext-\nsensitive versus context-insensitive analysis, and (2) whether influences caused by the pro-\ngram control flow instead of program data flow are taken into account (often distinguished\nbyusingthetermstaintanalysisversusinformationflowanalysis).\nTo reduce the number of false positives, a taint analysis can take into account sanitisation\nperformed by the program. Tainted values that were processed by designated sanitisation\nfunctions (that are assumed to validate thatthe values areharmless for further processing)\nhavetheirtaintremoved.\nAn important challenge is that taint analyses must be configured with the right sets of\nsources, sinks and sanitisers. In practice, such configurations currently often occur manu-\nallyalthoughsomerecentworkshaveaddedtoolassistanceinwhich,forinstance,machine\nlearningisusedtosupportsecurityanalystsinthistask.\nKASoftwareSecurity |October2019 Page473 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n14.3.1.2 Soundstaticverification\nSecond,therearestaticanalysistechniquesthataimtobesoundforwell-definedcategories\nof vulnerabilities (but usually in practice still make compromises and give up soundness to\nsome extent). For categories of vulnerabilities that can be understood as specification or\ncontract violations, the main challenge is to express this underlying specification formally.\nOnce this is done, the large body of knowledge on static analysis and program verification\ndeveloped in other areas of computer science can be used to check compliance with the\nspecification.Thethreemainrelevanttechniquesareprogramverification,abstractinterpre-\ntationandmodelchecking.\nProgram verification uses a program logic to express program specifications, and relies on\ntheprogrammer\/verifiertoprovideanadequateabstractionoftheprogramintheformofin-\nductive loop invariants or function pre- and post-conditions to make it possible to construct\naproofthatcoversallprogramexecutions.Forimperativelanguageswithdynamicmemory\nallocation, separation logic [1233] is a program logic that can express absence of memory-\nmanagement and race-condition vulnerabilities (for data races on memory cells), as well as\ncompliancewithprogrammerprovidedcontractsonprogramAPIs.Checkingofcompliance\nwith a separation logic specification is typically not automatic: it is done by interactive pro-\ngram verification where program annotations are used to provide invariants, pre-conditions\nand post-conditions. However, if one is interested only in absence of memory management\nvulnerabilities, these annotations can sometimes be inferred, making the technique auto-\nmatic. Also avoiding the use of certain language features (e.g., pointers), and adhering to\nacodingstyleamenabletoverificationcanhelpmakingverificationautomatic.\nAbstract interpretation is an automatic technique where abstraction is made from the con-\ncrete program by mapping the run-time values that the program manipulates to adequate\nfinite abstract domains. For imperative programs that do not use dynamic allocation or re-\ncursion,abstractinterpretationisasuccessfultechniqueforprovingtheabsenceofmemory\nmanagementvulnerabilitiesautomaticallyandefficiently.\nModel checking is an automatic technique that exhaustively explores all reachable states\nof the program to check whether none of the states violates a given specification. Because\nof the state explosion problem, model checking can only exhaustively explore very small\nprograms,andinpracticetechniquestoboundtheexplorationneedtobeused,forinstance,\nbyboundingthenumberoftimesaprogramloopcanbeexecuted.Boundedmodelchecking\nisnolongersound,butcanstillfindmanyvulnerabilities.\nMostpracticalimplementationsoftheseanalysistechniquesgiveuponsoundnesstosome\nextent.Inordertobebothsoundandterminating,astaticanalysismustover-approximatethe\npossiblebehavioursoftheprogramitanalyses.Over-approximationleadstofalsepositives.\nReal programming languages have features that are hard to over-approximate without lead-\ning to an unacceptable number of false positives. Hence, practical implementations have\nto make engineering trade-offs, and will under-approximate some language features. This\nmakestheimplementationunsound,butmoreusefulinthesensethatitreducesthenumber\nof false positives. These engineering trade-offs are nicely summarised in the \u2018Soundiness\nManifesto\u2019[1234].\nKASoftwareSecurity |October2019 Page474 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n14.3.2 Dynamic Detection\nDynamic detection techniques execute a program and monitor the execution to detect vul-\nnerabilities. Thus, if sufficiently efficient, they can also be used for just-in-time vulnerability\nmitigation (See Topic 4). There are two important and relatively independent aspects to dy-\nnamic detection: (1) how should one monitor an execution such that vulnerabilities are de-\ntected, and (2) how many and what program executions (i.e., for what input values) should\nonemonitor?\n14.3.2.1 Monitoring\nForcategoriesofvulnerabilitiesthatcanbeunderstoodasviolationsofaspecifiedproperty\nofasingleexecution(SeeTopic14.1.6),completedetectioncanbeperformedbymonitoring\nforviolationsofthatspecification.Forothercategoriesofvulnerabilities,orwhenmonitoring\nforviolationsofaspecificationistooexpensive,approximativemonitorscanbedefined.\nMonitoringformemory-managementvulnerabilitieshasbeenstudiedintensively.Itis,inprin-\nciple,possibletobuildcompletemonitors,buttypicallyatasubstantialcostintimeandmem-\nory. Hence, existing tools explore various trade-offs in execution speed, memory use, and\ncompleteness. Modern C compilers include options to generate code to monitor for mem-\nory management vulnerabilities. In cases where a dynamic analysis is approximative, like a\nstaticanalysis,itcanalsogeneratefalsepositivesorfalsenegatives,despitethefactthatit\noperatesonaconcreteexecutiontrace.\nForstructuredoutputgenerationvulnerabilities,achallengeisthattheintendedstructureof\nthe generated output is often implicit, and hence there is no explicit specification that can\nbe monitored. Hence, monitoring relies on sensible heuristics. For instance, a monitor can\nuse a fine-grained dynamic taint analysis [1232] to track the flow of untrusted input strings,\nandthenflagaviolationwhenuntrustedinputhasanimpactontheparsetreeofgenerated\noutput.\nAssertions, pre-conditions and post-conditions as supported by the design-by-contract ap-\nproachtosoftwareconstruction[1225,c3]canbecompiledintothecodetoprovideamonitor\nfor API vulnerabilities at testing time, even if the cost of these compiled-in run-time checks\ncanbetoohightousetheminproductioncode.\nMonitoring for race conditions is hard, but some approaches for monitoring data races on\nsharedmemorycellsexist,forinstance,bymonitoringwhetherallsharedmemoryaccesses\nfollowaconsistentlockingdiscipline.\n14.3.2.2 Generatingrelevantexecutions\nAn important challenge for dynamic detection techniques is to generate executions of the\nprogram along paths that will lead to the discovery of new vulnerabilities. This problem is\nan instance of the general problem in software testing of systematically selecting appropri-\nate inputs for a program under test [1225, c4]. These techniques are often described by the\numbrellatermfuzztestingorfuzzing,andcanbeclassifiedas:\n\u2022 Black-boxfuzzing, where the generation of input values only depends on the input\/out-\nput behaviour of the program being tested, and not on its internal structure. Many dif-\nferent variants of black-box fuzzing have been proposed, including (1) purely random\ntesting, where input values are randomly sampled from the appropriate value domain,\nKASoftwareSecurity |October2019 Page475 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n(2) model-based fuzzing, where a model of the expected format of input values (typi-\ncallyintheformofagrammar)istakenintoaccountduringgenerationofinputvalues,\nand (3) mutation-based fuzzing, where the fuzzer is provided with one or more typical\ninput values and it generates new input values by performing small mutations on the\nprovidedinputvalues.\n\u2022 White-box fuzzing, where the internal structure of the program is analysed to assist in\nthegenerationofappropriateinputvalues.Themainsystematicwhite-boxfuzzingtech-\nniqueisdynamicsymbolicexecution.Dynamicsymbolicexecutionexecutesaprogram\nwith concrete input values and builds at the same time a path condition, a logical ex-\npression that specifies the constraints on those input values that have to be fulfilled\nfortheprogramtotakethisspecificexecutionpath.Bysolvingforinputvaluesthatdo\nnot satisfy the path condition of the current execution, the fuzzer can make sure that\nthese input values will drive the program to a different execution path, thus improving\ncoverage.\n14.4 MITIGATING EXPLOITATION OF VULNERABILITIES\n[1214,1235]\nEvenwithgoodtechniquestopreventintroductionofvulnerabilitiesinnewcode,ortodetect\nvulnerabilitiesinexistingcode,thereisboundtobeasubstantialamountoflegacycodewith\nvulnerabilitiesinactiveusefortheforeseeablefuture.Hence,vulnerabilitypreventionandde-\ntection techniques can be complemented with techniques that mitigate the exploitation of\nremainingvulnerabilities.Suchmitigationtechniquesaretypicallyimplementedintheexecu-\ntioninfrastructure,i.e.,thehardware,operatingsystem,loaderorvirtualmachine,orelseare\ninlinedintotheexecutablebythecompiler(aso-called\u2018inlinedreferencemonitor\u2019).Animpor-\ntant objective for these techniques is to limit the impact on performance, and to maximise\ncompatibilitywithlegacyprograms.\n14.4.1 Runtime Detection of Attacks\nRuntime monitoring of program execution is a powerful technique to detect attacks. In prin-\nciple,programmonitorstodetectvulnerabilitiesduringtesting(discussedin14.3.2Dynamic\nDetection)couldalsobeusedatruntimetodetectattacks.Forinstance,dynamictaintanal-\nysis combined with a dynamic check whether tainted data influenced the parse tree of gen-\nerated output has also been proposed as a runtime mitigation technique for SQL injection\nattacks.\nButthereisanimportantdifferenceintheperformancerequirementsformonitorsuseddur-\ning testing (discussed in Topic 14.3) and monitors used at runtime to mitigate attacks. For\nruntime detection of attacks, the challenge is to identify efficiently detectable violations of\npropertiesthatareexpectedtoholdfortheexecutiontraceoftheprogram.Awidevarietyof\ntechniquesareused:\n\u2022 Stack canaries detect violations of the integrity of activation records on the call stack,\nand hence detect some attacks that exploit memory management vulnerabilities to\nmodifyareturnaddress.\n\u2022 No Execute (NX) data memory detects attempts to direct the program counter to data\nmemoryinsteadofcodememoryandhencedetectsmanydirectcodeinjectionattacks.\nKASoftwareSecurity |October2019 Page476 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n\u2022 Control-FlowIntegrity(CFI)isaclassoftechniquesthatmonitorswhethertheruntime\ncontrol flow of the program complies with some specification of the expected control\nflow,andhencedetectsmanycode-reuseattacks.\nOndetectionofanattack,theruntimemonitormustreactappropriately,usuallybyterminat-\ningtheprogramunderattack.Terminationisagoodreactiontoensurethatanattackcando\nnofurtherdamage,butithasofcourseanegativeimpactonavailabilityproperties.\n14.4.2 Automated Software Diversity\nExploitation of vulnerabilities often relies on implementation details of the software under\nattack. For instance, exploitation of a memory management vulnerability usually relies on\ndetails of the memory layout of the program at runtime. A SQL injection attack can rely on\ndetailsofthedatabasetowhichtheSQLqueryisbeingsent.\nHence, a generic countermeasure to make it harder to exploit vulnerabilities is to diversify\nthese implementation details. This raises the bar for attacks in two ways. First, it is harder\nforanattackertoprepareandtesthis\/herattackonanidenticalsystem.Anattackthatworks\nagainstawebserverinstalledontheattackermachinemightfailagainstthesamewebserver\non the victim machine because of diversification. Second, it is harder to build attacks that\nwillworkagainstmanysystemsatonce.Insteadofbuildinganexploitonce,andthenusing\nit against many systems, attackers now have to build customised exploits for each system\ntheywanttoattack.\nThemostimportantrealisationofthisideaisAddressSpaceLayoutRandomization(ASLR),\nwhere the layout of code, stack and\/or heap memory is randomised either at load or at run-\ntime. Such randomisation can be coarse-grained, for instance, by just randomly relocating\nthe base address of code, stack and heap segments, or fine-grained where addresses of in-\ndividualfunctionsincodememory,activationrecordsinthestack,orobjectsintheheapare\nchosenrandomly.\nThe research community has investigated many other ways of automatically creating diver-\nsity at compilation time or installation time [1235], but such automatic diversification can\nalso bring important challenges to software maintenance as bug reports can be harder to\ninterpret,andsoftwareupdatesmayalsohavetobediversified.\n14.4.3 Limiting Privileges\nThe exploitation of a software vulnerability influences the behaviour of the software under\nattack such that some security objective is violated. By imposing general bounds on what\nthesoftwarecando,thedamagepotentialofattackscanbesubstantiallyreduced.\nSandboxingisasecuritymechanismwheresoftwareisexecutedwithinacontrolledenviron-\nment (the \u2018sandbox\u2019) and where a policy can be enforced on the resources that software in\nthe sandbox can access. Sandboxing can be used to confine untrusted software, but it can\nalsobeusedtomitigatetheimpactofexploitationonvulnerablesoftware:afterasuccessful\nexploitonthesoftware,anattackerisstillconfinedbythesandbox.\nThe generic idea of sandboxing can be instantiated using any of the isolation mechanisms\nthatmoderncomputersystemsprovide:thesandboxcanbeavirtualmachinerunningunder\nthe supervision of a virtual-machine monitor, or it can be a process on which the operating\nsystem imposes an access control policy. In addition, several purpose-specific sandboxing\nKASoftwareSecurity |October2019 Page477 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nmechanismshavebeendevelopedforspecificclassesofsoftware,suchas,forinstance,jails\nthatcansandboxnetwork-andfilesystem-accessinvirtualhostingenvironments.TheJava\nRuntime Environment implements a sandboxing mechanism intended to contain untrusted\nJava code, or to isolate code from different stakeholders within the same Java Virtual Ma-\nchine,butseveralsignificantvulnerabilitieshavebeenfoundinthatsandboxingmechanism\novertheyears[1236].\nCompartimentalisationisarelatedbutfiner-grainedsecuritymechanism,wherethesoftware\nitself is divided in a number of compartments and where some bounds are enforced on the\nprivilegesofeachofthesecompartments.Thisagainrequiressomeunderlyingmechanism\ntoenforcethesebounds.Forinstance,acompartimentalisedbrowsercouldrelyonoperating\nsystem process access control to bound the privileges of its rendering engine by denying it\nfile system access. Exploitation of a software vulnerability in the rendering engine is now\nmitigatedtotheextentthatevenafterasuccessfulexploit,theattackerisstillblockedfrom\naccessingthefilesystem.Veryfine-grainedformsofcompartimentalisationcanbeachieved\nby object-capability systems [1229], where each application-level object can be a separate\nprotectiondomain.\nTomitigateside-channelvulnerabilities,onecanisolatethevulnerablecode,forinstance,on\naseparatecoreoronseparatehardware,suchthattheinformationleakingthroughtheside\nchannelisnolongerobservableforattackers.\n14.4.4 Software Integrity Checking\nUnder the umbrella term Trusted Computing, a wide range of techniques have been devel-\noped to measure the state of a computer system, and to take appropriate actions if that\nstate is deemed insecure. A representative technique is Trusted Boot where measurements\nare accumulated for each program that is executed. Any modification to the programs (for\ninstance,becauseofasuccessfulattack)willleadtoadifferentmeasurement.Onecanthen\nenforcethataccesstosecretkeys,forinstance,isonlypossiblefromastatewithaspecified\nmeasurement.\nParnoetal.[1237]giveanexcellentoverviewofthisclassoftechniques.\nCONCLUSIONS\nSoftwareimplementationvulnerabilitiescomeinmanyforms,andcanbemitigatedbyawide\nrangeofcountermeasures.Table14.1summarisestherelationshipbetweenthecategoriesof\nvulnerabilitiesdiscussedinthischapter,andtherelevantprevention,detectionandmitigation\ntechniquescommonlyusedtocounterthem.\nKASoftwareSecurity |October2019 Page478 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nVulnerabilitycategory Prevention Detection Mitigation\nMemory management memory-safe languages, manystaticanddynamic stack canaries, NX, CFI,\nvulnerabilities fat\/smart pointers, cod- detectiontechniques ASLR,sandboxing\ningrules\nStructuredoutputgenera- regular expression types, taintanalysis runtimedetection\ntionvulnerabilities LINQ, Prepared State-\nments\nRaceconditionvulnerabil- ownership types, coding staticanddynamicdetec- sandboxing\nities guidelines tion\nAPIvulnerabilities contracts, usable APIs, runtime checking of compartimentalisation\ndefensive API implemen- pre- and post-conditions,\ntations static contract verifica-\ntion\nSide channel vulnerabili- codingguidelines staticdetection isolation\nties\nTable14.1:Summaryoverview\nAcknowledgments\nThe insightful and constructive comments and feedback from the reviewers and editor on\nearlier drafts have been extremely valuable, and have significantly improved the structure\nandcontentsofthischapter,ashavethecommentsreceivedduringpublicreview.\nKASoftwareSecurity |October2019 Page479 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nCROSS-REFERENCE OF TOPICS VS REFERENCE MATERIAL\n14.1CategoriesofVulnerabilities\n14.1.1MemoryManagementVulnerabilities c4,c5 c5 c6\n14.1.2StructuredOutputGenerationVulnerabilities c10,c11 c17 c9\n14.1.3RaceConditionVulnerabilities c7 c9\n14.1.4APIVulnerabilities c6 c9,c11\n14.1.5Side-channelVulnerabilities c17\n14.2PreventionofVulnerabilities\n14.2.1LanguageDesignandTypeSystems c1\n14.2.2APIDesign c18 c3\n14.2.3CodingPractices *\n14.3DetectionofVulnerabilities\n14.3.1StaticDetection *\n14.3.2DynamicDetection c4\n14.4MitigatingExploitationofVulnerabilities\n14.4.1RuntimeDetectionofAttacks c4\n14.4.2AutomatedSoftwareDiversity c4\n14.4.3LimitingPrivileges c7\nFURTHER READING\nBuilding Secure Software [1238] and 24 Deadly Sins of Software Security\n[1239]\nBuilding Secure Software was the first book focusing specifically on software security, and\neven if some of the technical content is somewhat dated by now, the book is still a solid\nintroduction to the field and the guiding principles in the book have withstood the test of\ntime.\n24 Deadly Sins of Software Security is a more recent and updated book by mostly the same\nauthors.\nKASoftwareSecurity |October2019 Page480\n]5121[ytiruces-retupmoc:uD\n]7121[tra:dwoD\n]0301[ytiruces8002nosredna\n]2221[340905:LPT:2002:ecreiP\n]4221[dradnats-gnidoc-C\n]5221[3vkobews\n]6121[sisylana-citats:ssehC TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nThe Art of Software Security Assessment [1217]\nEven if this is a book that is primarily targeted at software auditors, it is also a very useful\nresourcefordevelopers.Ithasclearanddetaileddescriptionsofmanyclassesofvulnerabil-\nities,includingplatform-specificaspects.\nSurreptitious Software [1240]\nSoftwaresecurityinthischapterisaboutpreventing,detectingandremovingsoftwareimple-\nmentationvulnerabilities.However,anothersensible,anddifferent,interpretationoftheterm\nis that it is about protecting the software code itself, for instance, against reverse engineer-\ningofthecode,againstextractionofsecretsfromthecode,oragainstundesiredtampering\nwiththecodebeforeorduringexecution.Obfuscation,watermarkingandtamperproofingare\nexamples of techniques to protect software against such attacks. Surreptitious Software is\narigoroustextbookaboutthisnotionofsoftwaresecurity.\nOWASP Resources\nThe Open Web Application Security Project (OWASP) is a not-for-profit, volunteer-driven or-\nganisation that organises events and offers a rich set of resources related to application\nsecurity and software security. They offer practice-oriented guides on secure development\nand on security testing, as well as a collection of tools and awareness raising instruments.\nAlltheseresourcesarepubliclyavailableathttps:\/\/www.owasp.org.\nKASoftwareSecurity |October2019 Page481 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nKASoftwareSecurity |October2019 Page482 Chapter 15\nWeb & Mobile Security\nSascha Fahl Leibniz University Hannover\n483 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n15.1 INTRODUCTION\nThe purpose of this Knowledge Area is to provide an overview of security mechanisms, at-\ntacks and defences in modern web and mobile ecosystems. This overview is intended for\nuseinacademiccoursesandtoguideindustryprofessionalsinterestedinthisarea.\nWebandmobilesecurityhavebecometheprimarymeansthroughwhichmanyusersinteract\nwiththeInternetandcomputingsystems.Hence,theirimpactonoverallinformationsecurity\nis significant due to the sheer prevalence of web and mobile applications (apps). Covering\nbothwebandmobilesecurity,thisKnowledgeAreaemphasisestheintersectionoftheirsecu-\nritymechanisms,vulnerabilitiesandmitigations.Bothareassharealotincommonandhave\nexperienced a rapid evolution in the features and functionalities offered by their client side\napplications (apps). This phenomenon, sometimes called appification, is a driver in modern\nweb and mobile ecosystems. Web and mobile client apps typically interact with server side\napplication interfaces using web technologies. This second phenomenon, also sometimes\ncalledwebification,equallyaffectsbothwebandmobileecosystems.Inthe1990s,weband\nmobilesecurityhadastrongfocusonserver-sideandinfrastructuresecurity.Webbrowsers\nweremostlyusedtorenderanddisplaystaticwebsiteswithoutdynamiccontent.Thefocus\non the server-side prevailed even with the rise of early scripting languages such as Perl and\nPHP. However, web content became more dynamic in the 2000s, and server-side security\nhadtoaddressinjectionattacks.Similarlytowebbrowsers,earlymobiledeviceshadlimited\nfunctionality and were mostly used to make calls or send SMS. Mobile security back then\nfocusedonaccesscontrol,callsandSMSsecurity.\nTheriseofmodernwebandmobileplatformsbroughtnotablechanges.Asignificantamount\nof web application code is no longer executed on the server-side but runs in the browser.\nWebbrowsersupportforJava,AdobeFlash,JavaScriptandbrowserpluginsandextensions\nbroughtmanynewfeaturestotheclient,whichpromptedadrasticchangeoftheattacksur-\nface on the web. New types of attacks such as Cross-Site Scripting emerged and plugins\nproved to be vulnerable, e.g. Adobe Flash browser plugins are known for being an attractive\ntargetforattackers.Inresponsetothesenewthreats,browservendorsandwebsitedevelop-\nersandoperatorstookmeasures.Forinstance,GoogleChromedisabledtheAdobeFlashplu-\nginbydefaultin2019[1241]andnewsecuritybestpracticesweredeveloped[1242].Similarly\nto web browsers, mobile devices became smarter and more feature-rich. Smartphones and\ntabletsareequippedwithsensors,includingmotion,GPSandcameras.Theyhaveextensive\ncomputing power, storage capacity and are connected to the Internet 24-7. Modern Android\nandiOSdevicesrunfull-blownoperatingsystemsandincreasinglyfeature-richandcomplex\napplication frameworks. Mobile apps can request access to all the devices\u2019 resources and\nsensors using permission based access control, and process highly sensitive user informa-\ntion.Beingpowerful,feature-rich,andconnectedmakesmobileclientspromisingandattrac-\ntivetargetsforattackers.\nModern web and mobile ecosystems are the primary drivers for the rise of appification and\nthe\"thereisanappforeverything\"mottosumsupmanyofthetechnologicalandsecurityde-\nvelopments in recent years. The appification trend resulted in millions of apps ranging from\nsimple flashlight apps to online social network apps, from online banking apps to mobile\nand browser-based games. It also sparked the merging of technologies and security mech-\nanisms used in web and mobile applications. Both ecosystems are typically client-server\noriented. Web browsers and mobile apps communicate with back-end services often using\nweb focused technologies. Communication is mostly based on the Hypertext Transfer Pro-\nKAWeb&MobileSecurity |October2019 Page484 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntocol (HTTP) and its secure extension HTTPS. Both web-browsers and mobile applications\ntendtoprimarilyexchangeHypertextMarkupLanguage(HTML),JSONandXMLdocuments\nand both make extensive use of the JavaScript programming language, on the server- and\ntheclient-side.Webificationdescribestheconversiontothesewebtechnologies.\nThe sheer amount of applications in modern web and mobile ecosystems also impacted\nthe software distribution model, which moved away from website downloads to centralised\napplicationstores,whichallowdeveloperstopublish,advertiseanddistributetheirsoftware,\nanduserstodownloadnewappsandappupdates.Thecentralisedsoftwaredistributionhad\napositiveimpactonupdatefrequenciesandspeedforbothwebandmobile.\nThisKnowledgeAreafocusesontheappificationtrendandanintroductiontothecoretech-\nnologies of the webification phenomenon. Figure 15.1 provides an overview of the entities\ninvolvedandtheirinteractions.\nServer Side\nS Aec pur pit y\nS\nC th oe rc eks InstP au\nll\ns ah\np\npap\nsp updates\nExchange Data with\nApplication\nServer\nHTTPS Re Hq Tu Te\nPst\nS\ns Responses\nWeb S\nD\nape\ne\npvr lev icle\no\napr\nti\now ne sb\nhttps:\/\/example.com and configure\nPublish apps and https:\/\/example.com infrastructure\nhttps:\/\/example.com\npush updates\n<html>\n<head>\n<title>This is an example<\/title>\n<\/head>\n<script src=\"myscripts.js\"><\/script>\n<body> Devs Users ... Devs\/Ops\nSandboxed Apps <\/body>\nApps <\/html>\nApps\nMobile Device Web Browser\nClient Side\nFigure15.1:WebandMobileEcosystem\nAfter introducing core technologies and concepts, we describe important security mecha-\nnisms and illustrate how they differ from non-web and non-mobile ecosystems. Software\nand content isolation are crucial security mechanisms and aim to protect apps and web-\nsitesfrommaliciousaccess.Whileisolationisunderstoodinrelationtotraditionaloperating\nsystems(cf.theOperatingSystems&VirtualisationKnowledgeArea(Chapter11)),specifics\nforwebandmobileplatformswillbeoutlined.\nModernwebandmobileplatformsintroducednewformsofaccesscontrolbasedonpermis-\nsiondialogues.WhilstamoregeneraldiscussionofaccesscontrolisincludedintheAuthen-\ntication,Authorisation&Accountability(AAA)KnowledgeArea(Chapter13),thisKnowledge\nAreadiscusseswebandmobilespecifics.Webandmobileapplicationsmakeextensiveuse\noftheHTTPandHTTPSprotocols.Hence,wewilldiscusstheWebPublic-KeyInfrastructure\n(PKI)andHTTPSextendingtheTransportLayerSecurity(TLS)sectionintheNetworkSecurity\nKnowledge Area (Section 17.4). Similarly, we will discuss web and mobile-specific authenti-\ncationaspects,referringreaderstotheAuthentication,Authorisation&Accountability(AAA)\nKAWeb&MobileSecurity |October2019 Page485\nsetisbeW\ndetalosI TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nKnowledge Area (Chapter 13) for a more general discussion of authentication. Finally, we\naddress frequent software updates as a crucial security measure. While software updates\nareequallyimportantintraditionalcomputersystems,thecentralisation1 ofwebandmobile\necosystems,introducesnewchallengesandopportunities.\nThe following sections focus on web and mobile-specific client and server-side security as-\npects. However, we will not address common software vulnerabilities (cf. the Software Se-\ncurity Knowledge Area (Chapter 14)) and operating system security (cf. Operating Systems\n& Virtualisation Knowledge Area (Chapter 11)) in general. Section 15.3 first covers phishing\nand clickjacking attacks and defenses. Both affect web and mobile clients and exploit hu-\nman difficulties in correctly parsing URLs or identifying changes in the visual appearance\nof web-sites. As feature-rich web and mobile clients store sensitive data, we will then dis-\ncussclient-sidestoragesecurityissuesandmitigations.Finally,Section15.3discussesphys-\nical attacks on mobile clients, including smudge attacks and shoulder surfing. Section 15.4\naddresses server-side challenges, starting with an overview of frequent injection attacks.\nWe discuss SQL and command injection attacks that allow malicious users to manipulate\ndatabasequeriestostoragebackendsofwebapplicationsandcommandsthatareexecuted.\nThisisfollowedbyadiscussionofcross-sitescriptingandcross-siterequestforgeryattacks\nandcommonserver-sidemisconfigurationsthatmightleadtovulnerableservicebackends.\nOverall, the discussion of client- and server-side security challenges aims to serve as the\nunderliningofthenaturalsplitbetweenentitiesinwebandmobileecosystems.Additionally,\nthe chosen aspects illustrate the difference between the web and mobile world from other\necosystems.\nDue to its focus on the intersection of both web and mobile security, this Knowledge Area\ndoesnotcoveraspectsthatareuniquetoeitherwebormobilesuchasmobiledevicesecurity,\nmobile network (i.e., 2G\/3G\/4G\/5G) security (see Physical Layer and Telecommunications\nKnowledge Area (Chapter 20)), and mobile malware. Some of these aspects are discussed\nin the Hardware Security Knowledge Area (Chapter 18), the Malware & Attack Technology\nKnowledgeArea(Chapter6)andtheNetworkSecurityKnowledgeArea(Chapter17).Wealso\ndonotdiscussside-channelattacks;theconceptandexamplesforside-channelsecurityare\ngivenintheHardwareSecurityKnowledgeArea(Chapter18).\n15.2 FUNDAMENTAL CONCEPTS AND APPROACHES\n[456,1243,1244,1245,1246,1247,1248,1249,1250]\nThis section describes fundamental concepts and approaches of modern web and mobile\nplatformsthataffectsecurity.Theinformationpresentedinthissectionisintendedtoserve\nas a foundation to better understand the security challenges in the following sections. Sim-\nilar to other software products and computer systems, mobile operating systems and appli-\ncationsandwebbrowsersaswellaswebserversmaycontainexploitablebugs.Generalpur-\nposesoftwarevulnerabilitiesarediscussedintheSoftwareSecurityKnowledgeArea(Chap-\nter14).\n1Thereareonlyalimitednumberofwidelyusedwebbrowsersandapplicationstores.\nKAWeb&MobileSecurity |October2019 Page486 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n15.2.1 Appification\nOver the last ten years, the rise of mobile devices and ubiquitous Internet access have\nchangedthewaysoftwareisproduced,distributedandconsumed,alteringhowhumansinter-\nactwithcomputerdevicesandwithsoftwareinstalledonthedevices.WhileregularInternet\nbrowsershavebeenthedominantwayofaccessingcontentonthewebinthepre-mobileera,\ntheconceptofappificationsignificantlychangedthewayusersaccesscontentonline[1244].\nAppification describes the phenomenon of moving away from a web-based platform to ac-\ncess most digital tools and media online with a web-browser through mobile applications\nwith highly specialised, tiny feature sets. As mobile devices grew to become the primary in-\nterface for web access worldwide [1251], the number of apps rose enormously over the last\ndecade.\u201cThereisanappforeverything\u201dbecamethemantraofappifiedsoftwareecosystems,\nwhichproducednumerousapplicationsforallsortsofusecasesandapplicationareas.Many\napps look like native local desktop or mobile applications. However, they are often (mobile)\nwebapplicationsthatcommunicatewithbackendservices,whichthenoutsourcecomputa-\ntion and storage tasks to the client. The shift towards appification had a significant impact\nonwebandmobilesecuritycreatingmoresecuritychallengesontheclient-side.Theriseof\nappificationalsoimpactedthedeveloperlandscape.Inthepre-appificationera,softwarede-\nvelopmentwasmostlydominatedbyexperienceddevelopers.Duetothemoreextensivetool\nandframeworksupport,themarketentrancebarrierislowerinappifiedecosystems.Thisat-\ntracts more inexperienced developers, and has negative consequences for web and mobile\nsecurityingeneral(cf.theHumanFactorsKnowledgeArea(Chapter4)).\nThe Rise of the Citizen Developer The appification trend attracts many non-professional\nsoftware developers called citizen developers. Many of them do not have a software engineer-\ningeducationbutmakeuseofmultiplesimpleAPIsandtoolsavailabletobuildappsfordifferent\nplatforms.Oltroggeetal.[1252]foundthattheadoptionofeasy-to-useOnlineApplicationGenera-\ntors(OAGs)todevelop,distributeandmaintainappshasanegativeimpactonapplicationsecurity.\nGeneratedappstendtobevulnerabletoreconfigurationandcodeinjectionattacksandrelyonan\ninsecureinfrastructure.\n15.2.2 Webification\nModern web and mobile platforms gave rise to another phenomenon. Many of the applica-\ntionsarenotnativeapplicationswrittenincompiledprogramminglanguagessuchasJavaor\nKotlinandC\/C++(e.g.forAndroidapps)orObjective-CandSwift(e.g.foriOSapps).Instead,\nthey are based on web technologies including server-side Python, Ruby, Java or JavaScript\nscriptsandclient-sideJavaScript.Inadditiontoconventionalwebapplicationstargetingreg-\nular web browsers, mobile web applications are more frequently built using these web tech-\nnologies.Inparticular,mobilewebapplicationsmakeheavyuseoftheJavaScriptlanguage.\nThis section gives a brief introduction to the most essential technologies needed to explain\nvulnerabilitiesandmitigationslaterintheKA.WeincludeUniformResourceLocators(URLs),\ntheHypertextTransferProtocol(HTTP),theHypertextMarkupLanguage(HTML),Cascading\nStyleSheets(CSS)andtheJavaScriptprogramminglanguage.Formoredetailedinformation,\nwesuggestreading [1253].\nKAWeb&MobileSecurity |October2019 Page487 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n15.2.2.1 UniformResourceLocators\nUniform Resource Locators (URLs) [1245] are a core concept in the web. A URL is a well-\nformed and fully qualified text string that addresses and identifies a resource on a server.\nAddress bars in modern browser User Interfaces (UIs) use the URLs to illustrate the remote\naddressofarendereddocument.AfullyqualifiedabsoluteURLstringconsistsofseveralseg-\nments and contains all the required information to access a particular resource. The syntax\nof an absolute URL is: scheme:\/\/credentials@host:port\/resourcepath?query_parameters#fragments.\nEachsegmenthasaparticularmeaning(cf.Table15.1).\nSegment Optional Description\nscheme: Indicatestheprotocolawebclientshouldusetoretrievearesource.\nCommonprotocolsinthewebarehttp:andhttps:\n\/\/ IndicatesahierarchicalURLasrequiredby[1245]\ncredentials@ Cancontainausernameandpasswordthatmightbeneededto\nretrievearesourcefromaremoteserver.\nhost Specifiesacase-insensitiveDNSname(e.g.cybok.org),arawIPv4\n(e.g.127.0.0.1)orIPv6address(e.g.[0:0:0:0:0:0:0:1])toindicatethe\nlocationoftheserverhostingaresource.\n:port Describesanon-defaultnetworkportnumbertoconnecttoa\nremoteserver.Defaultportsare80forHTTPand443forHTTPS.\n\/resourcepath Identifiestheresourceaddressonaremoteserver.Theresource\npathformatisbuiltontopofUnixdirectorysemantics.\n?query_parameters Passesnon-hierarchicalparameterstoaremoteresource,suchas\nserver-sidescriptinputparameters.\n#fragment Providesinstructionsforthebrowser.Inpractice,itisusedto\naddressanHTMLanchorelementforin-documentnavigation.\nTable15.1:URLsegments.\n15.2.2.2 HypertextTransferProtocol\nThe Hypertext Transfer Protocol (HTTP) is the most widely used mechanism to exchange\ndocuments between servers and clients on the web. While HTTP is mostly used to trans-\nfer HTML documents, it can be used for any data. Although HTTP\/2.0 [1254] is the newest\nprotocol revision, the most widely supported protocol version is HTTP\/1.1 [1243]. HTTP is\na text-based protocol using TCP\/IP. An HTTP client initiates a session by sending an HTTP\nrequesttoanHTTPserver.TheserverreturnsanHTTPresponsewiththerequestedfile.\nThe first line of a client request includes HTTP version information (e.g. HTTP\/1.1). The\nremaining request header consists of zero or more name:value pairs. The pairs are sep-\narated by a new line. Common request headers are User-Agent \u2013 these include browser in-\nformation,Host \u2013 theURL hostname,Accept \u2013 whichcarries allsupporteddocument types,\nContent-Length \u2013 the length of the entire request and Cookie \u2013 see Section 15.2.8. The\nrequestheaderisterminatedwithasingleemptyline.HTTPclientsmaypassanyadditional\ncontenttotheserver.Althoughthecontentcanbeofanytype,clientscommonlysendHTML\ncontent to the server, e.g. to submit form data. The HTTP server responds to the request\nwitharesponseheaderfollowedbytherequestedcontent.Theresponseheadercontainsthe\nsupported protocol version, a numerical status code, and an optional, human-readable sta-\nKAWeb&MobileSecurity |October2019 Page488 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntus message. The status notification is used to indicate request success (e.g. status 200),\nerror conditions (e.g. status 404 or 500) or other exceptional events. Response headers\nmightalsocontainCookieheaders\u2013cf.Section15.2.8.Additionalresponseheaderlinesare\noptional. The header ends with a single empty line followed by the actual content of the re-\nquestedresource.Similartotherequestcontent,thecontentmaybeofanytypebutisoften\nanHTMLdocument.\nAlthough cookies were not part of the original HTTP RFC [1243], they are one of the most\nimportant protocol extensions. Cookies allow remote servers to store multiple name=value\npairs in client storage. Servers can set cookies by sending a Set-Cookie: name=value re-\nsponse header and consume them by reading a client\u2019s Cookie: name=value request header.\nCookies are a popular mechanism to maintain sessions between clients and servers and to\nauthenticateusers.\nHTTPisrequest-responsebasedandneatlyfitsunidirectionaldatatransferusecases.How-\never, for better latency and more effective use of bandwidth, bidirectional network connec-\ntionsareneeded.Bidirectionalconnectionsnotonlyallowclientstopulldatafromtheserver,\nbut also the server to push data to the client at any time. Therefore, the WebSocket proto-\ncol [1255] provides a mechanism on top of HTTP. WebSocket connections start with a reg-\nular HTTP request that includes an Upgrade: WebSocket header. After the WebSocket\nhandshakeiscompleted,bothpartiescansenddataatanytimewithouthavingtorunanew\nhandshake.\n15.2.2.3 HypertextMarkupLanguage\nTheHypertextMarkupLanguage(HTML)[1246]isthemostwidelyusedmethodtoproduce\nand consume documents on the web. The most recent version is HTML5. The HTML syn-\ntaxisfairlystraightforward:ahierarchicaltreestructureoftags,name=valuetagparameters\nand text nodes form an HTML document. The Domain Object Model (DOM) defines the log-\nical structure of an HTML document and rules how it is accessed and manipulated. How-\never, competing web browser vendors introduced all sorts of custom features and modified\nthe HTML language to their wishes. The many different and divergent browser implementa-\ntions resulted in only a small portion of the websites on the Internet adhering to the HTML\nstandard\u2019ssyntax.Hence,implementationsofHTMLparsingmodesanderrorrecoveryvary\ngreatlybetweendifferentbrowsers.\nThe HTML syntax comes with some constraints on what may be included in a parameter\nvalueorinsideatextnode.Somecharacters(e.g.,anglebrackets,singleanddoublequotes\nandampersands)maketheblocksoftheHTMLmarkup.Whenevertheyareusedforadiffer-\nentpurpose,suchaspartsofsubstringsofatext,theyneedtobeescaped.Toavoidundesir-\nablesideeffects,HTMLprovidesanentityencodingscheme.However,thefailuretoproperly\napplytheencodingtoreservedcharacterswhendisplayinguser-controlledinformationmay\nleadtoseverewebsecurityflawssuchascross-sitescripting(cf.Section15.4).\nKAWeb&MobileSecurity |October2019 Page489 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n15.2.2.4 CascadingStyleSheets\nCascadingStyleSheets(CSS)[1256]areaconsistentandflexiblemechanismtomanipulate\nthe appearance of HTML documents. The primary goal of CSS was to provide a straight-\nforwardandsimpletext-baseddescriptionlanguagetosupersedethemanyvendor-specific\nHTMLtagparametersthatleadtomanyinconsistencies.However,similartodivergentHTML\nparsingimplementations,differentbrowsersalsoimplementdifferentCSSparsingbehavior.\nCSS allows HTML tags to be scaled, positioned or decorated without being limited by the\noriginal HTML markup constraints. Similar to HTML tag values, values inside CSS can be\nuser-controlledorprovidedexternally,whichmakesCSScrucialforwebsecurity.\n15.2.2.5 JavaScript\nJavaScript[1247]isasimpleyetpowerfulobject-orientedprogramminglanguagefortheweb.\nItrunsbothclient-sideinwebbrowsersandserver-sideaspartofwebapplications.Thelan-\nguageismeanttobeinterpretedatruntimeandhasaC-inspiredsyntax.JavaScriptsupports\naclasslessobjectmodel,providesautomaticgarbagecollectionandweakanddynamictyp-\ning. Client-side JavaScript does not support I\/O mechanisms out of the box. Instead, some\nlimited predefined interfaces are provided by native code inside the browser. Server-side\nJavaScript (e.g., Node.js [1257]) supports a wide variety of I\/O mechanisms, e.g., network\nand file access. The following discussion will focus on client JavaScript in web browsers.\nEvery HTML document in a browser is given its JavaScript execution context. All scripts in\na document context share the same sandbox (cf. Section 15.2.4). Inter-context communica-\ntion between scripts is supported through browser-specific APIs. However, execution con-\ntexts are strictly isolated from each other in general. All JavaScript blocks in a context are\nexecutedindividuallyandinawell-definedorder.Scriptprocessingconsistsofthreephases:\nParsing validatesthescriptsyntaxandtranslatesittoanintermediatebinaryrepresentation\nfor performance reasons. The code has no effect until parsing is completed. Blocks\nwithsyntaxerrorsareignored,andthenextblockisparsed.\nFunctionResolution registers all named, global functions the parser found in a block. All\nregisteredfunctionscanbereachedfromthefollowingcode.\nExecution runs all code statements outside of function blocks. However, exceptions may\nstillleadtoexecutionfailures.\nWhile JavaScript is a very powerful and elegant scripting language, it brings up new chal-\nlengesandsecurityissuessuchasCross-SiteScriptingvulnerabilities(cf.Section15.4.1).\n15.2.2.6 WebAssembly\nWebAssembly (Wasm) [1258] is an efficient and fast binary instruction format and is sup-\nported by most modern browser vendors. It is a stack-based virtual machine language and\nmainly aims to execute at native speed on client machines. Code written in WebAssembly\nis memory safe and benefits from all security features provided by regular code associated\nwith a website. WebAssembly code is sandboxed, enforces the same origin policy (cf. Sec-\ntion 15.2.4) and is limited to the resources provided by the corresponding website\u2019s permis-\nsions.Additionally,WebAssemblycodecanaccessJavaScriptcoderunninginthesameori-\ngincontainerandprovideitsfunctionalitytoJavaScriptcodefromthesameorigin.\nKAWeb&MobileSecurity |October2019 Page490 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n15.2.2.7 WebViews\nWebViews are a further trend in webification and mobile apps. They allow the easy integra-\ntion of web content into mobile apps [1259]. Developers can integrate apps with HTML and\nJavaScript and benefit from portability advantages. WebViews run in the context of regular\nmobile appsand allow arich two-wayinteraction withthe hosted webcontent. Mobile apps\ncan invoke JavaScript from within the web content, and monitor and intercept events in the\nwebcontent.Atthesametime,specificJavaScriptAPIsallowWebViewappstointeractwith\ncontent and sensors outside the WebView context. The interaction of web content with na-\ntive app content raises new security concerns and enables both app-to-web and web-to-app\nattacks[1260,1261,1262].App-to-webattacks,allowmaliciousappstoinjectJavaScriptinto\nhostedWebViewswiththegoaltoexfiltratesensitiveinformationortrickWebViewsintonavi-\ngatingtoandpresentinguserswithuntrustedandpotentiallymaliciouswebsites.Web-to-app\nattacks inject untrusted web content into an app and leverage an app\u2019s JavaScript bridge to\nthe underlying host app. The goal of a web-to-app attack is privilege escalation to the level\nofitshostingapp\u2019sprocess.\nBoththeappificationandwebificationphenomenaledtoanewwayofsoftwaredistribution.\nInstead of decentralised download sources, centralised application stores which are illus-\ntratedinthenextsectionemerged.\n15.2.3 Application Stores\nApplication stores are centralised digital distribution platforms that organise the manage-\nment and distribution of software in many web and mobile ecosystems. Famous examples\nare the Chrome web store for extensions for the Chrome browser, Apple\u2019s AppStore for iOS\napplications, and Google Play for Android applications. Users can browse, download, rate\nand review mobile applications or browser plugins and extensions. Developers can upload\ntheir software to application stores that manage all of the software distribution challenges,\nincluding the provision of storage, bandwidth and parts of the advertisement and sales. Be-\nfore publication, most application stores deploy application approval processes for testing\nreliability,adherencetostorepolicies,andforsecurityvetting[1263,1264].\nMost of the software available in ecosystems that have application stores is distributed\nthrough the stores. Only a few users side-load software (i.e. install software from other\nsourcesthanthestore).Applicationstoresallowproviderstocontrolwhichapplicationsare\navailable in their stores, which allows them to ban particular applications. Whilst this can\ngive rise to accusations of censorship, the deployment of security vetting techniques has\nhelped to significantly reduce the amount of malicious software available in stores [1263]\nand to reduce the number of applications that suffer from vulnerabilities due to the misuse\nofsecurityAPIsbydevelopers[421].Deployedsecurityvettingtechniquesincludestaticand\ndynamic analysis applied to application binaries and running instances of applications. In\naddition to security vetting techniques, application stores require applications to be signed\nby developer or application store keys. In Android, application signing does not rely on the\nsamepublickeyinfrastructuresusedontheweb.Instead,developersareencouragedtouse\nself-signedcertificatesandrequiredtosignapplicationupdateswiththesamekeytoprevent\nmaliciousupdates[1265].TheapplicationsigningprocedureoniOSdevicesrequiresappsto\nbe signed by Apple. Unsigned apps cannot be installed on iOS devices. Application stores\nnot only allow developers and users centralised access to software publication, distribution\nand download, they also enable users to rate and review published applications. User rating\nand reviews are intended to help other users make more informed download decisions, but\nKAWeb&MobileSecurity |October2019 Page491 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntheyalsohaveadirectconnectiontoapplicationsecurity.\nImpact of User Ratings and Reviews on Application Security Nguyen et al. [1266] con-\nductedalarge-scaleanalysisofuserreviewsforAndroidapplicationsandtheirimpactonsecurity\npatches. They found that the presence of security- and privacy-related user reviews for applica-\ntionsarecontributingfactorstofuturesecurity-relatedapplicationupdates.\n15.2.4 Sandboxing\nBoth modern mobile and browser platforms make use of different sandboxing techniques\nto isolate applications and websites and their content from each other (cf. Operating Sys-\ntems & Virtualisation Knowledge Area (Chapter 11)) [1267, 1268]. This also aims to protect\nthe platform against malicious applications and sites. Major web browsers (e.g. Google\nChrome [1269]) and mobile platforms (e.g. Android [1270]) implement isolation at an oper-\natingsystemprocesslevel.Eachapplicationorwebsiterunsinitsownprocess2.Bydefault,\nisolatedprocessescannotinteractwitheachotherandcannotshareresources.Inbrowsers,\nsite isolation serves as a second line of defence as an extension to the same-origin-policy\n(cf.Section15.2.4.2).\n15.2.4.1 ApplicationIsolation\nModernmobileplatformsprovideeachapplicationwiththeirsandboxrunninginadedicated\nprocessandtheirownfile-systemstorage.Mobileplatformstakeadvantageofunderlyingop-\nerating system process protection mechanisms for application resource identification and\nisolation.Forexample,applicationsandboxesinAndroid[1270]areset-upatkernel-level.Se-\ncurityisenforcedthroughstandardoperatingsystemfacilities,includinguserandgroupIDs\nas well as security contexts. By default, sandboxing prevents applications from accessing\neach other and only allows limited access to operating system resources. To access pro-\ntected app and operating system resources inter-app communication through controlled in-\nterfacesisrequired.\n15.2.4.2 ContentIsolation\nContentisolationisoneofthemajorsecurityassurancesinmodernbrowsers.Themainidea\nis to isolate documents based on their origin so that they cannot interfere with each other.\nThe Same-Origin-Policy (SOP) [1271] was introduced in 1995 and affects JavaScript and its\ninteraction withadocument\u2019sDOM,networkrequestsandlocalstorage(e.g.,cookies).The\ncoreideabehindSOPisthattwoseparateJavaScriptexecutioncontextsareonlyallowedto\nmanipulateadocument\u2019sDOMifthereisanexactmatchbetweenthedocumenthostandthe\nprotocol,DNSnameandportnumbers3.Cross-originmanipulationrequestsarenotallowed.\nTable 15.2 illustrates sample SOP validation results. Similar to JavaScript-DOM-interaction,\ntheSOPlimitstheJavaScriptXMLHttpRequestcapabilitiestoonlyissueHTTPrequeststo\ntheoriginofthehostdocument.\nOne major flaw of SOP is that it relies on DNS instead of IP addresses. Attackers who can\nintentionally change the IP address of a DNS entry can therefore circumvent SOP security\nguarantees.\n2Process-basedsiteisolationismostlyusedondesktopcomputers[1269].\n3Theprotocol,DNSnameandportnumbertripleiscalledorigin.\nKAWeb&MobileSecurity |October2019 Page492 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nOriginatingdocument Accesseddocument Browserbehaviour\nhttps:\/\/www.cybok.org\/docs\/ https:\/\/www.cybok.org\/scripts\/ Accessokay\nhttps:\/\/www.cybok.org\/ https:\/\/books.cybok.org\/ Hostmismatch\nhttp:\/\/www.cybok.org\/ https:\/\/www.cybok.org\/ Protocolmismatch\nhttps:\/\/www.cybok.org\/ https:\/\/www.cybok.org:10443\/ Portmismatch\nTable15.2:SOPvalidationexamples.\nSincecodethatenforcesthesame-origin-policyoccasionallycontainssecuritybugs,modern\nbrowsersintroducedasecondlineofdefence:websitesarerenderedintheirownprocesses\nthat run in a sandbox. Sandboxing websites is meant to prevent attacks such as stealing\ncross-sitecookiesandsavedpasswords[1272].\nAnother additional layer of defence to enforce the same-origin policy and improve web ap-\nplication security is the Content Security Policy (CSP) mechanism [1273]. A CSP is primarily\nintendedtopreventcodeinjectionattackssuchasXSS(cf.Section15.4.1),whichexploitthe\nbrowsers\u2019trustofcontentthatwassentbyawebserver.Thisallowsmaliciousscriptstobe\nexecuted in clients\u2019 browsers. CSP allows web developers and server operators to limit the\nnumber of origins that browsers should consider to be trusted sources of content \u2013 includ-\ningexecutablecodeandmediafiles.ACSPcanbeusedsothatserverscangloballydisable\ncode execution on the client. To enable CSP, developers or operators can either configure a\nwebservertosendaContent-Security-PolicyHTTPresponseheaderoraddaHTML\n<meta> tag to a website. Compatible browsers will then only execute code or load media\nfilesfromtrustedorigins.\nExample: Content Security Policy Header The following CSP allows users of a web appli-\ncation to include images from any origin, but to restrict media data (audio or video media) to\nthetrustedtrusted-media.comdomain.Additionally, scriptsare restricted tothetrusted-scripts.com\noriginthatthewebdevelopertrusts:\nContent-Security-Policy: default-src \u2019self\u2019; img-src *; media-src\ntrusted-media.com; script-src trusted-scripts.com\n15.2.5 Permission Dialog Based Access Control\nPermissionsystemsinmodernmobileandwebplatformsenableprotectionoftheprivacyof\ntheir users and reduce the attack surface by controlling access to resources. The control of\naccess to resources on a traditional computer system requires the accurate definition of all\ninvolvedsecurityprincipalsandtheprotectedresourcesinthesystem.Finally,anaccesscon-\ntrol system requires a non-bypassable and trusted mechanism to evaluate access requests\n(the reference monitor) and sound security policies that define the appropriate course of ac-\ntionforallaccessrequests.Basedonthesecuritypolicies,thereferencemonitorcandecide\nwhether it grants access or denies access (cf. the Authentication, Authorisation & Account-\nability(AAA)KnowledgeArea(Chapter13)).\nModernmobileandwebplatformsdeviatefromconventionalcomputersystemsinmultiple\nways:\nKAWeb&MobileSecurity |October2019 Page493 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n15.2.5.1 TheSecurityPrincipals\nTraditional computer systems are primarily multi-user systems with human users and pro-\ncessesrunningontheirbehalf.Modernmobileandwebplatformsextendconventionalmulti-\nuser systems to also consider all involved developers that have their applications installed\nonthesystemassecurityprincipals.\n15.2.5.2 TheReferenceMonitor\nTypically,conventionalcomputersystemsimplementaccesscontrolaspartoftheOperating\nSystem (OS), e.g., the file system and network stack. User-level processes can then extend\nthisOSfunctionalityandimplementtheirownaccesscontrolmechanisms.\nLike conventional computer systems, modern mobile and web platforms build on top of OS\nlow-levelaccesscontrolmechanisms.Additionally,theextensiveframeworksontopofwhich\napplicationsaredevelopedanddeployed,provideextendedinterfaces.Modernwebandmo-\nbileplatformsuseInter-ProcessCommunication(IPC)forprivilegeseparationandcompart-\nmentalisationbetweenappsandbetweenappsandtheoperatingsysteminsteadofallowing\ndirectaccesstoresources.Accesscontrolmechanismsoncallingprocessesareusedtopro-\ntectIPCinterfaces.\n15.2.5.3 TheSecurityPolicy\nIn conventional computer systems, a process can have different privilege levels. It can run\nasthesuperuser,asasystemservice,withuser-levelprivilegesorwithguestprivileges4.All\nprocesses that share the same privilege level have the same set of permissions and can\naccessthesameresources.\nModern mobile and web platforms make a clear distinction between system and third-party\napplications:accesstosecurity-andprivacy-criticalresourcesisonlygrantedtodesignated\nprocesses and third-party applications have, by default, no access to critical resources. If\nsuch access is required, application developers must request permissions from a set com-\nmonlyavailabletoallthird-partyapplications.Mostpermissionsallowdeveloperstousedes-\nignated system processes as deputies to access protected sensitive resources. Those sys-\ntemprocessesserveasreferencemonitorsandenforceaccesscontrolpolicies.\n15.2.5.4 DifferentPermissionApproaches\nMobile and web platforms implement distinct permission approaches. First, platforms dis-\ntinguish different privilege levels. A common distinction is two levels (e.g., as implemented\nonAndroid):normal(e.g.,accesstotheInternet)anddangerouspermissions(e.g.,accessto\nthe camera or microphone). While application developers have to request both normal and\ndangerous permissions to grant their applications access to the respective resources, the\nlevelsdifferforapplicationusers.Normalpermissionsaregrantedsilentlywithoutanyappli-\ncationuserinteraction.However,wheneverapplicationsrequiredangerouspermissions,the\nunderlying mobile or web platform presents users with permission dialogues. While earlier\nAndroidversionsshowedusersalistofallthenecessarypermissionsofanapplicationatin-\nstalltime,modernmobileplatformsandbrowserspresentpermissiondialoguesatrun-time.\nApermissiondialogusuallyisshownthefirsttimeanapplicationrequestsaccesstothecor-\nrespondingresource.Applicationuserscantheneithergrantordenytheapplicationaccess\n4Dependingonthesystem,morelevelsmaybeimplemented.\nKAWeb&MobileSecurity |October2019 Page494 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nto the resource. Modern permission-based access control systems allow greater flexibility\nandcontrolforbothdevelopersandusers.\n(a) Installpermissions (b) Runtimepermissions\nFigure15.2:FirefoxPermissionDialogues\n(a) Install permissions that can still be found (b) Runtimepermissionsonmodernapps\nonlegacyapps\nFigure15.3:AndroidPermissionDialogues\nPermission Dialogues: Attention, Comprehension and Behaviour While permission dia-\nlogues theoretically allow for greater flexibility and control, in practice they tend to have serious\nlimitations.PorterFeltetal.foundthatAndroidapplicationsdeveloperstendtorequestmoreper-\nmissions for their applications than needed [1248]. Hence, applications request access to more\nresourcesthanstrictlynecessary,whichviolatestheleast-privilegeprinciple.Similarlytodevelop-\ners,end-usersstrugglewithpermissiondialogues.PorterFeltetal.[1157]foundthattheyoftendo\nnotcorrectlyunderstandpermissiondialoguesandignorethemduetohabituation(cf.theHuman\nFactorsKnowledgeArea(Chapter4)).\nKAWeb&MobileSecurity |October2019 Page495 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n15.2.6 Web PKI and HTTPS\nThewebPKIandtheHTTPS[456,1249]protocolplayacentralroleinmodernmobileandweb\nplatforms,bothofwhicharebasedonclient-serverarchitectures.Intheweb,webserversor\napplicationsexchangeinformationwithbrowsers.Onmobileplatforms,appsexchangeinfor-\nmationwithbackend(web)servers.Inbothcases,HTTPSshouldalwaysbeusedforsecure\nnetworkconnectionsbetweenclientsandservers.Toestablishsecurenetworkconnections,\nthe web public key infrastructure is used. Using the web PKI and X.509 certificates, clients\nandserverscanauthenticateeachotherandexchangecryptographickeymaterialforfurther\nencrypted information transport. This KA will not provide further details on how the authen-\ntication process and the key exchange procedures work in detail (cf. the Network Security\nKnowledge Area (Chapter 17)). Rather, it gives an overview of aspects specific to web and\nmobileplatforms.\nHTTPSisthe mostwidely deployed secure networkprotocol onthe weband mobile.Itover-\nlaysHTTPontopoftheTLSprotocoltoprovideauthenticationoftheserver,andintegrityand\nconfidentiality for data in transit. While HTTPS offers mutual authentication of servers and\nclients based on X.509 certificates, the primary use is the authentication of the accessed\nserver. Similar to TLS, HTTPS protects HTTP traffic against eavesdropping and tampering\nbypreventingman-in-the-middleattacks.SinceHTTPSencapsulatesHTTPtraffic,itprotects\nURLs,HTTPheaderinformationincludingcookiesandHTTPcontentagainstattackers.How-\never, it does not encrypt the IP addresses and port numbers of clients and servers. While\nHTTPS can hide the information exchanged by clients and servers, it allows eavesdroppers\nto learn the top-level domains of the websites browsers that users visit, and to identify the\nbackendserversthatmobileappscommunicatewith.\nBoth web browsers and mobile apps authenticate HTTPS servers by verifying X.509 certifi-\ncates signed by Certificate Authorities CAs. Browsers and mobile apps come with a list of\npre-installed certificate authorities or rely on a list of pre-installed CAs in the host operating\nsystem. A pre-installed certificate authority list in modern browsers and on modern mobile\nplatforms typically contains hundreds of CAs. To be trusted, an HTTPS server certificate\nneedstobesignedbyonepre-installedCA.5\nModern browsers present users with a warning message (e.g., see Figure 15.4) when the\nserver certificate could not be validated. The warning messages are intended to indicate a\nman-in-the-middle attack. However, common reasons for warning messages are invalid cer-\ntificates, certificates that were issued for a different hostname, network errors between the\nclientandserveranderrorsontheclientsuchasmisconfiguredclocks[1274].Inmostcases,\nbrowser users can click-through a warning message and visit a website even if the server\ncertificate could not be validated [1275]. Browsers use coloured indicators in the address\nbar to display the security information for a website. Websites loaded via HTTP, websites\nloadedviaHTTPSthatloadsomeoftheircontent(e.g.CSSorJavaScriptfiles)overanHTTP\nconnection6 and sites that use an invalid certificate but for which the user clicked through\na warning are displayed as insecure. HTTPS websites with a valid certificate are displayed\nwith a corresponding security indicator (e.g., see Figure 15.4). In contrast, users of mobile,\nnon-browser apps cannot easily verify whether an application uses the secure HTTPS pro-\ntocol with a valid certificate. No visual security indicators similar to those used in browsers\nare available. Instead, users have to trust application developers to take all the necessary\nsecuritymeasuresforHTTPSconnections.\n5SeetheNetworkSecurityKnowledgeArea(Chapter17)fordetailsonthevalidationprocess.\n6Calledmixedcontent.\nKAWeb&MobileSecurity |October2019 Page496 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n(a) WarningmessageforinvalidcertificateinChrome\n(b) Invalidcertificate (c) Valid and (d) Extendedvalidationcertificate\ntrusted certifi-\ncate\nFigure15.4:WarningmessagesandsecurityindicatorsinChrome.\nAs of 2019, most of the popular websites support HTTPS, and the majority of connections\nfrom clients to servers in the web and mobile applications use HTTPS to protect their users\nagainstman-in-the-middleattacks.TofurtherincreasetheadoptionofHTTPS,serveropera-\ntors are encouraged to use HTTPS for all connections and deploy HTTP Strict Transport Se-\ncurity(HSTS)[1276].Additionally,browseruserscaninstallextensionsandpluginstorewrite\ninsecureHTTPURLstosecureHTTPSURLs[1277]ifpossible,andmobileapplicationframe-\nworksmakeHTTPSthedefaultnetworkprotocolforHTTPconnections.\nUsing HTTPS does protect the content against attackers but does not preserve metadata\n(e.g., which websites a user visits). Please refer to the Privacy & Online Rights Knowledge\nArea(Chapter5)formoreinformation,includingprivatebrowsingandtheTornetwork.\nRogue Certificate Authorities and Certificate Transparency The web PKI allows every\ntrusted root certificate authority to issue certificates for any domain. While this allows website\noperators to freely choose a CA for their website, in the past some CAs have issued fraudulent\ncertificates for malicious purposes. One of the most prominent examples is the DigiNotar CA,\nwhichin2011[1278]issuedfraudulentcertificatesformultiplewebsitesincludingGoogle\u2019sGmail\nservice.Nobodyhasbeenchargedfortheattack.However,DigiNotarwentbankruptin2011.Cer-\ntificate transparency [1279] was introduced to fight fraudulent certificate issuance. Certificate\ntransparency provides a tamper proof data structure and monitors all certificate issuance pro-\ncesses of participating CAs. While it cannot prevent fraudulent certificate issuance, it improves\nthe chances of detection. Clients can verify the correct operation of the certificate transparency\nproviders and should only connect to websites that use X.509 certificates that include a signed\ncertificatetimestamp.Certificatetransparencyissupportedbymostmajorcertificateauthorities\nandbrowservendors.\nKAWeb&MobileSecurity |October2019 Page497 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n15.2.7 Authentication\nAuthentication in the web and on mobile platforms is an important security mechanism de-\nsignedtoenablehumanuserstoasserttheiridentitytowebapplications,mobiledevicesor\nmobileapps.Authenticationgoeshandinhandwithauthorisationwhichdescribesthespec-\nificationofaccessprivilegestoresources.Thespecifiedaccessprivilegesarelateronused\ntograntordenyaccesstoresourcesforauthenticatedusers.Thissectionwillnotgiveade-\ntailedoverviewofauthenticationandauthorisationconcepts(cf.theAuthentication,Authori-\nsation&Accountability(AAA)KnowledgeArea(Chapter13))butwillfocusonauthentication\nmechanismsandtechnologiesrelevantforwebandmobileplatforms.\n15.2.7.1 HTTPAuthentication\nFigure15.5:BasicHTTPAuthenticationexchange.\nIn the HTTP context, authentication generally refers to the concept of verifying the identity\nof a client to a server, e.g., by requiring the client to provide some pre-established secrets\nsuch as username and password with a request. This section highlights two widely used\nauthenticationmethodsontheweb,BasicHTTPauthentication,andthemorefrequentlyused\nHTTPForm-basedHTTPauthentication.\nBasic HTTP authentication [1280] is a mechanism whose results are used to enforce ac-\ncess control to resources. It does not rely on session identifiers or cookie data. Nor does\nthe Basic HTTP authentication scheme require the setup of dedicated login pages, as all\nmajor browsers provide an integrated login form. A server can trigger this authentication\noption by sending a response header containing the \u201cHTTP 401 Unauthorised\u201d sta-\ntus code and a \u201cWWW-Authenticate: Basic\u201d field. Credentials entered into this form\nby the client are combined with a \u201c:\u201d (\u201cUsername:Password\u201d), Base64 encoded for transit\n(\u201cVXNlcm5hbWU6UGFzc3dvcmQK\u201d), and added as Authorisation header to the next request\n(\u201cAuthorization: Basic VXNlcm5hbWU6UGFzc3dvcmQK\u201d). An example exchange be-\ntween server and client is shown in Figure 15.5. The Basic authentication scheme is not se-\ncure, as the credentials are transmitted after a simple Base64 encoding, which is trivial to\nreverse. Hence, login credentials are transmitted in plain text across the network, which al-\nlows attackers or network observers to easily steal the credentials. Therefore, Basic HTTP\nauthentication should not be used without additional enhancements that ensure confiden-\ntialityandintegritysuchasHTTPS.\nForm-based HTTP authentication in which websites use a form to collect login credentials\nisawidelyprevalentformofauthenticationinmodernwebandmobileapplications.Forthis\nKAWeb&MobileSecurity |October2019 Page498 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nscheme, an unauthenticated client trying to access restricted content is shown an HTML-\nbased web form that prompts for their credentials. The client then submits the entered cre-\ndentials to the sever (e.g., in a POST request). The server validates the form data and au-\nthenticates the client on successful validation. Similar to Basic authentication, Form-based\nauthenticationexposesusercredentialsinplaintextifnotprotectedbyHTTPS.\n15.2.7.2 MobileDeviceAuthentication\nMobiledevicesdeployavarietyofauthenticationmechanismstounlockdevices,grantusers\naccess,andprotecttheirdatafromillegitimateaccess.Themostcommonmechanismsfor\nmobiledeviceauthenticationarepasswords,PINs,patternsandbiometricfeatures.\nUsers can use common alphanumeric passwords, including special characters. However,\nsincemobiledeviceauthenticationisafrequenttask[1281],manyuserstendtounlocktheir\nmobile device using numerical PINs. Android devices also support unlock patterns (see Fig-\nure 15.6). Instead of choosing a password or PIN, users can pick an unlock pattern from a\n3x3grid.\nModern mobile devices allow users to authenticate using biometric features, including fin-\ngerprintandfacialrecognition.Theseauthenticationfeaturesrelyonhardwaresecurityprim-\nitives,suchasARM\u2019sTrustZone(cf.theHumanFactorsKnowledgeArea(Chapter18)).\n(a) PIN (b) Pattern (c) Password (d) Fingerprint In- (e) FacialRecogni-\ndicator tionIndicator\nFigure15.6:AndroidDeviceUnlocking\nAndroid Unlock Patterns Similar to passwords (see Section 15.2.9) device unlock patterns\nsufferfrommultipleweaknesses.Uellenbecketal.[384]conductedastudytoinvestigateusers\u2019\nchoicesof3\u00d73unlockpatterns.Theyfoundempiricalevidencethatuserstendtochoosebiased\npatterns,e.g.,userstypicallystartedintheupperleftcornerandselectedthree-pointlongstraight\nlines.Hence,similartoregularpasswords(cf.theHumanFactorsKnowledgeArea(Chapter4))the\nentropyofunlockpatternsisratherlow.Inadditiontouserschoosingweakunlockpatterns,the\nmechanismisvulnerabletoshouldersurfingattacks(seeSection15.3.3).Asacountermeasure,\nDeLucaetal.[1282]proposetousethebackofadevicetoauthenticateusers.\nKAWeb&MobileSecurity |October2019 Page499 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n15.2.8 Cookies\nWeb servers can associate stateful information with particular clients by using HTTP cook-\nies[1283].Cookieinformation(e.g.,IDsofitemsaddedtotheshoppingcartinanonlineshop)\nisstoredbytheclient.Cookiesallowclientsandserverstoincludetheiruniquesessionidenti-\nfiersineachHTTPrequest-response,avoidingtheneedforrepeatedauthentication.Session\ncookiesexpirewhenthesessionisclosed(e.g.,bytheclientclosingthebrowser)butpersis-\ntentcookiesonlyexpireafteraspecifictime.\nCookie-basedauthenticationallowsclientstore-establish sessionseverytimetheysendre-\nquests to the server with a valid cookie. Cookie-based session management is vulnerable\nto the hijacking of session identifiers [1284]. Hijackers who post valid session cookies can\nconnecttotheattackedserverwiththeprivilegesoftheauthenticatedvictim.\nCookies can also be used to track users across multiple sessions by providers. This be-\nhaviourisgenerallyjeopardisinguserprivacy(cf.theAdversarialBehavioursKnowledgeArea\n(Chapter7)andthePrivacy&OnlineRightsKnowledgeArea(Chapter5)).\n15.2.9 Passwords and Alternatives\nPasswords are the most widely deployed mechanism to let users authenticate to websites\nand mobile applications and protect their sensitive information against illegitimate access\nonline.Theyarethedominantmethodforuserauthenticationduetotheirlowcost,deployabil-\nity,convenienceandgoodusability.However,theuseofpasswordsformostonlineaccounts\nharms account security [1250]. Since humans tend to struggle memorising many different\ncomplicatedpasswords,theyoftenchooseweakpasswordsandre-usethesamepassword\nformultipleaccounts.Weakpasswordscaneasilybeguessedbyattackersofflineoronline.\nRe-used passwords amplify the severity of all password attacks. One compromised online\naccountresultsinallotheraccountsprotectedwiththesamepasswordasvulnerable.While\npasswordguidelinesinthepastfrequentlyrecommendedtheuseofcomplexpasswords,cur-\nrentguidelinesstatethatrequiringcomplexpasswordsactuallyweakenspasswordsecurity\nand advise against policies that include password complexity [1285, 1286]. These aspects\narefurtherdiscussedintheHumanFactorsKnowledgeArea(Chapter4).\nOnline service providers deploy various countermeasures to address security issues with\nweakpasswordsandpasswordre-use:\nKAWeb&MobileSecurity |October2019 Page500 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n15.2.9.1 PasswordPolicies\nPassword policies are rule sets to encourage users to choose stronger passwords. Some\npassword policies also address the memorability issue. To support stronger passwords,\nmostrulesaddresspasswordlengthandcomposition,blacklistsandthevalidityperiodofa\npassword[1287,1288].\n15.2.9.2 PasswordStrengthMeters\nPasswordStrengthMeters(PSMs)pursuethesamegoalaspasswordpoliciesandaimtoen-\ncouragethechoiceofstrongerpasswords.PSMstypicallyprovidevisualfeedbackorassign\npasswordsscorestoexpresspasswordstrength(seeFigure15.7)[1289].\nFigure15.7:Apasswordstrengthmeter\nHowever, addressing weak passwords and password re-use by deploying restrictive poli-\ncies or PSMs has only a limited effect on overall password security [1290]. Hence, service\nproviderscanuseextensionstosimplepasswordstoincreaseauthenticationsecurity.\n15.2.9.3 PasswordManagers\nPassword managers can help users generate, store and retrieve strong passwords. Strong\npasswords are generated and stored using secure random number generators and secure\nencryption. They come as locally installable applications, online services or local hardware\ndevices. While they can help users use more diverse and stronger passwords, their effect\non overall password security is limited due to usability issues [1291]. For a more detailed\ndiscussionpleaserefertotheHumanFactorsKnowledgeArea(Chapter4).\n15.2.9.4 Multi-FactorAuthentication\nInstead of requiring only one factor (e.g., a password), multi-factor authentication systems\nrequire users to present multiple factors during the authentication process [1292]. Website\npasswordsareoftencomplementedwithasecondfactorfortwo-factorauthentication(2FA).\nMostcommonly,thesecondfactortypicallymakesuseofamobiledevice.Soinadditiontoa\npassword,usersneedtohavetheirdeviceathandtoreceiveaone-timetokentoauthenticate\nsuccessfully. The European Payment Services Directive 2 (PSD2) requires 2FA for all online\npayment services in web and mobile environments (cf. the Authentication, Authorisation &\nAccountability(AAA)KnowledgeArea(Chapter13)).\nKAWeb&MobileSecurity |October2019 Page501 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n15.2.9.5 WebAuthn\nTheWebAuthn(WebAuthentication)[1293]webstandardisacorecomponentoftheFIDO2\nproject(cf.theAuthentication,Authorisation&Accountability(AAA)KnowledgeArea(Chap-\nter 13)) and aims to provide a standardised interface for user authentication for web-based\napplications using public-key cryptography. WebAuthn is supported by most modern web-\nbrowsers and mobile operating systems. It can be used in single-factor or multi-factor au-\nthentication mode. In multi-factor authentication mode PINs, passcodes, swipe-patterns or\nbiometricsaresupported.\n15.2.9.6 OAuth\nWhile not an authentication mechanism itself (cf. the Authentication, Authorisation & Ac-\ncountability(AAA)KnowledgeArea(Chapter13)),OpenAuthorisation(OAuth)[1294]canbe\nused for privacy-friendly authentication and authorisation for users against third-party web\napplications.OAuthusessecuretokensinsteadofrequiringuserstoprovidelogincredentials\nsuchasusernamesandpasswords.Onbehalfoftheirusers,OAuthserviceprovidersprovide\naccess tokens that authorise specific account information to be shared with third-party ap-\nplications.MorerecentsuccessorsoftheOAuthprotocolincludingOAuth2[1186]orOpenID\nConnect [1295] support federations (cf. the Authentication, Authorisation & Accountability\n(AAA) Knowledge Area (Chapter 13)). Large providers of online services such as Google or\nFacebook can act as identity providers to authenticate users, thus helping users to reduce\nthenumberoflogincredentialsandaccounts.Whilesuchprotocolsaimtoprovideimproved\nsecurity,thecorrectandsecureimplementationofsuchcomplexprotocolswasshowntobe\nerror-proneandmightallowmalicioususerstorunimpersonationattacks[1296].\n15.2.10 Frequent Software Updates\nFrequent software updates are a fundamental security measure and particularly crucial for\nwebandmobileplatforms.Thissectiondiscussesthedifferentcomponentsintheweband\nmobile ecosystems that require regular updates, the different update strategies, and their\npros and cons. Traditionally, browser and mobile device updates required their users to in-\nstall updates manually whenever new versions were available. Users had to keep an eye on\nsoftware updates and were responsible for downloading and installing new releases. This\napproach was error-prone and resulted in many outdated and insecure deployed software\ncomponents.\nMost of the critical components on modern web and mobile platforms have short release\ncycles.Webbrowsers,includingGoogleChromeandMozillaFirefox,implementauto-update\nfeaturesandfrequentlypushnewversionsandsecuritypatchestotheirusers.\nMobileplatformsalsoprovideautomaticapplicationupdatesforthird-partyapps.Whilethis\napproachgenerallyresultsinquickerupdatesandthetimelydistributionofsecuritypatches,\nautomatic mobile application updates are only enabled by default for devices connected to\nWiFi.Devicesconnectedtoacellularnetwork(e.g.,3G\/4G)donotbenefitfromautomaticap-\nplicationupdatesbydefault.Thisupdatebehaviourensuresmostthird-partyapplicationup-\ndatesareinstalledonmobiledeviceswithinaweek[1297].Automaticthird-partyapplication\nupdatesworkwellonmobiledevices.Mobileoperatingsystemupdatebehaviourheavilyde-\npendsontheplatform.Inparticular,manynon-GoogleAndroiddevicessufferfromoutdated\nandinsecureoperatingsystemversions.\nOverall, modern web and mobile platforms recognised the disadvantages of non-automatic\nKAWeb&MobileSecurity |October2019 Page502 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nsoftware updates and now provide automatic or semi-automatic platform or application up-\ndatesinmostcases.\nOutdated Third Party Libraries While frequent software updates are crucial in general, up-\ndatesofthird-partylibrariesisaparticularlyimportantsecuritymeasureforsoftwaredevelopers\nwhoneedtopatchtheirowncodeanddistributeupdates,whilealsotrackingvulnerabilitiesinli-\nbrariestheyuseandupdatingthemforbettersecurity.Derretal.[1298]conductedameasurement\nstudyofthird-partylibraryupdatefrequenciesinAndroidapplicationsandfoundthatasignificant\nnumberofdevelopersuseoutdatedlibraries,exposingtheiruserstosecurityissuesintheaffected\nthirdpartylibraries.Lauingeretal.[1299]conductedasimilarstudyforJavaScriptlibrariesinweb\napplicationsandalsofoundmanywebsitesthatincludeoutdatedandvulnerablelibraries.\n15.3 CLIENT SIDE VULNERABILITIES AND MITIGATIONS\n[1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312]\nThissectioncoversattacksandtheircountermeasureswithafocusontheclient.Itdiscusses\nissuesinbothmodernwebbrowsersandmobiledevices.Theillustratedsecurityissueshigh-\nlightaspectsthathavedominatedsecuritydiscussionsinrecentyears.Wefocusonattacks\nthatexploitweaknessesintheinteractionbetweenusersandwebbrowsersandmobileapps.\nWe then discuss challenges resulting from the trend of storing more and more information\non the client instead of the server. Finally, we discuss physical attacks that do not focus on\nexploitingsoftwareorhumanvulnerabilities,butexploitweakpointsinmobiledevices.\n15.3.1 Phishing & Clickjacking\nThis section presents two prevalent issues that exploit user interface weaknesses of both\nweb andmobile clients. Phishing and clickjackingrely on issueshumans have with properly\nverifyingURLsandthedynamiccontentofrenderedHTMLdocuments.\n15.3.1.1 Phishing\nPhishingattacksarefraudulentattacksthataimtostealsensitiveinformation,includinglogin\ncredentialsandcreditcardnumbersfromvictims[1302].Commontypesofphishingattacks\nuseemail,websitesormobiledevicestodeceivevictims.Attackersdisguisethemselvesas\ntrustworthy parties and send fake emails, show fake websites or send fake SMS or instant\nmessages. Fake websites may look authentic. Attackers can use successfully stolen login\ncredentials or credit card numbers to impersonate victims and access important online ac-\ncounts.Successfulphishingattacksmayresultinidentitytheftorlossofmoney.\nAttackers commonly forge websites that appear legitimate to trick users into believing they\nareinteractingwiththegenuinewebsite.Toinitiateaphishingattack,attackersplantmanip-\nulated links on users via email, a website or any other electronic communication. The ma-\nnipulated link leads to a forged website that appears to belong to the genuine organisation\nbehind the website in question. Attackers often spoof online social media, online banking\norelectronicpaymentproviderwebsites.Theytrickvictimsintofollowingmanipulatedlinks\nusingmisspelledURLs,subdomainsorhomographattacks.\nKAWeb&MobileSecurity |October2019 Page503 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nExample:PhishingURL InthefollowingexampleURL:\nhttps:\/\/paymentorganization.secure.server.com,\nitappearsthattheURLpointstothesecure.serversectionofthepaymentorganizationwebsite.How-\never,infactthelinkleadstothepaymentorganization.securesectionoftheserver.comwebsite.\nTomakeforgedwebsiteslookevenmoreauthentic,somephishersalterabrowser\u2019saddress\nbar by replacing the original address bar with a picture of the legitimate URL or by replacing\ntheoriginaladdressbarwithanewone.Addressbarmanipulationattacksrequiretheuseof\nJavaScriptcommands.Additionally,phishersleverageInternationalisedDomainName(IDN)\nhomographattacks[1313].Suchattacksexploitthatuserscannoteasilydistinguishdifferent\ncharacterencodings.Forexample,theletters\u201dl\u201dand\u201dI\u201d(capitali)arehardtodistinguish,and\nby replacing the Latin characters \u201da\u201d with the cyrilic character \u201da\u201d in the https:\/\/paypal.com url,\nuserscandeceptivelyberedirectedtoaphishedPayPalwebsite.[1314].Attacksthatinvolve\nmanipulated URLs and address bars are even harder to detect in mobile browsers since the\naddress bar is not visible during regular browsing. Website phishing is one of the most fre-\nquentattacks.MosthumanusersfindithardtotospotphishingURLsandwebsites[1300].\nTherefore, common countermeasures are anti-phishing training and public awareness cam-\npaigns[1301]thattrytosensitiseusersandteachthemhowtospotphishingURLs.Modern\nbrowsers deploy technical security measures, including blacklists and visual indicators that\nhighlightthetop-leveldomainofaURL,e.g.GoogleChromeshowsURLsusinganencoding\nthatexposesdeceptivecharactersinIDNattacks7.\nDrive-by-download Attacks Drive-by-download attacks happen when users visit a website,\nclick on a link or on an attachment in a phishing email or on a malicious popup window. While\nbeingageneralproblemintheweb,drive-by-downloadsplayaparticularroleinphishingattacks.\nInstead of visiting a benign website, drive-by-download attacks download and install malware\n(cf.theMalware&AttackTechnologyKnowledgeArea(Chapter6))onauser\u2019scomputer.Attack-\ners need to fingerprint victim clients and exploit vulnerable software components on the client\u2019s\ncomputer to plant the malware. Detecting such attacks is an active research area and includes\napproachessuchasanomalyorsignaturebasedmalwaredetection[814].\n15.3.1.2 Clickjacking\nInaclickjackingattack,attackersmanipulatethevisualappearanceofawebsitetotrickusers\ninto clicking on a fake link, button, or image. Clickjacking is also known as a user interface\nredressattackandbelongstotheclassofconfuseddeputyattacks[1303].Attackersfooltheir\nvictimsusingtransparentoropaquelayersoveroriginalwebsites.Whilevictimsbelievethey\nhaveclickedontheoverlayelement,theoriginalwebsiteelementisclickedon.Attackerscan\nthus make their victims trigger arbitrary actions on the original website. The attack website\nuses an iFrame to load the target website and can make use of the absolute positioning\nfeatures of iFrames for correct visual alignment. Thus, it is hard for victims to detect the\nattack elements over the original website. Clickjacking attacks are particularly dangerous\nwhen victims have already logged in to an online account and visit their account settings\nwebsite.Inthosecases,anattackercantrickthevictimintoperformingactionsonatrusted\nsitewhenthevictimisalreadyloggedin.Oneofthemostprominentclickjackingattackshit\nthe Adobe Flash plugin settings page [1304]. Attackers used invisible iFrames to trick their\n7cf.https:\/\/www.chromium.org\/developers\/design-documents\/idn-in-google-chrome\nKAWeb&MobileSecurity |October2019 Page504 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nvictims into changing the plugin\u2019s security settings and permitting the attackers to access\nthemicrophoneandcameraoftheirvictims\u2019machines.\nClickjacking attacks can be used to launch other attacks against websites and their\nusers, including Cross-Site Request Forgery and Cross-Site Scripting attacks (see Sec-\ntion15.4.1)[1303].\nAclickjackingattackisnotaprogrammingmistakebutaconceptualproblemwithJavaScript.\nHence,detectionandpreventionarenottrivial.Detectingandpreventingclickjackingattacks\ncan be done both server- and client-side. Web browser users can disable JavaScript and\niFrames to prevent clickjacking attacks. However, since this would break many legitimate\nwebsites, different browser plugins (e.g., NoScript [1305]) allow the controlled execution of\nJavaScriptscriptsonbehalfoftheuser.Inordertocontaintheimpactofclickjackingattacks,\nusers should log out of online accounts when leaving a website, although this could be im-\npractical.Inordertopreventclickjackingattacksontheserver-side,websitedevelopersneed\nto make sure that a website is not frame-able, i.e. a website does not load if it is inside an\niFrame.WebsitescanincludeJavaScriptcodetodetectwhetherawebsitehasbeenputinto\naniFrameandbreakoutoftheiFrame.ThisdefencetechniqueiscalledFrameBusting[1306].\nHowever, since users might have disabled JavaScript, this method is not reliable. The rec-\nommended server-side defence mechanism is to set a proper HTTP response header. The\nX-FRAME-OPTIONS header can be set to DENY, which will prevent a website being loaded\ninsideaniFrame.\nClickjackingattacksaffectbothdesktopandmobilewebbrowsers.\nPhishing and Clickjacking on Mobile Devices Phishing and Clickjacking are not limited to\nbrowsersandtheweb.Mobileapplicationusersaresusceptibletobothattacks.Aonzoetal.[1315]\nfindthatitispossibletotrickusersintoanend-to-endphishingattackthatallowsattackerstogain\nfullUIcontrolbyabusingAndroid\u2019sInstantAppfeatureandpasswordmanagerstosteallogincre-\ndentials.Fratantonioetal. [1316]describetheCloak&Daggerattackthatallowsamaliciousap-\nplicationwithonlytwopermissions(cf.Section15.2.5)totakecontrolovertheentireUIloop.The\nattackallowsforadvancedclickjacking,keylogging,stealthyfishingandsilentphoneunlocking.\n15.3.2 Client Side Storage\nClient-side storage refers to areas that a browser or operating system provides to websites\nor mobile applications to read and write information. Storage is local to the client and does\nnot require server-side resources or an active Internet connection. At the same time, mali-\ncioususersmaymanipulatestoredinformation.Hence,client-sidestorageareasneedtobe\nprotectedfrommaliciousaccess.Thissectiondescribescommonclient-sidestorageareas\nandtheirprotectionmechanisms.\nKAWeb&MobileSecurity |October2019 Page505 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n15.3.2.1 ClientSideStorageintheBrowser\nHistorically,client-sidebrowserstoragewasonlyusedtostorecookieinformation(seeSec-\ntion15.2.8).However,duetotheirsimpledesignandlimitedcapacity,cookiescannotbeused\ntostorelargeorcomplexamountsofinformation.WiththeriseofHTML5,morepowerfuland\nfeature-rich alternatives for client-side storage in the browser exist. These include WebStor-\nage[1307],whichissimilartocookiesandstoreskey-valuepairs,andIndexedDB[1308],which\nserves as a database in the vein of noSQL databases and can be used to store documents,\notherfilesandbinaryblobs.\nAs mentioned, the primary security issue with client-side storage mechanisms is that mali-\ncioususerscanmanipulatethem.Toguaranteeintegrityforsensitiveinformation(e.g.,ses-\nsion information), developers are advised to cryptographically sign the data stored on the\nclientandverifyituponretrieval.\nInadditiontoinformationintegrity,asecondimportantaspectofWebStorageandIndexedDB\nstorageisthatstoredinformationisnotautomaticallyclearedafterusersleaveawebsite.To\nstoreinformationinasession-likefashion,webapplicationdevelopersareadvisedtorelyon\nthesessionStorageobjectoftheWebStorageAPI[1310].\n15.3.2.2 ClientSideStorageinMobileApplications\nInmobileapplications,handlingclient-sidestoragesecurityalsodependsonthetypeofinfor-\nmationandstoragemechanism,e.g.,privatestorageofanapplicationorpublicstoragesuch\nasanSDcard.Mostimportantly,datashouldbedigitallysignedandverified(cf.theCryptog-\nraphy Knowledge Area (Chapter 10)) for both browser and mobile client storage purposes.\nIt is recommended that developers sign and encrypt sensitive information and apply proper\nuserinputsanitisation.ThisisparticularlyrelevantforsharedstoragesuchasSD-cardsthat\ndonotusesecureaccesscontrolmechanisms.Instead,properaccessadministrationmech-\nanismsareprovidedforstorageareasthatareprivatetoanapplication.\nSensitive Information Leaks in Android Applications Encketal.[427]investigatedthese-\ncurity of 1,100 popular Android applications. Amongst other things, they found that a significant\nnumberofappsleakedsensitiveuserinformationtopubliclyreadablestoragelocationssuchas\nlog files and the SD card. Reardon et al. [1317] discovered that some sensitive information leaks\naremadeintentionallytopasssensitiveinformationtoanother,collaboratingandmaliciousapp.\nKAWeb&MobileSecurity |October2019 Page506 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n15.3.3 Physical Attacks\nInstead of attacking web or mobile applications\u2019 code, physical attacks aim to exploit bugs\nand weak points that result from using a device. We focus on two representative examples\nbelow.\n15.3.3.1 Smudgeattacks\nInasmudgeattack,anattackertriestolearnpasswords,PINsorunlockpatternsenteredona\ntouchscreendevice.Themainproblemwithenteringsensitiveunlockinformationthrougha\ntouchscreenistheoilysmudgesthatusers\u2019fingersleavebehindwhenunlockingadevice.Us-\ninginexpensivecamerasandimageprocessingsoftware,anattackercanrecoverthegrease\ntrailsandinferunlockpatterns,passwords,andPINs[1311].Toperformasmudgeattack,an\nattackerneedsaclearviewofthetargetdisplay.\n15.3.3.2 ShoulderSurfing\nShoulder surfing is a physical attack where an attacker tries to obtain sensitive information\nsuchaspasswords,PINs,unlockpatterns,orcreditcardnumbers[1312].Forashouldersurf-\ning attack, an attacker needs a clear view of the target display. The attacker can mount a\nshoulder surfing attack either directly by looking over the victim\u2019s shoulder or from a longer\nrangebyusingdedicatedtoolssuchascamerasortelescopes.Shouldersurfingattacksare\nparticularly dangerous for mobile device users when authenticating to the device or online\nservicesinpublicspacessuchastrains,railways,andairports.\n15.4 SERVER SIDE VULNERABILITIES AND MITIGATIONS\n[1318,1319,1320,1321,1322,1323,1324,1325,1326,1327]\nThissectiondiscussesserver-sidesecurity.Itprovidesdetailsforcommonaspectsofserver\nsecurity, including well-known vulnerabilities and mitigations. The section discusses root\ncauses,illustratesexamples,andexplainsmitigations.Theaspectsdiscussedbelowarecen-\ntral for the web and mobile environments and dominated many of the security discussions\ninthisareainthepast.\n15.4.1 Injection Vulnerabilities\nInjection attacks occur whenever applications suffer from insufficient user input validation\nso that attackers can insert code into the control flow of the application (cf. the Software\nSecurity Knowledge Area (Chapter 14)). Prevalent injection vulnerabilities for web and mo-\nbile applications are SQL and Shell injections [1253]. Due to inadequate sanitisation of user\ninput, requests to a database or shell commands can be manipulated by an attacker. Such\nattackscanleakormodifyinformationstoredinthedatabaseorissuecommandsonasys-\ntem in ways developers or operators have not intended. The main goal of injection attacks\nis to circumvent authentication and expose sensitive information such as login credentials,\npersonallyidentifiableinformation,orvaluableintellectualpropertyofenterprises.\nInjection vulnerabilities can be addressed by adequately sanitising attacker-controlled infor-\nmationanddeployingproperaccesscontrolpolicies.Thegoalofinputsanitisationistofilter\nKAWeb&MobileSecurity |October2019 Page507 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ninvalidanddangerousinput.Additionally, strictaccesscontrolpoliciescan beimplemented\ntopreventinjectedcodefromaccessingormanipulatinginformation[1318].\n15.4.1.1 SQL-Injection\nSQL-injection attacks refer to code injections into database queries issued to relational\ndatabases using the Structured Query Language (SQL). Many web and mobile applications\nallow users to enter information through forms or URL parameters. SQL injection occurs if\nsuch user input is not filtered correctly for escape characters and then used to build SQL\nstatements.EnablingattackerstomodifySQLstatements canresult inmaliciousaccessor\nmanipulationofinformationstoredinthedatabase.\nExample:SQLInjectionattack Thestatementbelowillustratesthevulnerability.\nvuln_statement = \" \u2019SELECT * FROM creditcards WHERE number = \u2019\" +\n1\nuser_input + \" ; \u2019 \"\nThe intention of the statement is to retrieve credit card information for a given user input. An\nexampleforanexpectedinput123456789.\nHowever,thestatementaboveallowsmaliciousvaluesfortheuser_inputvariable.Anattacker\nmightprovide\u2019 OR \u20191\u2019=\u20191asinputwhichwouldrenderthefollowingSQLstatement:\nvuln_statement = \" \u2019SELECT * FROM creditcards WHERE number = \u2019 \u2019\n1\nOR \u20191 \u2019= \u20191 \u2019; \"\nInsteadofretrievingdetailedcreditcardinformationonlyforonespecificcreditcardnumber,the\nstatementretrievesinformationforallcreditcardsstoredinthedatabasetable.Apotentialweb\napplicationwiththeaboveSQLinjectionvulnerabilitycouldleaksensitivecreditcardinformation\nforallusersoftheapplication.\nThe consequences of the above SQL injection vulnerability might be directly visible to the\nattacker if all credit card details are listed on a results page. However, the impact of an SQL\ninjectioncanalsobehiddenandnotvisibletotheattacker.\nblind SQL injections [1319], do not display the results of the vulnerability directly to the at-\ntacker (e.g., because results are not listed on a website). However, the impact of an\nattack might still be visible through observing information as part of a true-false re-\nsponse of the database. Attackers might be able to determine the true-false response\nbasedonthewebapplicationresponseandthewaythewebsiteisdisplayed.\nsecondorder IncontrasttotheprevioustypesofSQLinjectionattacks,secondorderattacks\noccurwheneverusersubmittedinputisstoredinthedatabaseforlateruse.Otherparts\noftheapplicationthenrelyonthestoreduserinputwithoutescapingorfilteringitprop-\nerly.\nOnewaytomitigateSQLinjectionattacksiswiththeuseofpreparedstatements[1320,1321].\nInsteadofembeddinguserinputintorawSQLstatements(seeabove),preparedstatements\nuse placeholder 8 variables to process user input. Placeholder variables are limited to store\nvaluesofagiventypeandprohibittheinputofarbitrarySQLcodefragments.SQLinjections\nattacks would result in invalid parameter values in most cases and not work as intended\nby an attacker. Also, prepared statements are supported by many web application devel-\nopment frameworks at the coding level using Object Relational Mapping (ORM) interfaces.\n8Alsocalledbindvariables.\nKAWeb&MobileSecurity |October2019 Page508 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nORMs do not require developers to write SQL queries themselves but generate database\nstatementsfromcode.Whilepreparedstatementsareaneffectivemitigationmechanism,a\nfurther straightforward way is to escape characters in user input that have a special mean-\ning in SQL statements. However, this approach is error-prone, and many applications that\napply some form of SQL escaping are still vulnerable to SQL injection attacks. The reasons\nforthemistakesareoftenincompletelistsofcharactersthatrequireescaping.Whenescap-\ning is used, developers should rely on functions provided by web application development\nframeworks (e.g. the mysqli_real_escape_string() function in PHP) instead of im-\nplementingtheirownescapingfunctionality.\n15.4.1.2 CommandInjections\nThistypeofinjectionattackaffectsvulnerableapplicationsthatcanbeexploitedtoexecute\narbitrarycommandsonthehostoperatingsystemofawebapplication[1328].SimilartoSQL\ninjectionattacks,commandinjectionsaremostlypossibleduetoinsufficientuserinputvali-\ndation.Vulnerablecommandsusuallyrunwiththesameprivilegesasthehostapplication.\nAnexampleofacommandinjectionattackisawebapplicationthatconvertsuser-provided\nimages using a vulnerable image command line program. Providing malicious input (e.g., a\nfilename or a specially crafted support graphic that includes malicious code) might allow\nattackers to exploit insufficient input validation and extend the original command or run ad-\nditionalsystemcommands.\nAmitigationforcommandinjectionattacksistoconstructthecommandstrings,includingall\nparametersinasafewaythatdoesnotallowattackerstoexploitmaliciousstringinput.Inad-\nditiontoproperinputvalidationduetoescaping,followingtheprincipleofleast-privilegeand\nrestricting the privileges of system commands and the calling application is recommended.\nThe number of callable system commands should be limited by using string literals instead\nofrawuser-suppliedstrings.Inordertofurtherincreasesecurity,regularcodereviewsarerec-\nommended,andvulnerabilitydatabases(e.g.,theCVE[1322]database)shouldbemonitored\nfor new vulnerabilities. Finally, if possible, executing system commands should be avoided\naltogether. Instead, the use of API calls in the respective development framework is recom-\nmended.\n15.4.1.3 UserUploadedFiles\nFilesprovidedbyuserssuchasimagesorPDFshavetobehandledwithcare.Maliciousfiles\ntrigger unwanted command execution on the host operating system of the server, overload\nthehostsystem,triggerclient-sideattacks,ordefacevulnerableapplications[1253].\nExample: Online Social Network An example application could be an online social network\nthatallowsuserstouploadtheiravatarpicture.Withoutpropermitigationtechniquesinplace,the\nwebapplicationitselfmightbevulnerable.Amalicioususercoulduploada.phpfile.Accessing\nthatfilemightprompttheservertoprocessitasanexecutablePHPfile.Thisvulnerabilitywould\nallowattackerstobothexecutecodeontheserverwiththepermissionsofthePHPprocessand\nalsocontrolthecontentservedtootherusersoftheapplication.\nTopreventattacksthroughuser-uploadedfiles,bothmeta-dataincludingfilenamesandthe\nactual content of user-uploaded files need to be restricted and filtered, e.g. looking for mal-\nware in uploaded files. Filenames and paths should be constructed using string literals in-\nsteadofrawstringsandpropermime-typesforHTTPresponsesusedwheneverpossible.\nKAWeb&MobileSecurity |October2019 Page509 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nFiles that are only available for download and should not be displayed inline in the browser,\ncan be tagged with a Content-Disposition HTTP response header [1323]. Another suc-\ncessfulmitigationfortheaboveissueistoservefilesfromadifferentdomain.Ifthedomainis\nnotasubdomainoftheoriginaldomain,theSOP15.2.4.2preventscookiesandothercritical\ninformation from being accessible to the malicious file. Additionally, JavaScript and HTML\nfilesareprotectedbytheSOPaswell.\n15.4.1.4 LocalFileInclusion\nThis type of vulnerability is a particular form of the above command injection or user-\nuploaded files vulnerabilities [1253]. For example, attackers can exploit a command injec-\ntion, use a malformed path in a database or a manipulated filename. The file path resulting\nfrom one of these vulnerabilities can be crafted to point to a local file on the server, e.g., a\n.htaccess or the \/etc\/shadow file. A vulnerable web application might then access the\nmaliciously crafted file path and instead of loading a benign file, read and send the content\noftheattacker-chosenfileande.g.leaklogincredentialsinthe\/etc\/shadowfile.\nIn addition to sanitisation of file path parameters such as leading \/ and .. in user input,\ntheapplicationoftheleastprivilegeprincipleisrecommended.Awebapplicationshouldbe\nexecutedwithminimalprivilegesandsothatitcannotaccesssensitivefiles.\n15.4.1.5 Cross-SiteScripting(XSS)\nCross-Site Scripting (XSS) [1324] attacks are injection vulnerabilities that allow attackers to\ninject malicious scripts (e.g., JavaScript) into benign websites. They can occur whenever\nmaliciouswebsiteusersareabletosubmitclientscriptstowebapplicationsthatredistribute\nthemaliciouscodetootherend-users.Commonexamplesofwebsitesthatarevulnerableto\nXSS attacks are message forums that receive user content and show it to other users. The\nprimary root cause for XSS vulnerabilities is web applications that do not deploy effective\ninputvalidationmechanisms.Untrustedandnon-validateduser-provideddatamightcontain\nclient-side scripts. Without proper user input validation, a malicious JavaScript previously\nprovidedbyoneuser,mightbedistributedtootherusersandmanipulatethewebsitetheyare\nvisitingorstealsensitiveinformation.InanXSSattack,theclientbrowsercannotdetectthe\nmalicious code, since it is sent from the original remote host, i.e. same-origin-policy based\nsecuritymeasuresareineffective.WedistinguishtwotypesofXSSattacks:\nstored InastoredXSSattackthemaliciousscriptispermanentlystoredonthetargetserver\n(e.g. in a database) and distributed to the victims whenever they request the stored\nscript for example as part of a comment in a message forum. Stored XSS attacks are\nalsocalledpermanentorType-IXSS.\nreflected In a reflected XSS attack, the malicious script is not permanently stored on the\ntarget server, but reflected by the server to the victims. Malicious scripts in reflected\nattacks are distributed through different channels. A common way of delivering a ma-\nlicious script is to craft a link to the target website. The link contains the script and\nclickingthelinkexecutesthemaliciousscriptinthewebsite\u2019sscriptexecutioncontext.\nReflectedXSSattacksarealsocallednon-permanentorType-IIXSS.\nPreventingbothtypesofXSSattacksrequiresrigoroususerinputvalidationandescapingby\ntheserver.Themosteffectivemeansofinputvalidationisawhitelistapproach,whichdenies\nany input that is not explicitly allowed. For proper and secure entity encoding, the use of a\nKAWeb&MobileSecurity |October2019 Page510 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nsecurity encoding library is recommended, since writing encoders is very difficult and code\nreviewincombinationwiththeuseofstaticcodeanalysistoolsisalsovaluable.\nSince eliminating XSS vulnerabilities entirely due to user input sanitization is hard, different\napproaches are discussed in the literature. A promising approach is the randomisation of\nHTMLtagsandattributes.Webapplicationsrandomisetheirordersoclientscandistinguish\nbetweenbenignandtrustedcontentandpotentiallyuntrustedmaliciouscontent.Aslongas\nan attacker doesnot know the randomisation mapping, clientscan successfully distinguish\ntrustedfromuntrustedscripts[1329].\n15.4.1.6 Cross-SiteRequestForgery\nCrossSiteRequestForgery(CSRF)[1325]attacksmisleadvictimsintosubmittingmalicious\nHTTP requests to remote servers. The malicious request is executed on behalf of the user\nand inherits their identity and permissions. CSRF attacks are so dangerous because most\nrequests to remote servers include credentials and session information associated with a\nuser\u2019s identity, including session cookies. Authenticated users are particularly attractive vic-\ntimsforattackerssinceitcanbehardforremoteserverstodistinguishbetweenbenignand\nmaliciousrequestsaslongastheyaresubmittedfromthevictim\u2019smachine.CSRFattacksdo\nnoteasilyallowattackerstoaccesstheserverresponseforthemaliciousrequest.Therefore,\nthemaingoalofaCSRFattackistotrickvictimsintosubmittingstate-changingrequeststo\nremote servers. Attractive targets are requests that change the victim\u2019s credentials or pur-\nchasesomething.\nExample: Online Banking In the following online banking scenario Alice wishes to trans-\nfer 50 EUR to Bob using an online banking website that is vulnerable to a CSRF attack. A be-\nnign request for an authenticated user Alice for the mentioned scenario could be similar to GET\nhttps:\/\/myonlinebank.net\/transaction?to=bob&value=50.Inafirststep,anattacker\ncan craft a malicious URL such as https:\/\/myonlinebank.et\/transaction?to=attacker&value=50 and re-\nplace the intended recipient of the transaction with the attacker\u2019s account. The second step for\nsuccessful CSRF attack requires the attacker to trick Alice into sending the malicious request\nwith her web browser, e.g. by sending a SPAM email containing the request which Alice subse-\nquently clicks on. However, CSRF attacks are not limited to HTTP GET requests but also affect\nPOSTrequests,e.g.bycraftingmalicious<form>tags.\nMany misconceptions lead to ineffective countermeasures. CSRF attacks cannot be pre-\nvented by using secret cookies because all cookies are sent from a victim to the remote\nserver. Also, the use of HTTPS is ineffective as long as the malicious request is sent from\nthevictim,becausetheprotocoldoesnotmatterandtheuseofPOSTrequestsforsensitive\ninformationisinsufficientsinceattackerscancraftmaliciousHTMLformswithhiddenfields.\nToeffectivelypreventCSRFattacks,itisrecommendedtoincluderandomisedtokensinsen-\nsitiverequests,e.g.,byaddingthemtotherequestheaders.Thetokensmustbeuniqueper\nsession and generated with a secure random number generator to prevent attackers from\npredicting them. Servers must not accept requests from authenticated clients that do not\nincludeavalidtoken.\nKAWeb&MobileSecurity |October2019 Page511 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n15.4.2 Server Side Misconfigurations & Vulnerable Components\nAwebapplicationstackconsistsofmultiplecomponents,includingwebservers,webapplica-\ntionframeworks,databaseservers,firewallsystems,andloadbalancersandproxies.Overall,\nwebapplicationsecurityhighlydependsonthesecurityofeachoftheinvolvedcomponents.\nAsingleinsecurecomponentisoftenenoughtoallowanattackeraccesstothewebapplica-\ntionandfurtherescalatetheirattackfromtheinside.Thisiswhydeployingandmaintaining\na secure web application requires more than focusing on the code of the app itself. Every\ncomponentofthewebapplicationstackneedstobeconfiguredsecurelyandkeptuptodate\n(seeSection15.2.10).\nTheHeartbleedVulnerability Afamousexampleofacriticalvulnerabilitythataffectedmany\nwebapplicationstacksin2014isHeartbleed[1326].Heartbleedwasavulnerabilityinthewidely\nusedOpenSSLlibraryandcausedwebserverstoleakinformationstoredinthewebservers\u2019mem-\nory.ThisincludedTLScertificateinformationsuchasprivatekeys,connectionencryptiondetails,\nand any data the user and server communicated, including passwords, usernames, and credit\ncard information [1327]. To fix affected systems, administrators had to update their OpenSSL li-\nbraries as quickly as possible and ideally also revoke certificates and prompt users to change\ntheirpasswords.\nAspreviouslydiscussed,theprincipleofleastprivilegecanreduceawebapplication\u2019sattack\nsurfacetremendously.Properfirewallandloadbalancerconfigurationsserveasexamples:\n15.4.2.1 Firewall\nTo protect a webserver, a firewall should be configured to only allow access from outside\nwhereaccessisneeded.Accessshouldbelimitedtoportslike80and443forHTTPrequests\nvia the Internet and restricting system configuration ports for SSH and alike to the internal\nnetwork(cf.theNetworkSecurityKnowledgeArea(Chapter17)).\n15.4.2.2 LoadBalancers\nA load balancer is a widely deployed component in many web applications. Load balancers\ncontrol HTTP traffic between servers and clients and provide additional access control for\nweb application resources. They can be used to direct requests and responses to different\nweb servers or ports, balance traffic load between multiple web servers and protect areas\nof a website with additional access control mechanisms. The most common approach for\ncontrollingaccessistheuseof.htaccessfiles.Theycanrestrictaccesstocontentonthe\noriginalwebserverandinstructloadbalancerstorequireadditionalauthentication.\nLoadbalancerscanalsoserveforratelimitingpurposes.Theycanlimitrequestsize,allowed\nrequestmethodsandpathsordefinetimeouts.Themainuseofrate-limitingistoreducethe\npotentially negative impact of denial of service attacks on a web server and prevent users\nfromspammingsystems,aswellasrestrictandpreventunexpectedbehavior.\nAdditionally, load balancers can be used to provide secure TLS connections for web appli-\ncations. When managing TLS, load balancers serve as a network connection endpoint for\nthe TLS encryption and either establish new TLS connections to the application service or\nconnect to the web application server using plain HTTP. If the web application server is not\nhostedonthesamemachine,usingplainnetworkconnectionsmightleakinformationtothe\nKAWeb&MobileSecurity |October2019 Page512 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ninternalnetwork.However,ifthewebapplicationserverdoesnotprovideHTTPSitself,using\naloadbalancerasaTLSendpointincreasessecurity.\nHTTPS Misconfigurations One cornerstone of web and mobile security is the correct and\nsecureconfigurationofHTTPSonwebservers.However,Holzetal.[1330]foundthatasignificant\nnumberofpopularwebsitesdeployinvalidcertificateswithincompletecertificatechains,issued\nfor the wrong hostname or expired lifetime. In a similar study Fahl et al. [1331] confirmed these\nfindingsandalsoaskedwebsiteoperatorsforthereasonsfordeployinginvalidcertificates.Most\noperators were not aware of using an invalid certificate or used one on purpose because they\ndid not trust the web PKI. Krombholz et al. [1332, 1333] conducted a set of studies and found\nthatoperatorshavedifficultieswithcorrectlyconfiguringHTTPS,ortheyharbourmisconceptions\naboutthesecurityfeaturesofHTTPS.\n15.4.2.3 Databases\nSimilar to load balancers and firewalls, many web applications include databases to store\nuserinformationpermanently.Often,databasesareoperatedasanadditionalservicethatis\nhostedonanotherserver.Theapplicationserverinteractswiththedatabasethroughlibraries\nandAPIs.Itisimportanttopreventinjectionvulnerabilitiesontheserver.Additionally,errors\nintheimplementationofdatabaselibrariesorcoarsepermissionsrequiredbytheapplication\ncanleadtovulnerabilities.\nToreducetheattackvector,mostdatabasesystemsprovideusermanagement,tolimituser\nprivilegestocreate,read,deleteormodifyentriesintablesandacrossdatabases.Inthisway\nonedatabaseperapplicationcanbecreatedandparticularuserswithread-onlypermissions\ncanbeusedbytheapplicationserver.\nAn important aspect of increasing database security is the decision on how to store data.\nEncryptingdatabeforestorageinthedatabasecanhelp.However,especiallyforpasswords\norotherinformationthatonlyneedstobecomparedforequality,hashingbeforestoragecan\ntremendouslyincreasesecurity.Inthecaseofadataleak,thesensitiveinformationremains\nunreadable.Tostorepasswordssecurely,webandmobileappdevelopersarerecommended\nto use a secure hash function such as Argon2 [1334] or PBKDF2 [1335] in combination with\na cryptographically strong credential-specific salt. A salt is a cryptographically strong fixed-\nlengthrandomvalueandneedstobenewlygeneratedforforeachsetofcredentials[1336].\nPassword Leaks Developers tend to store plain passwords, credit card information or other\nsensitive information in databases instead of encrypting or hashing them (cf. the Human Fac-\ntors Knowledge Area (Chapter 4)). Hence, many leaks of password databases or credit card in-\nformationputusersatrisk[1337].Modernbrowsersandpasswordmanagershelpuserstoavoid\npasswordsthatwerepartofapreviousdatabreach[1338].\nKAWeb&MobileSecurity |October2019 Page513 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n15.5 CONCLUSION\nAs we have shown, web and mobile security is a diverse and broad topic covering many ar-\neas.ThisKnowledgeAreaemphasisedanintersectionalapproachbyexploringsecuritycon-\nceptsandmechanismsthatcanbefoundinboththewebandthemobileworlds.Ittherefore\nbuildsuponandextendstheinsightsfromotherKnowledgeAreas,inparticulartheSoftware\nSecurity Knowledge Area (Chapter 14), Network Security Knowledge Area (Chapter 17), Hu-\nman Factors Knowledge Area (Chapter 4), Operating Systems & Virtualisation Knowledge\nArea (Chapter 11), Privacy & Online Rights Knowledge Area (Chapter 5), Authentication, Au-\nthorisation&Accountability(AAA)KnowledgeArea(Chapter13)andthePhysicalLayerand\nTelecommunicationsKnowledgeArea(Chapter20).\nWe showed that due to the ubiquitous availability and use of web and mobile applications\nanddevices,payingattentiontotheirsecurityissuesiscrucialforoverallinformationsecurity.\nWediscussedwebtechnologiesthatbuildthecoreofbothwebandmobilesecurity,outlined\ntheircharacteristicsandillustratedhowtheyaredifferentfromotherecosystems.\nLateron,wesplitthediscussionintoclient-andserver-sideaspects.Inparticular,thisKnowl-\nedgeAreahasfocusedonattacksanddefencesthatwereprevalentinwebandmobileclients\nandserversandthatdominateddiscussionsinrecentyears.\nCROSS-REFERENCE OF TOPICS VS REFERENCE MATERIAL\nSection References\n15.2FundamentalConceptsandApproaches\n15.2.1Appification [1244,1252]\n15.2.2Webification [1247,1253,1262]\n15.2.3ApplicationStores [1263,1264,1266]\n15.2.4Sandboxing [1267,1268,1269,1270]\n15.2.5PermissionDialogBasedAccessControl [1157,1248]\n15.2.6WebPKIandHTTPS [456,1249,1274,1279]\n15.2.7Authentication [384,1280]\n15.2.8Cookies [1283]\n15.2.9PasswordsandAlternatives [1287,1289,1291]\n15.2.10FrequentSoftwareUpdates [1298,1299]\n15.3ClientSideVulnerabilitiesandMitigations\n15.3.1Phishing&Clickjacking [1300,1301,1302,1306]\n15.3.2ClientSideStorage [1307]\n15.3.3PhysicalAttacks [1311,1312]\n15.4ServerSideVulnerabilitiesandMitigations\n15.4.1InjectionVulnerabilities [1318,1319,1320,1324,1325]\n15.4.2ServerSideMisconfigurations&VulnerableComponents [1330,1332,1333,1338]\nFURTHER READING\nThe following resources provide a deeper insight into web and mobile security as well as\nguidance and recommendations for preventing and handling the vulnerabilities presented\nanddiscussedabove.\nKAWeb&MobileSecurity |October2019 Page514 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nThe OWASP Project & Wiki\nTheOpenWebApplicationSecurityProject(OWASP)isaninternationalnot-for-profitcharita-\nbleorganisationprovidingpracticalinformationaboutapplicationandwebsecurity.Itfunds\nmany projects including surveys like the OWASP TOP 10, books, CTFs and a wiki contain-\ning in-depth descriptions, recommendations and checklists for vulnerabilities and security\nmeasurements.Thecorewikicanbefoundathttps:\/\/www.owasp.org\/.\nMozilla Developer Network\nAn all-encompassing resource provided by Mozilla covering open web standards, including\nsecurityadviceandcrossplatformbehaviourforJavascriptAPIs,aswellasaHTMLandCSS\nspecifications.Itcanbefoundathttps:\/\/developer.mozilla.org\nAndroid Developers\nThe official documentation for the Android development ecosystem, including security ad-\nviceforclientsidestorage,webviews,permissions,Androiddatabasesandnetworkconnec-\ntions. It also includes information for outdated operating system versions and the Google\nPlayUpdateprocess.Availableathttps:\/\/developer.android.com\nKAWeb&MobileSecurity |October2019 Page515 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nKAWeb&MobileSecurity |October2019 Page516 Chapter 16\nSecure Software Lifecycle\nLaurie Williams North Carolina State University\n517 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nINTRODUCTION\nThe purpose of this Secure Software Lifecycle knowledge area is to provide an overview of\nsoftware development processes for implementing secure software from the design of the\nsoftwaretotheoperationaluseofthesoftware.Thisimplementationmayinvolvenewcoding\naswellastheincorporationofthirdpartylibrariesandcomponents.Thegoalofthisoverview\nisforuseinacademiccoursesintheareaofsoftwaresecurity;andtoguideindustryprofes-\nsionalswhowouldliketouseasecuresoftwarelifecycle.\nTheSoftwareSecurityKnowledgeArea(Chapter14)providesastructuredoverviewofsecure\nsoftware development and coding and the known categories of software implementation\nvulnerabilities and of techniques that can be used to prevent or detect such vulnerabilities\nortomitigatetheirexploitation.Bycontrast,thisSecureSoftwareLifecycleKnowledgeArea\nfocuses on the components of a comprehensive software development process to prevent\nanddetectsecuritydefectsandtorespondintheeventofanexploit.\nThisKnowledgeAreawillbeginwithahistoryofsecuresoftwarelifecyclemodels.Section2\nprovides examples of three prescriptive secure software lifecycle processes; the Microsoft\nSecureDevelopmentLifecycle,Touchpoints,andSAFECode.Section3discusseshowthese\nprocesses can be adapted in six specific domains: agile\/DevOps, mobile, cloud computing,\ninternetofthings,roadvehicles,andecommerce\/paymentcard.Section4providesinforma-\ntiononthreeframeworksforassessinganorganisation\u2019ssecuresoftwarelifecycleprocess.\nCONTENT\n16.1 MOTIVATION\n[1238,1339,1340,1341,1342,1343,1344,1345,1346]\nHistorically, and at times currently, organisations have focused their security strategies at\nthe network system level, such as with firewalls, and have taken a reactive approach to soft-\nwaresecurity,usinganapproachcommonlyreferredtoas\u2019penetrateandpatch\u2019.[1342]With\nthis approach, security is assessed when the product is complete via penetration testing by\nattemptingknownattacks;orvulnerabilitiesarediscoveredpostreleasewhenorganisations\nare victims of an attack on deployed software. In either case, organisations then react by\nfindingandfixingthevulnerabilityviaasecuritypatch.Thefollowingshortcomingsarelikely\ntobemoreprevalentwithapredominantlyreactiveapproachtocybersecurity:\n\u2022 Breachesarecostly.Baseduponastudyof477companiesin15countries,in2018the\nPonemanInstitute[1341]reportedthatabreachcost,onaverage,7.9millionUSdollars\nin the United States and 5.3 million US dollars in the Middle East. Breaches were the\nleast expensive in India and Brazil, but these countries still spent an average of 1.8\nmillionand1.2millionUSdollarsperbreach,respectively.Lossofreputationcausedby\nabreachisdifficulttoquantify.\n\u2022 Attackers can find and exploit vulnerabilities without being noticed. Based upon a\nstudy of 477 companies in 15 countries, in 2018 the Poneman Institute [1341] reported\nthat themean time toidentify that abreach hadoccurred was197 days,and themean\ntime to find and fix a vulnerability once the breach was detected was an additional 69\ndays.\nKASecureSoftwareLifecycle |October2019 Page518 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n\u2022 Patchescanintroducenewvulnerabilitiesorotherproblems.Vulnerabilitypatchesare\nconsideredurgentandcanberushedout,potentiallyintroducingnewproblemstoasys-\ntem.Forexample,Microsoft\u2019searlypatchesfortheMeltdown1 chipflawintroducedan\nevenmoreseriousvulnerabilityinWindows72.Thenewvulnerabilityallowedattackers\ntoreadkernelmemorymuchfasterandtowritetheirownmemory,andcouldallowan\nattackertoaccesseveryuser-levelcomputingprocessrunningonamachine.\n\u2022 Patches often go unapplied by customers. Users and system administrators may be\nreluctanttoapplysecuritypatches.Forexample,thehighly-publicisedHeartbleed3 vul-\nnerabilityinOpenSSLallowsattackerstoeasilyandquietlyexploitvulnerablesystems,\nstealingpasswords,cookies,privatecrypto-keys,andmuchmore.Thevulnerabilitywas\nreportedinApril2014;butinJanuary2017ascanrevealed200,000Internet-accessible\ndevicesremainedunpatched[1343].Onceavulnerabilityispubliclyreported,attackers\nformulate a new mechanism to exploit the vulnerability with the knowledge that many\norganisationswillnotadoptthefix.\nIn 1998, McGraw [1342] advocated moving beyond the penetrate and patch approach based\nupon his work on a DARPA-funded research effort investigating the application of software\nengineeringtotheassessmentofsoftwarevulnerabilities.Hecontendedthatproactiverigor-\noussoftwareanalysisshouldplayanincreasinglyimportantroleinassessingandpreventing\nvulnerabilities in applications based upon the well-known fact that security violations occur\nbecause of errors in software design and coding. In 2002, Viega and McGraw published the\nfirst book on developing secure programs, Building Secure Software [1238], with a focus on\npreventingtheinjectionofvulnerabilitiesandreducingsecurityriskthroughanintegrationof\nsecurityintoasoftwaredevelopmentprocess.\nIn the early 2000s, attackers became more aggressive, and Microsoft was a focus of this\naggression with exposure of security weaknesses in their products, particularly the Internet\nInformation Services (IIS). Gartner, a leading research and advisory company who seldom\nadvisesitsclientstosteerclearofspecificsoftware,advisedcompaniestostopusingIIS.In\nresponsetocustomerconcernsandmountingbadpress,thethenMicrosoftCEO,BillGates,\nsent the Trustworthy Computing memo [1339] to all employees on January 15, 2002. The\nmemowasalsowidelycirculatedontheInternet.AnexcerptofthememodefinesTrustwor-\nthyComputing:\n\u2018Trustworthy Computing is the highest priority for all the work we are doing. We\nmust lead the industry to a whole new level of Trustworthiness in computing ...\nTrustworthy Computing is computing that is as available, reliable and secure as\nelectricity,waterservicesandtelephony\u2019.\nTheTrustworthyComputingmemocausedashiftinthecompany.Twoweekslater,Microsoft\nannouncedthedelayofthereleaseofWindows.NETServer[1344]toensureapropersecurity\nreview (referred to as the Windows Security Push), as mandated by Microsoft\u2019s Trustworthy\nComputing initiative outlined in this memo. In 2003, Microsoft employees Howard and Le\nBlanc[1345]publiclypublishedasecondeditionofabookonwritingsecurecodetoprevent\nvulnerabilities,todetectdesignflawsandimplementationbugs,andtoimprovetestcodeand\ndocumentation.ThefirsteditionhadbeenrequiredreadingforallmembersoftheWindows\nteamduringthePush.\n1https:\/\/meltdownattack.com\/Meltdownletshackersgetaroundabarrierbetweenapplicationsandcomputer\nmemorytostealsensitivedata.\n2https:\/\/www.cyberscoop.com\/microsoft-meltdown-patches-windows-7-memory-management\/\n3http:\/\/heartbleed.com\/\nKASecureSoftwareLifecycle |October2019 Page519 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nDuring the ensuing years, Microsoft changed their development process to build secure\nproducts through a comprehensive overhaul of their development process from early plan-\nningthroughproductend-of-life.Theirproductscontaineddemonstrablyfewervulnerabilities\n[1345].Afterinternaluseoftheprocess,Microsoftcodifiedandcontributedtheir13-stagein-\nternaldevelopmentprocess,theMicrosoftSecurityDevelopmentLifecycle(SDL)tothecom-\nmunity through its book entitled The Security Development Lifecycle [1340] in 2006. True to\nGates\u2019 original intent, the Microsoft SDL provided the foundation for the information tech-\nnology industry by providing the first documented comprehensive and prescriptive lifecycle.\nAlsoin2006,McGrawpublishedthefirstbookonsoftwaresecuritybestpractices[1346].\nAsdiscussedintherestofthisknowledgearea,organisationshavebuiltuponthefoundation\nsetforthbyMicrosoftandbyViegaandMcGraw[1238,1342].\n16.2 PRESCRIPTIVE SECURE SOFTWARE LIFECYCLE\nPROCESSES\n[8,70,75,1238,1340,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,\n1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370]\nSecuresoftwarelifecycleprocessesareproactiveapproachestobuildingsecurityintoaprod-\nuct,treatingthe\u2018disease\u2019ofpoorlydesigned,insecuresoftwareatthesource,ratherthan\u2018ap-\nplying a band aid\u2019 to stop the symptoms through a reactive penetrate and patch approach.\nThese processes work software security deeply into the full product development process\nand incorporate people and technology to tackle and prevent software security issues. This\nsectionwillprovideinformationonthreeprominentsecuresoftwarelifecycleprocessesand\nthenreflectonthecommonalitiesbetweentheminTable16.1.\n16.2.1 Secure Software Lifecycle Processes\nThreeexemplarprescriptivesecuresoftwarelifecycleprocessesaresummarisedinthissec-\ntion.Theprocessesareprescriptiveinthattheyexplicitlyrecommendsoftwarepractices.The\nthree processes were chosen because the practices of these processes are integrated and\ncover a broad spectrum of the lifecycle phases, from software requirements to release\/de-\nploymentandsoftwaremaintenance.Twooftheseprocesseswereidentifiedinasystematic\nmapping study [1359] on security approaches in software development lifecycles. As such,\nthe practices span the prevention of security defects, the detection of security defects, and\nthe mitigation of security defects once a product is in the field. The three were also chosen\ndue to their maturity in terms of the number of years they have existed and in terms of their\nwidespread acceptance in the industry. As will be discussed in Section 2.2, no \u2019best\u2019 secure\nsoftwarelifecycleprocessexists.Practitionersshouldconsiderincorporatingpracticesfrom\neachoftheseprocessesintotheirownsecuresoftwareprocess.\nKASecureSoftwareLifecycle |October2019 Page520 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n16.2.1.1 MicrosoftSecurityDevelopmentLifecycle(SDL)\nAs discussed in Section 16.1, Microsoft used an internal development process, the Security\nDevelopment Lifecycle (SDL), to improve the security of their products. Howard and Lipner\n[1340]disseminatedasnapshotofthisprocessin2006.Sincethattime,Microsofthascontin-\nuedtoevolvetheirSDLandtoprovideup-to-dateresourcestothecommunity[1347],including\nanincreasedfocusoncompliancerequirementsthatarebeingimposedontheindustry.\nCurrently [1347], the Microsoft SDL contains 12 practices which are enumerated below. For\neach of the practices, techniques for implementing the practice may be mentioned though\ntheSDLdoesnotprescribethespecifictechnique.\n1. ProvideTraining.Arangeofprofessionals,suchasdevelopers,serviceengineers,pro-\ngram managers, product managers, and project managers, participate in the develop-\nmentofsecureproductswhilestilladdressingbusinessneedsanddeliveringuservalue.\nSoftwaredevelopersandarchitectsmustunderstandtechnicalapproachesforprevent-\ning and detecting vulnerabilities. The entire development organisation should be cog-\nnisant of the attacker\u2019s perspective, goals, and techniques; and of the business impli-\ncationsofnotbuildingsecureproducts.\nOften,theformaleducationoftheseprofessionalsdoesnotincludecybersecurity.Addi-\ntionally,attackvectors,securitytools,secureprogramminglanguages,andexperiences\nareconstantlyevolving,soknowledgeandcoursematerialmustberefreshed.Ongoing\ncybersecuritytrainingisessentialforsoftwareorganisations.\n2. Define Security Requirements. Security requirements should be defined during the ini-\ntialdesignandplanningphases.Factorsthatinfluencetheserequirementsincludethe\nspecific functional requirements of the system, the legal and industry compliance re-\nquirements, internal and external standards, previous security incidents, and known\nthreats.\nTechniques have been developed for systematically developing security requirements.\nForexample,SecurityQualityRequirementsEngineering(SQUARE)[1360]isanine-step\nprocess that helps organisations build security into the early stages of the production\nlifecycle.Abusecases,aswillbediscussedinSection2.1.2bullet5,areanothermeans\nofspecifyingsecurityrequirements.vanLamsweerdeextendedtheKeepAllObjectives\nSatisfied (KAOS) framework for goal-based requirements specification language to in-\nclude anti-models [1361]. An anti-model is constructed by addressing malicious obsta-\ncles (called anti-goals) set up by attackers to threaten a system\u2019s security goals. An\nobstaclenegatesexistinggoalsofthesystem.Securei*[1362]extendsthei*-modeling\nframeworkwithmodelingandanalysisofsecuritytrade-offsandalignssecurityrequire-\nmentswithotherrequirements.\nSecurityrequirementsmustbecontinuallyupdatedtoreflectchangesinrequiredfunc-\ntionality,standards,andthethreatlandscape.\n3. DefineMetricsandComplianceReporting.LordKelvinisquotedasstating,\u2019Ifyoucan\nnotmeasureit,youcannotimproveit\u2019.Themanagementteamshouldunderstandand\nbe held accountable for minimum acceptable levels of security using security metrics\n[1349].AsubsetofthesemetricsmaybesetasKeyPerformanceIndicators(KPIs)for\nmanagement reporting. Defect tracking should clearly label security defects and se-\ncurity work items as such to allow for accurate prioritisation, risk management, track-\ning, and reporting of security work. Additionally, products increasingly must comply\nKASecureSoftwareLifecycle |October2019 Page521 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nwith regulatory standards, such as the Payment Card Industry Data Security Standard\n(PCIDSS)4,ortheEUGeneralDataProtectionRegulation[122](GDPR)5,whichmayim-\nposeadditionalprocessstepsandmetricsforcompliance,reporting,andaudits.\n4. Perform Threat Modelling. Through the use of threat modelling [75, 1356], teams con-\nsider,documentanddiscussthesecurityimplicationsofdesignsinthecontextoftheir\nplanned operational environment and in a structured fashion. Teams should consider\nthe motivations of their adversaries and the strengths and weaknesses of systems to\ndefend against the associated threat scenarios. An approach is to consider the (1) the\nmaliciousandbenevolentinteractorswiththesystem;(2)thedesignofthesystemand\nits components (i.e. processes and data stores), (3) the trust boundaries of the sys-\ntem; and (4) the data flow of the system within and across trust boundaries to\/from\nits interactors. Threats can be enumerated using a systematic approach of consider-\ningeachsystemcomponentrelativetotheSTRIDE(Spoofing,Tampering,Repudiation,\nInformationDisclosure,DenialofService,ElevationofPrivilege)[1345]threats:\n(a) Spoofing identity. Spoofing threats allow an attacker to pose as another user or\nallowarogueservertoposeasavalidserver.\n(b) Tampering with data. Data tampering threats involves malicious modification of\ndata.\n(c) Repudiation.Repudiationthreatsareassociatedwithuserswhodenyperforming\nanactionwithoutotherpartieshavinganywaytoproveotherwise.\n(d) Informationdisclosure.Informationdisclosurethreatsinvolvetheexposureofin-\nformationtoindividualswhoarenotsupposedtohaveaccesstoit.\n(e) Denialofservice.ADenialofService(DoS)attackdeniesservicetovalidusersby\nmakingthesystemunavailableorunusable.\n(f) Elevation of privilege. An unprivileged user gains privileged access and thereby\nhassufficientaccesstocompromiseordestroythesystem.\nThreat modelling aids the team in enumerating threats, so that the system design can\nbe fortified and security features can be selected. In addition to STRIDE, other models\nexist to formulate threat models, such as 12 methods6, including attack trees [1363]\nwhich are conceptual diagrams of threats on systems and possible attacks to reach\nthosethreats.Aclosely-relatedpracticetothreatmodellingisArchitecturalRiskAnaly-\nsis,aswillbediscussedinSection2.1.2bullet2.\nGames have been created to aid teams in collaboratively (and competitively) conduct-\ningthreatmodeling:\n(a) ElevationofPrivilege7\n(b) SecurityCards8\n(c) ProtectionPoker[1364]\n4https:\/\/www.pcisecuritystandards.org\/\n5https:\/\/eugdpr.org\/\n6https:\/\/insights.sei.cmu.edu\/sei_blog\/2018\/12\/threat-modeling-12-available-methods.html\n7https:\/\/www.usenix.org\/conference\/3gse14\/summit-program\/presentation\/shostack\n8https:\/\/securitycards.cs.washington.edu\/\nKASecureSoftwareLifecycle |October2019 Page522 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n5. EstablishDesignRequirements.Designrequirementsguidetheimplementationof\u2019se-\ncurefeatures\u2019(i.e.,featuresthatarewellengineeredwithrespecttosecurity).Addition-\nally, the architecture and design must be resistant to known threats in the intended\noperationalenvironment.\nThe design of secure features involves abiding by the timeless security principles set\nforth by Saltzer and Schroeder [8] in 1975 and restated by Viega and McGraw [1238] in\n2002.TheeightSaltzerandSchroederprinciplesare:\n\u2022 Economy of mechanism. Keep the design of the system as simple and small as\npossible.\n\u2022 Fail-safe defaults. Base access decisions on permissions rather than exclusion;\nthe default condition is lack of access and the protection scheme identifies con-\nditions under which access is permitted. Design a security mechanism so that a\nfailurewillfollowthesameexecutionpathasdisallowingtheoperation.\n\u2022 Completemediation.Everyaccesstoeveryobjectmustbecheckedforauthorisa-\ntion.\n\u2022 Open design. The design should not depend upon the ignorance of attackers but\nratheronthepossessionofkeysorpasswords.\n\u2022 Separationofprivilege.Aprotectionmechanismthatrequirestwokeystounlock\nis more robust than one that requires a single key when two or more decisions\nmustbemadebeforeaccessshouldbegranted.\n\u2022 Least privilege. Every program and every user should operate using the least set\nofprivilegesnecessarytocompletethejob.\n\u2022 Least common mechanism. Minimise the amount of mechanisms common to\nmorethanoneuseranddependedonbyallusers.\n\u2022 Psychologicalacceptability.Thehumaninterfaceshouldbedesignedforeaseof\nusesothatusersroutinelyandautomaticallyapplythemechanismscorrectlyand\nsecurely.\nTwootherimportantsecuredesignprinciplesincludethefollowing:\n\u2022 Defense in depth. Provide multiple layers of security controls to provide redun-\ndancyintheeventasecuritybreach.\n\u2022 Designforupdating.Thesoftwaresecuritymustbedesignedforchange,suchas\nforsecuritypatchesandsecuritypropertychanges.\nDesignrequirementsalsoinvolvetheselectionofsecurityfeatures,suchascryptogra-\nphy, authentication and logging to reduce the risks identified through threat modelling.\nTeamsalsotakeactionstoreducetheattacksurfaceoftheirsystemdesign.Theattack\nsurface,aconceptintroducedbyHoward[1350]in2003,canbethoughtofasthesum\nof the points where attackers can try to enter data to or extract data from a system\n[1357,1358].\nIn2014,theIEEECenterforSecureDesign[1351]enumeratedthetoptensecuritydesign\nflaws and provided guidelines on techniques for avoiding them. These guidelines are\nasfollows:\n(a) Earnorgive,butneverassume,trust.\nKASecureSoftwareLifecycle |October2019 Page523 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n(b) Useanauthenticationmechanismthatcannotbebypassedortamperedwith.\n(c) Authoriseafteryouauthenticate.\n(d) Strictly separate data and control instructions, and never process control instruc-\ntionsreceivedfromuntrustedsources.\n(e) Defineanapproachthatensuresalldataareexplicitlyvalidated.\n(f) Usecryptographycorrectly.\n(g) Identifysensitivedataandhowtheyshouldbehandled.\n(h) Alwaysconsidertheusers.\n(i) Understandhowintegratingexternalcomponentschangesyourattacksurface.\n(j) Beflexiblewhenconsideringfuturechangestoobjectsandactors.\n6. Define and Use Cryptography Standards. The use of cryptography is an important de-\nsign feature for a system to ensure security- and privacy-sensitive data is protected\nfrom unintended disclosure or alteration when it is transmitted or stored. However, an\nincorrectchoiceintheuseofcryptographycanrendertheintendedprotectionweakor\nineffective. Experts should be consulted in the use of clear encryption standards that\nprovide specifics on every element of the encryption implementation and on the use\nof only properly vetted encryption libraries. Systems should be designed to allow the\nencryption libraries to be easily replaced, if needed, in the event the library is broken\nbyanattacker,suchaswasdonetotheDataEncryptionStandard(DES)through\u2019Deep\nCrack\u20199, a brute force search of every possible key as designed by Paul Kocher, presi-\ndentofCryptographyResearch.\n7. ManagetheSecurityRiskofUsingThird-PartyComponents.Thevastmajorityofsoft-\nwareprojectsarebuiltusingproprietaryandopen-sourcethird-partycomponents.The\nBlack Duck On-Demand audit services group [1352] conducted open-source audits on\nover 1,100 commercial applications and found open-source components in 95% of the\napplications with an average 257 components per application. Each of these compo-\nnents can have vulnerabilities upon adoption or in the future. An organisation should\nhave an accurate inventory of third-party components [1366], continuously use a tool\ntoscanforvulnerabilitiesinitscomponents,andhaveaplantorespondwhennewvul-\nnerabilities are discovered. Freely available and proprietary tools can be used to iden-\ntifyprojectcomponentdependenciesandtocheckifthereareanyknown,publiclydis-\nclosed,vulnerabilitiesinthesecomponents.\n8. Use Approved Tools. An organisation should publish a list of approved tools and their\nassociatedsecuritychecksandsettingssuchascompiler\/linkeroptionsandwarnings.\nEngineers should use the latest version of these tools, such as compiler versions, and\ntakeadvantageofnewsecurityanalysisfunctionalityandprotections.Often,theresul-\ntantsoftwaremustbebackwardcompatiblewithpreviousversions.\n9. PerformStaticAnalysisSecurityTesting(SAST).SASTtoolscanbeusedforanauto-\nmated security code review to find instances of insecure coding patterns and to help\nensurethatsecurecodingpoliciesarebeingfollowed.SASTcanbeintegratedintothe\ncommitanddeploymentpipelineasacheck-ingatetoidentifyvulnerabilitieseachtime\nthesoftwareisbuiltorpackaged.Forincreasedefficiency,SASTtoolscanintegrateinto\n9https:\/\/w2.eff.org\/Privacy\/Crypto\/Crypto_misc\/DESCracker\/HTML\/19980716_eff_des_faq.html\nKASecureSoftwareLifecycle |October2019 Page524 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nthedeveloperenvironmentandberunbythedeveloperduringcoding.SomeSASTtools\nspot certain implementation bugs, such as the existence of unsafe or other banned\nfunctions and automatically replace with (or suggest) safer alternatives as the devel-\noperisactivelycoding.SeealsotheSoftwareSecurityKnowledgeArea(Section14.3.1).\n10. Perform Dynamic Analysis Security Testing (DAST). DAST performs run-time verifica-\ntionofcompiledorpackagedsoftwaretocheckfunctionalitythatisonlyapparentwhen\nallcomponentsareintegratedandrunning.DASTofteninvolvestheuseofasuiteofpre-\nbuilt attacks and malformed strings that can detect memory corruption, user privilege\nissues, injection attacks, and other critical security problems. DAST tools may employ\nfuzzing,anautomatedtechniqueofinputtingknowninvalidandunexpectedtestcases\natanapplication,ofteninlargevolume.SimilartoSAST,DASTcanberunbythedevel-\noperand\/orintegratedintothebuildanddeploymentpipelineasacheck-ingate.DAST\ncanbeconsideredtobeautomatedpenetrationtesting.SeealsotheSoftwareSecurity\nKnowledgeArea(Section14.3.2).\n11. Perform Penetration Testing. Manual penetration testing is black box testing of a run-\nning system to simulate the actions of an attacker. Penetration testing is often per-\nformed by skilled security professionals, who can be internal to an organisation or\nconsultants, opportunistically simulating the actions of a hacker. The objective of a\npenetration test is to uncover any form of vulnerability - from small implementation\nbugs to major design flaws resulting from coding errors, system configuration faults,\ndesignflawsorotheroperationaldeploymentweaknesses.Testsshouldattemptboth\nunauthorisedmisuseofandaccesstotargetassetsandviolationsoftheassumptions.\nA widely-referenced resource for structuring penetration tests is the OWASP Top 10\nMost Critical Web Application Security Risks10. As such, penetration testing can find\nthe broadest variety of vulnerabilities, although usually less efficiently compared with\nSAST and DAST [1353]. Penetration testers can be referred to as white hat hackers or\nethical hackers. In the penetration and patch model, penetration testing was the only\nlineofsecurityanalysispriortodeployingasystem.\n12. Establish a Standard Incident Response Process. Despite a secure software lifecycle,\norganisationsmustbepreparedforinevitableattacks.Organisationsshouldproactively\nprepare an Incident Response Plan (IRP). The plan should include who to contact in\ncaseofasecurityemergency,establishtheprotocolforefficientvulnerabilitymitigation,\nfor customer response and communication, and for the rapid deployment of a fix. The\nIRP should include plans for code inherited from other groups within the organisation\nandforthird-partycode.TheIRPshouldbetestedbeforeitisneeded.Lessonslearned\nthroughresponsestoactualattackshouldbefactoredbackintotheSDL.\n10https:\/\/www.owasp.org\/index.php\/Category:OWASP_Top_Ten_Project\nKASecureSoftwareLifecycle |October2019 Page525 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n16.2.1.2 Touchpoints\nInternational software security consultant, Gary McGraw, provided seven Software Security\nTouchpoints [1346] by codifying extensive industrial experience with building secure prod-\nucts. McGraw uses the term touchpoint to refer to software security best practices which\ncan be incorporated into a secure software lifecycle. McGraw differentiates vulnerabilities\nthat are implementation bugs and those that are design flaws [1351]. Implementation bugs\nare localized errors, such as buffer overflow and input validation errors, in a single piece of\ncode, making spotting and comprehension easier. Design flaws are systemic problems at\nthedesignlevelofthecode,suchaserror-handlingandrecoverysystemsthatfailinaninse-\ncurefashionorobject-sharingsystemsthatmistakenlyincludetransitivetrustissues[1346].\nKuhn et al. [1366] analysed the 2008 - 2016 vulnerability data from the US National Vulnera-\nbility Database (NVD)11 and found that 67% of the vulnerabilities were implementation bugs.\nTheseventouchpointshelptopreventanddetectbothbugsandflaws.\nThese seven touchpoints are described below and are provided in orderofeffectiveness\nbased upon McGraw\u2019s experience with the utility of each practice over many years, hence\nprescriptive:\n1. CodeReview(Tools).\nCodereviewisusedtodetectimplementationbugs.Manualcodereviewmaybeused,\nbut requires that the auditors are knowledgeable about security vulnerabilities before\ntheycanrigorouslyexaminethecode.\u2019Codereviewwithatool\u2019(a.k.a.theuseofstatic\nanalysis tools or SAST) has been shown to be effective and can be used by engineers\nthat do not have expert security knowledge. For further discussion on static analysis,\nseeSection2.1.1bullet9.\n2. ArchitecturalRiskAnalysis.\nArchitectural risk analysis, which can also be referred to as threat modelling (see Sec-\ntion2.1.1bullet4),isusedtopreventanddetectdesignflaws.Designersandarchitects\nprovideahigh-levelviewofthetargetsystemanddocumentationforassumptions,and\nidentifypossibleattacks.Througharchitecturalriskanalysis,securityanalystsuncover\nandrankarchitecturalanddesignflawssomitigationcanbegin.Forexample,riskanaly-\nsismayidentifyapossibleattacktype,suchastheabilityfordatatobeinterceptedand\nread. This identification would prompt the designers to look at all their code\u2019s traffics\nflows to see if interception was a worry, and whether adequate protection (i.e. encryp-\ntion) was in place. That review that the analysis prompted is what uncovers design\nflaws,suchassensitivedataistransportedintheclear.\nNo system can be perfectly secure, so risk analysis must be used to prioritise secu-\nrity efforts and to link system-level concerns to probability and impact measures that\nmatter to the business building the software. Risk exposure is computed by multiply-\ning the probability of occurrence of an adverse event by the cost associated with that\nevent[1367].\nMcGrawproposesthreebasicstepsforarchitecturalriskanalysis:\n\u2022 Attackresistanceanalysis.Attackresistanceanalysisusesachecklist\/systematic\napproach of considering each system component relative to known threats, as is\ndoneinMicrosoftthreatmodellingdiscussedinSection2.1.1bullet4.Information\n11http:\/\/nvd.nist.gov\nKASecureSoftwareLifecycle |October2019 Page526 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\naboutknownattacksandattackpatternsareusedduringtheanalysis,identifying\nrisks in the architecture and understanding the viability of known attacks. Threat\nmodellingwiththeincorporationofSTRIDE-basedattacks,asdiscussedinSection\n2.1.1bullet4,isanexampleprocessforperformingattackresistanceanalysis.\n\u2022 Ambiguity analysis. Ambiguity analysis is used to capture the creative activity re-\nquiredtodiscovernewrisks.Ambiguityanalysisrequirestwoormoreexperienced\nanalystswhocarryoutseparateanalysisactivitiesinparallelonthesamesystem.\nThrough unifying the understanding of multiple analysis, disagreements between\ntheanalystscanuncoverambiguity,inconsistencyandnewflaws.\n\u2022 Weakness analysis. Weakness analysis is focused on understanding risk related\ntosecurityissuesinotherthird-partycomponents(seeSection2.1.1bullet7).The\nideaistounderstandtheassumptionsbeingmadeaboutthird-partysoftwareand\nwhatwillhappenwhenthoseassumptionsfail.\nRiskidentification,ranking,andmitigationisacontinuousprocessthroughthesoftware\nlifecycle,beginningwiththerequirementphase.\n3. PenetrationTesting.\nPenetration testing can be guided by the outcome of architectural risk analysis (See\nSection 2.1.2 bullet 2). For further discussion on penetration testing, see Section 2.1.1,\nbullet11.\n4. Risk-basedSecurityTesting.\nSecurity testing must encompass two strategies: (1) testing of security functionality\nwith standard functional testing techniques; and (2) risk-based testing based upon at-\ntack patterns and architectural risk analysis results (see Section 2.1.2 bullet 2), and\nabusecases(seeSection2.1.2bullet5).Forwebapplications,testingofsecurityfunc-\ntionalitycanbeguidedbytheOWASPApplicationSecurityVerficationStandard(ASVS)\nProject12 open standard for testing application technical security controls. ASVS also\nprovidesdeveloperswithalistofrequirementsforsecuredevelopment.\nGuiding tests with knowledge of the software architecture and construction, common\nattacks, and the attacker\u2019s mindset is extremely important. Using the results of archi-\ntecturalriskanalysis,thetestercanproperlyfocusonareasofcodewhereanattackis\nlikelytosucceed.\nThe difference between risk-based testing and penetration testing is the level of the\napproachandthetimingofthetesting.Penetrationtestingisdonewhenthesoftwareis\ncompleteandinstalledinanoperationalenvironment.Penetrationtestsareoutside-in,\nblackboxtests.Risk-basedsecuritytestingcanbeginbeforethesoftwareiscomplete\nandevenpre-integration,includingtheuseofwhiteboxunittestsandstubs.Thetwoare\nsimilarinthattheybothshouldbeguidedbyriskanalysis,abusecasesandfunctional\nsecurityrequirements.\n5. AbuseCases.\nThistouchpointcodifies\u2019thinkinglikeanattacker\u2019.Usecasesdescribethedesiredsys-\ntem\u2019s behaviour by benevolent actors. Abuse cases [1354] describe the system\u2019s be-\nhaviour when under attack by a malicious actor. To develop abuse cases, an analyst\n12https:\/\/www.owasp.org\/index.php\/Category:OWASP_Application_Security_Verification_Standard_Project#tab=Home\nKASecureSoftwareLifecycle |October2019 Page527 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nenumerates the types of malicious actors who would be motivated to attack the sys-\ntem.Foreachbadactor,theanalystcreatesoneormoreabusecase(s)forthefunction-\nalitythebadactordesiresfromthesystem.Theanalystthenconsiderstheinteraction\nbetween the use cases and the abuse cases to fortify the system. Consider an auto-\nmobile example. An actor is the driver of the car, and this actor has a use case \u2019drive\nthecar\u2019.Amaliciousactorisacarthiefwhoseabusecaseis\u2019stealthecar\u2019.Thisabuse\ncase threatens the use case. To prevent the theft, a new use case \u2019lock the car\u2019 can be\naddedtomitigatetheabusecaseandfortifythesystem.\nHuman error is responsible for a large number of breaches. System analysts should\nalsoconsideractionsbybenevolentusers,suchasbeingthevictimofaphishingattack,\nthat result in a security breach. These actions can be considered misuse cases [1355]\nandshouldbeanalysedsimilarlytoabusecases,consideringwhatusecasethemisuse\ncasethreatensandthefortificationtothesystemtomitigatethemisusecase.\nThe attacks and mitigations identified by the abuse and misuse case analysis can be\nusedasinputintothesecurityrequirements(Section2.1.1bullet2.);penetrationtesting\n(Section2.1.1bullet11);andrisk-basedsecuritytesting(Section2.1.2bullet4).\n6. SecurityRequirements.\nForfurtherdiscussiononsecurityrequirements,seeSection2.1.1bullet2.\n7. SecurityOperations.\nNetwork security can integrate with software security to enhance the security posture.\nInevitably, attacks will happen, regardless of the applications of the other touchpoints.\nUnderstandingattackerbehaviourandthesoftwarethatenabledasuccessfulattackis\nan essential defensive technique. Knowledge gained by understanding attacks can be\nfedbackintothesixothertouchpoints.\nTheseventouchpointsareintendedtobecycledthroughmultipletimesasthesoftwareprod-\nuct evolves. The touchpoints are also process agnostic, meaning that the practices can be\nincludedinanysoftwaredevelopmentprocess.\n16.2.1.3 SAFECode\nThe Software Assurance Forum for Excellence in Code (SAFECode)13 is a non-profit, global,\nindustry-led organisation dedicated to increasing trust in information and communications\ntechnologyproductsandservicesthroughtheadvancementofeffectivesoftwareassurance\nmethods.TheSAFECodemissionistopromotebestpracticesfordevelopinganddelivering\nmoresecureandreliablesoftware,hardwareandservices.TheSAFECodeorganisationpub-\nlishesthe\u2019Fundamentalpracticesforsecuresoftwaredevelopment:Essentialelementsofa\nsecure development lifecycle program\u2019 [1368] guideline to foster the industry-wide adoption\nof fundamental secure development practices. The fundamental practices deal with assur-\nance\u2013theabilityofthesoftwaretowithstandattacksthatattempttoexploitdesignorimple-\nmentation errors. The eight fundamental practices outlined in their guideline are described\nbelow:\n1. Application Security Control Definition. SAFECode uses the term Application Security\nControls (ASC) to refer to security requirements (see Section 2.1.1 bullet 2). Similarly,\n13https:\/\/safecode.org\/\nKASecureSoftwareLifecycle |October2019 Page528 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nNIST 800-53 [70] uses the phrase security control to refer to security functionality and\nsecurityassurancerequirements.\nThe inputs to ASC include the following: secure design principles (see Section 2.1.3\nbullet 3); secure coding practices; legal and industry requirements with which the ap-\nplicationneedstocomply(suchasHIPAA,PCI,GDPR,orSCADA);internalpoliciesand\nstandards;incidentsandotherfeedback;threatsandrisk.ThedevelopmentofASCbe-\ngins before the design phase and continues throughout the lifecycle to provide clear\nand actionable controls and to be responsive to changing business requirements and\ntheever-evolvingthreatenvironment.\n2. Design. Software must incorporate security features to comply with internal security\npracticesandexternallawsorregulations.Additionally,thesoftwaremustresistknown\nthreats based upon the operational environment. (see Section 2.1.1 bullet 5.) Threat\nmodelling(seeSection2.1.1bullet4),architecturalreviews,anddesignreviewscanbe\nusedtoidentifyandaddressdesignflawsbeforetheirimplementationintosourcecode.\nThe system design should incorporate an encryption strategy (see Section 2.1.1 bullet\n6)toprotectsensitivedatafromunintendeddisclosureoralterationwhilethedataare\natrestorintransit.\nThe system design should use a standardised approach to identity and access man-\nagement to perform authentication and authorisation. The standardisation provides\nconsistencybetweencomponentsandclearguidanceonhowtoverifythepresenceof\nthepropercontrols.Authenticatingtheidentityofaprincipal(beitahumanuser,other\nservice or logical component) and verifying the authorisation to perform an action are\nfoundationalcontrolsofthesystem.Severalaccesscontrolschemeshavebeendevel-\noped to support authorisation: mandatory, discretionary, role-based or attribute-based.\nEach of these has benefits and drawbacks and should be chosen based upon project\ncharacteristics.\nLogfilesprovidetheevidenceneededinforensicanalysiswhenabreachoccurstomit-\nigate repudiation threats. In a well-designed application, system and security log files\nprovide the ability to understand an application\u2019s behaviour and how it is used at any\nmoment, and to distinguish benevolent user behaviour from malicious user behaviour.\nBecause logging affects the available system resources, the logging system should\nbe designed to capture the critical information while not capturing excess data. Poli-\ncies and controls need to be established around storing, tamper prevention and mon-\nitoring log files. OWASP provides valuable resources on designing and implementing\nlogging1415.\n3. Secure Coding Practices. Unintended code-level vulnerabilities are introduced by pro-\ngrammer mistakes. These types of mistakes can be prevented and detected through\nthe use of coding standards; selecting the most appropriate (and safe) languages,\nframeworks and libraries, including the use of their associated security features (see\nSection 2.1.1 bullet 8); using automated analysis tools (see Section 2.1.1 bullets 9 and\n10);andmanuallyreviewingthecode.\nOrganisationsprovidestandardsandguidelinesforsecurecoding,forexample:\n14https:\/\/cheatsheetseries.owasp.org\/cheatsheets\/Logging_Cheat_Sheet.html\n15https:\/\/www.owasp.org\/images\/e\/e0\/OWASP_Logging_Guide.pdf\nKASecureSoftwareLifecycle |October2019 Page529 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n(a) OWASPSecureCodingPractices,QuickReferenceGuide16\n(b) OracleSecureCodingGuidelinesforJavaSE17\n(c) SoftwareEngineeringInstitute(SEI)CERTSecureCodingStandards18\nSpecial care must also be given to handling unanticipated errors in a controlled and\ngraceful way through generic error handlers or exception handlers that log the events.\nIf the generic handlers are invoked, the application should be considered to be in an\nunsafestatesuchthatfurtherexecutionisnolongerconsideredtrusted.\n4. Manage Security Risk Inherent in the Use of Third-Party Components. See Section\n2.1.1bullet7.\n5. Testing and Validation. See Section 2.1.1 bullets 9-11 and Section 2.1.2 bullets 1, 3 and\n4.\n6. ManageSecurityFindings.Thefirstfivepracticesproduceartifactsthatcontainorgen-\nerate findings related to the security of the product (or lack thereof). The findings in\nthese artifacts should be tracked and actions should be taken to remediate vulnera-\nbilities, such as is laid out in the Common Criteria (see Section 4.3) flaw remediation\nprocedure[1369].Alternatively,theteammayconsciouslyacceptthesecurityriskwhen\nthe risk is determined to be acceptable. Acceptance of risk must be tracked, including\naseverityrating;aremediationplan,anexpirationorare-reviewdeadline;andthearea\nforre-review\/validation.\nCleardefinitionsofseverityareimportanttoensurethatallparticipantshaveandcom-\nmunicate with a consistent understanding of a security issue and its potential impact.\nA possible starting point is mapping to the severity levels, attributes, and thresholds\nused by the Common Vulnerability Scoring System (CVSS)19 such as 10\u20138.5 is critical,\n8.4\u20137.0 is high, etc. The severity levels are used to prioritise mitigations based upon\ntheircomplexityofexploitationandimpactonthepropertiesofasystem.\n7. Vulnerability Response and Disclosure. Even with following a secure software lifecy-\ncle, no product can be \u2019perfectly secure\u2019 because of the constantly changing threat\nlandscapes. Vulnerabilities will be exploited and the software will eventually be com-\npromised. An organisation must develop a vulnerability response and disclosure pro-\ncesstohelpdrivetheresolutionofexternallydiscoveredvulnerabilitiesandtokeepall\nstakeholders informed of progress. ISO provides industry-proven standards20 for vul-\nnerabilitydisclosureandhandling.Topreventvulnerabilitiesfromre-occurringinnewor\nupdatedproducts,theteamshouldperformarootcauseanalysisandfeedthelessons\nlearned into the secure software lifecycle practices. For further discussion, see Sec-\ntions2.1.1bullet12and2.1.2bullet7.\n8. Planning the Implementation and Deployment of Secure Development. A healthy and\nmature secure development lifecycle includes the above seven practices but also an\nintegration of these practices into the business process and the entire organisation,\nincludingprogrammanagement,stakeholdermanagement,deploymentplanning,met-\nricsandindicators,andaplanforcontinuousimprovement.Theculture,expertiseand\n16https:\/\/www.owasp.org\/images\/0\/08\/OWASP_SCP_Quick_Reference_Guide_v2.pdf\n17https:\/\/www.oracle.com\/technetwork\/java\/seccodeguide-139067.html\n18https:\/\/wiki.sei.cmu.edu\/confluence\/display\/seccode\/SEI+CERT+Coding+Standards\n19https:\/\/www.first.org\/cvss\/\n20https:\/\/www.iso.org\/standard\/45170.htmlandhttps:\/\/www.iso.org\/standard\/53231.html\nKASecureSoftwareLifecycle |October2019 Page530 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nskill level of the organisation needs to be considered when planning to deploy a se-\ncure software lifecycle. Based upon past history, the organisation may respond better\nto a corporate mandate, to a bottom-up groundswell approach or to a series of pilot\nprograms. Training will be needed (see Section 2.1.1 bullet 1). The specification of the\norganisation\u2019ssecuresoftwarelifecycleincludingtherolesandresponsibilitiesshould\nbedocumented.Plansforcomplianceandprocesshealthshouldbemade(seeSection\n16.4).\n16.2.2 Comparing the Secure Software Lifecycle Models\nIn2009,DeWinetal.[1370]comparedCLASP,Microsoft\u2019soriginally-documentedSDL[1340],\nandTouchpoints(seeSection2.1.2)forthepurposeofprovidingguidanceontheircommon-\nalities and the specificity of the approach, and making suggestions for improvement. The\nauthors mapped the 153 possible activities of each lifecycle model into six software devel-\nopment phases: education and awareness; project inception; analysis and requirements; ar-\nchitectural and detailed design; implementation and testing; and release, deployment and\nsupport. The activities took the practices in Sections 2.1.1\u20132.1.3 into much finer granularity.\nThe authors indicated whether each model includes each of the 153 activities and provides\nguidanceonthestrengthsandweaknessesofeachmodel.Theauthorsfoundnoclearcom-\nprehensive \u2019winner\u2019 among the models, so practitioners could consider using guidelines for\nthedesiredfine-grainedpracticesfromallthemodels.\nTable16.1placesthethepracticesofSections2.1.1\u20132.1.3intothesixsoftwaredevelopment\nphases used by De Win et al. [1370]. Similar to prior work [1370], the models demonstrate\nstrengths and weaknesses in terms of guidance for the six software development phases.\nNomodelcanbeconsideredperfectforallcontexts.Securityexpertscancustomizeamodel\nfortheirorganizationsconsideringthespreadofpracticesforthesixsoftwaredevelopment\nphases.\nKASecureSoftwareLifecycle |October2019 Page531 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nMicrosoftSDL Touchpoints SAFECode\n\u2022 Planningthe\nEducationand implementationand\nawareness \u2022 Providetraining deploymentofsecure\ndevelopment\n\u2022 Definemetricsand\ncompliancereporting\n\u2022 Planningthe\nProjectinception \u2022 Defineanduse implementationand\ncryptography deploymentofsecure\nstandards development\n\u2022 Useapprovedtools\n\u2022 Definesecurity\nAnalysisand requirements \u2022 Abusecases \u2022 Applicationsecurity\nrequirements \u2022 Performthreat \u2022 Securityrequirements controldefinition\nmodelling\nArchitecturaland \u2022 Establishdesign \u2022 Architecturalrisk\ndetaileddesign requirements analysis \u2022 Design\n\u2022 Performstaticanalysis\nsecuritytesting(SAST)\n\u2022 Performdynamic\nanalysissecurity\n\u2022 Securecoding\ntesting(DAST)\n\u2022 Codereview(tools) practices\nImplementation \u2022 Performpenetration \u2022 Penetrationtesting \u2022 Managesecurityrisk\nandtesting testing inherentintheuseof\n\u2022 Risk-basedsecurity\n\u2022 Defineanduse third-partycomponents\ntesting\ncryptography\n\u2022 Testingandvalidation\nstandards\n\u2022 Managetheriskof\nusingthird-party\ncomponents\nRelease, \u2022 Establishastandard\ndeployment,and incidentresponse \u2022 Securityoperations \u2022 Vulnerabilityresponse\nsupport process anddisclosure\nTable16.1:ComparingtheSoftwareSecurityLifecycleModels\nKASecureSoftwareLifecycle |October2019 Page532 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n16.3 ADAPTATIONS OF THE SECURE SOFTWARE\nLIFECYCLE\n[1368,1371,1372,1373,1374,1375,1376,1377,1378,1379]\nThesecuresoftwarelifecyclemodelsdiscussedinSection16.2.1canbeintegratedwithany\nsoftware development model and are domain agnostic. In this section, information on six\nadaptationstosecuresoftwarelifecycleisprovided.\n16.3.1 Agile Software Development and DevOps\nAgile and continuous software development methodologies are highly iterative, with new\nfunctionalitybeingprovidedtocustomersfrequently-potentiallyasquicklyasmultipletimes\nperdayoras\u2019slowly\u2019aseverytwotofourweeks.\nAgile software development methodologies can be functional requirement-centric, with the\nfunctionality being expressed as user stories. SAFECode [1371] provides practical software\nsecurity guidance to agile practitioners. This guidance includes a set of 36 recommended\nsecurity-focused stories that can be handled similarly to the functionality-focused user sto-\nries. These stories are based upon common security issues such as those listed in the\nOWASP Top 1021 Most Critical Web Application Security Risks. The stories are mapped to\nCommonWeaknessEnumerations(CWEs)22 identifiers,asapplicable.Thesecurity-focused\nstoriesarewordedinaformatsimilartofunctionalitystories(i.e.,Asa[stakeholder],Iwantto\n[new functionality] so that I can [goal]). For example, a security-focused story using this for-\nmatisprovided:AsQualityAssurance,Iwanttoverifythatallusershaveaccesstothespecific\nresourcestheyrequirewhichtheyareauthorisedtouse,thatismappedtoCWE-862andCWE-\n863. The security-focused stories are further broken down into manageable and concrete\ntasks that are owned by team roles, including architects, developers, testers and security\nexperts,andaremappedtoSAFECodeFundamentalPractices[1368].Finally,17operational\nsecurity tasks were specified by SAFECode. These tasks are not directly tied to stories but\narehandledascontinuousmaintenancework(suchas,Continuouslyverifycoverageofstatic\ncodeanalysistools)orasanitemrequiringspecialattention(suchas,Configurebugtracking\ntotracksecurityvulnerabilities).\nWithaDevOpsapproachtodevelopingsoftware,developmentandoperationsaretightlyinte-\ngratedtoenablefastandcontinuousdeliveryofvaluetoendusers.Microsofthaspublished\na DevOps secure software lifecycle model [1372] that includes activities for operations engi-\nneerstoprovidefastandearlyfeedbacktotheteamtobuildsecurityintoDevOpsprocesses.\nTheSecureDevOpsmodelcontainseightpractices,includingeightofthe12practicesinthe\nMicrosoftSecurityDevelopmentLifecyclediscussedinSection2.1.1:\n1. Provide Training. The training, as outlined in Section 2.1.1 bullet 1, must include the\noperations engineers. The training should encompass attack vectors made available\nthroughthedeploymentpipeline.\n2. DefineRequirements.SeeSection2.1.1bullet2.\n3. DefineMetricsandComplianceReporting.SeeSection2.1.1bullet3.\n21https:\/\/www.owasp.org\/index.php\/Category:OWASP_Top_Ten_Project\n22https:\/\/cwe.mitre.org\/; CWE is a community-developed list of common software security weaknesses. It\nservesasacommonlanguage,ameasuringstickforsoftwaresecuritytools,andasabaselineforweakness\nidentification,mitigation,andpreventionefforts.\nKASecureSoftwareLifecycle |October2019 Page533 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n4. UseSoftwareCompositionAnalysis(SCA)andGovernance.Whenselectingbothcom-\nmercial and open-source third-party components, the team should understand the im-\npactthatavulnerabilityinthecomponentcouldhaveontheoverallsecurityofthesys-\ntemandconsiderperformingamorethoroughevaluationbeforeusingthem.Software\nCompositionAnalysis(SCA)tools,suchasWhiteSource23 canassistwithlicensingex-\nposure, provide an accurate inventory of components, and report any vulnerabilities\nwithreferencedcomponents.SeealsoSection2.1.1bullet7.\n5. Perform Threat Modelling. See Section 2.1.1 bullet 4. Threat modelling may be per-\nceived as slowing down the rapid DevOps pace. However, products that are deployed\nrapidlyunderaDevOpsdeploymentprocessshouldhaveadefinedoverallarchitecture\nwithinwhichtheDevOpsprocessmakeschangesandaddsfeatures.Thatarchitecture\nshould be threat modeled, and when the team needs to change the architecture the\nthreat model should also be updated. New features that do not have an architectural\nimpactrepresentanullchangetothethreatmodel.\n6. UseToolsandAutomation.SeeSection2.1.1bullets8,9and10.Theteamshouldcare-\nfullyselecttoolsthatcanbeintegratedintotheengineer\u2019sIntegratedDevelopmentEnvi-\nronment(IDE)andworkflowsuchthattheycauseminimaldisruption.Thegoalofusing\nthese tools is to detect defects and vulnerabilities and not to overload engineers with\ntoo many tools or alien processes outside of their everyday engineering experience.\nThe tools used as part of a secure DevOps workflow should adhere to the following\nprinciples:\n(a) Tools must be integrated into the Continuous Integration\/Continuous Delivery\n(CI\/CD)pipeline.\n(b) Toolsmustnotrequiresecurityexpertisebeyondwhatisimpartedbythetraining.\n(c) Toolsmustavoidahighfalse-positiverateofreportingissues.\n7. Keep Credentials Safe. Scanning for credentials and other sensitive content in source\nfiles is necessary during pre-commit to reduce the risk of propagating the sensitive in-\nformation through the CI\/CD process, such as through Infrastructure as Code or other\ndeployment scripts. Tools, such as CredScan24, can identify credential leaks, such as\nthose in source code and configuration files. Some commonly found types of creden-\ntials include default passwords, hard-coded passwords, SQL connection strings and\nCertificateswithprivatekeys.\n8. UseContinuousLearningandMonitoring.Rapidly-deployedsystemsoftenmonitorthe\nhealth of applications, infrastructure and networks through instrumentation to ensure\nthe systems are behaving \u2019normally\u2019. This monitoring can also help uncover security\nand performance issues which are departures from normal behaviour. Monitoring is\nalso an essential part of supporting a defense-in-depth strategy and can reduce an\norganisation\u2019s Mean Time To Identify (MTTI) and Mean Time To Contain (MTTC) an\nattack.\n23https:\/\/www.whitesourcesoftware.com\/\n24https:\/\/secdevtools.azurewebsites.net\/helpcredscan.html\nKASecureSoftwareLifecycle |October2019 Page534 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n16.3.2 Mobile\nSecurityconcernsformobileappsdifferfromtraditionaldesktopsoftwareinsomeimportant\nways, including local data storage, inter-app communication, proper usage of cryptographic\nAPIs and secure network communication. The OWASP Mobile Security Project [1373] is a\nresourcefordevelopersandsecurityteamstobuildandmaintainsecuremobileapplications;\nseealsotheWeb&MobileSecurityKnowledgeArea(Chapter15).\nFourresourcesareprovidedtoaidinthesecuresoftwarelifecycleofmobileapplications:\n1. OWASPMobileApplicationSecurityVerificationStandard(MASVS)SecurityRequire-\nments and Verification. The MASVS defines a mobile app security model and lists\ngeneric security requirements for mobile apps. The MASVS can be used by architects,\ndevelopers, testers, security professionals, and consumers to define and understand\nthequalitiesofasecuremobileapp.\n2. Mobile Security Testing Guide (MSTG). The guide25 is a comprehensive manual for\nmobileapplicationsecuritytestingandreverseengineeringforiOSandAndroidmobile\nsecuritytesters.Theguideprovidesthefollowingcontent:\n(a) Ageneralmobileapplicationtestingguidethatcontainsamobileappsecuritytest-\ning methodology and general vulnerability analysis techniques as they apply to\nmobile app security. The guide also contains additional technical test cases that\nare operating system independent, such as authentication and session manage-\nment,networkcommunications,andcryptography.\n(b) Operating system-dependent testing guides for mobile security testing on the An-\ndroidandiOSplatforms,includingsecuritybasics;securitytestcases;reverseen-\ngineeringtechniquesandprevention;andtamperingtechniquesandprevention.\n(c) DetailedtestcasesthatmaptotherequirementsintheMASVS.\n3. Mobile App Security Checklist. The checklist26 is used for security assessments and\ncontainslinkstotheMSTGtestcaseforeachrequirement.\n4. MobileThreatModel.Thethreatmodel[1374]providesachecklistofitemsthatshould\nbe documented, reviewed and discussed when developing a mobile application. Five\nareasareconsideredinthethreatmodel:\n(a) Mobile Application Architecture. The mobile application architecture describes\ndevice-specific features used by the application, wireless transmission protocols,\ndata transmission medium, interaction with hardware components and other ap-\nplications.Theattacksurfacecanbeassessedthroughamappingtothearchitec-\nture.\n(b) Mobile Data. This section of the threat model defines the data the application\nstores, transmits and receives. The data flow diagrams should be reviewed to de-\ntermineexactlyhowdataarehandledandmanagedbytheapplication.\n(c) ThreatAgentIdentification.Thethreatagentsareenumerated,includinghumans\nandautomatedprograms.\n25https:\/\/www.owasp.org\/index.php\/OWASP_Mobile_Security_Testing_Guide\n26https:\/\/github.com\/OWASP\/owasp-mstg\/tree\/master\/Checklists\nKASecureSoftwareLifecycle |October2019 Page535 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n(d) Methods of Attack. The most common attacks utilised by threat agents are de-\nfinedsothatcontrolscanbedevelopedtomitigateattacks.\n(e) Controls.Thecontrolstomitigateattacksaredefined.\n16.3.3 Cloud Computing\nThe emergence of cloud computing bring unique security risks and challenges. In conjunc-\ntionwiththeCloudSecurityAlliance(CSA)27,SAFECodehasprovideda\u2019PracticesforSecure\nDevelopment of Cloud Applications\u2019 [1375] guideline as a supplement to the \u2019Fundamental\nPractices for Secure Software Development\u2019 guideline [1368] discussed in Section 16.2.1.3 -\nseealsotheDistributedSystemsSecurityKnowledgeArea(Chapter12).TheCloudguideline\nprovides additional secure development recommendations to address six threats unique to\ncloudcomputingandtoidentifyspecificsecuritydesignandimplementationpracticesinthe\ncontextofthesethreats.Thesethreatsandassociatedpracticesareprovided:\n1. Threat: Multitenancy. Multitenancy allows multiple consumers or tenants to maintain\na presence in a cloud service provider\u2019s environment, but in a manner where the com-\nputations, processes, and data (both at rest and in transit) of one tenant are isolated\nfromandinaccessibletoanothertenant.Practices:\n(a) Model the application\u2019s interfaces in threat models. Ensure that the multitenancy\nthreats, such as information disclosure and privilege elevation are modeled for\neach of these interfaces, and ensure that these threats are mitigated in the appli-\ncationcodeand\/orconfigurationsettings.\n(b) Usea\u2019separateschema\u2019databasedesignandtablesforeachtenantwhenbuilding\nmultitenantapplicationsratherthanrelyingona\u2019TenantID\u2019columnineachtable.\n(c) Whendevelopingapplicationsthatleverageacloudserviceprovider\u2019sPlatformas\naService(PaaS)services,ensurecommonservicesaredesignedanddeployedin\nawaythatensuresthatthetenantsegregationismaintained.\n2. Tokenisation of Sensitive Data. An organisation may not wish to generate and store\nintellectual property in a cloud environment not under its control. Tokenisation is a\nmethod of removing sensitive data from systems where they do not need to exist or\ndisassociatingthedatafromthecontextortheidentitythatmakesthemsensitive.The\nsensitivedataarereplacedwithatokenforthosedata.Thetokenislaterusedtorejoin\nthesensitivedatawithotherdatainthecloudsystem.Thesensitivedataareencrypted\nandsecuredwithinanorganisation\u2019scentralsystemwhichcanbeprotectedwithmulti-\nplelayersofprotectionandappropriateredundancyfordisasterrecoveryandbusiness\ncontinuity.Practices:\n(a) Whendesigningacloudapplication,determineiftheapplicationneedstoprocess\nsensitive data and if so, identify any organisational, government, or industry regu-\nlations that pertain to that type of sensitive data and assess their impact on the\napplicationdesign.\n(b) Considerimplementingtokenisationtoreduceoreliminatetheamountofsensitive\ndatathatneedtobeprocessedandorstoredincloudenvironments.\n27https:\/\/cloudsecurityalliance.org\/\nKASecureSoftwareLifecycle |October2019 Page536 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n(c) Consider data masking, an approach that can be used in pre-production test and\ndebug systems in which a representative data set is used, but does not need to\nhave access to actual sensitive data. This approach allows the test and debug\nsystemstobeexemptfromsensitivedataprotectionrequirements.\n3. Trusted Compute Pools. Trusted Compute Pools are either physical or logical group-\nings of compute resources\/systems in a data centre that share a security posture.\nThese systems provide measured verification of the boot and runtime infrastructure\nfor measured launch and trust verification. The measurements are stored in a trusted\nlocation on the system (referred to as a Trusted Platform Module (TPM)) and verifi-\ncation occurs when an agent, service or application requests the trust quote from the\nTPM.Practices:\n(a) Ensuretheplatformfordevelopingcloudapplicationsprovidestrustmeasurement\ncapabilities and the APIs and services necessary for your applications to both re-\nquestandverifythemeasurementsoftheinfrastructuretheyarerunningon.\n(b) Verifythetrustmeasurementsaseitherpartoftheinitialisationofyourapplication\norasaseparatefunctionpriortolaunchingtheapplication.\n(c) Auditthetrustoftheenvironmentsyourapplicationsrunonusingattestationser-\nvicesornativeattestationfeaturesfromyourinfrastructureprovider.\n4. DataEncryptionandKeyManagement.Encryptionisthemostpervasivemeansofpro-\ntectingsensitivedatabothatrestandintransit.Whenencryptionisused,bothproviders\nand tenants must ensure that the associated cryptographic key materials are properly\ngenerated,managedandstored.Practices:\n(a) When developing an application for the cloud, determine if cryptographic and key\nmanagement capabilities need to be directly implemented in the application or\nif the application can leverage cryptographic and key management capabilities\nprovidedbythePaaSenvironment.\n(b) Make sure that appropriate key management capabilities are integrated into the\napplication to ensure continued access to data encryption keys, particularly as\nthe data move across cloud boundaries, such as enterprise to cloud or public to\nprivatecloud.\n5. Authentication and Identity Management. As an authentication consumer, the appli-\ncation may need to authenticate itself to the PaaS to access interfaces and services\nprovided by the PaaS. As an authentication provider, the application may need to au-\nthenticatetheusersoftheapplicationitself.Practices:\n(a) Cloud application developers should implement the authentication methods and\ncredentialsrequiredforaccessingPaaSinterfacesandservices.\n(b) Cloudapplicationdevelopersneedtoimplementappropriateauthenticationmeth-\nodsfortheirenvironments(private,hybridorpublic).\n(c) When developing cloud applications to be used by enterprise users, developers\nshouldconsidersupportingSingleSignOn(SSO)solutions.\n6. Shared-DomainIssues.Severalcloudprovidersofferdomainsthatdeveloperscanuse\ntostoreusercontent,orforstagingandtestingtheircloudapplications.Assuch,these\nKASecureSoftwareLifecycle |October2019 Page537 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ndomains, which may be used by multiple vendors, are considered \u2019shared domains\u2019\nwhenrunningclient-sidescript(suchasJavaScript)andfromreadingdata.Practices:\n(a) Ensurethatyourcloudapplicationsareusingcustomdomainswheneverthecloud\nprovider\u2019sarchitectureallowsyoutodoso.\n(b) Reviewyoursourcecodeforanyreferencestoshareddomains.\nThe European Union Agency for Cybersecurity (ENISA) [1377] conducted an in-depth and in-\ndependentanalysisoftheinformationsecuritybenefitsandkeysecurityrisksofcloudcom-\nputing. The analysis reports that the massive concentrations of resources and data in the\ncloud present a more attractive target to attackers, but cloud-based defences can be more\nrobust,scalableandcost-effective.\n16.3.4 Internet of Things (IoT)\nThe Internet of Things (IoT) is utilised in almost every aspect of our daily life, including the\nextensionintoindustrialsectorsandapplications(i.e.IndustrialIOT(IIoT)).IoTandIIoTcon-\nstituteanareaofrapidgrowththatpresentsuniquesecuritychallenges.[Fromthispointforth\nwe include IIoT when we use IoT.] Some of these are considered in the Cyber-Physical Sys-\ntems Security Knowledge Area (Chapter 19), but we consider specifically software lifecycle\nissues here. Devices must be securely provisioned, connectivity between these devices and\nthecloudmustbesecure,anddatainstorageandintransitmustbeprotected.However,the\ndevicesaresmall,cheap,resource-constrained.Buildingsecurityintoeachdevicemaynotbe\nconsidered to be cost effective by its manufacturer, depending upon the value of the device\nandtheimportanceofthedataitcollects.AnIoT-basedsolutionoftenhasalargenumberof\ngeographically-distributeddevices.Asaresultofthesetechnicalchallenges,trustconcerns\nexist with the IoT, most of which currently have no resolution and are in need of research.\nHowever,theUSNationalInstituteofStandardsandTechnology(NIST)[1376]recommends\nfourpracticesforthedevelopmentofsecureIoT-basedsystems.\n1. UseofRadio-FrequencyIdentification(RFID)tags.Sensorsandtheirdatamaybetam-\npered with, deleted, dropped, or transmitted insecurely. Counterfeit \u2019things\u2019 exist in the\nmarketplace.UniqueidentifierscanmitigatethisproblembyattachingRadio-Frequency\nIdentification(RFID)tagstodevices.Readersactivateatag,causingthedevicetobroad-\ncast radio waves within a bandwidth reserved for RFID usage by governments interna-\ntionally.Theradiowavestransmitidentifiersorcodesthatreferenceuniqueinformation\nassociatedwiththedevice.\n2. Not using or allowing the use of default passwords or credentials. IoT devices are\noften not developed to require users and administrators to change default passwords\nduringsystemsetup.Additionally,devicesoftenlackintuitiveuserinterfacesforchang-\ningcredentials.Recommendedpracticesaretorequirepasswordstobechangedorto\ndesign in intuitive interfaces. Alternatively, manufacturers can randomise passwords\nperdeviceratherthanhavingasmallnumberofdefaultpasswords.\n3. Use of the Manufacturer Usage Description (MUD) specification. The Manufacturer\nUsage Description (MUD)28 specification allows manufacturers to specify authorised\nand expected user traffic patterns to reduce the threat surface of an IoT device by re-\nstricting communications to\/from the device to sources and destinations intended by\nthemanufacturer.\n28https:\/\/tools.ietf.org\/id\/draft-ietf-opsawg-mud-22.html\nKASecureSoftwareLifecycle |October2019 Page538 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n4. Development of a Secure Upgrade Process. In non-IoT systems, updates are usually\ndeliveredviaasecureprocessinwhichthecomputercanauthenticatethesourcepush-\ning the patches and feature and configuration updates. IoT manufacturers have, gen-\nerally,notestablishedsuchasecureupgradeprocess,whichenablesattackerstocon-\nduct a man-in-the-middle push of their own malicious updates to the devices. The IoT\nFirmwareUpdateArchitecture29providesguidanceonimplementingasecurefirmware\nupdatearchitectureincludinghardrulesdefininghowdevicemanufacturersshouldop-\nerate.\nAdditionally,theUKDepartmentforDigital,Culture,Media,andSporthaveprovidedtheCode\nof Practice for consumer IoT security30. Included in the code of practice are 13 guidelines\nfor improving the security of consumer IoT products and associated services. Two of the\nguidelines overlap with NIST bullets 2 and 4 above. The full list of guidelines include the fol-\nlowing: (1) No default passwords; (2) Implement a vulnerability disclosure policy; (3) Keep\nsoftware updated; (4) Securely store credentials and security-sensitive data; (5) Communi-\ncate securely (i.e. use encryption for sensitive data); (6) Minimise exposed attack surfaces;\n(7)Ensuresoftwareintegrity(e.g.useofasecureboot);(8)Ensurethatpersonaldataispro-\ntected (i.e. in accordance with GDPR); (9) Make systems resilient to outages; (10) Monitor\nsystem telemetry data; (11) Make it easy for consumers to delete personal data; (12) Make\ninstallationandmaintenanceofdeviceseasy;and(13)Validateinputdata.Finally,Microsoft\nhasprovidedanInternetofThingssecurityarchitecture.31\n16.3.5 Road Vehicles\nA hacker that compromises a connected road vehicle\u2018s braking or steering system could\ncause a passenger or driver to lose their lives. Attacks such as these have been demon-\nstrated, beginning with the takeover of a Ford Escape and a Toyota Prius by white-hat hack-\ners Charlie Miller and Chris Valasek in 201332. Connected commercial vehicles are part of\nthe critical infrastructure in complex global supply chains. In 2018, the number of reported\nattacks on connected vehicles shot up six times more than the number just three years ear-\nlier[1378],duetoboththeincreaseinconnectedvehiclesandtheirincreasedattractiveness\nas a target of attackers [1379]. Broader issues with Cyber-Physical Systems are addressed\nintheCyber-PhysicalSystemsSecurityKnowledgeArea(Chapter19).\nThe US National Highway Traffic Safety Administration (HTSA) defines road vehicle cyber\nsecurity as the protection of automotive electronic systems, communication networks, con-\ntrol algorithms, software, users and underlying data from malicious attacks, damage, unau-\nthorised access or manipulation33. The HTSA provides four guidelines for the automotive\nindustryforconsiderationintheirsecuresoftwaredevelopmentlifecycle:\n1. The team should follow a secure product development process based on a systems-\nengineering approach with the goal of designing systems free of unreasonable safety\nrisksincludingthosefrompotentialcybersecuritythreatsandvulnerabilities.\n2. The automotive industry should have a documented process for responding to inci-\ndents,vulnerabilitiesandexploits.Thisprocessshouldcoverimpactassessment,con-\n29https:\/\/tools.ietf.org\/id\/draft-moran-suit-architecture-02.html\n30https:\/\/www.gov.uk\/government\/publications\/code-of-practice-for-consumer-iot-security\/code-of-practice-for-\nconsumer-iot-security\n31https:\/\/docs.microsoft.com\/en-us\/azure\/iot-fundamentals\/iot-security-architecture\n32https:\/\/www.wired.com\/2015\/07\/hackers-remotely-kill-jeep-highway\/\n33https:\/\/www.nhtsa.gov\/crash-avoidance\/automotive-cybersecurity#automotive-cybersecurity-overview\nKASecureSoftwareLifecycle |October2019 Page539 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntainment,recoveryandremediationactions,theassociatedtesting,andshouldinclude\nthe creation of roles and responsibilities for doing so. The industry should also estab-\nlishmetricstoperiodicallyassesstheeffectivenessoftheirresponseprocess.\n3. The automotive industry should document the details related to their cyber security\nprocess,includingtheresultsofriskassessment,penetrationtestingandorganisations\ndecisionsrelatedtocybersecurity.Essentialdocuments,suchascybersecurityrequire-\nments,shouldfollowarobustversioncontrolprotocol.\n4. Thesesecurityrequirementsshouldbeincorporatedintotheproduct\u2019ssecurityrequire-\nments,aslaidoutinSection2.1.1bullet2,Section2.1.2bullet6,andSection2.1.3bullet\n1.:\n(a) Limitdeveloper\/debuggingaccesstoproductiondevices,suchasthroughanopen\ndebuggingportorthroughaserialconsole.\n(b) Keys (e.g., cryptographic) and passwords which can provide an unauthorised, el-\nevated level of access to vehicle computing platforms should be protected from\ndisclosure.Keysshouldnotprovideaccesstomultiplevehicles.\n(c) Diagnosticfeaturesshouldbelimitedtoaspecificmodeofvehicleoperationwhich\naccomplishestheintendedpurposeoftheassociatedfeature.Forexample,adiag-\nnosticoperationwhichmaydisableavehicle\u2019sindividualbrakescouldberestricted\ntooperatingonlyatlowspeedsornotdisablingallthebrakesatthesametime.\n(d) Encryption should be considered as a useful tool in preventing the unauthorised\nrecoveryandanalysisoffirmware.\n(e) Limit the ability to modify firmware and\/or employ signing techniques to make it\nmorechallengingformalwaretobeinstalledonvehicles.\n(f) TheuseofnetworkserversonvehicleECUsshouldbelimitedtoessentialfunction-\nality,andservicesovertheseportsshouldbeprotectedtopreventusebyunautho-\nrisedparties.\n(g) Logicalandphysicalisolationtechniquesshouldbeusedtoseparateprocessors,\nvehiclenetworks,andexternalconnectionsasappropriatetolimitandcontrolpath-\nwaysfromexternalthreatvectorstocyber-physicalfeaturesofvehicles.\n(h) Sending safety signals as messages on common data buses should be avoided,\nbutwhenusedshouldemployamessageauthenticationschemetolimitthepos-\nsibilityofmessagespoofing.\n(i) Animmutablelogofeventssufficienttoenableforensicanalysisshouldbemain-\ntained and periodically scrutinised by qualified maintenance personnel to detect\ntrendsofcyber-attack.\n(j) Encryption methods should be employed in any IP-based operational communi-\ncation between external servers and the vehicle, and should not accept invalid\ncertificates.\n(k) Plan for and design-in features that could allow for changes in network routing\nrulestobequicklypropagatedandappliedtoone,asubsetorallvehicles\nThe International Organization for Standardization (ISO)34 and the Society for Automative\n34https:\/\/www.iso.org\/standard\/70918.html\nKASecureSoftwareLifecycle |October2019 Page540 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nEngineering(SAE)International35 arejointlydevelopinganinternationalStandard,ISO21434\nRoadvehicles-cybersecurityengineering36.Thestandardwillspecifyminimumrequirements\non security engineering processes and activities, and will define criteria for assessment. Ex-\nplicitly, the goal is to provide a structured process to ensure cyber security is designed in\nupfrontandintegratedthroughoutthelifecycleprocessforbothhardwareandsoftware.\nThe adoption of a secure software lifecycle in the automotive industry may be driven by leg-\nislation, such as through the US SPY Car Act37 or China and Germany\u2019s Intelligent and Con-\nnectedVehicles(ICVs)initiative38.\n16.3.6 ECommerce\/Payment Card Industry\nThe ability to steal large quantities of money makes the Payment Card Industry (PCI) an es-\npecially attractive target for attackers. In response, the PCI created the Security Standards\nCouncil,aglobalforumfortheongoingdevelopment,enhancement,storage,dissemination,\nand implementation of security standards for account data protection. The Security Stan-\ndards Council established the Data Security Standard (PCI DSS), which must be upheld by\nanyorganisationsthathandlepaymentcards,includingdebitandcreditcards.PCIDSScon-\ntains 12 requirements39 that are a set of security controls that businesses are required to\nimplementtoprotectcreditcarddata.Thesespecificrequirementsareincorporatedintothe\nproduct\u2019ssecurityrequirements,aslaidoutinSection2.1.1bullet2,Section2.1.2bullet6,and\nSection2.1.3bullet1.The12requirementsareasfollows:\n1. Installandmaintainafirewallconfigurationtoprotectcardholderdata.\n2. Donotusevendor-supplieddefaultsforsystempasswordsandothersecurityparame-\nters.\n3. Protectstoredcardholderdata.\n4. Encrypttransmissionofcardholderdataacrossopen,publicnetworks.\n5. Useandregularlyupdateantivirussoftware.\n6. Develop and maintain secure systems and applications, including detecting and miti-\ngatingvulnerabilitiesandapplyingmitigatingcontrols.\n7. Restrictaccesstocardholderdatabybusinessneed-to-know.\n8. AssignauniqueIDtoeachpersonwithcomputeraccess.\n9. Restrictphysicalaccesstocardholderdata.\n10. Trackandmonitorallaccesstonetworkresourcesandcardholderdata.\n11. Regularlytestsecuritysystemsandprocesses.\n12. Maintainapolicythataddressesinformationsecurity.\n35www.sae.org\n36https:\/\/www.iso.org\/standard\/70918.html\n37https:\/\/www.congress.gov\/bill\/115th-congress\/senate-bill\/680\n38http:\/\/icv.sustainabletransport.org\/\n39https:\/\/searchsecurity.techtarget.com\/definition\/PCI-DSS-12-requirements\nKASecureSoftwareLifecycle |October2019 Page541 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n16.4 ASSESSING THE SECURE SOFTWARE LIFECYCLE\n[1380,1381]\nOrganisationsmaywishtoorberequiredtoassessthematurityoftheirsecuredevelopment\nlifecycle.Fourassessmentapproachesaredescribedinthissection.\n16.4.1 SAMM\nThe Software Assurance Maturity Model (SAMM)40 is an open framework to help organisa-\ntionsformulateandimplementastrategyforsoftwaresecuritythatistailoredtothespecific\nrisks facing the organisation. Resources are provided for the SAMM to enable an organisa-\ntiontodothefollowing:\n1. Defineandmeasuresecurity-relatedactivitieswithinanorganisation.\n2. Evaluatetheirexistingsoftwaresecuritypractices.\n3. Buildabalancedsoftwaresecurityprograminwell-definediterations.\n4. Demonstrateimprovementsinasecurityassuranceprogram.\nBecauseeachorganisationutilisesitsownsecuresoftwareprocess(i.e.,itsownuniquecom-\nbination of the practices laid out in Sections 2 and 3), the SAMM provides a framework to\ndescribe software security initiatives in a common way. The SAMM designers enumerated\nactivities executed by organisations in support of their software security efforts. Some ex-\nampleactivitiesinclude:buildandmaintainabusecasemodelsperproject;specifysecurity\nrequirementsbaseduponknownrisks;andidentifythesoftwareattacksurface.Theseactiv-\nities are categorised into one of 12 security practices. The 12 security practices are further\ngrouped into one of four business functions. The business functions and security practices\nareasfollows:\n1. BusinessFunction:Governance\n(a) Strategyandmetrics\n(b) Policyandcompliance\n(c) Educationandguidance\n2. BusinessFunction:Construction\n(a) Threatassessment\n(b) Securityrequirements\n(c) Securearchitecture\n3. BusinessFunction:Verification\n(a) Designreview\n(b) Codereview\n(c) Securitytesting\n4. BusinessFunction:Deployment\n40https:\/\/www.opensamm.org\/andhttps:\/\/www.owasp.org\/images\/6\/6f\/SAMM_Core_V1-5_FINAL.pdf\nKASecureSoftwareLifecycle |October2019 Page542 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n(a) Vulnerabilitymanagement\n(b) Environmenthardening\n(c) Operationalenablement\nThe SAMM assessments are conducted through self-assessments or by a consultant cho-\nsen by the organisation. Spreadsheets are provide by SAMM for scoring the assessment,\nprovidinginformationfortheorganisationontheircurrentmaturitylevel:\n\u2022 0:ImplicitstartingpointrepresentingtheactivitiesinthePracticebeingunfulfilled.\n\u2022 1:InitialunderstandingandadhocprovisionoftheSecurityPractice.\n\u2022 2:Increaseefficiencyand\/oreffectivenessoftheSecurityPractice.\n\u2022 3:ComprehensivemasteryoftheSecurityPracticeatscale.\nAssessmentsmaybeconductedperiodicallytomeasureimprovementsinanorganisation\u2019s\nsecurityassuranceprogram.\n16.4.2 BSIMM\nGaryMcGraw,SammyMigues,andBrianChessdesiredtocreateadescriptivemodelofthe\nstate-of-the-practice in secure software development lifecycle. As a result, they forked an\nearly version of SAMM (see Section 4.1) to create the original structure of the Building Se-\ncurityInMaturityModel(BSIMM)[1380,1381]in2009.Sincethattime,theBSIMMhasbeen\nused to structurea multi-year empirical studyof the current state ofsoftware security initia-\ntivesinindustry.\nBecauseeachorganisationutilisesitsownsecuresoftwareprocess(i.e.,itsownuniquecom-\nbination of the practices laid out in Sections 2 and 3), the BSIMM provides a framework to\ndescribe software security initiatives in a common way. Based upon their observations, the\nBSIMM designers enumerated 113 activities executed by organisations in support of their\nsoftware security efforts. Some example activities include: build and publish security fea-\ntures;useautomatedtoolsalongwithamanualreview;andintegrateblack-boxsecuritytools\ninto the quality assurance process. Each activity is associated with a maturity level and is\ncategorised into one of 12 practices. The 12 practices are further grouped into one of four\ndomains.Thedomainsandpracticesareasfollows:\n1. Domain:Governance\n(a) Strategyandmetrics\n(b) Complianceandpolicy\n(c) Training\n2. Domain:Intelligence\n(a) Attackmodels\n(b) Securityfeaturesanddesign\n(c) Standardsandrequirements\n3. Domain:Securesoftwaredevelopmentlifecycletouchpoints\n(a) Architectureanalysis\nKASecureSoftwareLifecycle |October2019 Page543 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n(b) Codereview\n(c) Securitytesting\n4. Domain:Deployment\n(a) Penetrationtesting\n(b) Softwareenvironment\n(c) Configurationmanagementandvulnerabilitymanagement\nBSIMM assessments are conducted through in-person interviews by software security pro-\nfessionals at Cigital (now Synopsys) with security leaders in a firm. Via the interviews, the\nfirmobtainsascorecardonwhichofthe113softwaresecurityactivitiesthefirmuses.After\nthefirmcompletestheinterviews,theyareprovidedinformationcomparingthemselveswith\ntheotherorganisationsthathavebeenassessed.BSIMMassessmentshavebeenconducted\nsince 2008. Annually, the overall results of the assessments from all firms are published, re-\nsulting in the BSIMM1 through BSIMM9 reports. Since the BSIMM study began in 2008, 167\nfirms have participated in BSIMM assessment, sometimes multiple times, comprising 389\ndistinctmeasurements.Toensurethecontinuedrelevanceofthedatareported,theBSIMM9\nreportexcludedmeasurementsolderthan42monthsandreportedon320distinctmeasure-\nmentscollectedfrom120firms.\n16.4.3 The Common Criteria\nThe purpose of this Common Criteria (CC)41 is to provide a vehicle for international recog-\nnition of a secure information technology (IT) product (where the SAMM and BSIMM were\nassessmentsofadevelopmentprocess).TheobjectiveoftheCCisforITproductsthathave\nearnedaCCcertificatefromanauthorisedCertification\/ValidationBody(CB)tobeprocured\nor used with no need for further evaluation. The Common Criteria seek to provide grounds\nfor confidence in the reliability of the judgments on which the original certificate was based\nbyrequiringthataCBissuingCommonCriteriacertificatesshouldmeethighandconsistent\nstandards. A developer of a new product range may provide guidelines for the secure devel-\nopment and configuration of that product. This guideline can be submitted as a Protection\nProfile (the pattern for similar products that follow on). Any other developer can add to or\nchange this guideline. Products that earn certification in this product range use the protec-\ntionprofileasthedeltaagainstwhichtheybuild.\nBased upon the assessment of the CB, a product receives an Evaluation Assurance Level\n(EAL).Aproductorsystemmustmeetspecificassurancerequirementstoachieveaparticu-\nlarEAL.Requirementsinvolvedesigndocumentation,analysisandfunctionalorpenetration\ntesting.Thehighestlevelprovidesthehighestguaranteethatthesystem\u2019sprincipalsecurity\nfeatures are reliably applied. The EAL indicates to what extent the product or system was\ntested:\n\u2022 EAL1:Functionallytested.Applieswhensecuritythreatsarenotviewedasserious.The\nevaluationprovidesevidencethatthesystemfunctionsinamannerconsistentwithits\ndocumentationandthatitprovidesusefulprotectionagainstidentifiedthreats.\n\u2022 EAL 2: Structurally tested. Applies when stakeholders require low-to-moderate\nindependently-assured security but the complete development record is not readily\n41https:\/\/www.commoncriteriaportal.org\/ccra\/index.cfm\nKASecureSoftwareLifecycle |October2019 Page544 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\navailable,suchaswithsecuringalegacysystem.\n\u2022 EAL 3: Methodically tested and checked. Applies when stakeholders require a moder-\natelevelofindependently-assuredsecurityandathoroughinvestigationofthesystem\nanditsdevelopment,withoutsubstantialre-engineering.\n\u2022 EAL4:Methodicallydesigned,testedandreviewed.Applieswhenstakeholdersrequire\nmoderate-to-high independently-assured security in commodity products and are pre-\nparedtoincuradditionalsecurity-specificengineeringcosts.\n\u2022 EAL 5: Semi-formally designed and tested. Applies when stakeholders require high,\nindependently-assured security in a planned development and require a rigorous de-\nvelopment approach that does not incur unreasonable costs from specialist security\nengineeringtechniques.\n\u2022 EAL6:Semi-formallyverifieddesignandtested.Applieswhendevelopingsystemsin\nhigh-risksituationswherethevalueoftheprotectedassetsjustifiesadditionalcosts.\n\u2022 EAL 7: Formally verified design and tested. Applies when developing systems in ex-\ntremely high-risk situations and when the high value of the assets justifies the higher\ncosts.\nThe CC provides a set of security functional and security assurance requirements. These\nrequirements, as appropriate, are incorporated into the product\u2019s security requirements, as\nlaidoutinSection2.1.1bullet2,Section2.1.2bullet6,andSection2.1.3bullet1.\n16.5 ADOPTING A SECURE SOFTWARE LIFECYCLE\n[1380,1381,1382]\nThisknowledgeareahasprovidedamyriadofpossiblepracticesanorganisationcaninclude\ninitssecuresoftwarelifecycle.Someofthesepractices,suchasthosediscussedinSection\n2, potentially apply to any product. Other practices are domain specific, such as those dis-\ncussedinSection3.\nOrganisations adopting new practices often like to learn from and adopt practices that are\nusedbyorganisationssimilartothemselves[1382].Whenchoosingwhichsecuritypractices\nto include in a secure software lifecycle, organisations can consider looking at the latest\nBSIMM [1380, 1381] results which provide updated information on the adoption of practices\nintheindustry.\nDISCUSSION\n[1383]\nThischapterhasprovidedanoverviewofofthreeprominentandprescriptivesecuresoftware\nlifecycleprocessesandsixadaptationsoftheseprocessesthatcanbeappliedinaspecified\ndomain. However, the cybersecurity landscape in terms of threats, vulnerabilities, tools, and\npractices is ever evolving. For example, a practice has has not be been mentioned in any of\nthesenineprocessesistheuseofabugbountyprogramfortheidentificationandresolution\nof vulnerabilities. With a bug bounty program, organisations compensate individuals and\/or\nresearchers for finding and reporting vulnerabilities. These individuals are external to the\nKASecureSoftwareLifecycle |October2019 Page545 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\norganisation producing the software and may work independently or through a bug bounty\norganisation,suchasHackerOne42.\nWhile the majority of this knowledge area focuses on technical practices, the successful\nadoption of these practices involves organisational and cultural changes in an organisa-\ntion. The organisation, starting from executive leadership, must support the extra training,\nresources,andstepsneededtouseasecuredevelopmentlifecycle.Additionally,everydevel-\nopermustupholdhisorherresponsibilitytotakepartinsuchaprocess.\nA team and an organisation need to choose the appropriate software security practices to\ndevelopacustomisedsecuresoftwarelifecyclebaseduponteamandtechnologycharacter-\nisticsanduponthesecurityriskoftheproduct.\nWhile this chapter has provided practices for developing secure products, information inse-\ncurity is often due to economic disincentives [1383] which drives software organizations to\nchoosetherapiddeploymentandreleaseoffunctionalityovertheproductionofsecureprod-\nucts.Asaresult,increasinglygovernmentsandindustrygroupsareimposingcybersecurity\nstandards on organisations as a matter of legal compliance or as a condition for being con-\nsidered as a vendor. Compliance requirements may lead to faster adoption of a secure de-\nvelopmentlifecycle.However,thiscompliance-drivenadoptionmaydiverteffortsawayfrom\nthe real security issues by driving an over-focus on compliance requirements rather than on\nthepragmaticpreventionanddetectionofthemostriskysecurityconcerns.\nCROSS-REFERENCE OF TOPICS VS REFERENCE MATERIAL\n16.1Motivation c1 c1 c1\n16.2PrescriptiveSecureSoftwareLifecycleProcesses\n16.2.1SecureSoftwareLifecycleProcesses c2 c2 c2 c2\n16.2.2ComparingtheSecureSoftwareLifecycleModels\n16.3AdaptationsoftheSecureSoftwareLifecycle\n16.3.1AgileSoftwareDevelopmentandDevOps c3\n16.3.2Mobile\n16.3.3CloudComputing\n16.3.4InternetofThings(IoT)\n16.3.5RoadVehicles\n16.3.6ECommerce\/PaymentCardIndustry\n16.4AssessingtheSecureSoftwareLifecycle\n16.5AdoptingaSecureSoftwareLifecycle\n42https:\/\/www.hackerone.com\nKASecureSoftwareLifecycle |October2019 Page546\n]0431[LDSdrawoH\n]8321[1102-ageiV\n]5431[CSWdrawoH\n]8631[latnemadnuFedoCEFAS TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nFURTHER READING\nBuilding Secure Software: How to Avoid Security Problems the Right Way\n[1238]\nThis book introduces the term software security as an engineering discipline for building\nsecurityintoaproduct.Thisbookprovidesessentiallessonsandexperttechniquesforsecu-\nrityprofessionalswhounderstandtheroleofsoftwareinsecurityproblemsandforsoftware\ndeveloperswhowanttobuildsecurecode.Thebookalsodiscussesriskassessment,devel-\nopingsecuritytests,andpluggingsecurityholesbeforesoftwareisshipped.\nWriting Secure Code, Second Edition. [1345]\nThefirsteditionofthisbookwasinternallypublishedinMicrosoftandwasrequiredreading\nfor all members of the Windows team during the Windows Security Push. The second edi-\ntionwasmadepubliclyavailableinthe2003bookandprovidessecurecodingtechniquesto\npreventvulnerabilities,todetectdesignflawsandimplementationbugs,andtoimprovetest\ncodeanddocumentation.\nSoftware Security: Building Security In [1346]\nThisbookdiscusses sevensoftwaresecuringbestpractices,calledtouchpoints.Italsopro-\nvides information on software security fundamentals and contexts for a software security\nprograminanenterprise.\nThe Security Development Lifecycle (Original Book) [1340]\nThisseminalbookprovidesthefoundationfortheotherprocesseslaidoutinthisknowledge\narea,andwascustomisedovertheyearsbyotherorganisations,suchasCisco43.Thebook\nlays out 13 stages for integrating practices into a software development lifecycle such that\ntheproductismoresecure.Thisbookisoutofprint,butisavaialbleasafreedownload44.\nThe Security Development Lifecycle (Current Microsoft Resources) [1347]\nTheMicrosoftSDLarepracticesthatareusedinternallytobuildsecureproductsandservices,\nandaddresssecuritycompliancerequirementsbyintroducingsecuritypracticesthroughout\neveryphaseofthedevelopmentprocess.Thiswebpageisacontinuously-updatedversionof\nthe seminal book [1340] based on Microsoft\u2019s growing experience with new scenarios such\nasthecloud,theInternetofThings(IoT)andArtificialIntelligence(AI).\n43https:\/\/www.cisco.com\/c\/en\/us\/about\/trust-center\/technology-built-in-security.html#~stickynav=2\n44https:\/\/blogs.msdn.microsoft.com\/microsoft_press\/2016\/04\/19\/free-ebook-the-security-development-lifecycle\/\nKASecureSoftwareLifecycle |October2019 Page547 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nSoftware Security Engineering: A Guide for Project Managers [1360]\nThis book is a management guide for selecting from among sound software development\npracticesthathavebeenshowntoincreasethesecurityanddependabilityofasoftwareprod-\nuct, both during development and subsequently during its operation. Additionally, this book\ndiscussesgovernanceandtheneedforadynamicriskmanagementapproachforidentifying\nprioritiesthroughouttheproductlifecycle.\nCyberSecurityEngineering:APracticalApproachforSystemsandSoftware\nAssurance [1384]\nThisbookprovidesatutorialonthebestpracticesforbuildingsoftwaresystemsthatexhibit\nsuperioroperationalsecurity,andforconsideringsecuritythroughoutyourfullsystemdevel-\nopment and acquisition lifecycles. This book provides seven core principles of software as-\nsurance, and shows how to apply them coherently and systematically. This book addresses\nimportant topics, including the use of standards, engineering security requirements for ac-\nquiring COTS software, applying DevOps, analysing malware to anticipate future vulnerabili-\nties,andplanningongoingimprovements.\nSAFECode\u2019s Fundamental Practices for Secure Software Development: Es-\nsential Elements of a Secure Development Lifecycle Program, Third Edition\n[1368]\nEightpracticesforsecuredevelopmentareprovidedbasedupontheexperiencesofmember\ncompaniesoftheSAFECodeorganisation.\nOWASP\u2019s Secure Software Development Lifecycle Project (S-SDLC) [1348]\nBased upon a committee of industry participants, the Secure-Software Development Life-\ncycle Project (S-SDLC) defines a standard Secure Software Development Life Cycle and pro-\nvidesresourcestohelpdevelopersknowwhatshouldbeconsideredorbestpracticesateach\nphase of a development lifecycle (e.g., Design Phase\/Coding Phase\/Maintain Phase\/etc.)\nThe committee of industry participants are members of the Open Web Application Security\nProject (OWASP)45, an international not-for-profit organisation focused on improving the se-\ncurityofwebapplicationsoftware.Theearliestsecuresoftwarelifecyclecontributionsfrom\nOWASP were referred to as the Comprehensive, Lightweight Application Security Process\n(CLASP).\n45https:\/\/www.owasp.org\/\nKASecureSoftwareLifecycle |October2019 Page548 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nSecurity controls\nGovernmentandstandardsorganizationshaveprovidedsecuritycontrolstobeintegratedin\nasecuresoftwareorsystemslifecyle:\n1. TheTrustworthySoftwareFoundation46 providesthetheTrustworthySoftwareFrame-\nwork (TSFr) 47 a collection of good practice, existing guidance and relevant standards\nacrossthefivemainfacetsoftrustworthiness:Safety;Reliability;Availability;Resilience;\nandSecurity.ThepurposeoftheTSFristoprovideaminimumsetofcontrolssuchthat,\nwhen applied, all software (irrespective of implementation constraints) can be speci-\nfied,realisedandusedinatrustworthymanner.\n2. The US National Institute of Standards and Technology (NIST) has authored the Sys-\ntems Security Engineering Cyber Resiliency Considerations for the Engineering [1385]\nframework (NIST SP 800-160). This Framework provides resources on cybersecurity\nKnowledge,SkillsandAbilitiess(KSAs),andtasksforanumberofworkrolesforachiev-\ning the identified cyber resiliency outcomes based on a systems engineering perspec-\ntiveonsystemlifecycleprocesses.\n3. The Software Engineering Institute (SEI) has collaborated with professional organisa-\ntions, industry partners and institutions of higher learning to develop freely-available\ncurricula and educational materials. Included in these materials are resources for a\nsoftwareassuranceprogram48 totrainprofessionalstobuildsecurityandcorrectfunc-\ntionalityintosoftwareandsystems.\n4. TheUKNationalCyberSecurityCentre(NCSC)49provideresourcesforsecuresoftware\ndevelopment:\n(a) Application development50: recommendations for the secure development, pro-\ncurement,anddeploymentofgenericandplatform-specificapplications.\n(b) Secure development and deployment guidance51: more recommendations for\nthe secure development, procurement, and deployment of generic and platform-\nspecificapplications.\n(c) Theleakypipeofsecurecoding52:adiscussionofhowsecuritycanbewovenmore\nseamlessly into the development process, particularly by developers who are not\nsecurityexperts.\n46https:\/\/tsfdn.org\n47https:\/\/tsfdn.org\/ts-framework\/\n48https:\/\/www.sei.cmu.edu\/education-outreach\/curricula\/software-assurance\/index.cfm\n49https:\/\/www.ncsc.gov.uk\/\n50https:\/\/www.ncsc.gov.uk\/collection\/application-development\n51https:\/\/www.ncsc.gov.uk\/collection\/developers-collection\n52https:\/\/www.ncsc.gov.uk\/blog-post\/leaky-pipe-secure-coding\nKASecureSoftwareLifecycle |October2019 Page549 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nTraining materials\nTrainingmaterialsarefreely-availableontheInternet.Somesitesincludethefollowing:\n1. TheTrustworthySoftwareFoundationprovidesaresourcelibrary53ofawarenessmate-\nrialsandguidancetargetedforthosewhoteachtrustworthysoftwareprinciples,those\nwho seek to learn about Trustworthy Software and those who want to ensure that the\nsoftware they use is trustworthy. The resources available include a mixture of docu-\nments,videos,animationsandcasestudies.\n2. The US National Institute of Standards and Technology (NIST) has created the NICE\nCyber security Workforce Framework [1386]. This Framework provides resources on\ncybersecurityKnowledge,SkillsandAbilitiess(KSAs),andtasksforanumberofwork\nroles.\n3. The Software Engineering Institute (SEI) has collaborated with professional organisa-\ntions, industry partners and institutions of higher learning to develop freely-available\ncurricula and educational materials. Included in these materials are resources for a\nsoftwareassuranceprogram54 totrainprofessionalstobuildsecurityandcorrectfunc-\ntionalityintosoftwareandsystems.\n4. SAFECodeoffersfreesoftwaresecuritytrainingcoursesdeliveredviaon-demandweb-\ncasts55.\n53https:\/\/tsfdn.org\/resource-library\/\n54https:\/\/www.sei.cmu.edu\/education-outreach\/curricula\/software-assurance\/index.cfm\n55https:\/\/safecode.org\/training\/\nKASecureSoftwareLifecycle |October2019 Page550 V Infrastructure Security\n551  Chapter 17\nNetwork Security\nSanjay Jha University of New South Wales\n553 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nINTRODUCTION\nThe ubiquity of the Internet allows us to connect all sorts of devices to the network and\ngainunprecedentedaccesstoawholerangeofapplicationsandservicesanytime,anywhere.\nHowever, our heavy reliance on networking technology also makes it an attractive target for\nmalicious users who are willing to compromise the security of our communications and\/or\ncausedisruptiontoservicesthatarecriticalforourday-to-daysurvivalinaconnectedworld.\nInthischapter,wewillexplainthechallengesassociatedwithsecuringanetworkunderava-\nrietyofattacksforanumberofnetworkingtechnologiesandwidelyusedsecurityprotocols,\nalongwithemergingsecuritychallengesandsolutions.Thischapteraimstoprovidethenec-\nessary background in order to understand other knowledge areas, in particular the Security\nOperations&IncidentManagementKnowledgeArea(Chapter8)whichtakesamoreholistic\nview of security and deals with operational aspects. An understanding of basic networking\nprotocol stack and TCP\/IP suite is assumed. Basic networking text books explain the fun-\ndamentals of the 7-layer ISO OSI model and Internet Protocol [1387]. When considering the\nsecurityoftheInternetandWirelessLAN(WLAN)technologies,itcansometimesbeinstruc-\ntive to consider how certain original protocols are either designed without bearing security\nin mind, or with poor security design decisions. This is not merely of historical interest: con-\ntemporarydesignsareoftenconstrainedbytheirpredecessorsforpragmaticreasons.\nCONTENT\n17.1 INTERNET ARCHITECTURE\nAcomplexsystemsuchasdistributedapplicationsrunningoverarangeofnetworkingtech-\nnologies is best understood when viewed as layered architecture. Figure 17.1 shows the 7-\nlayer protocol ISO OSI stack and the interaction between the various layers. The model also\nallows us to understand the security issues on each layer and the interplay between them.\nTheInternetisthepredominantarchitecturetoday.However,itusesonlyfivelayersfromthe\nprotocol stack in figure 17.1 i.e., layers 1\u20134 and layer 7. The Presentation and Session layers\nshowninthedottedboxareoptionalintheIPprotocolstackandsomeorallofthefunctions\ncan be custom built on application requirements. Network security requires cryptographic\ntechniquessuchaspublicandsymmetrickeysforencryptionandsigning,blockandstream\nciphers, hashing, and digital signature, as described in the Cryptography Knowledge Area\n(Chapter 10). We will take an applied approach to understand how these techniques help\nbuildasecurenetwork.\n17.2 NETWORK PROTOCOLS AND VULNERABILITY\nTypically,theDolev-Yao[28]adversarialformalmodelisusedforaformalanalysisofsecurity\nprotocols in the research literature. The Dolev-Yao model assumes that an adversary has\ncompletecontrolovertheentirenetwork,andconcurrentexecutionsoftheprotocolbetween\nthesamesetof2-or-morepartiescantakeplace.TheDolev-Yaomodeldescribestheworst\npossibleadversary:dependingonthecontext,realadversariesmayhavelimitedcapabilities.\nThis model is summarised as allowing the adversary to read any message, prevent delivery\nofanymessage,duplicateanymessage,orotherwisesynthesiseanymessageforwhichthe\nadversaryhastherelevantcryptographickeys(ifany).\nKANetworkSecurity |October2019 Page554 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nClient Server\nCommunica-on\nNetwork\nL7. Applica+on Applica-on Layer L7. Applica+on\nL6. Presenta+on Presenta-on Layer L6. Presenta+on\nL5. Session Session Layer L5. Session\nL4. Transport Transport Layer L4. Transport\nL3. Network Net. Layer L3. Network L3. Network Net. Layer L3. Network\nL2. Datalink D\/L Layer L2. Datalink L2. Datalink D\/L Layer L2. Datalink\nL1. Physical Phy. Layer L1. Physical L1. Physical Phy. Layer L1. Physical\nPhysical path traversed by data\nLogical path traversed by data Network Devices\nFigure17.1:7LayerProtocolStack\nWe examine a few common network security attacks to highlight the importance of under-\nstanding network security issues. The popular characters called Alice and Bob from the se-\ncurity literature want to exchange messages securely. In terms of information and commu-\nnication infrastructure context, we can replace Alice and Bob with Web servers and clients,\ntwo email clients, two people using video-conferencing and so on. The hackers, an eaves-\ndropper called Eve, and a malicious attacker called Mallory are waiting to compromise their\ncommunications. Messages sent by Alice and Bob over a network can be captured by Eve\nusingpacketsniffingtools.ThisallowsEvetoinspecteachpacketandpossiblyextractconfi-\ndentialinformationsuchaspasswords,creditcarddetailsandmanyothertypesofsensitive\ninformation. Broadcast networking technologies such as WLAN or cable modem make it\nrelatively easy to sniff packets. The man in the middle attack (MITM) is another common\nsecurity threat where Mallory, an attacker, places himself between Alice and Bob. For exam-\nple, a compromised gateway\/router\/access-point, malware present in the user\u2019s device or\nserver can potentially capture all of the packets being exchanged between the two parties,\nadd\/modify\/delete information and carry out other malicious activities. The Denial of Ser-\nvice (DoS) attack is a technique where an attacker sends an avalanche of bogus packets to\naserver.Thiswouldeitherkeeptheserverconstantlybusyorcloguptheaccesslink,result-\ning in disruption of service for legitimate users. Typically, a large number of compromised\nhosts (bots) are used to launch a distributed DoS attack, aka DDoS. DoS and MITM are not\ndisjoint; many DoS attacks are also MITM, and vice-versa. Mirai [1388] is an example of a\nmalware, first found in 2016, which launched a DDoS attack by compromising Linux-based\nconsumer devices, aka Internet of Things (IoT) devices, such as IP cameras, utility meters,\nhome routers and others. The IoT devices were turned into bots by exploiting weak authen-\ntication configurations including use of default passwords. The bots were then used from a\ncommand and control centre to attack several high-profile websites. The use of IoT devices\nallowedtheattackerstocircumnavigatetraditionalsecuritymeasures.\nKANetworkSecurity |October2019 Page555 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nInanIPspoofingattack,anattackertriestoimpersonateasanauthoriseduserbycraftinga\npacketwithaforgedIPaddressandadjustingcertainotherfieldstomakeitlooklegitimate.\nHaving looked at examples of network attacks, we will now examine the security on each\nlayeroftheprotocolstack.\n17.3 APPLICATION-LAYER SECURITY\nAsanexampleofanapplication-layersecurityprotocol,AliceandBobwanttouseemail.Ina\nsimplisticscenario,AliceandBobwoulddecidetouseanencryptionalgorithmsuchasAES\nwith a 128 or 256-bit key to encrypt their messages. This meets their confidentiality require-\nment as the message cannot be decrypted by anyone other than Alice and Bob. However,\nthis would require Alice and Bob to agree on a shared key. Distributing this key over the net-\nwork makes the secret key an easy target for Eve or Mallory. Also, the above scenario fails\ntoprovideintegrityandoriginauthentication.Themessagecanbealteredasittraversesthe\nnetwork. Alice and Bob (in this instance, their email clients) must use additional measures\nto provide message integrity and origin authentication. In a variant of this setting, it is also\nlikely that Alice and Bob do not care about the confidentiality of their messages, but they\nwant assurance that their messages will not be tampered with in transit. Alice could calcu-\nlatethehashofhermessageusingtheSHA-3algorithmandsendittoBob.Onreceivingthis\nmessage, Bob would recalculate the hash and verify whether there is a match. However, a\npotentialattackercouldeasilyreplacethegenuinemessagewithaforgedoneandamatch-\ninghash.BobcannottellwhetherthemessagesentbyAlicehasbeenalteredsincethehash\nmatches.OnepossiblesolutionforAliceistouseapre-negotiatedsymmetrickeytoencrypt\nthe hash. Bob now decrypts this hash using the pre-negotiated symmetric key and verifies\ntheintegrityofthemessagereceived.Thisalsoauthenticatesthatthemessagewassentby\nsomeonewhosharesakeywithBob,inthisinstanceAlice.\nWe highlighted the challenges of key distribution over the network. See the Cryptography\nKnowledgeArea(Chapter10)fordetailsofpublickeycryptography.Wewillignoretheconfi-\ndentialityrequirementforthemoment.Alicesignsthehashofhermessageusingherprivate\nkey.BobthendecryptsthemessageusingAlice\u2019spublickey.Thisallowsforanintegritycheck\nand authentication at the same time, as no one other than Alice knows her private key. We\navoidedpre-negotiationorsharingofkeys.So,howdoesBobgetAlice\u2019spublickeyandtrust\nthat Eve or Mallory are not using a forged public\/private key to perform MITM? We provide\nabriefintroductiontokeymanagementinthecontextofpublickeycryptographyinthenext\nsection, as it is used by a number of network security protocols. The above example also\nachieves non-repudiation, as it can be proved that the hash (or in other cases, the whole\nmessage)wassignedbyAlice\u2019sprivatekeyandshecouldnotdenythisfact.\n17.3.1 Public Key Infrastructure\nPublic-Key Infrastructure (PKI) provides a solution for registering and managing a trustwor-\nthy public key. Government agencies or standard organisations appoint or recognise regis-\ntrarswhoissuekeys,andkeeptrackofthepubliccertificatesofentities(individuals,servers,\nroutersetc).Theregistrars,alargenumberofwhichareprivatecompanies,themselveshave\naregisteredpublic\/privatekeypairwithstakeholdersrelevanttotheapplicationdomain.The\nideaissimilartoregisteringyourmotornumberplatewithanauthority.Alicegeneratesapair\nofpublic\/privatekeysforherselfusinghercomputer.Shethenpresentsherproofofidentity\nto one of the registrars. The registrar then issues a certificate to Alice. This certificate is\nKANetworkSecurity |October2019 Page556 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nsignedbytheregistrar\u2019sprivatekeyandcanbeverifiedbyanyoneusingtheregistrar\u2019spublic\nkey.Typically,auser\u2019sidentity,public-keyandCAinformationareusedasaninputtothehash\nfunction. The hash is then signed with the CA\u2019s private key to produce a Public Key Certifi-\ncate(PKC).Thefieldsonthecertificateincludeauniqueidentifier\/serialnumber,asignature\nalgorithm used by the CA and the period of validity. The IETF RFC1422 and ITU-X.509 stan-\ndards have prescribed the format and standard for managing PKI [1389]. Organisations can\nalsomanagetheirownprivatePKI.CAsalsopublishalistofrevokedcertificateswhichhave\neither expired or been revoked. The web of trust is an alternative scheme where users can\ncreateacommunityoftrustedpartiesbymutuallysigningcertificateswithoutneedingareg-\nistrar. Continuing with our email example, Alice could send her certificate to Bob along with\nher email message. Bob is now able to check the validity of the certificate presented by Al-\nice.Inoursimpleexample,AliceandBobcouldusethesetechniquestobuildasecureemail\nsystem. Pretty Good Privacy (PGP) was one of the earliest email systems to propose the\nsecurity approach described above, albeit using the web of trust for certificates. Generally,\nin order for systems to be compatible across platforms and between vendors, application\ndevelopers make use of the standard application layer protocol, the Simple Mail Transfer\nProtocol (SMTP) for exchanging messages between mail servers. The content itself is for-\nmattedbasedonasetofstandardscalledMultipurposeInternetMailExtensions(MIME).As\nthe original Internet protocols lacked security features, a secure version SMIME was devel-\nopedinordertoaddanintegritycheckandcertificatestotheemailheader.Thefunctionsof\nthecertificateverificationandcheckingrevocationlistareautomaticallyperformedbyAlice\nandBob\u2019smailagents.\nThe existing PKI model has faced several challenges, as evidenced by a number of docu-\nmented cases where Certificate Authorities have issued certificates in error, or under coer-\ncion,orthroughtheirowninfrastructurebeingattacked.Recentyearshaveseenmanypartial\nsolutions such as certificate pinning and public immutable logs of issued certificates being\nimplementedtopreventthePKItrustmodelfrombeingundermined.[1330].\n17.3.2 DNS Security Extensions\nInternetdesignphilosophymandateskeepingtheInternetcorefunctionsimplementedinthe\nbackbone routers to be simple along with other supporting functions to be deployed at the\nedge. For most people, human cognition means that it is easier to remember host\/server\nnames, e.g., cnn.com, over an IP address 151.101.1.XX. Internet routing and other protocols,\nhowever, function using IP addresses. The IETF has designed an application-layer protocol,\nthe Domain Name System (DNS), which performs the translation between a host name and\nthe corresponding IP address. This mapping is performed and maintained by a hierarchy\nof name servers. There have been a number of DDoS attacks in recent years [1390]. We\nprovide an overiew of attacks on DNS. In an MITM, Mallory can impersonate a DNS server,\nreturnabogusaddressanddiverttraffictoamaliciousserver,thusallowingittocollectuser\npasswords and other credentials. A DNS cache poisoning attack, aka DNS spoofing, allows\nattackerstoplantbogusaddresses,thusdivertingauserrequesttomaliciousservers.How-\never,therobustdistributeddesignoftheDNShasfortunatelysavedusfromatotalcollapse\noftheInternet.Learningfromtheseattacks,theIETFintroducedasecureversioncalledDNS\nSecurity Extensions (DNSSEC). DNSSEC uses techniques similar to our secure email exam-\nple above by sending a response signed by the private key of a DNS server. The authenticity\nof the DNS records is proven by the fact that a responding server signs the record using its\nprivate key, which a requester can verify using the corresponding public key. In addition, a\ndigitalsignaturealsoprovidestheintegrityoftheresponsedata.Anastutereadermaynote\nKANetworkSecurity |October2019 Page557 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nthatconfidentialityisnotasignificantissueforthistransaction.MorethanhalfadozenIETF\nRFCs cover DNSSEC. A study by Chung et al. [1391] suggests that only 1% of domains use\ntheDNSSECmechanismsforsecurity.VeryfewregistrarssupportDNSSECandothermecha-\nnisms,ascommunicatingDNSSECinformationhasseveralsecurityvulnerabilities.DDoSde-\nfenceisnotpartofDNSSEC.WewilllookatdefencemechanismsinIDS\/IPSinsection17.8.\n17.3.3 Hyper Text Transfer Protocol Secure (HTTPS)\nThemostprominentapplication-layerprotocol,theHypertextTransferProtocol(HTTP),was\ndesigned without any security considerations. The popularity of HTTP and its wide adop-\ntionfore-commerceimposedstrictsecurityrequirementsonthisprotocol.Asecureversion\ncalled HTTPS was introduced by using security services from the transport layer, which al-\nlowstheURL,content,formsandcookiestobeencryptedduringcommunication.Wediscuss\nthesecuretransportlayerprotocolsinthenextsection.Anewversion,HTTP2.0,hasfurther\nenrichedthesecurityfeaturesofHTTP1.0.Althoughnotmandated,mostbrowserssupport\nconfidentiality by encrypting data. New features such as header compression and flow con-\ntrol require servers to maintain additional state information. An attacker could send a large\nnumberofemptyortinyframesandkeeptheserverbusyprocessingframeheaders.Servers\nmust employ a threshold on the number of connections being processed to limit such at-\ntacks.\n17.3.4 Network Time Protocol (NTP) Security\nThe Network Time Protocol [RFC 5905] is an application-layer protocol used to synchronise\ndevices (hosts, server, routers etc.) to within a few milliseconds of Coordinated Universal\nTime (UTC). The protocol is typically implemented either as a client-server model or a peer-\npeer one. In the client-server model, the client sends a request using UDP on port 123 and\nreceives a response back from the server. As with other application-layer protocols, NTP\nhas been subject to replay, DoS and MITM attacks. Further, an intruder could delay a packet\nbetweenclientserver,thusskewingthetimingcalculations.InaDoSamplificationattack,an\nattacker can send a few bytes of the MONLIST command and get the server to send a list\nof the last 600 clients that made an NTP request. A possible countermeaure would require\nrestrictingaccesstothiscommandfrominternalhostsonly.Themostrecentimplementation\nof the NTP daemon ntpd) uses a hierarchical security model implementing several PKIs,\ndigitalsignaturesandotherstandardapplication-layersecuritymechanisms.\n17.4 TRANSPORT-LAYER SECURITY\nIn the previous section, we discussed ways in which applications could build security fea-\ntures by using cryptographic primitives. Data sent over the TCP\/IP protocol were not safe\nand hence each application had to take care of security itself. Ideally, if the transport-layer\ncouldprovideconfidentiality,integrityandauthenticationmechanisms,theapplication-layer\ncould be relieved from the burden of security and use the transport layer services instead.\nThis would also provide compatiblity across platforms\/vendors. These capabilities are pro-\nvidedbyashimlayerbetweentheapplicationandtransportlayerscalledtheSecureSockets\nLayer(SSL).AstandardApplicationProgramingInterface(API),similartothesocketAPI,al-\nlows applications to bootstrap secure connections and to send\/receive data securely. IETF\nstarted to develop the Transport Layer Security (TLS) borrowing most of its ideas from the\nSSL 3.0 protocol. The most prominent web browsers have started to support the latest TLS\nKANetworkSecurity |October2019 Page558 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nAlice (Receiver)\nBob (Sender)\nInternet\nTCP 3-way Handshake\nStart of TLS Client Hello\nHandshake\nServer Hello\nCer@ficate\nServer Hello Done\nClientKeyExchange\nChangeCipherSpec\nFinished\nChangeCipherSpec\nFinished\nEncrypted Applica@on Data\nTraffic\nFigure17.2:TLSHandshake\n1.3standardisedin2018.Inthissection,ourdiscussionswillrelatetoasimplifiedversionof\nthesecurityfeaturesinordertounderstandthebasicsoftheTLSprotocol.Theexactsyntax\nandsemanticsoftheprotocolsandarichsetofconfigurationsaredescribedinhundredsof\npagesofRFCs.\nWewillnowbringAlice(server)andBob(client)backintotheaction.Aliceisconfiguredwith\nherpublic\/privatekeypairs,asdescribedin17.3.1.Itisworthemphasisingthatsomeofthese\nbasic techniques are also used in security protocols on other layers, which we will discuss\nin this chapter. The TLS protocol has 3 phases: handshake, key-derivation and data transfer,\nasshowninfigure17.2.\n17.4.1 Handshake\n1. First Bob and Alice exchange the three-way TCP SYN, SYNACK and ACK messages. It\nshouldbenotedthatthisstepisnotpartofTLS\/SSL.\n2. BobthensendsaClientHellomessagetoAlicealongwiththeciphersuites(ciphersand\nthe hash functions it supports) and a nonce, a large, random number, chosen specifi-\ncallyforthisrunoftheprotocol.\n3. AlicerespondswithaServerHellomessagealongwithherchoicefromtheciphersuites\n(e.g., AES for confidentiality, RSA for the public key, SHA2 for the Message Authentica-\ntionCode(MAC)),acertificatecontainingherpublickeyandanonce.Additionally,she\ncouldalsorequesttheclient\u2019scertificateandparametersforotherTLSextensions.\n4. BobchecksvalidityofthecertificateandisassuredthatitbelongstoAlice.Heinitiates\ntheClientKeyExchangemessage.Thiscanusearangeofkeyexchangemethods,e.g.,\nRSA or the Diffie-Hellman (and variants) to establish a symmetric key for the ensuing\nsession. For example, when using RSA, Bob could generate a 48-bit Pre-Master Secret\nKANetworkSecurity |October2019 Page559 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n(PMS)andencryptitwithAlice\u2019spublickeyobtainedusingthestepsasdescribedabove\nandsendittoAlice.\n5. Bob sends a ClientCipherSpec and a Finished Message suggesting that the key gener-\nationandauthenticationarecomplete.\n6. Alicealsohasthesharedkeyatthispoint.SherespondswithaChangeCipherSpecand\naFinishedMessagebacktoBob.\n7. Bobdecryptsthemessagewiththenegotiatedsymmetrickeyandperformsamessage\nintegritycheck.\nAfter successfully completing the above steps, a secure tunnel is established and the en-\ncryptedapplicationdatacannowbesent,asshownatthebottomoffigure17.2.Thedetails\noftheprotocolexchangeandmessageprocessingcanbefoundin [1389].\n17.4.2 Key-Derivation\nTheclientnonce,servernonceandPMSareinputintoapseudorandomfunctiontoproduce\namastersecret.Alltheotherkeydataforthisconnectionarederivedfromthismastersecret\nin conjunction with the additional parameters. The following four common keys are derived\natbothends:\n1. SessionencryptionkeyfordatasentfromBobtoAlice(clientencryptionkey).\n2. SessionencryptionkeyfordatasentfromAlicetoBob(serverencryptionkey).\n3. SessionMACkeyfordatasentfromBobtoAlice(clientMACkey).\n4. SessionMACkeyfordatasentfromAlicetoBob(serverMACkey).\nBobandAlicederiveseparatekeysforencryptionandintegrityineachdirectionforenhanced\nsecurity.Generatingtheseephemeralkeysallowsforperfectforwardsecrecy,asthesekeys\ncannot be reused in future sessions. For example, Eve could capture every communication\nbetweenAliceandBob.ShecouldpretendtobeBobandrepeatthesequenceofcommands\nsent by Bob later in the day. This attack is called a connection replay attack. The TLS and\nmost other protocols use a session specific nonce, a random number, to avoid this attack.\nThe PMS generation algorithm uses a nonce in the mix. The connection replay attack will\nfail,asAlicewouldhaveadifferentsetofkeysfromEveforthenewsessionduetothisnew\nnonce.\n17.4.3 Data-Transfer\nTCP is a byte oriented transport protocol where application-layer data are sent as a stream\nof bytes. Integrity check algorithms require fixed length data for a MAC calculation. If appli-\ncations have to collect and pass fixed length data to these algorithms, further delay will be\nincurred. Hence, TLS defines a record format, as shown in figure 17.3, where the length of\nthe data sent in each record can be indicated along with the type of record (data or control).\nA MAC is also appended at the end of each record. For example, if data are sent from Bob\nto Alice, the session MAC key for the data sent from Bob to Alice are used to generate this\nMAC.Further,thedataplustheMACareencryptedusingthesessionencryptionkeyfordata\nsentfromBobtoAlice.\nKANetworkSecurity |October2019 Page560 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n0-byte 1 2 3 4\nContent Type\nVersion Length\nPayload\nMAC\nPadding\n(block ciphers only)\nFigure17.3:TLSRecordStructure\nAstheTCPsequencenumberisnotencrypted,apossibleMITMattackcouldsimplycapture\nthe TCP segments and swap the TLS records between these segments. A receiver would\nnotbeabletodetectthisattackastheintegrityoftheTLSrecordsremainsunchanged.The\nTLSprovidesaseparatemechanismwherethesenderandreceiverkeeptrackoftherecord\nsequence number without explicitly exchanging it. However, the MAC calculations at both\nends use this sequence number in the mix. Any MITM rearrangement of records will fail an\nintegritycheck.\nHaving discussed the technical details of the TLS, we now consider how it performs in the\npresence of certain attacks. In a Password Sniffing attack, Eve captures a few packets and\nwantstogetpasswordsinHTTPSorotherapplicationtraffic.Astheuserdataareencrypted,\nthepasswordcannotbesniffed.InanIPSpoofingattack,MalloryusesaforgedIPaddresses\nto fool Bob into accepting bogus data. Mallory must be in possession of the secret key as\nwell as the forged IP address to succeed. An MITM attack is prevented by using public key\ncertificatestoauthenticatethecorrespondents.\nWe note that in a related transport-layer attack called a SYN Flooding DDoS attack, a group\nofattackingmachineskeepsendingTCPSYNmessagestorequestaconnectionandletthe\nserverallocateresources.However,thistypeofattackcanbehandledbytheTCPandhence\nis not duplicated in the TLS. A defence known as SYN Cookies has been implemented in\nmany operating systems [RFC4987]. The server does not half open a connection right away\non receiving a TCP connection request. It selects an Initial Sequence Number (ISN) using a\nhash function over source and destination IP addresses, port numbers of the SYN segment,\naswellasasecretnumberonlyknowntotheserver.TheserverthensendstheclientthisISN,\notherwise known as a Cookie, in the SYNACK message. If the request is from a legitimate\nsender,theserverreceivesanACKmessagewithanewsequencenumberwhichisISNplus\n1. Once this validation is done, the server opens a TCP connection. A DDoS sender would\nKANetworkSecurity |October2019 Page561 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\neither not respond with ACK or would not have the correct ISN in its response. Hence, no\nTCPsourceshavebeenwasted.\nThe current version of SSL (and TLS) has evolved through experiencing several attacks and\nvulnerabilities found in earlier versions. SSLStrippingattacks remove the use of SSL\/TLS al-\ntogether by modifying unencrypted protocols which request the use of the TLS. The BEAST\nattack exploits the predictable initialisation vector of TLS 1.0 implementation due to use of\nthe Cipher Block Chaining (CBC). This allows an attacker to decrypt parts of a packet, e.g.,\nHTTPcookies.AlonglistofknownattacksandmitigationwerediscussedinRFC7457.Many\nof these vulnerabilities are also attributed to either an improper implementation or poor un-\nderstandingoftheprotocolsuiteratherthanalackofproperspecifications.Forexample,the\nTLSdesignproblemofcalculatingMACbeforeencryptionresultsinatimingside-channelat-\ntack called the Lucky Thirteen attack, which allows attackers to decrypt arbitrary ciphertext.\nCountermeasuresforthisattackincludeusingAES-GCMenrcyption,orusingtheencryptfirst\nandthencalculatingtheMACapproach[RFC7366].\n17.4.4 Quick UDP Internet Connections (QUIC)\nQUIC is a new transport protocol designed by Google for faster web-browsing using UDP\ninstead of HTTP over TCP. The protocol currently uses proprietary encryption and authen-\ntication. Firewalls and IDS systems typically detect HTTP traffic, and perform deep packet\ninspection, virus scanning and other security measures. Although QUIC uses the standard\nHTTP ports, security devices do not track this application layer protocol at present. It is\ntreated as regular UDP traffic. Since the standardisation work is already in progress, it is\nlikelytouseTLS1.3forsecuretransport.\nInthissection,welookedatvariousmechanismsforsecuringtheend-to-endcommunication\nchannelviatransportprotocols.However,ifthecontentbeingtransferredbecomesaccessi-\nbletoanattackeroutsidethecommunicationchannel,theycouldcomparethevolumeofthe\nencryptedmaterialandmakeinferences.Asaconsequence,itcouldpotentiallycompromise\nmessageconfidentiality.\n17.5 NETWORK LAYER SECURITY\nAlthough application-layer and transport-layer security help to provide end-to-end security,\nthere is also merit in adding security mechanisms onto the network layer. First, higher-layer\nsecuritymechanismsdonotnecessarilyprotectanorganisation\u2019sinternalnetworklinksfrom\nmalicious traffic. If and when malicious traffic is detected at the end-hosts, it is too late, as\nthe bandwidth has already been consumed. The second major issue is that the higher-layer\nsecuritymechanismsdescribedearlier(e.g.,TLS)donotconcealIPheaders.Thismakesthe\nIPaddressesofthecommunicatingend-hostsvisibletoeavesdroppers.\nAdditionally,manyorganisationsprefertheirtraffictobefullyencryptedasitleavestheirnet-\nwork. In the early days of networking, several private networks were in use. However, main-\ntainingaprivatenetworkmaynotbecosteffective.Analternativesolutionistomakeuseof\nthe Internet to connect several islands of private networks owned by an organisation. Also,\nemployers and employees want a flexible work environment where people can work from\nhome, or connect from a hotel room or an airport lounge without compromising their secu-\nrity.WehavealreadydeterminedthattheInternetisunsafe.TheconceptofaVirtualPrivate\nNetwork(VPN)overthepublicInternetrequiresasetofnetworklayersecuritymechanisms\nKANetworkSecurity |October2019 Page562 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nthat we will explore in this section. We start our discussion with security additions to the\nnetwork layer IP protocol called IPsec. Figure 17.4 shows that an employee working from\nhome accesses a server at work, the VPN client in their host encapsulates IPv4 datagrams\nintoIPsecandencrpytsIPv4payloadcontainingTCPorUDPsegments,orothercontrolmes-\nsages. The corporate gateway detects the IPSec datagram, decrypts it and decapsulates it\nbacktotheIPv4datagrambeforeforwardingittotheserver.Everyresponsefromtheserver\nis also encrypted by the gateway. We note that encryption is not mandatory in IPsec. Figure\n17.4isoneofseveralmodesofoperationforIPsec.Forexample,therecouldbetwocorporate\nnetworks,eachwiththeirownIPsecgatewaycommunicatingovertheopenInternet.\nIP TCP\/UDP Data\nHeader Header Payload\nPublic\nInternet\nIP IPSec TCP\/UDP Data Payload\nHeader Header Header\nIPSec compliant\nEncrypted\nGateway Router\nEnterprise Network\nIP IPSec TCP\/UDP Data Payload\nHeader Header Header\nEncrypted\nIPSec Compliant\nHost\nHome Network\nFigure17.4:ExampleIPsecClientServerInteraction\nWe started off with a simple example showing data confidentiality using encryption. How-\never, IPsec also provides data integrity, origin authentication and replay attack prevention.\nAgain,thesetofmodes\/configurations\/standardsprovidedbyIPsecisextensive;interested\nreadersshouldaccesstherelevantIETFRFCsforformatsandprotocoldetails.\nIPsec supports Tunneling and Transport modes of operation. In Transport mode, as shown\nin figure 17.5, the original IP header is used but the rest of the payload gets encrypted. In\nourexampleoffigure17.4,iftransportmodeisused,itwouldrequirearoutableIPv4address.\nThis can be achieved if the endpoint is behind a NAT. Details of NAT traversal can be found\ninRFC7296.\nIn the rest of this section, we will discuss the widely used alternate Tunneling mode in de-\ntail. If the edge devices (routers\/gateways) of two networks are IPsec aware, the rest of the\nservers\/hosts need not worry about IPsec. The edge devices perform the encapsulation of\neveryIPincludingtheheader.Thisvirtuallycreatesasecuretunnelbetweenthetwoedgede-\nvices. The receiving edge device then decapsulates the IPv4 datagram and forwards within\nitsnetworkusingstandardIPforwarding.Otherpossibleconfigurationsforatunnelcouldin-\nvolveoneIPsecawarehostandanIPsecawaregateway(asinfigure17.4).Atunnelbetween\nKANetworkSecurity |October2019 Page563 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntwo IPsec aware hosts is also possible without involving edge routers. The Tunneling mode\nremainsinwidespreaduseduetoitssimplicity,asitdoesnotrequireIPsecprotocolsupport\nin the end hosts. Also, key negotiation is simplified, as two edge devices can handle con-\nnections on behalf of multiple hosts in their respective networks. An additional advantage\nis that everything, including the IP source\/destination address, gets encrypted, thus making\ntrafficanalysisharder.TheESPv3allowstousetheTrafficFlowConfidentiality(TFC)mecha-\nnismswhichaddsarbitrarylengthpaddingtoobfuscatethetrafficpatternandpreventavoid\nstatistical traffic analysis attacks. Kiral et al. [1392] reported experimental results exploring\npadding and several other techniques such as packet framgmentation, introduction of artifi-\ncialinter-packetdelay,insertingofdummypacketstoavoidtrafficanalysis.\nTransport Mode: Tunnel Mode:\nOriginal IP Header New IP Header\nData Data\nTCP TCP\nData Data\nhdr hdr\norig IP TCP orig IP TCP\nData Data\nhdr hdr hdr hdr\norig IP ESP TCP ESP ESP ESP orig IP TCP ESP ESP\nData Data\nhdr hdr hdr trlr Auth hdr hdr hdr trlr Auth\nnew IP ESP orig IP TCP ESP ESP\nData\nhdr hdr hdr hdr trlr Auth\nFigure17.5:TransportandTunnelModeEncapsulation\nIPsec supports a set of formats to implement security. The Encapsulation Security Payload\n(ESP) format supports confidentiality using encrypted IP packets, data integrity using hash\nfunctions,andsourceauthentication.Ifanapplicationdoesnotrequireconfidentiality,itmay\nsimplyusetheAuthenticationHeader(AH)format,whichsupportsdataintegrityandsource\nauthentication.TheIETFRFC2410definestheNULLEncryptionalgorithmwithESPtoachieve\nthesameoutcome.Intotal,wegetfourdifferentoptionsforcommunication:Transportmode\nwith ESP, Transport mode with AH, Tunnel mode with ESP and Tunnel Mode with AH. Since\nVPNtunnelsarefullyencrypted,theTunnelmodewithESPremainstheprotocolofchoice.\nTwo entities participating in IPsec communication establish Security Association (SA) for\neachdirectionofthelink.Essentially,anumberofvariablesarerecordedinadatabasecalled\ntheSecurityAssociationDatabase(SAD)forlookupduringIPsecprotocolprocessing,some-\nwhat similar to the TCP connection state. Some of the state information includes the type\nof encryption used (e.g., AES or 3DES), the encryption key, the type of integrity check used\n(e.g., SHA-2 or MD5), the authentication key and so on. An Anti-Replay Window is also used\ntodeterminewhetheraninboundAHorESPpacketisareplay.\nKANetworkSecurity |October2019 Page564 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nWhen a large number of end-points use IPsec, distributing the keys becomes challenging.\nThe RFC7296 defines the Internet Key Exchange protocol (IKEv2). Readers will observe a\nsimilaritybetweenTLS17.4andIKE,inthatIKEalsorequiresaninitialhandshakeprocessto\nnegotiatecryptographicalgorithmsandothervaluessuchasnoncesandexhangeidentities\nand certificates. We will skip the details of a complex two-phase protocol exchange which\nresults in the establishment of a quantity called SKEYSEED. These SKEYSEEDs are used to\ngeneratethekeysusedduringasession,aswerecallIPsecSAs.WenotethattheIKEv2has\nevolved from IKEv1, Internet Security Association and Key Management Protocol (ISAKMP),\nandseveralotherearlierefforts.TheISAKMPisaframeworkthatdefinestheproceduresfor\nauthenticatingthecommunicatingpeer,creationandmanagementofSecurityAssociations,\nand the key generation techniques. It can also provide threat mitigation against DoS and\nreplayattack.DefinedinRFC2408,ISAKMPisalsopartofIKEv2forkeyexchange.\n17.5.1 IP Masquerading\nDuetotheshortageofIPv4addressspace,NetworkAddressTranslation(NAT)wasdesigned\nso that private IP addresses could be mapped onto an externally routable IP address by the\nNAT device [1387]. For an outgoing IP packet, The NAT device changes the private source\nIP address to a public IP address of the outgoing link. As a consequence, it obfuscates the\ninternalIPaddressfromtheoutsideworld.Toapotentialattacker,thepacketsappeartobe\ncomingfromtheNATdevice,nottherealhost\/serverbehindtheNATdevice.\n17.5.2 IPv6 Security\nOur discussions about security so far have assumed the use of IPv4. The shortage of IPv4\naddresses resulted in the development of new IPv6 protocol, as the NAT mechanism had\nseveralflaws.AsIPv6adoptionisgraduallyincreasing,weshouldhighlightthesecurityben-\nefitsandchallengesassociatedwiththedeploymentofIPv6.Forexample,theuseof128-bit\naddressspacemeansattackersneedalotmoretimetoscantheports,asopposedtoIPv4,\nwhere the entire address space can be scanned in a few hours. Several security problems\nassociatedwithARP,whichcanbediscussedlaterinthischapter,disappearasIPv6layer-3\naddresses are derived directly from layer-2 addresses without any need for address resolu-\ntion.However,thisallowsattackerstoinferinformationaboutthehost\/serverswhichcanbe\nhandywhenlaunchingattacks.Usinghashfunctionforaddressgenerationisrecommended\nas a mitigation technique. Further, IPv6 allows for a Cryptographically Generated Address\n(CGA) where an address is bound to a public signature key. This helps when authenticating\nbetween routers for secure message exchange. Initially, IPsec was mandated to be used in\nIPv6networks, butduetoimplementationdifficultiesitremainsarecommendation.Several\ninformational IETF RFCs and vendor-specific white papers provide a comprehensive treat-\nmentofIPv6securitychallenges.\nKANetworkSecurity |October2019 Page565 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n17.5.3 Routing Protocol Security\nSo far, we have primarily focussed on the security of data being sent using the TCP\/IP pro-\ntocol suite. However, a network can easily be disrupted if either the routers themselves are\ncompromised or they accept spurious routing exchange messages from malicious actors.\nFirst, we will discuss the Interior Gateway Protocols (IGP) which are used for exchanging\nroutinginformationwithinanAutonomousSystem(AS),anISP,forexample.Twoprominent\nprotocols:RoutingINformationProtocol(RIPv2)andOpenShortestPathFirst(OSPFv2)are\nin widespread use with ASs for IPv4 networks. The newer RIPng and OSPFv3 versions sup-\nport IPv6. These protocols support no security by default but can be configured to support\neitherplaintext-basedauthenticationorMD5-basedauthentication.Plaintextauthentication\nsendsasecretkeyincleartextalongwithroutingupdates,thusmakingiteasytobesniffed\nby a packet analyser. A more secure option uses the MD5. Routers exchange a message di-\ngestandakey-idalongwiththeroutingupdates.TheKey-idindicateswhichkeytousefroma\nlistofpasswords.Thisavoidsthesnifferattack.Authenticationcanavoidseveralkindsofat-\ntackssuchasbogusrouteinsertionormodifyingandaddingarogueneighbour.Additionally,\nroutersmayemployroutefilteringtoavoidpropagatingtheonlylegitimateroute.\n17.5.3.1 BorderGatewayProtocol(BGP)Security\nTheInternetusesahierarchicalsystemwhereeachASmanagedbyanISP,exchangesrout-\ning information with other ASs using the Border Gateway Protocol (BGP). See RFC1163 and\nRFC1267forthedetailsoftheBGPprotocol.AfterreceivinganIPprefix[1387],thereachabil-\nityinformation,fromitsneighbour,therouterchecksthenewlyreceivedinformationagainst\nits stored knowledge to see if there is a better path to reach a destination network. This in-\nformation is updated locally and propagated to its immediate neighbours. The distributed\nsystemallowsnetworkstoreacheachotherglobally.\nInrecentyears,attacksontheBGPhavebeenseenwiththeapparentintentionofdisrupting\nYouTubeservicesglobally.TheentireInternetexperiencedanoutageinanothercountrydue\nto either mis-configuration or the malicious advertising of bogus BGP updates. Either way,\nthis highlights the security weakness in the BGP protocol. This vulnerability arises because\nofalackofintegrityandauthenticationforBGPmessages.Wewilldescribesomewell-known\nattacksontheBGPprotocol.\nIn what is known as a BGP route hijacking attack, a malicious router could advertise an IP\nPrefix, saying that the best route to a service is through its network. Once the traffic starts\nto flow through its network, it will then choose to drop all the packets to this service for a\nvariety of reasons, including censorship. It could also read all of the un-encrypted packets.\nAdditionally. the attacker could divert traffic through an unsuspecting AS, thus suddenly in-\ncreasingtheirload.InaBGPdenial-of-service(DoS)attack,amaliciousrouterwouldsendan\navalanche of BGP traffic to a victim AS, while keeping its border router busy so that it could\nnotprocessanyvalidupdates.TheattackercouldalsopropagatespuriousBGPupdatesand\ncorruptroutingtablessoastopreventtrafficfromreachingitsintendeddestination.\nIETF is currently working on a standard called BGPSec to address these security concerns.\nThisworkisbasedonapriorproposalcalledS-BGP [1393].Thecoreoftheschemeliesinthe\nuseofPKItoverifythesignaturesoftheneighbourssendingtheupdates.Twoneighbouring\nrouters could use IPsec mechanisms for point-point security to exchange updates. We will\nnow look at a simple example where a BGP router receives a path ZZZ YYY XXX. The BGP\nrouterverifiesthesignatureofASXXXusingPKImechanismsthatwelearntaboutearlier.It\nKANetworkSecurity |October2019 Page566 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nthenverifiesthesignaturegeneratedbyYYYandsubsequentlybyZZZ.Thisallowsustoverify\ntheoriginandauthenticityofthewholechainofupdates.However,thisapproachentailslarge\noverheads. Signature verification comes at a cost, implementing BGPSec would require the\nborderrouterstoverifyalargernumberofsignaturesonbooting.Additionalcryptohardware\nandmemorywouldcertainlyhelpkeeptheperformanceontrack.\nDespite these BGPSec and other standardisation efforts, not many routers deploy these\nmechanisms due to additional costs and a lack of short-term benefits unless there is a con-\nsensus to mandate it globally [1394]. Mechanism costs are an additional but smaller barrier\nto widespread deployment. The existing BGP security proposals suffer from a classic eco-\nnomicproblem.AnewBGPSecdeploymentmostlybenefits(non-deploying)operatorsother\nthan those deploying the mechanism; thus the deployer\u2019s reward lies in the future, while the\nlossesfromnon-deployingnetworksarestackedupfront.\n17.6 LINK LAYER SECURITY\nInthissection,weareconfiningourattentiontothesecurityoflinklayertechnologieswhich\narerelevanttoend-user\/PCdeployments.Otherlinklayertechnologiesareaddressedinother\nknowledgeareas.Wewillstartourdiscussionwiththeprominent802.1XPort-basedAuthen-\ntication followed by link layer security issues in Ethernet Switched LAN and WLAN environ-\nments.\n17.6.1 IEEE 802.1X Port-based Authentication\nTheIEEE802.1Xisaport-basedauthenticationforsecuringbothwiredandwirelessnetworks.\nBefore a user can access a network at the link layer, it must authenticate the switch or ac-\ncesspoint(AP)theyareattemptingtoconnectto,eitherphysicallyorviaawirelesschannel.\nAs with most standards bodies, this group has its own jargon. Figure 17.6 shows a typical\n802.1X setup. A user is called a supplicant and a switch or AP is called an authenticator.\nThe architecture requires an Authentication Server (AuthS) that can be implemented using\none of the existing protocols: Remote access dial-in user service (RADIUS), DIAMETER, Ker-\nberos,LightweightDirectoryAccessProtocol(LDAP)orActiveDirectory(AD),amongothers.\nTheASfunctioncanalsobeco-locatedwiththeauthenticator.WewillnowconsiderRADIUS\nas our example AS. Typically, the AS and authenticator are pre-configured with a shared se-\ncret. Using the RADIUS protocol as an example, once a supplicant request is received, the\nauthenticator sends a RADIUS Access Request message to the RADIUS server, requesting\nauthorisationtobegrantedtoaccesstheresources.\nSupplicantsoftwareistypicallyavailableonvariousOSplatformsoritcanalsobeprovidedby\nchip-setvendors.Asupplicant(client)wishingtoaccessanetworkmustusetheExtensible\nAuthenticationProtocol(EAP)toconnecttotheASviaanauthenticator.\nKANetworkSecurity |October2019 Page567 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nAuthen\u2019cator\nProtected\nInfrastructure\nRADIUS,LDAP,\nAc\u2019ve Directory\nServer..\nAuthen\u2019ca\u2019on\nSupplicant Supplicant Server\nFigure17.6:802.1XPort-BasedAuthenticationArchitecture\n17.6.1.1 ExtensibleAuthenticationProtocol(EAP)\nTheEAPisanend-endclienttoauthenticationserverprotocol.Fromsupplicanttoauthentica-\ntor,itissentoverLayer2protocols,i.e.,ExtensibleAuthenticationProtocoloverLAN(EAPoL).\nThereisnoneedforhigherlayerprotocols.AstheauthenticatorisconnectedtotheASusing\na trusted link with a shared secret, a higher layer protocol such as RADIUS\/DIAMETER over\nUDPcanbeusedonthissideofthelink.\nWhenanewclient(supplicant)isconnectedtoanauthenticator,theportontheauthenticator\nis set to the \u2018unauthorised\u2019 state, allowing only 802.1X traffic. Other higher layer traffic, such\nas TCP\/UDP is blocked. The authenticator sends out the EAP-Request identity to the suppli-\ncant. The supplicant responds with the EAP-response packet, which is forwarded to the AS.\nThistypicallyincludesthesupplicant\u2019scredentials(usernameandhashofpassword).Upon\nverification, the AS returns one of the following responses: Access Accept, Access Reject,\nAccess Challenge for extra credentials. If the result is Access Accept, the authenticator un-\nblockstheporttolethigherlayertrafficthrough.Whenthesupplicantlogsoff,theEAP-logoff\ntotheauthenticatorsetstheporttoblockallnon-EAPtraffic.\nSending a supplicant\u2019s credentials in plaintext is problematic for several reasons. To safe-\nguard against any eavesdropping, the EAP uses a Tunnel for authentication and authorisa-\ntion. A whole range of EAP Tunneling protocols are available. EAP-Transport Layer Security\n(EAP-TLS), EAP for GSM Subscriber Identity (EAP-SIM) and EAP Protected Authentication\nProtocol(EAP-PEAP)aresomeoftheexamplesforestablishingasecuretunnel.EAP-PEAP,\nalso known as \u2018EAP inside EAP\u2019 is one of the most popular protocols. If we dig deeper, be-\nforethe port isunblocked,a complexprocessis usedtogeneratea dynamicencryption key\nusinga4-wayhandshake.Essentially,alloftheseprotocolsestablishaTLStunnelbutdiffer\ninchoiceofhashalgorithms,thetypeofcredentialsused,whetheraclient-sidecertificateis\nusedetc.Mostprotocolswoulduseaserversidecertificate.\nKANetworkSecurity |October2019 Page568 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nEAP TLS\nEAP\nRADIUS\/LDAP\/.. EAP over LAN (EAPOL)\nUDP\/IP IEEE 802.11\nHub\nWired LAN\nAuthenticator\nRADIUS Server\n(Switch\/AP)\nWireless Device\nSupplicant\nFigure17.7:ExtensibleAuthenticationProtocol(EAP)\nOncethesupplicantandASmutuallyauthenticate,theytogethergenerateaMasterKey(MK).\nAswehavealreadydiscussed,theauthenticatorhasbeenplayingtheroleofarelayuptothis\npoint.Duringthisprocess,thesupplicantderivesaPairwiseMasterKey(PMK).TheASalso\nderivesthesamePMKandsendsthistotheauthenticator.Fromthispointon,thesupplicant\nandauthenticatorusethePMKtoderivetheTemporalKey(TK)usedforthemessageencryp-\ntion and integrity. The key derivation process is similar to what we learnt in the TLS earlier.\nWe will revisit key generation and the relationship between the various keys in detail later in\ntheRobustSecureNetworking(RSN)section.\n17.6.2 Attack On Ethernet Switch\nAlthough the research literature has primarily focused on higher layer security, the Stuxnet\n[796]attackhasdemonstratedthataninnocuouslookingUSBdrivecouldeasilywreakhavoc\nin a Local Area Network (LAN) environment without any need for an Internet connection.\nWidely deployed Ethernet technology is built around self-learning and configuring protocols.\nThis allows for ease of management, but at the same time introduces several security vul-\nnerabilities [1395].Weprovideabriefreviewofsomeofthepossibleattackshere.\nMediaAccessControlAttack:SwitchPoisoningAttack\nEthernet switches keep forwarding table entries in a Content Addressable Memory (CAM).\nAs a switch learns about a new destination host, it updates the table and for all future com-\nmunications, this table entry is looked up to forward a frame. Unlike broadcast Ethernet or\nWLAN, these frames are not accessible to hosts attached to other ports. However, if the\nswitch does not have a mapping to a new Media Access Control (MAC) address, i.e., which\nporttoforwardanewframeto,itwillfloodtheframeonallofitsoutgoingports.Anattacker\ncould craft several frames with random addresses to populate an entire CAM. This would\nresult in the switch flooding all the incoming data frames to all the outgoing ports, as there\nKANetworkSecurity |October2019 Page569 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nisnospaceavailabletoenteranewmapping.Thismakestheframeavailabletotheattacker\nattached to one of these ports. As a consequence, a MAC flooding attack would also affect\nall the VLANs filling their CAM. However, this kind of attack requires an attacker to control\na device that is directly connected to an Ethernet switch or possibly to some used but unat-\ntendedEthernetwallsocketswhicharestillconnectedtoaport.Mitigatingthiskindofattack\nwouldrequireauthenticatingandverifyingtheMACaddressesfromsomelocaldatabaseof\nlegitimateaddressesbeforepopulatingtheforwardingtableentry.\nMAC Spoofing: attacks occur when an attacker eavesdrops on a link and detects the MAC\naddressofatargethost.Itthenmasqueradesasalegitimatehostbyalteringitshost\u2019sMAC\naddress to match the newly detected MAC address. The attacker floods the network with\nthe newly configured MAC address while directing the traffic to itself by altering the switch\nforwardingtableentry.Theswitchisnowtrickedintoforwardingtheframesdestinedforthe\ntargethosttotheattackinghost.\nTheMACaddressisnotnotdesignedorintendedtobeusedforsecurity.The802.1X,which\nwediscussedearlier,isagoodstartingpointforpreventingunauthorisedusersfromaccess-\ning any service on a network. As a side issue, a user may choose to spoof his or her MAC\naddressinordertoprotecthisorherprivacy.MostpopularoperatingsystemssupportMAC\naddressrandomisationtoavoiddevicesbeingtrackedbasedonaMACaddress.\nAddress Resolution Protocol (ARP) Spoofing: attacks occur when an attacker sends a fake\nARP message over a LAN, binding the target\u2019s IP address to its own MAC address. Once it\nmanages to compromise the ARP table, it will start receiving any data that were intended\nfor the target\u2019s IP address. ARP spoofing can also be used for DoS attacks by populating\ntheARPtablewithmultipleIPaddressescorrespondingtoasingleMACaddressofatarget\nserver,forexample.Thiswouldthenredirectunnecessarytraffictothetarget,keepingitbusy\nprocessing these messages. ARP Spoofing is also helpful in session hijacking and MITM\nattacks.\nIn fact, a mitigation scheme would set limits on the number of addresses that can be learnt\nper-port on a switch. Some vendors use a verification process where they inspect the MAC\naddress and IP address information in ARP packets against the MAC-IP bindings contained\nin a trusted binding table. This allows for any ARP packets that do not have an entry in the\nbindingtabletobediscarded.Thebindingtablemustbeupdatedfrequentlytoavoidblocking\nlegitimateupdates.\nVLAN hopping:VLAN hopping attacks allow an attacking host on a VLAN to gain access to\nresourcesonotherVLANsthatwouldnormallyberestricted.Therearetwoprimarymethods\nofVLANhopping:switchspoofinganddoubletagging.\nIn a switch spoofing attack, an attacking host impersonates a trunking switch responding\nto the tagging and trunking protocols (e.g., IEEE 802.1Q or Dynamic Trunking Protocol) typi-\ncallyusedinaVLANenvironment.Theattackernowsucceedsinaccessingtrafficformulti-\npleVLANs.Vendorsmitigatetheseattacksbyproperswitchconfiguration.Forexample,the\nports are assigned a trunking role explicitly and the others are configured as access ports\nonly. Also, any automatic trunk negotiation protocol can be disabled. In a double tagging at-\ntack,anattackersucceedsinsendingitsframetomorethanoneVLANbyinsertingtwoVLAN\ntagstoaframeittransmits.However,thisattackdoesnotallowthemtoreceivearesponse.\nAgain,vendorsproviderecommendedconfigurationmethodstodealwiththesepossibleat-\ntacks. A comprehensive survey of Ethernet attacks and defence can be found in [1395] and\nvendor-specificcourses.\nKANetworkSecurity |October2019 Page570 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n17.7 WIRELESS LAN SECURITY\nWireless LAN are more vulnerable to security risks due to the broadcast nature of media,\nwhichsimplifieseavesdropping.TheWiredEquivalentPrivacy(WEP)protocol,despitebeing\nobsoleteduetoitsdesignflaws,providesseveralimportantlessonsabouthownottodesign\na security protocol. The WEP protocol was designed to provide integrity, confidentiality and\nauthentication.Itusesasymmetrickeyencryptionmethodwherethehostsharesakeywith\nan access point using out of band methods, mostly pre-installation by an administrator or a\nhomenetworkuser.Thesendercalculatesa32-bitIntegrityCheckValue(ICV)usingaCyclic\nRedundancyCheck(CRC)algorithmoverthepayload.A104-bitsharedkeycombinedwitha\n24-bitInitialisationVector(IV)isfedintoaPseudoRandomNumberGenerator(PRNG)such\nas a RC4 stream cipher. The plaintext payload and the CRC of the frame are then combined\nwiththekeysequencegeneratedbytheRC4usingbit-wiseexclusive-oroperationtoencrypt\ntheframe.AnewIVisusedforeachframe.\nFor authentication, the Access Points (APs) advertise via beacon frames whether authenti-\ncation is necessary or not. However, not all APss support this feature. If authentication is\nrequired, before association a host connecting to an AP would receive a 128-bit nonce from\nthe AP. It would encrypt the nonce with the shared key and send it back to the AP. The AP\nwould decrypt this response with the shared key and verify whether it matched the nonce\nit sent originally. The receiver would extract the IV received in plaintext, input IV and shared\nsecretkeyintoPRNG,getakeystream,XORthekeystreamwiththeencrypteddatatodecrypt\ndata+ICVandfinallyverifytheintegrityofthedatawiththeICV.\nTheWEPprotocolhasanumberofdesignflaws.First,theuseofa24-bitIVintroducesaweak-\nnessintotheschemeinthat224or16millionuniqueIVscanbeexhaustedinhigh-speedlinks\nin less than 2 hours. Given that IVs are sent in plaintext, an eavesdropper can easily detect\nthis reuse and mount a known plaintext attack. Using the RC4 in WEP allows for the Fluhrer,\nMartin and Shamir (FMS) attacks. In the FMS, an attacker can recover the key in an RC4 en-\ncrypted stream by capturing a large number of messages in that stream [1396]. The linear\nCRC algorithm is good for detecting random link errors but is a poor choice for maliciously\nmodifying the message. Strong cryptographic techniques such as message authentication\ncodesandsignatures,asdiscussedinhigherlayerprotocols,arebettersuitedforthistask.\nGiventhepoorsecuritydesignofWEP,theWi-FiAlliancetookonthejobofsecuringwireless\nnetworks. An interim standard called the Wi-Fi Protected Access (WPA) was quickly devel-\nopedforbackwardhardwarecompatibility,whileWPA2wasbeingworkedout.WPAusesthe\nTemporal Key Integrity Protocol (TKIP) but maintains RC4 for compatibility. The Pre-Shared\nKey(PSK),alsoknownasWPA-Personal,issimilartotheWEP-Key.However,thePSKisused\ndifferently, a nonce, and PSK are hashed to generate a temporal key. Following this, a cryp-\ntographic mixing function is used to combine this temporal key, the Temporal MAC (TMAC),\nand the sequence counter resulting in one key for encryption (128 bits) and another key for\nintegrity(64bits).Asaconsequence,everypacketisencryptedwithauniqueencryptionkey\nto avoid FMS-style attacks. Also, the WPA extends the WEP IV to 48 bits, which is used as a\npacketsequencecounter.Itwouldtake100yearstoreplaythesameIV.Apacketreceivedout\nof order, would be dropped by the receiving station. Several new fields include a new Frame\nCheck Sequence (FCS) field, a CRC-32 checksum for error correction and a hash function\nbasedonthenewfieldMichael(MIC)foranintegritycheck.TheWPAhashaditsownshare\nofattacks,asreportedintheliterature[1397].\nThe Wifi alliance WPA2 standards derived from the IEEE 802.11i standards were finalised in\nKANetworkSecurity |October2019 Page571 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n2004.WPA2reliesonmorepowerfulhardwaresupportinga128-bitAESCounterModewith\nthe Cipher Block Chaining Message Authentication Code Protocol (CCMP). These methods\narediscussedintheCryptographyKnowledgeArea(Chapter10).Italsoprovidesanimproved\n4-wayhandshakeandtemporarykeygenerationmethod.\nIn 2018, a new WPA3 standard was accepted to make a gradual transition and eventually re-\nplacetheWPA2.TheWPA3overcomesthelackofperfectforwardsecrecyinWPAandWPA2.\nThe PSK is replaced with a new key distribution called the Simultaneous Authentication of\nEquals (SAE) based on the IETF Dragonfly key exchange. The WPA3-Personal mode uses a\n128-bitencryption,whereastheWPA3-Enterpriseuses192-bitencryption.\n17.7.1 Robust Security Network (RSN)\nAnearliersectiondescribedtheevolutionoftheWEPintotheWPAandWPA2.However,the\nIEEE 802.11i working group came up with the RSN framework to provide the strongest form\nofsecurity.Itadoptsthe802.1X-basedmechanismsforaccesscontrol,asdiscussedabove.\nAuthentication and key-generation are done via the EAP. It continues to use the TKIP and\nCCMPforvariouscryptographicfunctionssuchasencryption\/decryption,integritycheck,as\nwell as origin authentication and replay attack detection. Stallings [1389] provides a good\noverviewoftheRSNprotocolsandstandards.\nThe RSN Key derivation mechanisms are involved to a degree, as can be seen in figure 17.8.\nWewillprovideasummaryofthis,asmanyotherprotocols(includingCellularGSM)following\na similar scheme to the pairwise key scheme provide a mechanism for generating dynamic\nsessionkeyseachtimeauserstartsanewsession.\nAs a starting point, the user device and AP would have a Pre-Shared Key (PSK) using out-\nof-band methods. However, this is not a scalable solution and in an enterprise setup using\ntheIEEE802.1X,aMasterSessionKey(MSK)istypicallygeneratedduringtheauthentication\nphase. With these two options available, a Pairwise Master Key (PMK) can be generated\nin the following two ways: using the PSK as the PMK or deriving the PMK from the MSK\nusing the Pseudo-Random Function (PRF). The PSK also uses the host and AP addresses\nwhen generating the PTK, thus providing additional defence against session hijacking and\nimpersonation. Further, a nonce is used in the mix to achieve good random keying material.\nThePTKisnowsplitthreeways,thusgeneratingseparatekeysforeachfunction.\nTheRSNalsocatersforagroupkeygenerationwhereahostcancommunicatewithamulti-\ncastgroup,asshowninfigure17.9.ThiskeyisgeneratedbytheAPanddistributedsecurely\ntothehostsassociatedusingthesecurepairwisekeysderivedabove.Thisgroupkeycanbe\nchangedperiodicallybasedonavarietyofnetworkpolicies.TheGroupTemporalKeygener-\nationmethodisnotdefinedinthestandards.\nKANetworkSecurity |October2019 Page572 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nConfirma6on\nKey\nEAP path AAA Key\n128-bits\n\u2265 256-bits\n(Possible PRF using\ntrunca6on) Pairwise HMAC-SHA-1 Pairwise Encryp6on\nMaster Key transient Key Key\n256-bits 384-bits (CCMP) 128-bits\n256-bits (TKIP)\nOut-of- Pre-shared\nband path Key\nTemporal\n256-bits Key\n128-bits\nComponents of PTK\nPairwise key hierarchy\nFigure17.8:WLANRSNPairwiseKeyHierarchy\n17.8 NETWORK DEFENCE TOOLS\nIdeally, attacks should be detected as early as possible, or even predicted before they have\nstarted so that they can be prevented altogether. We will discuss a number of approaches\nthatcanbeimplementedonvariouslayersoftheprotocolstack.Weprovideabriefoverview\nhere. The effective deployment of these tools is covered in detail in the Security Operations\n&IncidentManagementKnowledgeArea(Chapter8).\n17.8.1 Packet Filters\/Firewalls\nThe term filter is used for a set of rules configured by an administrator to inspect a packet\nand perform a matching action, e.g., let the packet through, drop the packet, drop and gen-\nerate a notification to the sender via ICMP messages. Packets may be filtered according to\ntheirsourceanddestinationnetworkaddresses,protocoltype(TCP,UDP,ICMP),TCPorUDP\nsource\/destination port numbers, TCP Flag bits (SYN\/ACK), rules for traffic from a host or\nleaving the network via a particular interface and so on. This was typical of the early packet\nfilters, which worked on inspecting header fields. These filters did not retain any state in-\nformation about the packets\/flows\/sessions they belonged to. As more computing power\nandcheapermemorybecameavailable,thenextgenerationofpacketfiltersstartedtotrack\ntransportlayerflow,achainofpacketsbelongingtoasession,knownasstatefulfilters.\nThe packet filters, aka, Firewall system can be co-located with routers or implemented as\nspecialised servers. In either case, they are gatekeepers, inspecting all incoming\/outgoing\ntraffic.Thefiltersaresetbasedonanetwork\u2019ssecuritypolicyandthepacketsaretreatedac-\ncordingly.Althoughfirewallsplayakeyroleinsecuringanetwork,takingdownafirewallcan\npotentiallywreakhavocfororganisationswhicharedependentonnetworkingtechnology.\nKANetworkSecurity |October2019 Page573 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nPRF using\nHMAC-SHA-1\nGroup master Key Group temporal Key\n(Changes periodically or if (Changes based on policy:\ncompromised) disassociaPon\/deauthenPcaPon)\n256-bits 40-bits, 104-bits (WEP)\n128-bits (CCMP)\n256-bits (TKIP)\nGroup key hierarchy\nFigure17.9:WLANRSNGroupKeyHierarchy\n17.8.2 Application Gateway (AG)\nAs we saw earlier, a firewall can check rules based on the filtering criterion using TCP\/UDP\nprotocolheaders,portnumbersetc.However,manyorganisationsuseapplicationlevelgate-\nways, aka application proxy, to perform access control, as they facilitate any additional re-\nquirements of user authentication before a session is admitted. These AGs can inspect in-\nformation from the full 5-layer (Internet) or 7-layer OSI stack, except for encrypted bits. In\na typical setting, the application gateway will use a firewall\u2019s services after performing au-\nthentication and policy enforcement. Both the AG and firewall are also co-located in many\ndeployments. A client wanting to access an external service would connect to the AG first.\nTheAGwouldprompthimorherforauthenticationbeforeinitiatingasessiontotheexternal\nserver.TheAGwouldnowestablishtheconnectionwiththedestinationactingasarelayon\nbehalfoftheclient,essentiallycreatingtwosessions:onebetweentheclientandtheAG,and\nonebetweentheAGandthedestination.\nAnother interesting application of an AG is SSL termination. An incoming webserver SSL\nconnection could be terminated at the AG, so that it could do the resource intensive en-\ncryption\/decryption and pass the un-encrypted traffic to the back-end servers. This allows\ntheworkloadonthesebusyserverstobereducedinadditiontoimplementingsecuritymea-\nsures. In practice, the AGs are also configured to inspect encrypted outbound traffic where\ntheclientsareconfiguredwithcorrespondingcertificatesinstalledattheAG.\nHigher level security provided by an AG comes at the expense of additional hardware\/soft-\nware resources. Further, an AG can slow down the connection, as authentication, policy\nchecks and state maintenance are performed to keep track of every session going through\nthe AG. Another complexity involved with an AG is the need to configure it for each applica-\ntion,orpossiblybeimplementedasmultipleapplicationspecificservers.\nKANetworkSecurity |October2019 Page574 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n17.8.3 Circuit-level Gateway (CG)\nA CG is a proxy that functions as a relay for TCP connections, thus allowing hosts from a\ncorporate Intranet to make TCP connections over the Internet. CGs are typically co-located\nwith a firewall. The most widely used CG today is SOCKS. For end user applications, it runs\ntransparentlyaslongasthehostsareconfiguredtouseSOCKSinplaceofastandardsocket\ninterface.ACGissimpletoimplementcomparedtoanAG,asitdoesnotneedtounderstand\napplicationlayerprotocols.\n17.8.4 Intrusion Detection Systems (IDS)\nIDS can provide valuable information about anomalous network behaviour. However, other\ncomplementarytechniquesarealsorequiredifalltrafficisencrypted.SimilartoAGs,theyin-\nspecthigherlayerinformationandmanymoreattributesofsessionsbeyondwhatapacket-\nfilter or firewall can do. An IDS would monitor network traffic with the help of agents\/sen-\nsors\/monitors on the network and sets off alarms when it detects (or thinks it has) suspi-\ncious activity. Essentially, the IDS would compare the traffic against what it considers nor-\nmaltrafficand,usingarangeoftechniques,wouldgenerateanalert.Falsealarmsareahuge\nproblemfornetwork\/securityadministratorsdespitedecadesofresearch.Forexample,false\npositives may be generated by the IDS for legitimate hosts carrying out identical legitimate\nbehaviour that may appear malicious. We will now consider a situation where a legitimate\ndomain accessed frequently by hosts in a network becomes temporarily unreachable. The\nfailed DNS queries to the same domain in this instance would be generated for many hosts\nandmayappearsuspicious,butshouldnotbeconsideredmaliciousactivity.Likewise,afalse\nnegativewouldcauseclassifyingmaliciousactivityasbenign.\nThefollowingarethetwomainIDScategories:\n\u2022 Signature-based intrusion detection systems compare monitored traffic against a\ndatabase containing known threat signatures similar to virus scan software. The\ndatabase has to be continually updated, however, or it will not detect new types of at-\ntacks.Signaturescanbeassimpleasasource\/destinationIPaddressorcontainmany\nother protocol headers including certain patterns in the payload. We provide a simple\nexamplefromanopensourceIDSSnortbelow.\nalert tcp any any \u2212> 192.168.5.7\/24 80\n1\n(content : \"GET\" ; msg: \"WWW GET has been detected\" ;\n2\nsid:1000007; rev :1;)\n3\nInthissimpleexample,theactionis\u2018alert\u2019.ThesourceisdefinedforanyTCPflowwith\nanyaddress.Thedestinationisdefinedas192.168.5.7\/24atport80.Theruleisdefined\ntocheckwhetherthepacketcontainsa\u2018GET\u2019stringandthengenerateanalert.The\u2018sid\u2019\nor Snort Identifier refers to the Snort rule used. Snort provides a long set of rules but\nallowsuserstodefinetheirown.\nIDS generates a heavy workload, as it has to compare huge numbers of signatures.\nSpeedofdetectionplaysakeyroleinpreventingtheseattacks.Severalsystemsdeploy\nparallelanddistributeddetectionsystemsthatcancopewithhightrafficratesonlarge\nnetworksandallowonlinedetection;othersexploitparallelismatthehardwarelevelin\norder to overcome processing delays so that packets and flows can be processed at\nhighspeeds,thusprovidingfasterresults.Alotofresearchhasalsofocusedonfaster\npatternsorrulematchingwiththeaimofreducingpacketprocessingdelays.\nKANetworkSecurity |October2019 Page575 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n\u2022 Anomaly-based intrusion detection systems use statistical features of normal traffic\nto compare with the monitored traffic. The criterion for capturing normal traffic could\nbe bandwidth usage, protocols, ports, arrival rate and burstiness [886]. For example, a\nlarge percentage of port scans would generate an alert. Attacks can be detected by\nmonitoring hosts or networks for behaviour typical of different attacks. A target link\nflooding attack aims to overwhelm a particular link in the network, thus disconnect-\ning a selected network region or server from the network. Observing an increase in\ntraceroute packets in the network could indicate an upcoming target link flooding\nDDoSattack.\nDespite using machine learning techniques such as Linear Regression, Neural Net-\nworks, Deep Learning etc., which train a classifier from normal or malicious data and\nuse it to identify the same behaviour within future data, these systems\u2019 false positives\nremainhigh[1398].\nAnother way of classifying IDSes is the point of monitoring for malicious behaviour. A Host\nIntrusion Detection System (HIDS) runs on individual hosts in the network. Most virus scan\nsoftware would have this feature where they also monitor inbound and outbound traffic in\naddition to the usual virus scanning. This can be particularly helpful if the hosts have been\ncompromisedandformpartofabottoattackotherservers\/networks.Incontrast,anetwork\nintrusion detection system is deployed at strategic locations within the network to monitor\ninboundandoutboundtraffictoandfromthedevicesinvarioussegmentsofthenetwork.\n17.8.5 An Intrusion Prevention System (IPS)\nAnIPSdistinguishesitselffromanIDSinthatitcanbeconfiguredtoblockpotentialthreats\nbysettingfilteringcriteriaonrouters\/switchesatvariouslocationsinthenetwork.\nIPSsystemsmonitortrafficinrealtimedroppinganysuspectedmaliciouspackets,blocking\ntraffic from malicious source addresses or resetting suspect connections. In most cases,\nan IPS would also have IDS capabilities. Several IDS\/IPS tools generate an alert for a spam\npreparation stage, which is indicated by a rise in DNS MX queries that spam bots generate\ntodiscoveramailserverbeforesendingspamemails.\nTheIPSsystemisproactiveand,intheory,itshouldworkautonomouslywithoutintervention\nfromasecurity\/networkadministrator.Forexample,oninspectingtheheaders,ifanIPSsys-\ntem suspects an email to be unsafe, it could prevent it from being forwarded to an end user.\nHowever, the risk of blocking legitimate traffic is a huge problem due to false positives or\nthe mis-configuration of these systems. In practice, however, IPS systems are mostly set to\ndetectmodesandstartblockingtrafficonlywhentheconfidenceintheincidencebeingtrue\npositivebecomeshigh.\nIDS\/IPSvendorsprovideregularsignatureupdatesandsecurityteamswillhavetodetermine\nwhichonestodeploy,dependingonthenetworkenvironmentthatitisdeployed.IDS\/IPScan\nalso be software, deployed on the application layer on strategic endpoints. These do not\nhave their own OS, relying instead on the host, but can be fine-tuned to support and protect\nthespecificdeviceitisdeployedto.\nThere are several other mechanisms for network defence. In highly secured environments\nsuchasdefenceorcriticalinfrastructure,adeviceknownasaDataDiodecanbeconfigured\nto allow a secure flow of data in one direction only. For example, a water dam could provide\ninformation on water levels to people living in the neighbourhood, but may restrict sending\nKANetworkSecurity |October2019 Page576 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nany information back to the dam control network. A comprehensive coverage of this topic\ncanbefoundintheSecurityOperations&IncidentManagementKnowledgeArea(Chapter8).\n17.8.6 Network Architecture Design\nThesenetworkprotectiontoolsaremosteffectivewhendeployedincombination,wheredif-\nferent local networks have distinct and focussed purposes. Network design must balance\ntheconcernsofcostandperformanceagainstthebenefitsofsegmentingtrafficasmuchas\npossible. An early example was Network Perimeter Protection. The network perimeter pro-\ntection idea comes from the ancient technique of using walls such as Hadrian\u2019s Wall or the\nGreat Wall for protecting a city. In networking parlance, a zone called a Demilitarised Zone\n(DMZ), aka a perimeter network, is created. All external untrusted users are restricted from\nusing the services available in this zone. Typically, an organisation\u2019s public web server and\nauthoritativeDNSwouldresideintheDMZ.Therestofthenetworkispartitionedintoseveral\nsecurityzonesbyasecurityarchitect.Forexample,apaymentdatabasewouldbedeployed\ntoanisolatednetwork.EachzoneismanagedbyoneormoreoftheIDS,IPSorAGsystems\nbasedonthesignificanceoftheinformation\/infrastructuretobeprotected.Althoughwithout\nanytightcontroloftheendpointsonthenetwork,thishasproventoachievelessseparation\nthanexpected.\n17.9 ADVANCED NETWORK SECURITY TOPICS\n17.9.1 Software Defined Network, Virtualisation\nSoftware Defined Networking (SDN) has become commonplace in data centres and other\ncontexts for managing and controlling the network operation. In conventional IP network,\nrouters perform both routing and forwarding functions. However, the SDN separates the\npacketforwardingfunctionalityoftheforwardingdevices,i.e.thedataplanefromthecontrol\nplane. The routing function and other intelligence is implemented in a centralised controller.\nOn receiving of a new packet, the SDN switch requests for a forwarding rule from the con-\ntroller. The switch then forwards all subsequent packets from the flow using this rule. The\nSDN architecture provides many new features to improve security for threat detection and\nattackpreventionandprovidesinnovativesecurityservices [1399,1400].\nFor example, a DDoS attack can be inferred by the central controller more accurately, and a\nthreat mitigation application may dynamically reprogram switches at the network perimeter\ntodropmalicioustrafficflows.Auseronaninfectedmachinecanautomaticallyberoutedto\naweb-serverissuingaquarantinenotification.Anothergroupofresearchershasfocussedon\nsecuringtheSDNplatformitself.TheSDNcontrollersuseaSpanningTreeAlgorithm(SPTA)\nfor topology updates. In a DoS attack, an adversary could advertise a fake link and force\nthe SPTA to block legitimate ports. Hong et al. [1401] provide a number of attack vectors on\npracticalSDNswitchimplementations.\nSDN switches are prone to a timing side channel attack. Liu et al. [1402] present several at-\ntack vectors. An attacker can send a packet and measure the time it takes the switch to\nprocess this packet. As discussed above, for a new packet, the switch will need to fetch a\nnew rule from the controller, thus resulting in additional delay over the flows that already\nhaverulesinstalledattheswitch.Asanexample,theattackercandeterminewhetheranex-\nchangebetweenanIDSandadatabaseserverhastakenplace,orwhetherahosthasvisited\nKANetworkSecurity |October2019 Page577 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\naparticularwebsite.Apossiblecountermeasurewouldintroducedelayforthefirstfewpack-\nets of every flow even if a rule exists [1403]. SDN switches store rules in the cache memory\nfor fast lookups. The rules are typically purged from the memory after a specified timeout\nperiodorremovedduetocertainotherpolicydecisions.Liuetal.[1402]alsodescribepoten-\ntial attacks by observing the cache rule removal behaviour. They suggest countermeasures\nsuch as a proactive rule setup or transforming the rule structure (e.g., merger) to make any\ninference difficult. Zerkane et al. [1404] have methodically analysed and reported 114 SDN\nvulnerabilities.\nA recent trend in networking is the use of Network Functions Virtualisation (NFV). The goal\nis to reduce capex and allow for the rapid introduction of new services to the market. Spe-\ncialisednetworkmiddleboxessuchasfirewalls,encoders\/decoders,DMZsanddeeppacket\ninspection units are typically closed black box devices running proprietary software [1405].\nNFVresearchershaveproposedthedeploymentofthesemiddleboxesentirelyasvirtualised\nsoftwaremodulesandmanagedviastandardisedandopenAPIs.Thesemodulesarecalled\nVirtual Network Functionss (VNFs). A large number of possible attacks concern the Virtual\nMachine(Hypervisor)aswellasconfiguringvirtualfunctions.Laletal. [1406]provideatable\nof NFV security issues and best practice for addressing them. For example, an attacker can\ncompromiseaVNFandspawnothernewVNFstochangetheconfigurationofanetworkby\nblockingcertainlegitimateports.Authorssuggesthypervisorintrospectionandsecurityzon-\ning as mitigation techniques. Yang et al. [1407] provide a comprehensive survey on security\nissuesinNFV.\n17.9.2 Internet of Things (IoT) Security\nAs discussed earlier, the Mirai malware shows how IoT devices such as IP cameras can\nbe used to launch serious DDoS attacks. As it is an application driven field, vendors prefer\n\u2019first to market\u2019 with the resulting security being low priority. The other reason is that IoT de-\nvices are typically low-end and have limited capability for participating in advanced security\nprotocols, especially when they are resource-constrained through battery power etc. Trans-\nportLayerSecurity(TLS)andDatagramTLS(DTLS)arecornerstonesofIoTsecurity.Promi-\nnent IoT application layer protocols adopt either TLS or DTLS as their security protocol in\ncombination with Public Key Crytography (PKC) or a Pre-Shared Key (PSK) suite. These IoT\napplication frameworks fulfill standard security requirements similar to traditional Internet\napplications. Since TLS requires a TCP connection, DTLS is widely used for limited band-\nwidthandlowerreliability,asitisconnectionlessandUDP-based.WhileDTLSisdesignedto\nbe used in constrained devices with limited communication capability, the End-to-End (E2E)\ncommunicationmanneroftheDTLScausesscalabilityissuesinlarge-scaleIoTapplications,\nespecially under low-bandwidth standards such as IEEE 802.15.4. Given the emerging char-\nacteristics of heterogeneity, energy and performance, scalability, mobility and management,\nitisobviousthatthecurrentPKCwithanE2Einfrastructurewillalmostcertainlynotscaleto\naccommodate future IoT applications [1408]. E2E communication causes unscalable com-\nmunication overheads and delays in large-scale applications. Furthermore, constrained de-\nvices are not equipped with adequate performance\/memory to process resource-intensive\nPKCsuites,thusresultinginperformance\/securitydegradation.\nKANetworkSecurity |October2019 Page578 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nCROSS-REFERENCE OF TOPICS VS REFERENCE MATERIAL\n17.1InternetArchitectureInternetArchitecture X\n17.2NetworkProtocolsandVulnerabilityNetworkProtocolsandVulnerability X X\n17.3Application-LayerSecurityApplicationLayerSecurity X X\n17.4Transport-LayerSecurityTransportLayerSecurity X X\n17.5NetworkLayerSecurityNetworkLayerSecurity X X\n17.6LinkLayerSecurityLinkLayerSecurity X X\n17.7WirelessLANSecurityWirelessLANSecurity X X\n17.8NetworkDefenceToolsNetworkDefenceTools X X\n17.9AdvancedNetworkSecurityTopicsAdvancedNetworkSecurityTopics X\nKANetworkSecurity |October2019 Page579\n]7831[7102:esoruK\n]9831[6102:sgnillatS\n]9931[51ahaT ]688[6648374 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nKANetworkSecurity |October2019 Page580 Chapter 18\nHardware Security\nIngrid Verbauwhede KU Leuven\n581 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nINTRODUCTION\nHardware security covers a broad range of topics from trusted computing to Trojan circuits.\nToclassifythesetopicswefollowthedifferenthardwareabstractionlayersasintroducedby\ntheY-chartofGajski&Kuhn.Thedifferentlayersofthehardwaredesignprocesswillbeintro-\nducedinsection18.1.Itislinkedwiththeimportantconceptofarootoftrustandassociated\nthreat models in the context of hardware security. Next follows section 18.2 on measuring\nand evaluating hardware security. The next sections gradually reduce the abstraction level.\nSection18.3describessecureplatforms,i.e.acompletesystemorsystem-on-chipastrusted\ncomputingbase.Nextsection18.4covershardwaresupportforsoftwaresecurity:whatfea-\nturesshouldaprogrammableprocessorincludetosupportsoftwaresecurity.Thissectionis\ncloselyrelatedtotheSoftwareSecurityKnowledgeArea(Chapter14).Registertransferlevel\nisthenextabstractionleveldown,coveredinsection18.5.Focusatthislevelistypicallythe\nefficientandsecureimplementationofcryptographicalgorithmssothattheycanbemapped\nonASICorFPGA.ThissectioniscloselyrelatedtotheCryptographyKnowledgeArea(Chap-\nter10).Allimplementationsalsoneedprotectionagainstphysicalattacks,mostimportantly\nagainstside-channelandfaultattacks.Physicalattacksandcountermeasuresaredescribed\ninsection18.6.Section18.7describesentropysourcesatthelowestabstractionlevel,close\nto CMOS technology. It includes the design of random numbers generators and physically\nunclonable functions. The last technical section describes aspects related to the hardware\ndesign process itself. This chapter ends with the conclusion and an outlook on hardware\nsecurity.\n18.1 HARDWARE DESIGN CYCLE AND ITS LINK TO\nHARDWARE SECURITY\nHardwaresecurityisaverybroadtopicandmanytopicsfallunderitsumbrella.Inthissection,\ntheseseeminglyunrelatedtopicsaregroupedandorderedaccordingtothedesignlevelsof\nabstractionasintroducedbytheY-chartofGajski&Kuhn[1409].WhileGajski&Kuhnpropose\nageneralapproachtohardwaredesign,inthischapteritisappliedtothesecurityaspectsof\nhardwaredesignanditislinkedtothreatmodelsandtheassociatedrootoftrust.\n18.1.1 Short background on the hardware design process\nDesignabstractionlayersareintroducedinhardwaredesigntoreducethecomplexityofthe\ndesign. As indicated in 18.1, the lowest abstraction level a designer considers are individ-\nual transistors at the center of the figure. These transistors are composed together to form\nbasic logic gates, such as NAND, NOR gates or flip-flops, called the logic level. Going one\nabstraction layer up, at register transfer level gates are grouped together to form modules,\nregisters,ALU\u2019s,etc,andtheiroperationissynchronizedbyaclock.Thesemodulesarethen\ncomposed to form processors, specified by instruction sets, upon which applications and\nalgorithmscanbeimplemented.\nBy going up in the abstraction layers, details of underlying layers are hidden. This reduces\ndesign complexity at higher abstraction layers. The abstraction layers are represented by\nconcentriccirclesinfigure18.1.Uponthesecircles,theY-chartofGajski&Kuhnintroduces3\ndesignactivities,representedbythreeaxes:abehavioralaxis,describingthebehaviororwhat\nneedstobeimplemented(akaspecifications),astructuralaxisdescribinghowsomethingis\nKAHardwareSecurity |October2019 Page582 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nBehaviouralDomain StructuralDomain\nSystems\nAlgorithms\nProcessors\nRegistertransfers\nALUs,RAM,etc.\nLogic\nGates,flip-flops,etc.\nCurrent,voltage\nTransistors\nTransistorlayout\nCelllayout\nModulelayout\nFloorplans\nPhysicalpartitions\nPhysicalDomain\nFigure18.1:Gajski-KuhnY-chart\nimplemented and a physical axis, how the layouts are composed together at gate, module,\nchip, board level. An actual design activity is a \u2018walk\u2019 through this design space. Typically\none starts with the specifications at the top of the behavioral domain. These specifications\n(=what) are decomposed in components at the same level of abstraction (=how) moving\nfrom the behavioral axis to the structural axis. A structural component at one abstraction\nlevelbecomesabehavioralcomponentatoneleveldown.\nAsanexampleofawalkthroughthedesignspace:Assumeahardwaredesignerisrequested\nto implement a light-weight, low power security protocol for an Internet of Things (IoT) de-\nvice. This designer will only receive specifications on what needs to be designed: a security\nprotocol aims at providing confidentiality and integrity (= what) and a set of cryptographic\nalgorithms(=components)tosupporttheprotocol.Thecrypto-algorithmsareprovidedasa\nbehavioralspecificationtothehardwaredesigner,whohasthechoiceofimplementingitas\nadedicatedco-processor,asanassemblyprogram,orsupportitwithasetofcustominstruc-\ntions. Depending on costs and volumes, a choice of a target CMOS technology or an FPGA\nplatformismade.Thisbehaviorallevelwillbetranslatedintoamoredetailedregister-transfer\nleveldescription(e.g.VHDLorVerilog).AttheRegisterTransferLevel(RTL),decisionsneed\ntobemadeifthiswillbeaparallelorsequentialversion,adedicatedorprogrammabledesign,\nwithorwithoutcountermeasuresagainstside-channelandfaultattacks,etc.\nEssentialforthedivisionindesignabstractionlayers,isthecreationofmodelsonhowcom-\nponentsbehave.E.g.tosimulatethethroughputorenergyconsumptionofaarithmeticunit,\nquality models of the underlying gates need to be available. Similarly, the Instruction Set Ar-\nchitectureisamodelofaprocessoravailabletotheprogrammer.\nKAHardwareSecurity |October2019 Page583 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n18.1.2 Root of trust\nIn the context of security, a root of trust is a model of an underlying component for the pur-\npose of security evaluation. According to Anderson [1030]: \"A root of trust is a component\nused to realize a security function, upon which a designer relies but of which the trustwor-\nthinesscannotbeexplicitlyverified.\"Thedesignerusesoneormultiplecomponentstocon-\nstruct a security function, which then defines the trusted computing base. It is defined by\nthe trusted computing group as follows: \u201cAn entity can be trusted if it always behaves in the\nexpectedmannerfortheintendedpurpose.\u201d [1410].\nE.g. for an application developer, a Trusted Platform Module (TPM) or a Subscriber Identity\nModule(SIM)arearootoftrustwhichthedeveloperusestoconstructasecurityapplication.\nFortheTPMdesigner,theTPMiscompositionofsmallercomponentswhicharecomposed\ntogether to provide security functionality. At the lowest hardware abstraction layers, basic\nrootsoftrustarethesecurestorageofthekeyinmemoryorthequalityoftheTrueRandom\nNumberGenerator.\nHardware security is used as an enabler for software and system security. For this reason,\nhardware provides basic security services such as secure storage, isolation or attestation.\nThe software or system considers the hardware as the trusted computing base. And thus\nfrom a systems or application view point, hardware has to behave as a trusted component.\nHowever,thehardwareimplementationcanviolatethetrustassumption.E.g.Trojancircuits\norside-channelattackscouldleakthekeyorothersensitivedatatoanattacker.Hence,hard-\nware itself also needs security. Moreover hardware needs security at all abstraction layers.\nTherefore,ateveryabstractionlayer,athreatmodelandassociatedtrustassumptionsneed\nto be made. An alternative definition for a root of trust in the context of design abstraction\nlayers is therefore: \u201cA root of trust is a component at a lower abstraction layer, upon which\nthesystemreliesforitssecurity.Itstrustworthinesscaneithernotbeverified,oritisverified\natalowerhardwaredesignabstractionlayer.\"\n18.1.3 Threat model\nAthreatmodelisassociatedwitheachrootoftrust.Whenusingarootoftrust,itisassumed\nthat the threat model is not violated. This means that the threat model is also linked to the\nhardware abstraction layers. If we consider a root of trust at a particular abstraction layer,\nthenallcomponentsthatconstitutethisrootoftrust,arealsoconsideredtrusted.\nExample 1: security protocols assume that the secret key is securely stored and not acces-\nsible to the attacker. The root of trust, upon which the protocol relies, is the availability of\nsecure memory to guard this key. For the protocol designer, this secure memory is a black\nbox.Thehardwaredesignerhastodecomposethisrequirementforasecurememoryintoa\nsetofrequirementsatalowerabstractionlayer.Whattypeofmemorywillbeused?Onwhich\nbusseswillthekeytravel?Whichotherhardwarecomponentsorsoftwarehaveaccesstothe\nstorage?Cantherebeside-channelleaks?\nExample2:Itisduringthistranslationofhigherabstractionlayerrequirementsfromprotocol\nor security application developers into lower abstraction layers for the hardware designers\nthat many security vulnerabilities occur. Implementations of cryptographic algorithms used\nto be considered black boxes to the attacker: only inputs\/outputs at the algorithm level are\navailable to mount mostly mathematical cryptanalysis attacks. However, with the appear-\nance of side-channel attacks (see section 18.6) this black box assumption no longer holds.\nTakingside-channelleakageintoaccounttheattackerhasthealgorithmlevelinformationas\nKAHardwareSecurity |October2019 Page584 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nwellastheextratiming,power,electro-magneticinformationasobservablefromtheoutside\nofthechip.Thustheattackermodelmovesfromblackboxtograybox.Itisstillassumedthat\ntheattackerdoesnotknowthedetailsoftheinternals,e.g.thecontentsofthekeyregisters.\nExample 3: for programmable processors, the model between hardware and software is tra-\nditionally considered the Instruction Set Architecture (ISA). The ISA is what is visible to the\nsoftwareprogrammerandtheimplementationoftheISAislefttothehardwaredesigner.The\nISAusedtobeconsideredthetrustboundaryforthesoftwaredesigner.Yet,withthediscov-\neryofmicro-architecturalside-channelattacks,suchasSpectre,Meltdown,Foreshadow,this\nISA model is no longer a black box, as also micro-architectural information and leakage are\navailabletotheattacker[1411].\n18.1.4 Rootoftrust,threatmodelandhardwaredesignabstractionlayers\nThe decomposition in abstraction layers, in combination with Electronic Design Automation\n(EDA) tools, is one of the main reasons that the exponential growth of Moore\u2019s law was sus-\ntainable in the past decades and it still is. This approach works well when optimizing for\nperformance,area,energyorpowerconsumption.Yetforhardwaresecurity,nosuchgeneral\ndecompositionexists.\nIn this chapter, we propose to organise the different hardware security topics, their associ-\natedthreatmodelsandrootoftrustaccordingtothehardwaredesignabstractionlayers,as\nthere is no known other general body of knowledge available to organize the topics. This or-\nganization has the advantage that it can be used to identify the state of the art on different\nsubtopics of hardware security. As an example, in the specific context of hardware imple-\nmentations of cryptographic algorithms, the state of the art is well advanced and robust\ncountermeasures exist to protect cryptographic implementations against a wide range of\nside-channelattacks,asshownindetailinsection18.5.Yetinthecontextofgeneralproces-\nsorsecurity,e.g.toisolateprocessrelateddataortoprovidesecureexecution,newsecurity\nhazardscontinuetobediscoveredonaregularbasis.\nIn an attempt to order the topics, table 18.1 summarizes this organization. The different ab-\nstraction layers are identified (first column) from a hardware perspective. The highest level\n(systemandsoftware)sitsontopofthehardwareplatform.E.g.asystemdesignerassumes\nthatasecureplatformisavailable.Thusthesecureplatformistherootoftrust,providingse-\ncurity functionality. The second column describes the functionality provided by the root of\ntrust. The third column describes how this functionality might be implemented. E.g. at the\nhighestabstractionlayerthismightbebyprovidingaTrustedExecutionModuleorasecure\nelement, etc. The fourth column describes the threat models and attack categories at that\nabstraction layer. E.g. at system level, the system designer assumes that they will receive a\nmodule that provides isolation, integrity, attestation, etc. The last column describes typical\ndesignactivitiesatthisparticulardesignabstractionlayer.\nThis exercise is repeated for each abstraction layer and described in detail in each of the\nfollowingsections.\nAt the processor level, one can distinguish general purpose programmable processors and\ndomainspecificprocessors.Generalpurposeprocessorsshouldsupportawiderangeofap-\nplications, which unfortunately typically include software vulnerabilities. Hardware features\nare added to address these software vulnerabilities, such as a shadow stack or measures\nto support hardware control flow integrity. Domain specific processors typically focus on\nKAHardwareSecurity |October2019 Page585 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nAbstractionlevel Rootoftrust- Structural(how)- ExampleThreats TypicalHWdesign\nfunctionality examples activities\nSystemand Secureplatforms e.g.Trusted tosupport security\napplication Execution isolation,integrity, application\n(Trustzone,SGX, attestation,... development\nTEE),HSM,Secure\nElement\nProcessor generalpurpose e.g.shadowstack SWvulnerabilities ISA,HW\/SW\nco-design\nProcessor domainspecific Cryptospecific Timingattacks Constantnumber\nRTL ofclockcycles\nRegisterTransfer Cryptospecific Buildingblocks, SideChannel Logicsynthesis\nAttack,\nLogic ResistancetoSCA, Masking,Circuit SideChannel FPGAtools,\nPower,EM,fault styles attack,fault standardcell\ndesign\nCircuitand Sourceofentropy TRNG,PUF,Secure Temperature, SPICEsimulations\ntechnology SRAM glitches\nPhysical Tamper Shields,sensors Probing,heating Layoutactivities\nResistance\nTable18.1:Designabstractionlayerslinkedtothreatmodels,rootoftrustanddesignactivities\na limited functionality. They are typically developed as co-processors in larger systems-on-\nchip. Typical examples are co-processors to support public key or secret key cryptographic\nalgorithms.Timeattheprocessorlevelistypicallymeasuredininstructioncycles.\nBoth general purpose and domain specific processors are composed together from compu-\ntational units, multipliers and ALU\u2019s, memory and interconnect. These modules are typically\ndescribed at the register transfer level: constant-time and resistance against side-channel\nattacksbecomethefocus.Timeatthislevelistypicallymeasuredinclockcycles.\nMultipliers,ALU\u2019s,memories,interconnectandbusinfrastructurearecreatedfromgatesand\nflip-flopsatthelogiclevel.Atthisdesignabstractionlevel,focusisonleakagethroughphys-\nical side-channels, power, electro-magnetic, and fault attacks. Time is typically measured in\nabsolutetime(nsec)basedontheavailablestandardcelllibrariesorFPGAplatforms.\nThe design of entropy sources requires knowledge and insights into the behavior of transis-\ntorsandtheunderlyingComplementaryMetal-Oxide-Semiconductor(CMOS)technology.The\ndesign of these hardware security primitives is therefore positioned at the circuit and tran-\nsistor level. Similarly the design of sensors and shields against physical tampering require\ninsightintothetechnology.Atthecircuitandtechnologylevelitismeasuredinabsolutetime,\ne.g.nsecdelayorGHzclockfrequency.\nThe table 18.1 does not aim to be complete. The idea is to illustrate each abstraction layer\nwithanexample.Inthenextsections,thehardwaresecuritygoalsandtheirassociatedthreat\nmodelswillbediscussedindetailinrelationtoandrelevanceforeachabstractionlayer.\nKAHardwareSecurity |October2019 Page586 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n18.2 MEASURING HARDWARE SECURITY\nDepending on the commercial application domain, several industrial and government orga-\nnizations have issued standards or evaluation procedures. The most well known ones are\nthe FIPS 140-2 (and the older FIPS 140-1), the Common Criteria (CC) evaluation and in the\nfinancial world the EMVCO. FIPS 140-2 mostly focuses on the implementation security of\ncryptographicalgorithms.CommonCriteriaareapplicabletoITsecurityingeneral.\n18.2.1 FIPS140-2\nFIPS140-2isaUSNISTstandardusedfortheevaluationofcryptographicmodules.FIPS140-2\ndefinessecuritylevelsfrom1to4(1beingthelowest).Thefollowinggivesadescriptionofthe\nfourlevelsfromaphysicalhardwaresecuritypointofview.Nexttothephysicalrequirements,\ntherearealsoroles,servicesandauthenticationrequirements(formoredetailssee[1412]and\notherKAs).\nSecurity level 1 only requires than an approved cryptographic algorithm be used, e.g. AES or\nSHA-3, but does not impose physical security requirements. Hence a software implementa-\ntioncouldmeetlevel1.Level2requiresafirstleveloftamperevidence.Level3alsorequires\nthetamperevidence,butontoprequirestamperresistance.\nNIST defines tampering as an intentional but unauthorized act resulting in the modification\nofasystem,componentsofsystems,itsintendedbehavior,ordata,[1413].\nTamper evidence means that there is a proof or testimony that tampering with a hardware\nmodulehashappened.E.g.abrokensealindicatesthatadevicewasopened.Alightsensor\nmightobservethatthelidofachippackagewaslifted.\nTamperresistancemeansthatontopoftamperevidence,protectionmechanismsareadded\ntothedevice.E.g.byextracoatingordensemetallayers,itisdifficulttoprobethekeyregis-\nters.\nLevel4increasestherequirementssuchthatthecryptographicmodulecanoperateinphys-\nically unprotected environments. In this context, the physical side-channel attacks pose an\nimportant threat. If any of these physical components depend on sensitive data being pro-\ncessed, information is leaked. Since the device is under normal operation, a classic tamper\nevidencemechanismwillnotrealizethatthedeviceisunderattack.Seelaterinsection18.6.\n18.2.2 Common criteria and EMVCo\n\u201cCommonCriteriaforinformationtechnologysecurityevaluation\"isaninternationalstandard\nfor IT product security (ISO\/IEC 15408), in short known as Common Criteria (CC). CC is a\nvery generic procedure applicable to the security evaluation of IT products. Several parties\nare involved in this procedure. The customer will define a set of security specifications for\nits product. The manufacturer will design a product according to these specifications. An\nindependent evaluation lab will verify if the product fulfills the claims made in the security\nrequirements. Certification bodies will issue a certification that the procedure was correctly\nfollowed and that the evaluation lab indeed confirmed the claims made. The set of security\nspecificationsarecollectedinaso-calledprotectionprofile.\nDepending on the amount of effort put into the security evaluation, the CC defines different\nEvaluationAssuranceLevels(EALs).Itrangesfrombasicfunctionallytesting,corresponding\nKAHardwareSecurity |October2019 Page587 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nto EAL1, to formally verified design and tested, corresponding to the highest level EAL7. CC\nfurthersubdividestheprocessofevaluationintoseveralclasses,wheremostoftheclasses\nverify the conformity of the device under test. The 5th class (AVA) deals with the actual vul-\nnerabilityassessment.Itisthemostimportantclassfromahardwaresecurityviewpointasit\nsearchesforvulnerabilitiesandassociatedtests.Itwillassignaratingonthedifficultytoex-\necutethetest,calledtheidentification,andthepossiblebenefitanattackercangainfromthe\npenetration,calledtheexploitation.Thedifficultyisafunctionofthetimerequiredtoperform\nthe attack, the expertise of the attacker from layman to multiple experts, how much knowl-\nedge of the device is required from simple public information to detailed hardware source\ncode,thenumberofsamplesrequired,andthecostandavailabilityofequipmenttoperform\nthe attack, etc. A high difficulty level will result in a high score and a high level of the AVA\nclass.ThehighestscoreonecanobtainisanAVAlevelof5,whichisrequiredtoobtainatop\nEALscore.\nItsusageiswellestablishedinthefieldofsmartcardsandsecureelementsastheyareused\nin telecom, financial, government ID\u2019s applications. It is also used in the field of Hardware\nSecurity Modules, Trusted Platform Modules and some more [1414]. For certain classes of\napplicationsminimumsetsofrequirementsaredefinedintoprotectionprofiles.Thereexists\nprotectionprofilesforTrustedPlatformModule(TPM),Javacards,Biometricpassports,SIM\ncards,secureelements,etc.\nSince certification comes from one body, there exist agreements between countries so that\nthe certifications in one country are recognized in other countries. As an exception EMVCo\nis a private organization to set the specifications for worldwide interoperability of payment\ntransactions.IthasitsowncertificationproceduresimilartoCC.\nPlease note that the main purpose of a common criteria evaluation is to verify that an IT\nproduct delivers the claims promised in the profile. It does not mean that there are no vul-\nnerabilities left. A good introduction to the topic can be found in [1415] and a list of certified\nproductson[1414].\n18.2.3 SESIP: Security Evaluation Standard for IoT Platforms\nIn the context of IoT security evaluation, a recent initiative is the SESIP Security Evaluation\nscheme [1416], currently at version 1.2. IoT devices are typically small, light-weight \u2019things\u2019,\nwithlimitedaccessibilityviainternet.SeverallevelsofthreatmodelforIoTarepossible:from\nonly remote internet access, over various remote software attack options, to also physical\nattackresistance.Acomprehensivesetofsecurityfunctionalrequirementsaredefined:iden-\ntificationandattestation,productlifecycle,securecommunication,softwareandphysicalat-\ntackresistance,cryptographicfunctionalityincludingrandomnumbergeneration,andsome\ncompliance functionality to e.g. provide secure encrypted storage or provide reliable time.\nSimilartoCommonCriteria,SESIPprovidesseverallevelsofassurance.Level1isthelowest\nlevelandconsistsofaself-assessment.ThehighestlevelofSESIPconsistsofafullCCeval-\nuation similar to smart cards or secure elements. The levels in between cover from a black\nboxpenetrationtestingoverwhiteboxpenetrationtestingwithorwithouttimelimitations.\nKAHardwareSecurity |October2019 Page588 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n18.3 SECURE PLATFORMS\nThissectiondescribesthegoalsandthestate-of-the-artinsecureplatforms.Atthishighlevel\nofabstractionthesystemdesignerreceivesacompletechiporboardastrustedcomputing\nbase. The system designers assume that the trusted root delivers a set of cryptographic\nfunctions, protected by the hardware and software inside the physical enclosure. Common\ntotheseplatformsisthattheyarestand-alonepiecesofsiliconwithastrictaccesspolicy.De-\npendingontheprovidedfunctionality,thehardwaretamperresistanceandprotectionlevels,\nand the communication interface, these secure platforms are used in different application\nfields(automotive,financial,telecom).ThreeimportantplatformsaretheHardwareSecurity\nModule(HSM),theSubscriberIdentificationModuleorSIMandtheTrustedPlatformModule\n(TPM).Thesearebrieflydescribednext.\n18.3.1 HSM Hardware Security Module\nA HSM module will typically provide cryptographic operations, e.g. a set of public key and\nsecret key algorithms, together with secure key management including secure generation,\nstorageanddeletionofkeys.EssentialtoHSM\u2019sisthattheseoperationsoccurinahardened\nandtamperresistantenvironment.ATRNGandanotionofareal-timeclockareusuallyalso\nincluded. HSM\u2019s are mostly used in server back-end systems to manage keys or payment\nsystems,e.g.inbankingsystems.\nA HSM is used as a co-processor, attached to a host system. Its architecture typically in-\ncludesamicro-processor\/micro-controller,asetofcryptoco-processors,securevolatileand\nnon-volatile memory, TRNG, real-time clock, and I\/O. The operations occur typically inside a\ntamper resistant casing. In previous generations, inside the casing multiple components re-\nsideononeboard.\nRecently, in some application domains, such as automotive, HSM functionality is no longer\nprovidedasastand-alonemodulebutisnowintegratedasasecureco-processorinalarger\nSystem on a Chip (SoC). Indeed Moore\u2019s law enables higher integration into one SoC. What\nexactly is covered under HSM functionality depends on the application domain. Therefore,\ncompliancewithsecuritylevelsisalsoevaluatedbyspecializedindependentevaluationlabs\naccordingtospecificprotectionprofiles.\n18.3.2 Secure Element and Smartcard\nSimilar to an HSM, a Secure Element and a smart card provide a set of cryptographic al-\ngorithms, public key, secret key, HMAC, etc. together with secure key storage, generation\nand deletion. The main difference with an HSM are cost, size, and form factor. They are typ-\nically implemented as one single integrated circuit and have a much smaller form factor\nfrom around 50 cm2 to less than 1 cm2. The main difference between a smart card and a\nsecure element sits in the form factor and the different markets they address. Secure ele-\nments are a more generic term, while smart cards have the very specific form factor of a\nbanking card. They are produced in large volumes and need to be very cheap as they are\nused for SIM cards in cell phones and smart phones. They are also used in banking cards,\npay-TV systems access cards, national identity cards and passports, and recently in IOT de-\nvices,vehicularsystemsandsoon.Tamperresistanceandphysicalprotectionareessential\ntosecureelements.Theyareaclearinstanceofwhatinacomputerarchitecturedomainare\nKAHardwareSecurity |October2019 Page589 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ncalled\u2019domainspecificprocessors\u2019.Specificprotectionprofilesexistdependingtheapplica-\ntiondomain:financial,automotive,pay-TV,etc.\nA typical embedded secure element is one integrated circuit with no external components.\nIt consists of a small micro-controller with cryptographic co-processors, secure volatile and\nnon-volatilestorage,TRNG,etc.I\/Oisusuallylimited,throughaspecificsetofpins,orthrough\na NFC wireless connection. Building a secure element is a challenge for a hardware de-\nsigner, as one needs to combine security with non-security requirements of embedded cir-\ncuits:smallformfactor(noexternalmemory),lowpowerand\/orlowenergyconsumptionin\ncombination with tamper resistance and resistance against physical attacks, such as side-\nchannelandfaultattacks(seesection18.6).\n18.3.3 Trusted Platform Module (TPM)\nTheTPMmodulehasbeendefinedbytheTrustedComputingGroup(TCG),anindustryasso-\nciation,toprovidespecificsecurityfunctionstothePersonalComputer(PC)platform.More\nspecifically, the TPM is a root of trust embedded on the PC platform, so that PC+TPM plat-\nform can identify itself and its current configuration and running software [1410]. The TPM\nprovides three specific roots of trust: the Root of Trust for Measurement (RTM), the Root of\nTrustforStorage(RTS),theRootofTrustforReporting(RTR).Besidesthesethreebasicfunc-\ntions, other functionality of TPMs is being used: access to specific cryptographic functions,\nsecurekeystorage,supportforsecurelogin,etc.\nTheTPMisimplementedasaseparatesecuritymodule,muchlikeasecureelementbutwith\na specific bus interface to a PC platform, e.g. through the LPC or I2C bus interface. Its archi-\ntectureatminimumconsistsofanembeddedmicro-controller,severalcryptocoprocessors,\nsecurevolatileandnon-volatilestorageforrootkeysandahighqualitytruerandomnumber\ngenerator. It includes hardware engines for hash functions (SHA1 and SHA256), public key\n(RSAandECC),secretkey(AES)andHMACcalculations.SinceaTPMisaseparatemodule,\nphysicalprotectionandtamperresistanceisessentialforsecurity.Nexttoitsmainscopeof\nintegrityprotection,TPMalsohasapplicationsindiskencryption,digitalrightsmanagement,\netc.\nThe most recent TPM2.0 version broadens the application scope from PC oriented to also\nsupporting networking, embedded, automotive, IoT, and so on. It also provides a more flex-\nible approach in the functionality included. Four types of TPM are identified: the dedicated\nintegrated circuit \u2018discrete element\u2019 TPM provides the highest security level. One step lower\nin protection level is the \u2018integrated TPM\u2019 as an IP module in a larger SoC. The lowest levels\nofprotectionareprovidedbythefirmwareandsoftwareTPM.\nTheadoptionofTPMshasevolveddifferentlyfromwhatwasoriginallythefocusoftheTCG.\nOriginally, the main focus was the support of a secure boot and the associated software\nstack,sothatacompletemeasurementofthesoftwareinstalledcouldbemade.Theproblem\nisthatthecomplexityofthiscompletesoftwarebasegrowstooquickly,makingittoodifficult\nto measure completely all variations in valid configurations. Thus TPMs are less used to\nprotect a complete software stack up to the higher layers of software. Still most new PCs\nnow have TPMs but they are used to protect the encryption keys, avoid firmware roll-back,\nandassistthebootprocessingeneral.\nStarting from the original TPM, the Trusted Computing Group has broadened its scope and\nnow has working groups on many different application, such as cloud, embedded systems,\nIoT,mobile,networkequipment,andsoon,[1417].\nKAHardwareSecurity |October2019 Page590 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n18.4 HARDWARE SUPPORT FOR SOFTWARE SECURITY AT\nARCHITECTURE LEVEL\nAtthesecureplatformlevel,thecompletemodule,i.e.hardwareanditsenclosedembedded\nsoftware, are part of the trusted computing base. One level down on the abstraction layers,\nwemaketheassumptionthatallhardwareistrusted,whilesoftwareisnolongertrusted.In-\ndeed, software vulnerabilities are a major source of security weaknesses (see the Software\nSecurityKnowledgeArea(Chapter14)).Topreventtheexploitationortomitigatetheeffects\nofsoftwarevulnerabilities,alargevarietyofhardwaremodifications\/additionstotheproces-\nsorarchitecturehavebeenproposedinliteratureandhavebeenincludedincommercialpro-\ncessors.Wecallthisabstractionlayerthehardware\/softwareboundary:hardwareformsthe\ntrustboundary,whilesoftwareisnolongertrusted.Thesesecurityadditionstothehardware\ntypicallyhaveacostinextraareaandlossinperformance.\nThemostimportantsecurityobjectivesatthisdesignabstractionlevelaretosupportprotec-\ntion,isolationandattestationforthesoftwarerunningonaprocessorplatform[1418],[1419],\n[1420].\n\u2022 Protection:\"Asetofmechanismsforensuringthatmultipleprocessessharingthepro-\ncessor, memory, or I\/O devices cannot interfere, intentionally or unintentionally, with\none another by reading or writing each others\u2019 data. These mechanisms also isolate\nthe operating system from the user process\" [1418]. In a traditional computer architec-\nture,usuallytheOSkernelispartoftheTrustedComputingBase(TCB),buttherestof\nthesoftwareisnot.\n\u2022 With isolation, a hardware mechanism is added that controls access to pieces of soft-\nware and associated data. Isolation separates two parties: a software module might\nneed protection from the surrounding software is one case. So, a Protected Model Ar-\nchitecture (PMA) provides a hardware guarantee that a piece of software runs unhin-\ndered from unwanted outside influences. The opposite case, if we want to limit the\neffects of possibly tainted software to its environment, it will be sandboxed or be put\nintoa\u2018compartment.\u2019ProtectedModuleArchitecturesareahardwareonlysolution:the\nOSisnotpartoftheTCB.Moredetailsaredescribedinsection18.4.4\n\u2022 Withattestation,thereishardwaresupporttodemonstratetoathirdpartythatthesys-\ntem, e.g. the code installed and\/or running on a processor, is in a particular state. At-\ntestation can be local or remote. Local attestation means that one software module\ncanattestitsstatetoanotheroneonthesamecomputeplatform.Remoteattestation\nmeansthatathirdparty,outsidethecomputeplatformcangetsomeguaranteeabout\nthestateofaprocessor.\nIn the context of general purpose computing, Virtual Machines (VMs) and Hypervisors have\nbeenintroducedtosupportmultipleoperatingsystemsononephysicalprocessor.Thisshar-\ning of resources improves efficiency and reuse. It can however only be realized by a secure\nandefficientsharingofphysicalmemory:virtualmachinesshouldonlybeallowedtousethe\nportions of physical memory assigned to it. The organization and details of virtual memory\nare out of scope of hardware security and part of the Operating Systems & Virtualisation\nKnowledge Area (Chapter 11). The hardware supports protection by providing privileged in-\nstructions,controlandstatusregistersandsometimessupportformultipleparallelthreads.\nInthecontextofembeddedmicro-controllers,withnooperatingsystem,andonlyoneapplica-\nKAHardwareSecurity |October2019 Page591 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntion,thehardwaresupportcouldbelimitedtoonlymachinelevelsupport.Memoryprotection\ncouldbeaddedasanoptionalhardwaremoduletotheprocessor.\nOthermoreadvancedsecurityobjectivestosupportsoftwaresecuritymightinclude:\n\u2022 Sealedstorageistheprocessofwrappingcodeand\/ordatawithcertainconfiguration,\nprocess or status values. Only under the correct configuration (e.g. program counter\nvalue,nonce,secretkey,etc.)canthedatabeunsealed.Dynamicrootoftrustincombi-\nnationwithalatelaunchguaranteesthateveniftheprocessorstartsfromanunknown\nstate,itcanenterafixedknownpieceofcodeandknownstate.Thistypicallyrequires\nspecialinstructionstoenterandexittheprotectedpartition.\n\u2022 Memory protection refers to the protection of data when it travels between the proces-\nsor unit and the on-chip or off-chip memory. It protects against bus snooping or side-\nchannelattacksormoreactivefaultinjectionattacks.\n\u2022 Controlflowintegrityisasecuritymechanismtopreventmalwareattacksfromredirect-\ning the flow of execution of a program. In hardware, the control flow of the program is\ncomparedon-the-flyatruntimewiththeexpectedcontrolflowoftheprogram.\n\u2022 Information flow analysis is a security mechanism to follow the flow of sensitive data\nwhileittravelsthroughthedifferentprocessorcomponents,frommemorytocacheover\nmultiple busses into register files and processing units and back. This is important in\nthecontextofmicro-architecturalandphysicalside-channelattacks.\nIn the next subsections a representative set of hardware approaches to address the above\nsoftwaresecuritychallengesarepresented.Somehardwaretechniquesaddressmultiplese-\ncurityobjectives.Somearelargecomplexapproaches,othersaresimplededicatedhardware\nfeatures.\nAs a side note: a large body of knowledge on software-only approaches is available in liter-\nature. Mostly, they offer a weaker level of security as they are not rooted in a hardware root\noftrust.E.g.forcontrolflowintegrity,software-onlyapproachesmightinstructthesoftware\ncode to check branches or jumps, while hardware support might calculate MACs on the fly\nandcomparethesetostoredassociatedMACs.\n18.4.1 Trusted Execution Environment (TEE)\nTEE was originally an initiative of Global Platform, a consortium of companies, to standard-\nize a part of the processor as a trusted secure part. TEE has since evolved and covers in\ngeneralthehardwaremodificationsmadetoprocessorstoprovideisolationandattestation\ntosoftwareapplications.Thereisalargebodyofknowledgebothfromtheindustrialsideas\nwellasfromtheacademicside.\nTEE is a concept that provides a secure area of the main processor \u201cto provide end-to-end\nsecurity by protecting the execution of authenticated code, confidentiality, authenticity, pri-\nvacy, system integrity and data access rights\u201d [1421]. It is important that the TEE is isolated\nfrom the so-called Rich Execution Environment (REE), which includes the untrusted OS. The\nreasoningbehindthissplitisthatitisimpossibletoguaranteesecureexecutionandtoavoid\nmalware in the normal world due to the complexity of the OS and all other applications run-\nningthere.TherichresourcesareaccessiblefromtheTEE,whiletheoppositeisnotpossible.\nGlobal Platform does not specify the specifics on how these security properties should be\nimplemented.Threemainhardwareoptionsaresuggested.Option1assumesthateverypro-\nKAHardwareSecurity |October2019 Page592 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ncessorcomponentontheICcanbesplitintoatrustedandarichpart,i.e.theprocessorcore,\nthe crypto accelerators, the volatile and non-volatile memory are all split. Option 2 assumes\nthat there is a separate secure co-processor area on the SoC with a well-defined hardware\ninterfacetotherestoftheSoC.Option3assumesadedicatedoff-chipsecureco-processor,\nmuchlikeasecureelement.\nGlobalPlatformdefinesalsoaCommonCriteriabasedprotectionprofile(seesection18.2.2)\nfortheTEE.Itassumesthatthepackageoftheintegratedcircuitisablackbox[1421]andthus\nsecurestorageisassumedbythefactthatthesecureassetremainsinsidetheSoC.Itfollows\nthe procedures of common criteria assurance package EAL2 with some extra features. It\npays extra attention to the evaluation of the random number generator and the concept of\nmonotonicincreasingtime.\n18.4.2 IBM 4758 Secure coprocessor\nAnearlyexample,evenbeforetheappearanceoftheTEEofGlobalPlatformistheIBM4758\nsecureprocessor.Physicalhardwaresecuritywasessentialforthisprocessor:itcontaineda\nboardwithageneralpurposeprocessor,DRAM,separatebatterybacked-DRAM,FlashROM,\ncryptoaccelerator(forDES),arandomnumbergeneratorandmore.Allofthesecomponents\nwereenclosedinaboxwithtamperresistantandtamperevidencemeasures.Itwascertified\ntoFIPS140-1,level4atthattime[1422].\n18.4.3 ARM Trustzone\nARM Trustzone is one well known instantiation of a TEE. It is part of a system of ARM pro-\ncessors integrated into System on a Chips (SoCs) mostly used for smartphones. The TEE\nis the secure part of the processor and it runs a smaller trusted OS. It is isolated from the\nnon-secure world, called the Rich Execution Environment, which runs the untrusted rich OS.\nThemainhardwarefeaturetosupportthissplitistheNon-Secure(NS)bit.TheAXIbustrans-\nactionsareenhancedwithaNSbitsothatitcanblocktheaccessofsecureworldresources\nby non-secure resources. Each AXI transaction comes with this bit set or reset. When the\nprocessor runs in the secure mode, then the transaction comes with the NS bit set to zero,\nwhichgivesitaccesstobothsecureandnon-secureresources.Whentheprocessorrunsin\nnormalmode,itcanonlyaccessresourcesfromthenormalworld.Thisconceptisextended\ntothelevel1andlevel2cache.Thesecachesstoreanextrainformationbittoindicateifthe\ncodecanbeaccessedbyasecureornon-securemaster.Specialproceduresareforeseento\njumpfromsecuretonon-secureandvice-versa.Thisissupportedbyaspecialmonitormode\nwhichexistsinthesecureworld.\nThesplitappliedbyARMTrustzoneishoweverabinarysplit.Applicationsfromdifferentven-\ndorscouldco-existtogetherinthesecureworldandsoifonetrustedcomponentviolatesthe\nsystem\u2019ssecurity,thesecuritycannolongerbeguaranteed.Toaddressthisissue,protected\nmodulearchitecturesareintroduced.\nTrustedExecutionEnvironmentsarealsobeingcreatedinopen-sourcecontext,morespecif-\nicallyinthecontextoftheRISC-Varchitecture.\nKAHardwareSecurity |October2019 Page593 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n18.4.4 Protected Module Architectures and HWSW co-design solutions\nIfmultiplesoftwareapplicationswanttorunonthesameplatformisolatedfromeachother,\nthen hardware needs to isolate them from each other at a more fine granularity. This can\nbe done by so-called protected module architectures. The basic idea is that small software\nmodules can run protected from all other software running on the processor. And because\ntheyaresmall,theirpropertiesandbehaviorcanbeverifiedmorethoroughly.Theprotection\nis provided by extra features added to the hardware in combination with an extremely small\ntrusted software base if needed. In the Flicker project, the software TCB relies on only 250\nlinesofcodesbutrequiresadedicatedTPMchip[1423].Table12ofthereviewworkof[1422],\nprovidesanin-depthcomparisonofseveralgeneralpurposesecureprocessorprojectswith\ntheir hardware and software TCB. The hardware TCB distinguishes between the complete\nmother board as TCB, e.g. for TPM usage, to CPU package only for SGX and other projects.\nThesoftwareTCB variesfromacompletesecureworldas isthecaseforTrustZone toprivi-\nlegedcontainersinthecaseofSGXoratrustedhypervisor,OSorsecuritymonitor.\nEven more advanced are solutions with a zero trusted software base: only the hardware is\ntrusted.ThisisthecasefortheSancusproject[1424].Itimplementsaprogramcounterbased\nmemoryaccesscontrolsystem.Extrahardwareisprovidedtocomparethecurrentprogram\ncounter with stored boundaries of the protected module. Access to data is only possible if\nthe program counter is in the correct range of the code section. Progress of the program in\nthe code section is also controlled by the hardware so that correct entry, progress and exit\nofthemodulecanbeguaranteed.\nIntel\u2019sSoftwareGuardExtension(SGX)arealsoaprotectionmechanismatsmallgranularity.\nSoftwaremodulesofanapplicationareplacedinmemoryenclaves.Enclavesaredefinedin\ntheaddressspaceofaprocess,butaccesstoenclavesisrestricted.Enclavesarecreated,ini-\ntialized,andclearedbypossiblyuntrustedsystemsoftware,butoperatingintheenclavecan\nonlybedonebytheapplicationsoftware.MinimizingtheextrahardwaretosupportSGX,and\nespecially avoiding performance degradation is an important goal. The details of the hard-\nwaremicro-architecturehavenotbeendisclosed:yetitsmostimportantpartsareamemory\nencryption unit, a series of hardware enforced memory access checks and secure memory\nrangeregisters[1422].\n18.4.5 Light-weight and individual solutions\nTheabovelistedsolutionsaremostlysuitedforgeneralpurposecomputing,i.e.forplatforms\non which a complex software stack will run. In literature, more solutions are proposed to\nprovideextremelylightweightsolutionstosupportspecificsecurityrequests.SMARTisone\nearlyexample:itincludesasmallimmutablepieceofbootROM,consideredtherootoftrust,\ntosupportremoteattestation[1425].\nTo protect against specific software attacks, more individual hardware countermeasures\nhave been introduced. One example is a hardware shadow stack: to avoid buffer overflow\nattacks and to protect control flow integrity, return addresses are put on both the stack and\nthe shadow stack. When a function loads a return address, the hardware will compare the\nreturn address of the stack to that of the shadow stack. They should agree for a correct\nreturn.\nAnother example is the protection of jump and return addresses to avoid buffer overflow at-\ntacksandotherabusesofpointers.Asimplebutrestrictiveoptionistouseread-onlymemory,\nwhichfixesthepointer.Anovelrecenttechniqueistheuseofpointerauthentication.Theau-\nKAHardwareSecurity |October2019 Page594 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nthenticationcodereliesoncryptographicprimitives.Achallengeforthesealgorithmsisthat\ntheyshouldcreatetheauthenticationtagwithverylowlatencytofitintothecriticalpathofa\nmicroprocessor. The ARMV8-A architectures uses therefore a dedicated low-latency crypto\nalgorithmQarma[1426].Inthisapproachtheunusedbitsina64-bitpointerareusedtostore\na tag. This tag is calculated based on a key and on the program state, i.e. current address\nandfunction.Thesetagsarecalculatedandverifiedonthefly.\nAddressSpaceLayoutRandomizationorStackcanariesareageneralsoftwaretechnique:its\naim is to make it hard to predict the destination address of the jump. A detailed description\ncanbefoundintheSoftwareSecurityKnowledgeArea(Chapter14).\n18.5 HARDWARE DESIGN FOR CRYPTOGRAPHIC\nALGORITHMS AT RTL LEVEL\nThe hardware features discussed so far are added to general purpose compute platforms,\ni.e. to a programmable micro-processor or micro-controller. General purpose means that a\nplatform is created of which the hardware designer does not know the future applications\nthat will run on it. Flexibility, reflected in the instruction set, is then of importance. A second\nclassofprocessorsaredomain-specificprocessors:theyhavelimitedornoprogrammability\nanddesignedforoneorasmallclassofapplications.\n18.5.1 Design process from RTL to ASIC or FPGA\nWhenadedicatedprocessorisbuiltforoneoraclassofcryptographicalgorithms,thisgives\nalotoffreedomtothehardwaredesigner.Typically,thehardwaredesignerwill,startingfrom\nthe cryptographic algorithm description, come up with hardware architectures at the Regis-\nter Transfer Level (RTL) taking into account a set of constraints. Area is measured by gate\ncountatRTLlevel.Throughputismeasuredbybits\/sec.Powerconsumptionisimportantfor\ncoolingpurposesandmeasuredinWatt.Energy,measuredinJoule,isimportantforbattery\noperateddevices.Itisoftenexpressedintheamountofoperationsoramountofbitsthatcan\nbeprocessedperunitenergy.Hencethedesigngoalistomaximizetheoperations\/Jouleor\nbits\/Joule. The resistance to side channel attacks is measured by the number of measure-\nmentsorsamplesrequiredtodisclosethekeyorothersensitivematerial.Flexibilityandpro-\ngrammability are difficult to measure and are typically imposed by the application or class\nof applications that need to be supported: will the hardware support only one or a few algo-\nrithms,encryptionand\/ordecryption,modesofoperation,initialization,requirementsforkey\nstorage,andsoon.\nA hardware architecture is typically described in a Hardware Description Language such\nas Verilog of VHDL. Starting from this description the two most important hardware plat-\nforms available to a hardware designer are ASIC and FPGA. An Application Specific Inte-\ngrated Circuit (ASIC) is a dedicated circuit fabricated in silicon. Once fabricated (baked) it\ncannot be modified anymore. A Field Programmable Gate Array (FPGA) is a special type of\nprogrammable device: it consists of regular arrays of 1-bit cells, that can programmed by\nmeansofabitstream.Thisspecialbitstreamprogramseachcelltoaspecificfunction,e.g.a\nonebitaddition,aregister,amultiplexer,andsoon.Bychangingthebit-streamthefunction-\nalityoftheFPGAchanges.FromtheviewpointoftheRegisterTransferLevel(RTL)theactual\ndesign process for either FPGA or ASIC doesn\u2019t differ that much. Similar design options are\navailable:thedesignercandecidetogoforserialorparallelarchitectures,makinguseofmul-\nKAHardwareSecurity |October2019 Page595 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntipledesigntrickstomatchthedesignwiththerequirements.Themostwell-knowntricksare\nto use pipelining to increase throughput, or unrolling to reduce latency, time multiplexing to\nreducearea,etc.\nFrom implementation viewpoint, at this register transfer abstraction level, a large body of\nknowledgeandalargesetofElectronicDesignAutomation(EDA)toolsexisttomapanappli-\ncationontoaFPGAorASICplatform[1409].Implementationresultsshouldbecomparednot\nonly on the number of operations, but also on memory requirements (program memory and\ndata memory), throughput and latency requirements, energy and power requirements, band-\nwidthrequirementsandtheeasewithwhichside-channelandfaultattackcountermeasures\ncanbeadded.Pleasenotethatthislargebodyofknowledgeexistsforimplementationsthat\nfocusonefficiency.However,whencombiningefficiencywithsecurityrequirements,suchas\nconstant time execution or other countermeasures, there is a huge lack of supporting EDA\ntools(seesection18.8).\n18.5.2 Cryptographic algorithms at RTL level\nCryptographicimplementationsaresubdividedinseveralcategories,enumeratedbelow.The\ndetailsofthecryptographicalgorithmsthemselvesarediscussedintheCryptographyKnowl-\nedge Area (Chapter 10). Here only remarks related to the RTL implementation are made. In\nthissectiononlynotesspecifictothehardwareimplementationsaremade.\n\u2022 Secretkeyalgorithms:bothblockciphersandstreamciphersresultusuallyincompact\nandfastimplementations.Feistelciphersarechosenforveryareaconstraineddesigns\nastheencryptionanddecryptionhardwareisthesame.Thisise.g.notthecaseforthe\nAESalgorithmforwhichencryptionanddecryptionrequiredifferentunits.\n\u2022 Secret key: light-weight algorithms. For embedded devices, over the years, many light-\nweight algorithms have been developed and implemented, e.g. Present, Prince, Rect-\nangle, Simon or Speck cipher. Focus in these cases is mostly on area cost. However,\nlately light-weight has been extended to include also low power, low energy and es-\npeciallylow-latency.Latencyisdefinedasthetimedifferencebetweeninputcleartext\nandcorrespondingencryptedoutputorMAC.Havingashortlatencyisimportantinreal-\ntimecontrolsystems,automotive,industrialIoTbutalsoinmemoryencryption,control\nflowintegrityapplicationsetc.MoreknowledgewillfollowfromtherecentNISTcallon\nlight-weightcrypto[1427].\n\u2022 Secret key: block ciphers by themselves are not directly applicable in security appli-\ncation. They need to be combined with modes of operation to provide confidentiality\nor integrity, etc. (see the Cryptography Knowledge Area (Chapter 10)). In this context\nefficient implementations of authenticated encryption schemes are required: this is\nthe topic of the CAESAR competition [1428]. From an implementation viewpoint, the\nsequential nature of the authenticated encryption schemes makes it very difficult to\nobtainhighthroughputsaspipeliningcannotdirectlybeapplied.\n\u2022 Hashalgorithmsrequiretypicallyamuchlargerareacomparedtosecretkeyalgorithms.\nEspecially the SHA3 algorithm and its different versions are large in area and slow in\nexecution.Therefore,light-weighthashalgorithmsareatopicofactiveresearch.\n\u2022 Oneimportanthardwareapplicationofhashfunctionsistheminingofcryptocurrencies,\nsuchasBitcoin,Etherium,Litecoinandothers,basedonSHA2,SHA256,SHA3,etc.To\nobtaintherequiredhighthroughputs,massiveparallelismandpipeliningisapplied.This\nKAHardwareSecurity |October2019 Page596 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nis however limited as hash algorithms are recursive algorithms and thus there is an\nupper bound on the amount of pipelining that can be applied [1429]. Cryptocurrencies\nform part of the more general technology of distributed ledgers, which is discussed in\ntheDistributedSystemsSecurityKnowledgeArea(Chapter12).\n\u2022 Thecomputationalcomplexityofpublickeyalgorithmsistypically2or3ordersofmag-\nnitudehigherthansecretkeyandthusitsimplementation2to3ordersslowerorlarger.\nEspecially for RSA and Elliptic curve implementations, a large body of knowledge is\navailable,rangingfromcompact[1430]tofast,forclassicandnewercurves[1431].\n\u2022 Algorithmsresistanttoattacksofquantumcomputers,akapost-quantumsecurealgo-\nrithms, are the next generation algorithms requiring implementation in existing CMOS\nASIC and FPGA technology. Computational bottle-necks are the large multiplier struc-\ntures, with\/without the Number Theoretic Transform, the large memory requirements\nand the requirements on random numbers that follow specific distributions. Currently,\nNISTisholdingacompetitiononpost-quantumcryptography[1432].Thusitisexpected\nthatafterthealgorithmsaredecided,implementationsinhardwarewillfollow.\n\u2022 Currently,themostdemandingimplementationsforcryptographicalgorithmsarethose\nused in homomorphic encryption schemes: the computational complexity, the size of\nthemultipliersandespeciallythelargememoryrequirementsarethechallengestoad-\ndress[1433].\n18.6 SIDE-CHANNEL ATTACKS, FAULT ATTACKS AND\nCOUNTERMEASURES\nThis section first provides an overview of physical attacks on implementations of crypto-\ngraphicalgorithms.Thesecondpartdiscussesawiderangeofcountermeasuresandsome\nopen research problems. Physical attacks, mostly side-channel and fault attacks, were orig-\ninally of great concern to the developers of small devices that are in the hands of attackers,\nespecially smart-cards and pay-TV systems. The importance of these attacks and counter-\nmeasures is growing as more electronic devices are easily accessible in the context of the\nIoT.\n18.6.1 Attacks\nAtthecurrentstateofknowledge,cryptographicalgorithmshavebecomeverysecureagainst\nmathematical and cryptanalytical attacks: this is certainly the case for algorithms that are\nstandardized or that have received an extensive review in the open research literature. Cur-\nrently, the weak link is mostly the implementation of algorithms in hardware and software.\nInformationleaksfromthehardwareimplementationthroughside-channelandfaultattacks.\nAdistinctionismadebetweenpassiveorside-channelattacksversusactiveorfaultattacks.\nA second distinction can be made based on the distance of the attacker to the device: at-\ntacks can occur remotely, close to the device still non-invasive to actual invasive attacks.\nMoredetailsonseveralclassesofattacksarebelow.\nPassive Side Channel Attacks General side-channel attacks are passive observations of a\ncompute platform. Through data dependent variations of execution time, power consump-\ntionorelectro-magneticradiationofthedevice,theattackercandeduceinformationofsecret\ninternals. Variations of execution time, power consumption or electro-magnetic radiations\nKAHardwareSecurity |October2019 Page597 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\naretypicallypickedupincloseproximityofthedevice,whileitisoperatedundernormalcon-\nditions.Itisimportanttonotethatthenormaloperationofthedeviceisnotdisturbed.Thus\nthedeviceisnotawarethatitisbeingattacked,whichmakesthisattackquitepowerful[997].\nSidechannelattacksbasedonvariationsonpowerconsumptionhavebeenextensivelystud-\nied.Theyareperformedclosetothedevicewithaccesstothepowersupplyorthepowerpins.\nOnemakesadistinctionbetweenSimplePowerAnalysis(SPA),DifferentialandHigherOrder\nPower Analysis (DPA), and template attacks. In SPA, the idea is to first study the target for\nfeatures that depend on the key. E.g. a typical target in timing and power attacks are if-then-\nelsebranchesthataredependentonkeybits.Inpublickeyalgorithmimplementations,such\nasRSAorECC,thealgorithmrunssequentiallythroughallkeybits.Whentheif-branchtakes\nmore or less computation time than the else-branch this can be observed from outside the\nchip. SPA attacks are not limited to public key algorithms, they have also been applied to\nsecretkeyalgorithms,oralgorithmstogenerateprimenumbers(incasetheyneedtoremain\nsecret).Sowithknowledgeoftheinternaloperationofthedevice,SPAonlyrequirestocollect\noneorafewtracesforanalysis.\nWith DPA, the attacker collects multiple traces, ranging from a few tens for unprotected im-\nplementations to millions in case of protected hardware implementations. In this situation,\nthe attacker exploits the fact that the instantaneous power consumption depends on the\ndata that is processed. The same operation, depending on the same unknown sub-key, will\nresult in different power consumption profiles if the data is different. The attacker will also\nbuilt a statistical model of the device to estimate the power consumption as a function of\nthedataandthedifferentvaluesofthesubkey.Statisticalanalysisonthesetracesbasedon\ncorrelation analysis, mutual information and other statistical tests are applied to correlate\nthemeasuredvaluestothestatisticalmodel.\nSide channel attacks based on Electro-Magnetic radiations have been recognized early-on\nin the context of military communication and radio equipment. As a reaction, NATO and the\ngovernmentsofmanycountrieshaveissuedTEMPEST[1434].Itconsistsofspecificationson\ntheprotectionofequipmentagainstunintentionalelectro-magneticradiationbutalsoagainst\nleakage of information through vibrations or sound. Electro-Magnetic radiation attacks can\nbemountedfromadistance,asexplainedabove,butalsoatcloseproximitytotheintegrated\ncircuit. Electro-Magnetic probing on top of an integrated circuit can release very localized\ninformationofspecificpartsofanICbyusinga2Dstepperandfineelectro-magneticprobers.\nThus electro-magnetic evaluation has the possibility to provide more fine grained leakage\ninformationcomparedtopowermeasurements.\nTimingattacksareanothersubclassofside-channelattacks[1220].Whentheexecutiontime\nof a cryptographic calculation or a program handling sensitive data, varies as a function of\nthesensitivedata,thenthistimedifferencecanbepickedupbytheattacker.Atimingattack\ncanbeassimpleasakeydependentdifferentexecutiontimeofanif-branchversusanelse-\nbranch in a finite state machine. Cache attacks, which abuse the time difference between a\ncachehitandacachemissareanimportantclassoftimingattacks[1435],[1436],.\nWith a template attack, the attacker will first create a copy or template of the target device\n[1437].Thistemplateisusedtostudythebehaviorofthedeviceforalloralargesetofinputs\nandsecret datavalues.One orafewsamples ofthetarget device are thencomparedtothe\ntemplates in the database to deduce secret information from the device. Template attacks\naretypicallyusedwhentheoriginaldevicehascountermeasuresagainstmultipleexecutions.\nE.g.itmighthaveaninternalcountertologthenumberoffailedattempts.Templatescanbe\nmade based on timing, power or electro-magnetic information. As machine learning and AI\nKAHardwareSecurity |October2019 Page598 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntechniquesbecomemorepowerful,sowilltheattackpossibilitywithtemplateattacks.\nMicro-architectural Side-channels Processor architectures are very vulnerable to timing at-\ntacks.Theproblemofinformationleaksandthedifficultyofconfinementbetweenprograms\nwas already identified early on in [1438]. Later timing variations in cache hits and misses\nbecame an important class of timing attacks [1439]. Recently gaining a lot of attention are\nthe micro-architectural side-channel attacks, such as Spectre, Meltdown, Foreshadow. They\nare also based on the observation of timing differences [1411][1439]. The strength of the\nattacks sits in the fact that they can be mounted remotely from software. Modern proces-\nsors include multiple optimization techniques to boost performance not only with caches,\nbutalsospeculativeexecution,out-of-orderexecution,branchpredictors,etc.Whenmultiple\nprocessesrunonthesamehardwareplatform,virtualizationandothersoftwaretechniques\nisolates the data of the different parties in separate memory locations. Yet, through the out-\nof-orderexecutionorspeculativeexecution(ormanyothervariants)thehardwareofthepro-\ncessor will access memory locations not intended for the process by means of so-called\ntransientinstructions.Theseinstructionsareexecutedbutnevercommitted.Theyhavehow-\nevertouchedmemorylocations,whichmightcreatesidechanneleffects,suchasvariations\ninaccesstime,andthusleakinformation.\nActive fault attacks Fault attacks are active manipulations of hardware compute platforms\n[1440]. The result is that the computation itself or the program control flow is disturbed.\nFaulty or no outputs are released. Even if no output is released or the device resets itself,\nthis decision might leak sensitive information. One famous example is published in [1441]:\nit describes an RSA signature implementation which makes use of the Chinese Remainder\nTheorem (CRT). With one faulty and one correct result signature, and some simple mathe-\nmaticalcalculations,thesecretsigningkeycanbederived.Physicalfault-attackscouldbea\nsimple clock glitching, power glitching, heating up or cooling down a device. These require\ncloseproximitytothedevicebutarenon-invasive.\nWith scaling of memories, more attack surfaces appear. A very specific attack on DRAM\nmemories, is the RowHammer attack [1006, 1442]. By repeating reading specific locations\nin DRAM memory, neighboring locations will loose their values. Thus by hammering certain\nlocations,bitflipswilloccurinnearbylocations.\nWithmoreexpensiveequipment,andwithopeningthelidoftheintegratedcircuitoretching\nthe silicon down, even more detailed information of the circuit can be obtained. Equipment\nthathasbeenusedincludeopticalfault[1443],laserattacks[1444],FocusedIonBeam(FIB),\naScanningElectronMicroscope(SEM)andother.Thelatteraretypicallyequipmentthathas\nbeen designed for chip reliability and failure analysis. This equipment can also be used or\nmisusedforreverseengineering.\n18.6.2 Countermeasures\nThere are no generic countermeasures that resist all classes of side-channel attacks. De-\npendingonthethreatmodel(remote\/localaccess,passive\/active,etc.)andtheassumptions\nmadeonthetrustedcomputingbase(i.e.whatisandwhatisnotincludedintherootoftrust),\ncountermeasures have been proposed at several levels of abstraction. The most important\ncategoriesaresummarizedbelow.\nTo resist timing attacks, the first objective is to provide hardware that executes the appli-\ncationorprograminconstanttimeindependentofsecretinputs,keysandinternalstate.De-\npendingonthetimegranularityofthemeasurementequipmentoftheattacker,constanttime\nKAHardwareSecurity |October2019 Page599 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ncountermeasuresalsoneedtobemorefinegrained.Attheprocessorarchitecturelevel,con-\nstant time means a constant number of instructions. At the RTL level, constant time means\naconstantnumberofclockcycles.Atlogicandcircuitlevel,constanttimemeansaconstant\nlogic depth or critical path independent of the input data. At instruction level, constant time\ncan be obtained by balancing execution paths and adding dummy instructions. Sharing of\nresources, e.g. through caches, make constant time implementations extremely difficult to\nobtain.\nAt RTL level, we need to make sure that all instructions run in the same number of clock\ncycles. dummy operations or dummy gates, depending on the granularity level. Providing\nconstant time RTL level and gate level descriptions is however a challenge as design tools,\nboth hardware and software compilers, will for performance reasons synthesize away the\ndummyoperationsorlogicwhichwereaddedtobalancethecomputations.\nAs many side-channel attacks rely on a large number of observations or samples, randomi-\nsation is a popular countermeasure. It is used to protect against power, electro-magnetic\nand timing side-channel attacks. Randomisation is a technique that can be applied at algo-\nrithm level: it is especially popular for public key algorithms, which apply techniques such\nas scalar blinding, or message blinding [1445]. Randomisation applied at register transfer\nand gate level is called masking. Masking schemes randomise intermediate values in the\ncalculations so that their power consumption can no longer be linked with the internal se-\ncrets.Alargesetofpapersongatelevelmaskingschemesisavailable,rangingfromsimple\nBoolean masking to threshold implementations that are provable secure under certain leak-\nage models [1446]. Randomisation has been effective in practice especially as a public key\nimplementation protection measure. The protection of secret key algorithms by masking is\nmorechallenging.Somemaskingschemesrequireahugeamountofrandomnumbers,oth-\ners assume leakage models that do not always correspond to reality. In this context, novel\ncryptographictechniquessummarizedunderthelabelleakageresilientcryptography,arede-\nvelopedthatareinherentlyresistantagainstside-channelattacks[1447,1448].Atthisstage,\nthereisstillagapbetweentheoryandpractice.\nHidingisanothermajorclassofcountermeasures.Theideaistoreducethesignaltonoisera-\ntiobyreducingthesignalstrength.ShieldinginthecontextofTEMPESTisonesuchexample.\nSimilarly, at gate level, reducing the power signature or electro-magnetic signature of stan-\ndard cells or logic modules, will increase the resistance against power or electro-magnetic\nattacks. Simple techniques such as using a jittery or drifting clock, and large decoupling ca-\npacitanceswillalsoreducethesignaltonoiseratio.\nSometimes solutions for leaking at one abstraction level, e.g. power side channels, can be\naddressed at a different abstraction level. Therefore, if there is a risk that an encryption key\nleaks from an embedded device, a cryptographic protocol that changes the key at a suffi-\ncientlyhighfrequency,willalsoavoidside-channelinformationleakage.\nGeneral purpose processors such as CPUs, GPUs, and micro-controllers can not be modi-\nfied once fabricated. Thus protecting against micro-architectural attacks after fabrication\nby means of software patches and updates is extremely difficult and mostly at the cost of\nreduced performance [1411]. Micro-code updates are also a form of software, i.e. firmware\nupdate and not a hardware update. The main difference is that the translation from instruc-\ntionstomicro-codeisacompanysecret,andthusfortheuseritlookslikeahardwareupdate.\nProvidinggenericsolutionstoprogrammablehardwareisachallengeasitisunknownbefore-\nhandwhichapplicationwillrun.Solutionstothisproblemwillbeacombinedeffortbetween\nhardwareandsoftwaretechniques.\nKAHardwareSecurity |October2019 Page600 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nProtectionagainstfaultattacksaremadeattheregistertransferlevel,aswellasatthecircuit\nlevel.AtRTL,protectionagainsfaultattacksismostlybasedonredundancyeitherinspaceor\nintimeandbyaddingchecksbasedoncoding,suchasparitychecks.Thepriceisexpensive\nascalculationsareperformedmultipletimes.Oneproblemwithaddingredundancyisthatit\nincreasestheattacksurfaceofside-channels.Indeed,duetotheredundantcalculations,the\nattackerhasmoretracesavailabletoperformtime,powerorelectro-magneticside-channel\nattacks[1445].Atcircuitlevel,monitorsontheclockorpowersupply,mightdetectdeviations\nfromnormaloperationsandraiseanalarm.\nManytypeofcircuitlevelsensorsareaddedtointegratedcircuits.Examplesarelightsensors\nthat detect that a lid of a package has been opened. Mesh metal sensors which are laid-out\nin top level metal layers can detect probing attacks. Temperature sensors detect heating or\ncoolingoftheintegratedcircuit.Antennasensorstodetectelectro-magneticprobescloseto\nthesurfacehavebeendeveloped:thesesensorsmeasureachangeinelectro-magneticfields.\nAndsensorsthatdetectmanipulationofthepowersupplyorclockcanbeaddedtothedevice.\nNote that adding sensors to detect active manipulation can again leak extra information to\nthesidechannelattacker.\nJointcountermeasuresagainstside-channelandfaultattacksarechallengingandanactive\nareaofresearch.\n18.7 ENTROPY GENERATING BUILDING BLOCKS: RANDOM\nNUMBERS, PHYSICALLY UNCLONABLE FUNCTIONS\nSourcesofentropyareessentialforsecurityandprivacyprotocols.Inthissectiontwoimpor-\ntantsourcesofentropyrelatedtosilicontechnologyarediscussed:randomnumbergenera-\ntorsandphysicallyunclonablefunctions.\n18.7.1 Random number generation\nSecurity and privacy rely on strong cryptographic algorithms and protocols. A source of en-\ntropy is essential in these protocols: random numbers are used to generate session keys,\nnonces, initialization vectors, to introduce freshness, etc. Random numbers are also used\nto create masks in masking countermeasures, random shares in multi party computation,\nzero-knowledge proofs, etc. In this section the focus is on cryptographically secure random\nnumbers as used in security applications. Random numbers are also used outside cryptog-\nraphy,e.g.ingaming,lotteryapplications,stochasticsimulations,etc.\nIngeneral,randomnumbersaresubdividedintwomajorclasses:thePseudoRandomNum-\nber Generator (PRNG) also called Deterministic Random Bit Generator (DRBG) and the True\nRandomNumberGenerator(TRNG)orNon-DeterministicRandomBitGenerator(NRBG).The\ndesign, properties and testing of random numbers is described in detail by important stan-\ndards,issuedintheUSbyNIST.NISThasissuedtheNIST800-90Afordeterministicrandom\nnumber generators, the NIST800-90B for entropy sources, and NIST800-90C for random bit\ngeneration constructions [1449], [1450] [1451] 1. In Germany and by extension in most of\nEurope, the German BSI has issued two important standards: the AIS-20 for functionality\nclasses and evaluation criteria for deterministic random number generators and the AIS-31\nforphysicalrandomnumbergenerators[1452,1453,1454].\n1NIST800-90Cdoesnotexistasastandardyet.\nKAHardwareSecurity |October2019 Page601 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nAn ideal RNG should generate all numbers with equal probability. Secondly, these numbers\nshouldbeindependentfrompreviousornextnumbersgeneratedbytheRNG,calledforward\nand backward secrecy. The probabilities are verified with statistical tests. Each standard in-\ncludesalargesetofstatisticaltestsaimedatfindingstatisticalweaknesses.Notbeingable\nto predict future values or derive previous values is important not only in many security ap-\nplications, e.g. when this is used for key generation, but also in many gaming and lottery\napplications.\nPseudo-random number generators are deterministic algorithms that generate a sequence\nof bits or numbers that look random but are generated by a deterministic process. Since a\nPRNG is a deterministic process, when it starts with the same initial value, then the same\nsequence of numbers will be generated. Therefore it is essential that PRNG starts with a\ndifferentstart-upvalueeachtimethePRNGisinitiated.Thisinitialseedcaneitherbegener-\nated by a slow true random number generated or at minimum by a non-repeating value, e.g.\nasprovidedbyamonotonicincreasingcounter.APRNGiscalledcryptographicallysecureif\nthe attacker, who learns part of the sequence, is not able to compute any previous or future\noutputs.CryptographicallysecurePRNGsrelyoncryptographicalgorithmstoguaranteethis\nforward and backward secrecy. Forward secrecy requires on top a regular reseeding to in-\ntroduce new freshness into the generator. Hybrid RNG have an additional non-deterministic\ninputtothePRNG.\nPRNGs provide conditional security based on the computational complexity of the underly-\ning cryptographic algorithms. See the Cryptography Knowledge Area (Chapter 10) for more\ndetails. In contrast, ideal true random number generators provide unconditional security as\nthey are based on unpredictable physical phenomena. Thus their security is guaranteed in-\ndependentofprogressinmathematicsandcryptanalysis.\nThecoreofatruerandomnumbergeneratorconsistsofanentropysource,whichisaphys-\nical phenomena with a random behavior. In electronic circuits, noise or entropy sources are\nusually based on thermal noise, jitter and metastability. These noise sources are never per-\nfect: the bits they generate might show bias or correlation or other variations. Hence they\ndon\u2019t have full entropy. Therefore, they are typically followed by entropy extractors or con-\nditioners. These building blocks improve the entropy per bit of output. But as the entropy\nextractor are deterministic processes, they cannot increase the total entropy. So the output\nlengthwillbeshorterthantheinputlength.\nDue to environmental conditions, e.g. due to temperature or voltage variations, the quality\nof the generated numbers might vary over time. Therefore, the standards describe specific\ntests that should be applied at the start and continuously during the process of generating\nnumbers.Onecandistinguishthreemaincategoriesoftests.Thefirstoneisthetotalfailure\ntest,appliedatthesourceofentropy.Thesecondonesareonlinehealthteststomonitorthe\nquality of the entropy extractors. The third ones are tests for the post-processed bits. The\nrequirements for these tests are well described in the different standards and specialized\ntextbooks[1455].\nThe challenge in designing TRNGs is first to provide a clear and convincing proof of the en-\ntropy source, second the design of online tests which at the same are compact and can de-\ntect a wide range of defects [1456]. The topic of attacks, countermeasures and sensors for\nTRNGs,especiallyinthecontextofIoTandembeddeddevices,isanactiveresearchtopic.\nKAHardwareSecurity |October2019 Page602 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n18.7.2 Physically Unclonable Functions\nFromahardwareperspective,PhysicallyUnclonableFunctions(PUFs),arecircuitsandtech-\nniques to derive unique features from silicon circuits, similar to human biometrics [1457].\nThe manufacturing of silicon circuits results in unique process variations which cannot be\nphysically cloned. The basic idea of PUFs is that these unique manufacturing features are\nmagnifiedanddigitizedsothattheycanbeusedinsecurityapplicationssimilartotheuseof\nfingerprintsorotherbiometrics.Processandphysicalvariationssuchasdopingfluctuations,\nline or edge widths of interconnect wires, result in variations of threshold voltages, transis-\ntordimensions,capacitances,etc.Thuscircuitsarecreatedthataresensitivetoandamplify\nthesevariations.\nThemajorsecurityapplicationforPUFsistoderiveuniquedevicespecifickeys,e.g.forusage\nin an IoT device or smart card. Traditionally, this storage of device unique keys is done in\nnon-volatilememory,asthekeyhastoremaininthechipevenwhenthepoweristurned-off.\nNon-volatilememoryrequireshoweverextrafabricationsteps,whichmakes chipswithnon-\nvolatilememorymoreexpensethanregularstandardCMOSchips.ThusPUFsarepromised\nas cheap alternative for secure non-volatile memory, because the unique silicon fingerprint\nis available without the extra processing steps. Indeed, each time the key is needed, it can\nbe read from the post-processed PUF and directly used in security protocols. They can also\nreplacefuses,whicharelargeandtheirstateisrelativelyeasytodetectunderamicroscope.\nThesecondsecurityapplicationistousePUFsinidentificationapplications,e.g.foraccess\ncontrolortrackingofgoods.TheinputtoaPUFiscalledachallenge,theoutputtheresponse.\nTheidealPUFhasanexponentialnumberofuniquechallengeresponsepairs,exponentialin\nthe number of circuit elements. The uniqueness of PUFs is measured by the inter-distance\nbetween different PUFs seeing the same challenge. The ideal PUF has stable responses: it\nreplies with the same response, i.e. there is no noise in the responses. Moreover, PUF re-\nsponsesshouldbeunpredictableandphysicallyunclonable.\nThe ideal PUF unfortunately does not exist. In literature, two main classes of PUFs are de-\nfined,characterizedbythenumberofchallenge-responsepairstheycangenerate.So-called\nweakPUFsarecircuitswithafinitenumberofelements,witheachelementprovidingahigh\namount of entropy. The number of possible challenge-response pairs grows typically linear\nwiththeareaoftheintegratedcircuit.HencetheyarecalledweakPUFs.Themostwellknown\nexampleistheSRAMPUF[1458].ThesePUFsaretypicallyusedforkeygeneration.Theraw\nPUF output material is not directly usable for key generation as the PUF responses are af-\nfected by noise. Indeed, subsequent readings of the same PUF might result in slightly vary-\ning noisy responses, typically up to 20%. Thus after the entropy extraction follows secure\nsketch (similar to error correction) circuits to eliminate the noise and compress the entropy\nto generate a full entropy key [1459]. The challenge for the PUF designer is to come up with\nprocessvariationsandcircuitsthatcanbeusedaskeymaterial,butwhicharenotsensitive\nto transient noise. A second challenge is to keep all the post-processing modules compact\nsothatthekey-generationPUFcanbeincludedinembeddedIoTdevices.\nThe second class are the so-called strong PUFs. In this case, the number of challenge-\nresponse pairs grows large, ideally exponential, with the silicon area. The most well-known\nexampleisthearbiterPUF[1460].Asmallnumberofsiliconelementsarecombinedtogether,\ne.g. to create a chain of multiplexers or comparators, so that simple combinations of the el-\nements create the large challenge-response space. Also in this case, the effects of noise in\nthecircuitsneedstobetakenintoaccount.StrongPUFsarepromisedtobeusefulinauthen-\ntication applications, e.g. for access control. Each time a challenge is applied to the PUF, a\nKAHardwareSecurity |October2019 Page603 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nresponse unique to the chip will be sent. The verifier will accept the response if it can be\nuniquely tied to the prover. This requires that the PUF responses are registered in a form of\nadatabasebeforehandduringanenrollmentphase.\nTheproblemwithstrongPUFsisthatthereisastrongcorrelationbetweendifferentchallenge-\nresponsepairsofmostcircuitsproposedinliterature.Henceallofthesecircuitsarebroken\nwith machine learning techniques [1461] and can not be used for authentication purposes.\nThe fundamental problem is that very basic, mostly linear operations are used to combine\nPUF elements, which makes them easy targets for machine learning attacks. Ideally, these\nshouldbecryptographicorothercomputationallyhardoperationsresistanttomachinelearn-\ning:unfortunatelythesecannottoleratenoise.Light-weightPUFbasedsecurityprotocolsare\nanactiveareaofresearch.\n18.8 HARDWARE DESIGN PROCESS\nIn this section, several hardware security topics are described which are directly related to\nthe lower design abstraction layers. One is the trust in the hardware design process itself.\nDirectly related to this, is the problem of Trojan circuits. Also part of the hardware design\nprocessarecircuitleveltechniquesforcamouflaging,logiclocking,etc.\n18.8.1 Design and fabrication of silicon integrated circuits\nIt is important to note that the hardware design process itself also needs to be trusted. Be-\ncause of its design complexity, design at each abstraction layer relies on Electronic Design\nAutomation(EDA)tools.Thedesign,fabrication,packagingandtestofsiliconintegratedcir-\ncuits is an international engagement: silicon foundries are mostly located in Asia. Silicon\ndesign tools are most developed in the US, and silicon testing and packaging usually occur\nallovertheworld.Forchipsthatend-upincriticalinfrastructure,suchastelecommunication,\nmilitary,aviation,trustandverificationofthecompletedesigncycleisessential.\nSince silicon foundries and mask making are extremely expensive, very few countries and\ncompaniescanstillafforditandahugeconsolidationhasandistakingplaceintheindustry.\nFor critical infrastructure, governments demand more tools and techniques to increase the\ntrustworthiness of this international design process. On this topic, large research projects\naredefinedtocomeupwithmethodsandtoolstoincreasethetrustworthinessofthedesign\nprocessandespeciallytoassesstheriskofTrojaninsertionsduringthedesignprocess.\n18.8.2 Trojan circuits\nTrojancircuitsarelogicorgatesaddedtolargeintegratedcircuits.Astheyarenotpartofthe\nspecifiedfunctionality,theyaredifficulttodetect.Theyrelyonthefactthattheyareextremely\nsmall in comparison with the large size of integrated circuits and SoCs. Trojan circuits are\nclassified according to three main criteria [1462, 1463]. The first one is the physical charac-\nteristics of the Trojan, i.e. how is the Trojan inserted into the circuit. E.g. does it requires\nlogicmodificationsoronlylayoutmodifications.Thesecondoneistheactivationcharacter-\nistic:willtheTrojanbeturnedonbyaninternalorexternalevent,etc.Thethirdcharacteristic\nclassifies the type of action taken by the Trojan, e.g. will it leak information or will it destroy\nfunctionality,etc.Theknowledgeareaonthistopicissummarizedin[1462,1463].\nKAHardwareSecurity |October2019 Page604 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n18.8.3 Circuit level techniques\nToavoidvisualinspection,circuitlevelcamouflagingtechniquesareintroduced[1464].These\narestandardcellsorothermodulesthatvisuallylookthesame,ortheylookcamouflagedby\nrandomextramaterial.Thisisdonetoavoidvisualinspectionandreverseengineeringbased\nonvisualinspection.\nAnother techniques to avoid loss of intellectual property is logic locking [1465]. With this\ntechnique,extragatesareaddedtoacircuitwithasecretinput.Onlywhenthecorrectkeyis\nappliedtothesecretgates,willthecircuitperformthecorrectfunctionality.Thisisanactive\nresearch topic with logic locking schemes being proposed and attacked, with SAT solvers\nbeingaveryusefultoolinattackingthecircuits.\n18.8.4 Board Level Security\nIntegratedcircuitsareplacedtogetheronPrinterCircuitBoards(PCBs).Manyoftheattacks\nand countermeasures mentioned before for integrated circuits, can be repeated for PCBs\nalbeitatadifferentscale.Whileintegratedcircuitsprovidesomelevelofprotectionbecause\nthey are encapsulated in packages and use much smaller CMOS technologies, PCB\u2019s are\nless complex and somewhat easier to access. Therefore, for PCB\u2019s special coatings, and\nmechanicaltamperevidentandtamperresistantprotectionmechanismscouldbeprovided.\nTherehavebeensomeconcernsthatTrojancircuitscouldalsobeincludedattheboardlevel.\n18.8.5 Time\nTheconceptoftimeandtheconceptofsequenceofeventsareessentialinsecurityprotocols.\nTheTCGidentifiesthreetypesofsequencing:amonotoniccounter,atickcounterandactual\ntrusted time [1410]. A monotonic counter always increases, but the wall clock time between\ntwoincrementsisunknown.Thetickcounterincreaseswithasetfrequency.Itonlyincreases\nwhen the power is on. At power-off the tick counter will reset. Therefore the tick counter is\nlinkedwithanonceandmethodsareforeseentolinkthiswitharealwallclocktime.Trusted\ntime is the most secure. It makes sure that there is a link between the tick counter and the\nrealwallclocktime.Fromahardwareviewpointitwillrequirenon-volatilememory,counters,\ncrystals, continuous power, and an on chip clock generator. The connection to a real wall\nclockwillrequiresynchronizationandanactualcommunicationchannel.\nTheimportanceoftimeisplacedinawidercontextintheDistributedSystemsSecurityKnowl-\nedgeArea(Chapter12).\n18.9 CONCLUSION\nHardware security is a very broad topic, covering many different topics. In this chapter, a\nclassification is made based on the different design abstraction layers. At each abstraction\nlayer,thethreatmodel,rootoftrustandsecuritygoalsareidentified.\nBecause ofthe growthof IoT,edge and cloudcomputing, theimportanceof hardware secu-\nrity is growing. Yet, in many cases hardware security is in conflict with other performance\noptimisations, such as low power or limited battery operated conditions. In these circum-\nstances,performanceoptimizationisthemostimportantdesigntask.Yetitisalsothemost\nimportantcauseofinformationleakage.Thisisthecaseatallabstractionlayers:instruction\nlevel,architecturelevelandlogicandcircuitlevel.\nKAHardwareSecurity |October2019 Page605 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nAnother trend is that hardware is becoming more \u2018soft\u2019. This is an important trend in pro-\ncessor architecture, where FPGA functionality is added to processor architectures. The fun-\ndamental assumption that hardware is immutable is lost here. This will create a whole new\nclassofattacks.\nAlastbigchallengeforhardwaresecurityisthelackofEDAtoolstosupporthardwaresecu-\nrity.EDAtoolsaremadeforperformanceoptimizationandsecurityisusuallyanafterthought.\nAn added challenge is that it is difficult to measure security and thus difficult to balance se-\ncurityversusarea,throughputorpoweroptimisations.\nKAHardwareSecurity |October2019 Page606 Chapter 19\nCyber-Physical Systems\nSecurity\nAlvaro Cardenas University of California Santa Cruz\n607 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nINTRODUCTION\nCyber-PhysicalSystems(CPSs)areengineeredsystemsthatarebuiltfrom,anddependupon,\nthe seamless integration of computation, and physical components. While automatic con-\ntrol systems like the steam governor have existed for several centuries, it is only in the past\ndecades that the automation of physical infrastructures like the power grid, water systems,\nor chemicalreactions have migrated from analogue controls toembedded computer-based\ncontrol,oftencommunicatingthroughcomputer-basednetworks.Inaddition,newadvances\nin medical implantable devices, or autonomous self-driving vehicles are increasing the role\nofcomputersincontrollingevenmorephysicalsystems.\nWhile computers give us new opportunities and functionalities for interacting with the phys-\nical world, they can also enable new forms of attacks. The purpose of this Knowledge Area\nistoprovideanoverviewoftheemergingfieldofCPSsecurity.\nIn contrast with other Knowledge Areas within CyBOK that can trace the roots of their field\nback toseveral decades, thework onCPS security isrelativelynew,and our communityhas\nnotdevelopedyetthesameconsensusonbestsecuritypracticescomparedtocybersecurity\nfieldsdescribedinotherKAs.Therefore,inthisdocument,wefocusonprovidinganoverview\nofresearchtrendsanduniquecharacteristicsinthisfield.\nCPSs are diverse and can include a variety of technologies, for example, industrial control\nsystemscanbecharacterisedbyahierarchyoftechnologylayers(thePurduemodel[1466]).\nHowever, the security problems in the higher layers of this taxonomy are more related to\nclassical security problems covered in other KAs. Therefore, the scope of this document\nfocuses on the aspects of CPSs more closely related to the sensing, control, and actuation\nofthesesystems(e.g.,thelowerlayersofthePurduemodel).\nThe rest of the Knowledge Area is organised as follows. In Section 19.1 we provide an intro-\nduction to CPSs and their unique characteristics. In Section 19.2, we discuss crosscutting\nsecurity issues in CPSs generally applicable to several domains (e.g., the power grid or ve-\nhicle systems); in particular we discuss efforts for preventing, detecting, and responding to\nattacks. In Section 19.3, we summarise the specific security challenges in a variety of CPS\ndomains, including the power grid, transportation systems, autonomous vehicles, robotics,\nandmedicalimplantabledevices.Finally,inSection19.4,weexaminetheuniquechallenges\nCPSsecurityposestoregulatorsandgovernments.Inparticular,weoutlinetheroleofgovern-\nmentsinincentivisingsecurityprotectionsforCPSs,andhowCPSsecurityrelatestonational\nsecurityandtheconductofwar.\nCONTENT\n19.1 CYBER-PHYSICAL SYSTEMS AND THEIR SECURITY\nRISKS\n[1467,1468,1469]\nThe term Cyber-Physical Systems (CPSs) emerged just over a decade ago as an attempt to\nunifythecommonresearchproblemsrelatedtotheapplicationofembeddedcomputerand\ncommunication technologies for the automation of physical systems, including aerospace,\nautomotive,chemicalproduction,civilinfrastructure,energy,healthcare,manufacturing,new\nKACyber-PhysicalSystemsSecurity |October2019 Page608 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nmaterials,andtransportation.CPSsareusuallycomposedofasetofnetworkedagentsinter-\nacting with the physical world; these agents include sensors, actuators, control processing\nunits,andcommunicationdevices,asillustratedinFigure19.1.\nThetermCPSswascoinedin2006byHelenGillfromtheNationalScienceFoundation(NSF)\nin the United States [1467]. In their program announcement, NSF outlined their goal for con-\nsidering various industries (such as water, transportation, and energy) under a unified lens:\nbyabstractingfromtheparticularsofspecificapplicationsinthesedomains,thegoalofthe\nCPSprogramistorevealcrosscuttingfundamentalscientificandengineeringprinciplesthat\nunderpintheintegrationofcyberandphysicalelementsacrossallapplicationsectors.\nSensors\nActuators\ns1\na1 Physical\ns2\nSystem\na2 s3\na3\ns4\nNetwork\nc1 c2 c3\nDistributed Controllers\nFigure19.1:Generalarchitectureofcyber-physicalsystems[1470].\nSoon after the CPS term was coined, several research communities rallied to outline and\nunderstandhowCPSscybersecurity researchisfundamentallydifferentwhencomparedto\nconventional IT cyber security. Because of the crosscutting nature of CPSs, the background\nof early security position papers from 2006 to 2009 using the term CPSs, ranged from real-\ntime systems [1471, 1472], to embedded systems [1473, 1474], control theory [1470], and cy-\nbersecurity[1469,1474,1475,1476,1477].\nWhile cyber security research had been previously considered in other physical do-\nmains\u2014most notably in the Supervisory Control and Data Acquisition (SCADA) systems of\nthe power grid [1478]\u2014these previous efforts focused on applying well-known IT cyber se-\ncurity best practices to control systems. What differentiates the early CPS security position\npaperswastheircrosscuttingnaturefocusingonamulti-disciplinaryperspectiveforCPSse-\ncurity (going beyond classical IT security). For example, while classical intrusion detection\nsystems monitor purely cyber-events (network packets, operating system information, etc.),\nearlyCPSspapersbringingcontroltheoryelements[1469]suggestedthatintrusiondetection\nsystemsforCPSscouldalsomonitorthephysicalevolutionofthesystemandthencheckit\nagainstamodeloftheexpecteddynamicsasawaytoimproveattackdetection.\nCPS is related to other popular terms including the Internet of Things (IoT), Industry 4.0, or\nthe Industrial Internet of Things, but as pointed out by Edward Lee, the term \u201cCPS\u201d is more\nKACyber-PhysicalSystemsSecurity |October2019 Page609 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nfoundational and durable than all of these, because it does not directly reference either im-\nplementationapproaches(e.g.,\u201cInternet\u201dinIoT)norparticularapplications(e.g.,\u201cIndustry\u201din\nIndustry4.0).Itfocusesinsteadonthefundamentalintellectualproblemofconjoiningtheen-\ngineeringtraditionsofthecyberandphysicalworlds[1467].\nTherestofthissectionisorganisedasfollows:inSection19.1.1,weintroducegeneralproper-\nties of CPS, then in Section 19.1.2, we discuss how physical systems have been traditionally\nprotectedfromaccidentsandfailures,andhowtheseprotectionsarenotenoughtoprotect\nthesystemagainstcyber-attacks.Wefinalisethissectionbydiscussingthesecurityandpri-\nvacy risks in CPSs along with summarising some of the most important real-world attacks\noncontrolsystemsinSection19.1.3.\n19.1.1 Characteristics of CPS\nCPSsembodyseveralaspectsofembeddedsystems,real-timesystems,(wiredandwireless)\nnetworking,andcontroltheory.\nEmbeddedSystems:OneofthemostgeneralcharacteristicsofCPSsisthat,becauseseveral\nof the computers interfacing directly with the physical world (sensors, controllers, or actua-\ntors) perform only a few specific actions, they do not need the general computing power of\nclassical computers\u2014or even mobile systems\u2014and therefore they tend to have limited re-\nsources. Some of these embedded systems do not even run operating systems, but rather\nrun only on firmware, which is a specific class of software that provides low-level control\nofthedevicehardware;deviceswithoutanoperatingsystemsarealsoknownasbaremetal\nsystems.Evenwhenembeddedsystemshaveanoperatingsystem,theyoftenrunastripped-\ndownversiontoconcentrateontheminimaltoolsnecessaryfortheplatform.\nReal-Time Systems: For safety-critical systems, the time in which computations are per-\nformed is important in order to ensure the correctness of the system [1479]. Real-time pro-\ngramminglanguagescanhelpdevelopersspecifytimingrequirementsfortheirsystems,and\nReal-TimeOperatingSystem(RTOS)guaranteethetimetoacceptandcompleteataskfrom\nanapplication[1480].\nNetwork Protocols: Another characteristic of CPSs is that these embedded systems com-\nmunicate with each other, increasingly over IP-compatible networks. While many critical in-\nfrastructures such as power systems have used serial communications to monitor remote\noperations in their SCADA systems, it is only in the past two decades that the information\nexchange between different parts of the system has migrated from serial communications\ntoIP-compatiblenetworks.Forexample,theserialcommunicationsprotocolModbuswasre-\nleasedbyModiconin1979,andsubsequentserialprotocolswithmorecapabilitiesincluded\nIEC60870-5-101andDNP3inthe1990s.Alltheseserialprotocolswerelateradaptedtosup-\nportIPnetworksinthelate1990sandearly2000swithstandardssuchasModbus\/TCP,and\nIEC60870-5-104[1481,1482].\nWireless: While most of the long-distance communications are done over wired networks,\nwirelessnetworksarealsoacommoncharacteristicofCPSs.Wirelesscommunicationsfor\nembeddedsystemsattractedsignificantattentionfromtheresearchcommunityintheearly\n2000s in the form of sensor networks. The challenge here is to build networks on top of\nlow-powered and lossy wireless links, where traditional concepts for routing like the \u201chop\ndistance\u201d to a destination are no longer applicable, and other link quality metrics are more\nreliable, e.g., the expected number of times a packet has to be sent before a one-hop trans-\nmission is successful. While most of the research on wireless sensor networks was done\nKACyber-PhysicalSystemsSecurity |October2019 Page610 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nin abstract scenarios, one of the first real-world successful applications of these technolo-\ngies was in large process control systems with the advent of WirelessHART, ISA100, and\nZigBee [1483, 1484]. These three communications technologies were developed on top of\nthe IEEE 802.15.4 standard, whose original version defined frames sizes so small, that they\ncould not carry the header of IPv6 packets. Since Internet-connected embedded systems\nareexpectedtogrowtobillionsofdevicesinthenextyears,vendorsandstandardorganisa-\ntionsseetheneedtocreateembeddeddevicescompatiblewithIPv6.TobeabletosendIPv6\npacketsinwirelessstandards,severaleffortstriedtotailorIPv6toembeddednetworks.Most\nnotably the Internet Engineering Task Force (IETF) launched the 6LoWPAN effort, originally\ntodefineastandardtosendIPv6packetsontopofIEEE802.15.4networks,andlatertoserve\nas an adaptation layer for other embedded technologies. Other popular IETF efforts include\nthe RPL routing protocol for IPv6 sensor networks, and CoAP for application-layer embed-\nded communications [1485]. In the consumer IoT space some popular embedded wireless\nprotocolsincludeBluetooth,BluetoothLowEnergy(BLE),ZigBee,andZ-Wave[1486,1487].\nControl: Finally, most CPSs observe and attempt to control variables in the physical world.\nFeedback control systems have existed for over two centuries, including technologies like\nthesteamgovernor,whichwasintroducedin1788.Mostoftheliteratureincontroltheoryat-\ntempts to model a physical process with differential equations and then design a controller\nthat satisfies a set of desired properties such as stability and efficiency. Control systems\nwere initially designed with analogue sensing and analogue control, meaning that the con-\ntrol logic was implemented in an electrical circuit, including a panel of relays, which usually\nencoded ladder logic controls. Analogue systems also allowed the seamless integration of\ncontrol signals into a continuous-time physical process. The introduction of digital electron-\nicsandthemicroprocessor,ledtoworkondiscrete-timecontrol[1488],asmicroprocessors\nand computers cannot control a system in continuous time because sensing and actuation\nsignals have to be sampled at discrete-time intervals. More recently, the use of computer\nnetworksalloweddigitalcontrollerstobefurtherawayfromthesensorsandactuators(e.g.,\npumps, valves, etc.), and this originated the field of networked-controlled systems [1489].\nAnotherrecentattempttocombinethetraditionalmodelsofphysicalsystems(likedifferen-\ntialequations)andcomputationalmodels(likefinite-statemachines)isencapsulatedinthe\nfield of hybrid systems [1490]. Hybrid systems played a fundamental role in the motivation\ntowardscreatingaCPSresearchprogram,astheywereanexampleofhowcombiningmod-\nels of computation and models of physical systems can generate new theories that enable\nustoreasonaboutthepropertiesofcyber-andphysical-controlledsystems.\nHavingdiscussedthesegeneralcharacteristicsofCPSs,onecaveatisthatCPSsarediverse,\nandtheyincludemodernvehicles,medicaldevices,andindustrialsystems,allwithdifferent\nstandards,requirements,communicationtechnologies,andtimeconstraints.Therefore,the\ngeneral characteristics we associate with CPSs might not hold true in all systems or imple-\nmentations.\nBeforewediscusscybersecurityproblems,wedescribehowphysicalsystemsoperatingun-\nderautomaticcontrolsystemshavebeenprotectedfromaccidentsandnaturalfailures,and\nhow these protections against non-malicious adversaries are not enough against strategic\nattackers(i.e.,attackersthatknowthattheseprotectionsareinplaceandtrytoeitherbypass\nthemorabusethem).\nKACyber-PhysicalSystemsSecurity |October2019 Page611 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n19.1.2 Protections Against Natural Events and Accidents\nFailures in the control equipment of physical infrastructures can cause irreparable harm to\npeople,theenvironment,andotherphysicalinfrastructures.Therefore,engineershavedevel-\nopedavarietyofprotectionsagainstaccidentsandnaturalcauses,includingsafetysystems,\nprotection,fault-detection,androbustness.\n{Community emergency response\nOrganizational\nResponse Plant emergency response\nPhysical protection (dikes) } Physical\nResponse:\nPrevention and\nPhysical protection (relief devices)\nContainment\n{\nAutomatic\nControl Automatic action: Safety Interlock\nSystem or Emergency Shutdown\nResponse\n}\nCritical alarms, operator supervision,\nand manual intervention Alarms and\nOperator\nBasic controls, process alarms, Intervention\nand operator supervision\nProcess design\n{ 1 SP4 5\nRegulatory 2 SP3 SP5\nControl 3 SP7 SP8 7\nSP9 8 SP2 Steam SP6\n4 SP1\n6\nFigure19.2:Layersofprotectionforsafety-criticalICS.\nSafety:Thebasicprinciplerecommendedbythegeneralsafetystandardforcontrolsystems\n(IEC61508)istoobtainrequirementsfromahazardandriskanalysisincludingthelikelihood\nofagivenfailure,andtheconsequenceofthefailure,andthendesignthesystemsothatthe\nsafety requirements are met when all causes of failure are taken into account. This generic\nstandardhasservedasthebasisformanyotherstandardsinspecificindustries,forexample,\ntheprocessindustry(refineries,chemicalsystems,etc.)usetheIEC61511standardtodesign\naSafetyInstrumentedSystem(SIS).ThegoalofaSISistopreventanaccidentby,e.g.,clos-\ning a fuel valve whenever a high-pressure sensor raises an alarm. A more general defense-\nin-depth safety analysis uses Layers of Protection [1491], where hazards are mitigated by a\nsetoflayersstartingfrom(1)basiclowpriorityalarmssenttoamonitoringstation,to(2)the\nactivationofSISsystems,to(3)mitigationsafeguardssuchasphysicalprotectionsystems\n(e.g.,dikes)and(4)organisationalresponseprotocolsforaplantemergencyresponse\/evac-\nuation.Figure19.2illustratesthesesafetylayersofprotection.\nProtection: A related concept to safety is that of protection in electric power grids. These\nprotectionsystemsinclude,\n\u2022 Protection of Generators: when the frequency of the system is too low or too high, the\ngeneratorwillbeautomaticallydisconnectedfromthepowergridtopreventpermanent\ndamagetothegenerator.\n\u2022 Under Frequency Load Shedding (UFLS): if the frequency of the power grid is too low,\ncontrolledloadsheddingwillbeactivated.Thisdisconnectionofportionsoftheelectric\ndistribution system is done in a controlled manner, while avoiding outages in safety-\nKACyber-PhysicalSystemsSecurity |October2019 Page612 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ncritical loads like hospitals. UFLS is activated in an effort to increase the frequency of\nthepowergrid,andpreventgeneratorsfrombeingdisconnected.\n\u2022 Overcurrent Protection: if the current in a line is too high, a protection relay will be trig-\ngered,openingtheline,andpreventingdamagetoequipmentoneachsideofthelines.\n\u2022 Over\/Under Voltage Protection: if the voltage of a bus is too low or too high, a voltage\nrelaywillbetriggered.\nReliability: While safety and protection systems try to prevent accidents, other approaches\ntry to maintain operations even after failures in the system have occurred. For example, the\nelectricsystemisdesignedandoperatedtosatisfytheso-calledN-1securitycriterion,which\nmeansthatthesystemcouldloseanyoneofitsNcomponents(suchasonegenerator,sub-\nstation, or transmission line) and continue operating with the resulting transients dying out\nto result in a satisfactory new steady-state operating condition, meaning that the reliable\ndeliveryofelectricpowerwillcontinue.\nFaultTolerance:Asimilar,butdata-drivenapproachtodetectandpreventfailuresfallsunder\nthe umbrella of Fault Detection, Isolation, and Reconfiguration (FDIR) [1492]. Anomalies are\ndetected using either a model-based detection system, or a purely data-driven system; this\npartoftheprocessisalsoknownasBadDataDetection.Isolationistheprocessofidentifying\nwhich device is the source of the anomaly, and reconfiguration is the process of recovering\nfrom the fault, usually by removing the faulty sensor (if there is enough sensor redundancy\ninthesystem).\nRobustControl:Finally,anotherrelatedconceptisrobustcontrol[1493].Robustcontroldeals\nwith the problem of uncertainty in the operation of a control system. These sources of un-\nknown operating conditions can come from the environment (e.g., gusts of wind in the op-\neration of planes), sensor noise, dynamics of the system not modelled by the engineers, or\ndegradation of system components with time. Robust control systems usually take the en-\nvelope of least favourable operating conditions, and then design control algorithms so that\nthesystemoperatessafely,evenintheworst-caseuncertainty.\nThese mechanisms are not sufficient to provide security: Before CPS security was a main-\nstream field, there was a lot of confusion on whether safety, protection, fault-tolerance, and\nrobustcontrolswereenoughtoprotectCPSsfromcyber-attacks.However,asarguedovera\ndecade ago [1470], these protection systems generally assume independent, non-malicious\nfailures, and in security, incorrect model assumptions are the easiest way for the adver-\nsary to bypass any protection. Since then, there have been several examples that show why\nthese mechanisms do not provide security. For example Liu et al. [1494] showed how fault-\ndetection(baddatadetection)algorithmsinthepowergridcanbebypassedbyanadversary\nthat sends incorrect data that is consistent with plausible power grid configurations, but at\nthesametimeiserroneousenoughfromtherealvaluestocauseproblemstothesystem.A\nsimilarexamplefordynamicsystems(systemswitha\u201ctime\u201dcomponent)considersstealthy\nattacks [1495]. These are attacks that inject small false data in sensors so that the fault-\ndetectionsystemdoesnotidentifythemasanomaliesbut,overalong-periodoftime,these\nattacks can drive the system to dangerous operating conditions. Similarly, the N-1 security\ncriterionintheelectricpowergridassumesthatifthereisafailure,allprotectionequipment\nwill react as configured, but an attacker can change the configuration of protection equip-\nment in the power grid. In such a case, the outcome of an N-1 failure in the power grid will\nbe completely unexpected, as equipment will react in ways that were unanticipated by the\noperatorsofthepowergrid,leadingtopotentialcascadingfailuresinthebulkpowersystem.\nKACyber-PhysicalSystemsSecurity |October2019 Page613 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nFinally,inSection19.1.3.1,wewilldescribehowreal-worldattacksarestartingtotargetsome\noftheseprotectionsagainstaccidents;forexample,theTritonmalwarespecificallytargeted\nsafetysystemsinaprocesscontrolsystem.\nSafety vs. Security: The addition of new security defences may pose safety concerns, for\nexample, a power plant was shutdown because a computer rebooted after a patch [1496].\nSoftware updates and patching might violate safety certifications, and preventing unautho-\nrisedusersfromaccessingaCPSmightalsopreventfirstrespondersfromaccesstothesys-\ntem in the case of an emergency (e.g., paramedics might need access to a medical device\nthat prevents unauthorised connections). Security solutions should take these CPS safety\nconcernsintoaccountwhendesigninganddeployingnewsecuritymechanisms.\n19.1.3 Security and Privacy Concerns\nCPSs are at the core of health-care devices, energy systems, weapons systems, and trans-\nportationmanagement.IndustrialControlSystemssystems,inparticular,performvitalfunc-\ntions in critical national infrastructures, such as electric power distribution, oil and natural\ngas distribution, water and waste-water treatment, and intelligent transportation systems.\nThe disruption of these CPSs could have a significant impact on public health, safety and\nleadtolargeeconomiclosses.\nFor example, attacks on the power grid can cause blackouts, leading to interdependent cas-\ncadingeffectsinothervitalcriticalinfrastructuressuchascomputernetworks,medicalsys-\ntems, or water systems creating potential catastrophic economic and safety effects in our\nsociety [1497]. Attacks on ground vehicles can create highway accidents [1498], attacks on\nGPSsystemscanmisleadnavigationsystemsandmakedriversreachadestinationdesired\nby the attacker [1499], and attacks on consumer drones can let attackers steal, cause acci-\ndentsorsurreptitiouslyturnoncamerasandmicrophonestomonitorvictims[1500].\nSupervision\/\nConfiguration\nController\nPhysical\nActuators Sensors\nProcess\nFigure19.3:GeneralArchitectureofaCPS.\nKACyber-PhysicalSystemsSecurity |October2019 Page614 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n19.1.3.1 AttacksAgainstCPSs\nIn general, a CPS has a physical process under its control, a set of sensors that report the\nstate of the process to a controller, which in turn sends control signals to actuators (e.g., a\nvalve) to maintain the system in a desired state. The controller often communicates with a\nsupervisoryand\/orconfigurationdevice(e.g.,aSCADAsysteminthepowergrid,oramedical\ndevice programmer) which can monitor the system or change the settings of the controller.\nThisgeneralarchitectureisillustratedinFigure19.3.\nAttacks on CPSs can happen at any point in the general architecture, as illustrated in Fig-\nure19.4,whichconsiderseightattackpoints.\n8\nSupervision\/\nConfiguration\n7\n3\nController\n4 2\n5 6 1\nPhysical\nActuators Sensors\nProcess\nFigure19.4:AttackPointsinaCPS.\n1. Attack1representsanattackerwhohascompromisedasensor(e.g.,ifthesensordata\nis unauthenticated or if the attacker has the key material for the sensors) and injects\nfalse sensor signals, causing the control logic of the system to act on malicious data.\nAnexampleofthistypeofattackisconsideredbyHuangetal.[1501].\n2. Attack 2 represents an attacker in the communication path between the sensor and\nthe controller, who can delay or even completely block the information from the sen-\nsorstothecontroller,sothecontrollerlosesobservabilityofthesystem(lossofview),\nthuscausingittooperatewithstaledata.Examplesoftheseattacksincludedenial-of-\nserviceattacksonsensors[1502]andstaledataattacks[1503].\n3. Attack 3 represents an attacker who has compromised the controller and sends incor-\nrectcontrolsignalstotheactuators.Anexampleofthisattackisthethreatmodelcon-\nsideredbyMcLaughlin[1504].\n4. Attack 4 represents an attacker who can delay or block any control command, thus\ncausingadenialofcontroltothesystem.Thisattackhasbeenconsideredasadenial-\nof-servicetotheactuators[1502].\n5. Attack5representsanattackerwhocancompromisetheactuatorsandexecuteacon-\ntrol action that is different to what the controller intended. Notice that this attack is\ndifferenttoanattackthatdirectlyattacksthecontroller,asthiscanleadtozerodynam-\nicsattacks.ThesetypesofattacksareconsideredbyTeixeiraetal.[1505].\nKACyber-PhysicalSystemsSecurity |October2019 Page615 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n6. Attack 6 represents an attacker who can physically attack the system (e.g., physically\ndestroyingpartoftheinfrastructureandcombiningthiswithacyber-attack).Thistype\nofjointcyberandphysicalattackhasbeenconsideredbyAminetal.[1506].\n7. Attack7representsanattackerwhocandelayorblockcommunicationstoandfromthe\nsupervisory control system or configuration devices. This attack has been considered\ninthecontextofSCADAsystems[1507].\n8. Attack 8 represents an attacker who can compromise or impersonate the SCADA sys-\ntemortheconfigurationdevices,andsendmaliciouscontrolorconfigurationchanges\nto the controller. These types of attacks have been illustrated by the attacks on the\npowergridinUkrainewheretheattackerscompromisedcomputersinthecontrolroom\noftheSCADAsystem[1508]andattackswheretheconfigurationdeviceofmedicalde-\nviceshasbeencompromised[1509].\nWhile traditionally most of the considered attacks on CPSs have been software-based, an-\notherpropertyofCPSsisthattheintegrityofthesesystemscanbecompromisedevenwith-\nout a computer-based exploit in what has been referred to as transduction attacks [1510]\n(these attacks represent a physical way to inject false signals, as covered by Attack 1 in Fig-\nure 19.4). By targeting the way sensors capture real-world data, the attacker can inject a\nfalse sensor reading or even a false actuation action, by manipulating the physical environ-\nment around the sensor [1510, 1511]. For example attackers can use speakers to affect the\ngyroscopeofadrone[1512],exploitunintentionalreceivingantennasinthewiresconnecting\nsensors to controllers [1513], use intentional electromagnetic interference to cause a servo\n(an actuator) to follow the attacker\u2019s commands [1513], or inject inaudible voice commands\ntodigitalassistants[1514].\nInadditiontosecurityandsafety-relatedproblems,CPSscanalsohaveprofoundprivacyim-\nplications unanticipated by designers of new systems. Warren and Brandeis stated in their\nseminal1890essayTherighttoprivacy[149]thattheysawagrowingthreatfromrecentinven-\ntions,like\u201cinstantaneousphotographs\u201dthatallowedpeopletobeunknowinglyphotographed,\nandnewmediaindustries,suchasnewspapers,thatwouldpublishphotographswithouttheir\nsubjects\u2019 consent. The rise of CPS technologies in general, and consumer IoT in particular,\naresimilarlychallengingculturalassumptionsaboutprivacy.\nCPS devices can collect physical data of diverse human activities such as electricity con-\nsumption, location information, driving habits, and biosensor data at unprecedented levels\nofgranularity.Inaddition,thepassivemannerofcollectionleavespeoplegenerallyunaware\nof how much information about them is being gathered. Furthermore, people are largely un-\nawarethatsuchcollectionexposesthemtopossiblesurveillanceorcriminaltargeting,asthe\ndata collected by corporations can be obtained by other actors through a variety of legal or\nillegalmeans.Forexample,automobilemanufacturersareremotelycollectingawidevariety\nofdrivinghistorydatafromcarsinanefforttoincreasethereliabilityoftheirproducts.Data\nknown to be collected by some manufacturers include speed, odometer information, cabin\ntemperature,outsidetemperature,batterystatus,andrange.Thispaintsaverydetailedmap\nofdrivinghabitsthatcanbeexploitedbymanufacturers,retailers,advertisers,autoinsurers,\nlawenforcement,andstalkers,tonamejustafew.\nHaving presented the general risks and potential attacks to CPSs we finalise our first sec-\ntionbydescribingsomeofthemostimportantreal-worldattacksagainstCPSslaunchedby\nmaliciousattackers.\nKACyber-PhysicalSystemsSecurity |October2019 Page616 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n19.1.3.2 High-Profile,Real-WorldAttacksAgainstCPSs\nControl systems have been at the core of critical infrastructures, manufacturing and indus-\ntrial plants for decades, and yet, there have been few confirmed cases of cyber-attacks\n(here we focus on attacks from malicious adversaries as opposed to attacks created by re-\nsearchersforillustrationpurposes).\nNon-targeted attacks are incidents caused by the same attacks that classical IT comput-\ners may suffer, such as the Slammer worm, which was indiscriminately targeting Windows\nservers but that inadvertently infected the Davis-Besse nuclear power plant [1515] affecting\nthe ability of engineers to monitor the state of the system. Another non-targeted attack ex-\namplewasacontrollerbeingusedtosendspaminawaterfilteringplant[1516].\nTargetedattacksare thosewhere adversariesknow that they are targeting aCPS, and there-\nfore, tailor theirattack strategy with theaim of leveraginga specific CPS property. We look in\nparticular at attacks that had an effect in the physical world, and do not focus on attacks\nusedtodoreconnaissanceofCPSs(suchasHavexorBlackEnergy[1517]).\nThe first publicly reported attack on an SCADA system was the 2000 attack on Maroochy\nShire Council\u2019s sewage control system1 in Queensland, Australia [1519], where a contractor\nwhowantedtobehiredforapermanentpositionmaintainingthesystemusedcommercially\navailable radios and stolen SCADA software to make his laptop appear as a pumping sta-\ntion. During a 3-month period the attacker caused more than 750,000 gallons of untreated\nsewagewatertobereleasedintoparks,rivers,andhotelgroundscausinglossofmarinelife,\nand jeopardising public health. The incident cost the city council $176,000 in repairs, moni-\ntoring, clean-ups and extra security, and the contractor company spent $500,000 due to the\nincident[1520].\nInthetwodecadessincetheMaroochyShireattacktherehavebeenotherconfirmedattacks\nonCPSs[1521,1522,1523,1524,1525,1526,1527,1528,1529].However,nootherattackhas\ndemonstrated the new sophisticated threats that CPSs face like the Stuxnet worm (discov-\nered in 2010) targeting the Nuclear enrichment program in Natanz, Iran [718]. Stuxnet inter-\nceptedrequeststoread,write,andlocateblocksonaProgrammableLogicController(PLC).\nBy intercepting these requests, Stuxnet was able to modify the data sent to, and returned\nfrom, the PLC, without the knowledge of the PLC operator. The more popular attack variant\nofStuxnetconsistedinsendingincorrectrotationspeedstomotorspoweringcentrifugesen-\nriching Uranium, causing the centrifuges to break down so that they needed to be replaced.\nAs a result, centrifuge equipment had to be replaced regularly, slowing down the amount of\nenrichedUraniumtheNatanzplantwasabletoproduce.\nTwo other high-profile confirmed attacks on CPSs were the December 2015 and 2016 at-\ntacksagainsttheUkrainianpowergrid[1530,1531].Theseattackscausedpoweroutagesand\nclearlyillustratetheevolutionofattackvectors.Whiletheattacksin2015leveragedaremote\naccess program that attackers had on computers in the SCADA systems of the distribution\npower companies, and as such a human was involved trying to send malicious commands,\nthe attacks in 2016 were more automated thanks to the Industroyer malware [1532] which\nhad knowledge of the industrial control protocols these machines use to communicate and\ncouldautomaticallycraftmaliciouspackets.\nThe most recent example in the arms race of malware creation targeting control systems\n1Therearepriorreportedattacksoncontrolsystems[1518]butthereisnopublicinformationcorroborating\ntheseincidentsandtheveracityofsomeearlierattackshasbeenquestioned.\nKACyber-PhysicalSystemsSecurity |October2019 Page617 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nis the Triton malware [1533] (discovered in 2017 in the Middle-East) which targeted safety\nsystems in industrial control systems. It was responsible for at least one process shutting\ndown.Stuxnet,Industroyer,andTritondemonstrateacleararmsraceinCPSattacksbelieved\ntobestatesponsored.Theseattackswillhaveaprofoundimpactonthewaycyber-conflicts\nevolveinthefutureandwillplayanessentialpartinhowwarsmaybewaged,aswediscuss\ninthelastsectionofthischapter.\n19.2 CROSSCUTTING SECURITY\n[1534,1535,1536]\nThefirststepforsecuringCPSistoidentifytherisksthatthesesystemsmayhave,andthen\nprioritise how to address these risks with a defence-in-depth approach. Risk assessment\nconsistsofidentifyingassetsinaCPS[1537],understandingtheirsecurityexposure,andim-\nplementingcountermeasurestoreducetheriskstoacceptablelevels[1478,1538,1539,1540,\n1541]. Penetration testing is perhaps the most common way to understand the level of risk\nof the system and can be used to design a vulnerability management and patching strategy.\nThe supply chain is also another risk factor, discussed further in the Risk Management &\nGovernanceKnowledgeArea(Chapter2).\nOnenewareainCPSsistoidentifytheactuatorsorsensorsthatgivetheattackermaximum\ncontrolability of the CPS if they are compromised [1495, 1542, 1543, 1544, 1545] and then\nprioritisetheprotectionofthesedevices.\nOncetheriskshavebeenidentified,ageneraldefence-in-depthapproachincludesprevention,\ndetection,andmitigationmechanisms.Inthissectionwelookatcrosscuttingsecurityefforts\ntoprevent,detect,andmitigateattacks,andthenextsectionwilllookatspecificCPSdomains\nsuchasthepowergridandintelligenttransportationsystems.Thissectionisdividedinthree\nparts (1) preventing attacks (Section 19.2.1), (2) detecting attacks (Section 19.2.2), and (3)\nmitigatingattacks(Section19.2.3).\n19.2.1 Preventing Attacks\nThe classical way to protect the first computer-based control systems was to have them\nisolatedfromtheInternet,andfromthecorporatenetworksoftheassetowners.Asbusiness\npracticeschanged,andefficiencyreasonscreatedmoreinterconnectionsofcontrolsystems\nwithotherinformationtechnologynetworks,theconceptofsub-networkzoneisolationwas\nadopted by several CPS industries, most notably in the nuclear energy sector. This network\nisolationisusuallyimplementedwiththehelpoffirewallsanddatadiodes[1546].\nOn the other hand, there are several ways to break the air gap, including insider attacks, or\nadding new connectivity to the network via mobile devices. Therefore, to prevent attacks in\nmodern CPSs, designers and developers have to follow the same best security practices as\nclassical IT systems; i.e., they need to follow a secure development life cycle to minimise\nsoftware vulnerabilities, implement access control mechanisms, and provide strong crypto-\ngraphicprotectionsalongwithasecurekeymanagementsystem[1547].\nWhilethebestsecuritypracticesofclassicalITsystemscangivethenecessarymechanisms\nforthesecurityofcontrolsystems,thesemechanismsalonearenotsufficientforthedefence-\nin-depth of CPSs. In this section we will discuss how, by understanding the interactions of\ntheCPSsystemwiththephysicalworld,weshouldbeableto\nKACyber-PhysicalSystemsSecurity |October2019 Page618 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n1. betterunderstandtheconsequencesofanattack.\n2. designnovelattack-detectionalgorithms.\n3. designnewattack-resilientalgorithmsandarchitectures.\nIn the rest of this subsection we will focus on illustrating the challenges for implementing\nclassical IT security best practices in CPSs, including the fact that several CPSs are com-\nposed of legacy systems, are operated by embedded devices with limited resources, and\nfacenewvulnerabilitiessuchasanalogueattacks.\nSecuringLegacySystems:ThelifecycleofCPSdevicescanbeanorderofmagnitudelarger\nthan regular computing servers, desktops, or mobile systems. Consumers expect that their\ncarslastlongerthantheirlaptops,hospitalsexpectmedicalequipmenttolastoveradecade,\nthe assets of most industrial control systems last for at least 25 years [1548], and most of\nthesedeviceswillnotbereplaceduntiltheyarefullydepreciated.Someofthesedeviceswere\ndesigned and deployed assuming a trusted environment that no longer exists. In addition,\neven if these devices were deployed with security mechanisms at the time, new vulnerabili-\nties will eventually emerge and if the devices are no longer supported by the manufacturer,\nthen they will not be patched. For example, after the Heartbleed vulnerability was discov-\nered, major manufacturers pushed updates to mitigate this problem; however most embed-\ndeddevicesmonitoringorcontrollingthephysicalworldwillnotbepatched(patchingsome\nsafety-criticalsystemsmightevenviolatetheirsafetycertification).Soevenifavendorused\nOpenSSL to create a secure communication channel between CPS devices originally, they\nalsoneedtoconsidersupportingthedeviceoveralong-timeframe.\nTherefore, to prevent attacks in CPSs we have to deal with (1) designing systems where se-\ncuritycanbecontinuouslyupdated,and(2)retrofittingsecuritysolutionsforexistinglegacy\nsystems[1549].\nSome devices cannot be updated with these new secure standards, and therefore a popu-\nlar way to add security to legacy networks is to add a bump-in-the-wire [1550]. Typically a\nbump-in-the-wireisanetworkappliancethatisusedtoaddintegrity,authentication,andcon-\nfidentiality to network packets exchanged between legacy devices. The legacy device thus\nsendsunencryptedandunauthenticatedpacketsandthenetworkappliancewilltunnelthem\nover a secure channel to another bump-in-the-wire system at the other end of the commu-\nnication channel that then removes the security protections and gives the insecure packet\nto the final destination. Note that a bump-in-the-wire can only protect the system from un-\ntrusted parties on a network, but if the end-point is compromised, a bump-in-the-wire won\u2019t\nbeeffective.\nA similar concept has been proposed for wireless devices like implantable medical devices.\nBecausesomeofthesewirelessdevicescommunicateoverinsecurechannels,attackerscan\nlisten or inject malicious packets. To prevent this, a wireless shield [1551] can be used near\nthe vulnerable devices. The wireless shield will jam any communication attempt to the vul-\nnerabledevicesexcepttheonesfromdevicesauthorisedbytheowneroftheshield.Wireless\nshieldshavealsobeenproposedforotherareas,suchasprotectingtheprivacyofconsumers\nusingBLEdevices[1552].Becauseoftheirdisruptivenature,itisnotclearifwirelessshields\nwillfindpracticalapplicationsinconsumerapplications.\nLightweight Security: While several embedded devices support classical cryptography, for\nsomedevicestheperformanceofcryptographicalgorithmsintermsofenergyconsumption,\norlatency,maynotbeacceptable[1553].Forsymmetriccryptography,NISThasplansforthe\nKACyber-PhysicalSystemsSecurity |October2019 Page619 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nstandardisationofaportfoliooflightweightcryptographicalgorithms[1554]andthecurrent\nCAESARcompetitionforanauthenticated-encryptionstandardisevaluatingtheperformance\noftheirsubmissionsinresource-constraineddevices[1555].Forpublic-keyalgorithms,Ellip-\ntic Curve Cryptography generally offers the best balance of performance and security guar-\nantees,butotherlightweightpublic-keyalgorithmsmightbemoreappropriatedependingon\ntherequirementsofthesystem[1556].Whenitcomestoexploitmitigation,thesolutionsare\nlessclear.Mostdeeplyembeddeddevicesdonothavesupportfordataexecutionprevention,\naddressspacelayoutrandomisation,stackcanaries,virtualmemorysupport,orcryptograph-\nicallysecurerandomnumbergenerators.Inadditionsystem-on-chipdeviceshavenowayto\nexpand their memory, and real-time requirements might pose limitations on the use of vir-\ntualmemory.However,therearesomeeffortstogiveembeddedOSbetterexploitmitigation\ntools[1557].\nSecure Microkernels: Another OS security approach is to try to formally prove the security\nof the kernel. The design of secure operating systems with formal proofs of security is an\neffort dating back to the Orange Book [1031]. Because the increasing complexity of code in\nmonolithic kernels makes it hard to prove that operating systems are free of vulnerabilities,\nmicrokernelarchitecturesthatprovideaminimalcoreofthefunctionalityofanoperatingsys-\ntem have been on the rise. One example of such a system is the seL4 microkernel, which is\nnotablebecauseseveralsecuritypropertieshavebeenmachine-checkedwithformalproofs\nof security [1049]. DARPA\u2019s HACMS program [1558] used this microkernel to build a quad-\ncopterwithstrongsafetyandsecurityguarantees[1558].\nPreventingTransductionAttacks:Asintroducedintheprevioussection,transductionattacks\nrepresent one of the novel ways in which CPS security is different from classical IT security.\nSensorsaretransducersthattranslateaphysicalsignalintoanelectricalone,butthesesen-\nsors sometimes have a coupling between the property they want to measure, and another\nanalogue signal that can be manipulated by the attacker. For example, sound waves can\naffect accelerometers in wearable devices and make them report incorrect movement val-\nues[1559],andradiowavescantrickpacemakersintodisablingpacingshocks[1560].Secu-\nritycountermeasurestopreventtheseattacksincludetheadditionofbetterfiltersinsensors,\nimprovedshieldingfromexternalsignals,anomalydetection,andsensorfusion[1511].Some\nspecific proposals include: drilling holes differently in a circuit board to shift the resonant\nfrequencyoutoftherangeofthesensor,addingphysicaltrenchesaroundboardscontaining\nspeakers to reduce mechanical coupling, using microfiber cloths for acoustic isolation, im-\nplementing low-pass filters that cut-off coupled signals, and secure amplifiers that prevent\nsignalclipping[1510,1559].\n19.2.2 Detecting Attacks\nDetecting attacks can be done by observing the internal state of a CPS device, by monitor-\ning the interaction among devices to spot anomalous activities, or even using out-of-band\nchannels.\nIn the first category, Remote Attestation is a field that has received significant attention for\ndetecting malware in embedded systems because they usually do not have strong malware\nprotectionsthemselves[1561,1562,1563,1564].Remoteattestationreliesontheverification\nofthecurrentinternalstate(e.g.,RAM)ofanuntrusteddevicebyatrustedverifier.Thereare\nthree variants of remote attestation: software-based attestation, hardware-assisted attesta-\ntion,andhybridattestation.Software-basedattestationdoesnotrelyonanyspecialsecurity\nhardware in the device, but it has weak security guarantees and usually requires wireless\nKACyber-PhysicalSystemsSecurity |October2019 Page620 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nrange between the verifier and the device being checked. In contrast, hardware-based attes-\ntation (e.g., attestation with the support from a TPM, TrustZone or SGX) provides stronger\nsecurity, but requires dedicated secure hardware in CPSs devices, which in turn increases\ntheir cost, which might not be affordable in some low-end embedded systems. Hybrid ap-\nproaches attempt to find a middle ground by reducing the secure hardware requirements\nwhile overcoming the security limitations of pure software-based approaches [1425, 1565].\nThe minimal secure hardware requirements include a secure place to store the secret key,\nandsafecodethathasexclusiveaccesstothatkey.Achallengeforhybridattestationisthe\nfact that it needs to be non-interruptible and atomic (it has to run from the beginning to the\nend), and the (so far) relatively long (5-7 seconds [1425, 1565]) secure measurement of em-\nbeddedmemorymightnotbeapplicableforsafety-criticalreal-timeapplications.Inaddition\nto academic work, industry is also developing standards to enhance the security of embed-\ndedsystemswithminimalsiliconrequirements.Forexample,theTrustedComputingGroup\n(TCG)DeviceIdentifierCompositionEngine(DICE)isworkingoncombiningsimplehardware\ncapabilitiestoestablishstrongidentity,attestsoftware,andsecuritypolicy,andassistinde-\nployingsoftwareupdates.Wefinaliseourdescriptionofattestationbypointingoutthatmost\nofthepracticalproposalsforattestationworkforinitialisation,butbuildingpracticalrun-time\nattestationsolutionsremainsadifficultchallenge.\nNetwork Intrusion Detection: The second category of solutions for detecting attacks relies\non monitoring the interactions of CPS devices. In contrast with classical IT systems, where\nsimpleFinite-Statemodelsofnetworkcommunicationswillfail,CPSsexhibitcomparatively\nsimpler network behaviour: servers change less frequently, there is a more stable network\ntopology, a smaller user population, regular communication patterns, and networks host a\nsmaller number of protocols. Therefore, intrusion detection systems, anomaly detection al-\ngorithms,andwhitelistingaccesscontrolsareeasiertodesignanddeploythaninclassical\nIT systems [1566]. If the CPS designer can give a specification of the intended behaviour of\nthe network, then any non-specified traffic can be flagged as an anomaly [1567]. Because\nmost of the communications in CPS networks are between machines (with no human inter-\nvention), they happen automatically and periodically, and given their regularity, these com-\nmunication patterns may be captured by finite state models like Deterministic Finite Au-\ntomata [1568, 1569] or via Discrete-Time Markov Chains [1570, 1571]. While network speci-\nfication is in general easier in CPS environments when compared to IT, it is still notoriously\ndifficulttomaintain.\nPhysics-Based Attack Detection: The major distinction of control systems with respect to\notherITsystemsistheinteractionofthecontrolsystemwiththephysicalworld.Incontrast\nto work in CPS intrusion detection that focuses on monitoring \u201ccyber\u201d patterns, another line\nof work studies how monitoring sensor (and actuation) values from physical observations,\nand control signals sent to actuators, can be used to detect attacks; this approach is usu-\nallycalledphysics-basedattackdetection[1535].Themodelsofthephysicalvariablesinthe\nsystem (their correlations in time and space) can be purely data-driven [1572], or based on\nphysical models of the system [1495]. There are two main classes of physical anomalies:\nhistoricalanomaliesandphysical-lawanomalies.\nHistorical Anomalies: identify physical configuration we have not seen before. A typical ex-\nampleistoplacelimitsontheobservedbehaviourofavariable[1573].Forexampleifduring\nthe learning phase, a water level in a tank is always between 1m and 2m, then if the water\nlevelevergoesaboveorbelowthesevalueswecanraiseanalert.Machinelearningmodels\nof the historical behaviour of the variables can also capture historical correlations of these\nvariables. For example, they can capture the fact that when the tank of a water-level is high,\nKACyber-PhysicalSystemsSecurity |October2019 Page621 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nthewaterlevelofasecondtankintheprocessisalwayslow[1574].Oneproblemwithhistor-\nicalanomaliesisthattheymightgeneratealargenumberoffalsealarms.\nPhysical-Law Anomalies: A complementary approach to historical observations that may\nhave fewer false alarms, is to create models of the physical evolution of the system. For\nexample we have a sensor that monitors the height of a bouncing ball, then we know that\nthis height follows the differential equations from Newton\u2019s laws of mechanics. Thus, if a\nsensorreportsatrajectorythatisnotplausiblegiventhelawsofphysics,wecanimmediately\nidentifythatsomethingisnotrightwiththesensor(afaultoranattack).Similarly,thephysical\npropertiesofwatersystems(fluiddynamics)orthepowergrid(electromagneticlaws)canbe\nusedtocreatetimeseriesmodelsthatwecanthenusetoconfirmthatthecontrolcommands\nsent to the field were executed correctly and that the information coming from sensors is\nconsistent with the expected behaviour of the system. For example, if we open an intake\nvalve we should expect that the water level in the tank should rise, otherwise we may have\na problem with the control, actuator, or the sensor. Models of the physical evolution of the\nsystem have been shown to be better at limiting the short-term impact of stealthy attacks\n(i.e., attacks where the attacker creates a malicious signal that is within the margin of error\nof our physical models) [1575]. However, if the attack persists for a long time and drives\nthe system to an unsafe region by carefully selecting a physically plausible trajectory, then\nhistoricalmodelscanhelpindetectingthispreviouslyunseenstate[1576].\nIn addition to the physics of the system being controlled, devices (such as actuators) have\ndynamics as well, and these physical properties can also be used to monitor the proper be-\nhaviourofdevices [1577].\nOut-of-band Detection: Another way to passively monitor the physical system is through\nout-of-band channels [1578]. For example, Radio Frequency-based Distributed Intrusion De-\ntection [1579] monitors radio frequency emissions from a power grid substation in order to\ncheck if there are malicious circuit breaker switching, transformer tap changes, or any acti-\nvationofprotectingrelayswithoutthedirectrequestsentfromtheSCADAserver.Thebasic\nidea is to correlate control commands sent by the SCADA server, with the radio frequency\nemissionsobservedinthesubstation.Apotentialdrawbackwiththisapproachisthatattack-\nerscanlaunchRFattacksmimickingtheactivationofavarietyofelectricsystems,whichcan\nleadtosecurityanalystslosingconfidenceintheveracityofthealerts.\nActive Detection: In addition to passively monitoring a CPS, an intrusion detection sys-\ntem can actively query devices to detect anomalies in how devices respond to these re-\nquests[1580].Inadditiontoanetworkquery,theintrusiondetectionsystemcanalsosenda\nphysical challenge to change the system\u2019s physical behaviour. This approach is also known\nasphysicalattestation[1574,1581,1582],whereacontrolsignalisusedtoalterthephysical\nworld, and in response, it expects to see the changes done in the physical world reflected in\nthe sensor values. For example, we can send signals to change the network topology of the\npowergridtoseeifthesensorsreportthisexpectedchange[1583],useachangeinthefield\nof vision of a camera to detect hacked surveillance cameras [1584], or use a watermarking\nsignalinacontrolalgorithm[1585].Theconceptofactivedetectionisrelatedtoresearchon\nmoving target defence applied to cyber-physical systems [1586, 1587, 1588, 1589]. However,\nboth active detection and moving target defence might impose unnecessary perturbations\nin a system by their change of the physical world for security purposes. Therefore, these\ntechniquesmightbetooinvasiveandcostly.Consequently,thepracticalityofsomeofthese\napproachesisuncertain.\nKACyber-PhysicalSystemsSecurity |October2019 Page622 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n19.2.3 Mitigating Attacks\nMost of the efforts for mitigating faults in CPSs have focused on safety and reliability (the\nprotection of the system against random and\/or independent faults). Attack mitigation is\nan extension of safety and reliability protections for when the faults in the systems are not\ncreatedatrandombynature,butbyanadversary.\nAttack mitigation is related to the concept of resilient control systems, defined as those\nthatmaintainstateawarenessandanacceptedlevelofoperationalnormalcyinresponseto\ndisturbances,includingthreatsofanunexpectedandmaliciousnature[1590].\nThere are two main types of mitigating technologies: i) proactive and ii) reactive. Proactive\nmitigation considers design choices deployed in the CPS prior to any attack. On the other\nhand, reactive responses only take effect once an attack has been detected, and they re-\nconfigure the system online in order to minimise the impact of the attack. We first describe\nproactiveapproaches.\nConservative Control: One of the first ideas for mitigating the impact of attacks was to op-\nerate the system with enough safety margins so that if an attack ever occurred, it would be\nharder for the attacker to reach an unsafe region. One intuitive idea for this type of control\nalgorithmistouseMulti-PartyComputation(MPC)todesignacontrolstrategythatpredicts\nthatanattackwillhappenstartingatthenexttimestep[1502],andthereforeplansanoptimal\ncontrol action that will attempt to keep the system safe if the attack happens. Operating a\nCPSconservativelyusuallycomesatthecostofsuboptimaloperationandextracostswhen\nthesystemisnotunderattack.\nResilientEstimation:Resilientestimationalgorithmsattempttoobtainthisstateofasystem,\neven if a subset of sensors is compromised [1591, 1592]. The basic idea is to use the knowl-\nedge of a CPS and the correlations of all sensor values. With enough redundancy in sensor\nmeasurements,aresilientestimationalgorithmcanrejectattemptedattacksandstillobtain\nan accurate state estimate. This idea is similar to error correcting codes in information the-\nory, where a subset of the bits transmitted can be corrupted, but the error correcting code\nreconstructs the original message. The drawback, however, is that not all CPSs will have a\nvariety of correlated sensors to check the consistency of others, so this approach depends\nonthepropertiesofthesystem.\nSensorFusion:Resilientestimationalgorithmsusuallyassumeavarietyofmulti-modalsen-\nsors to achieve their security guarantees. This is also the idea behind sensor fusion, where\nsensorsofdifferenttypescanhelp\u201cconfirm\u201dthemeasurementofothersensors[1593,1594,\n1595]. A basic example of sensor fusion in automotive systems is to verify that both the\nLiDARreadingsandthecamerameasurementsreportconsistentobservations.\nVirtualSensors:Whenweusephysical-lawsanomalydetectionsystems,wehave,ineffect,a\nmodelofthephysicalevolutionofthesystem.Therefore,onewaytomitigateattacksonthe\nsensorsofaCPSistouseaphysicalmodelofthesystemtocomeupwiththeexpectedsen-\nsorvaluesthatcanthenbeprovidedtothecontrolalgorithm[1495,1576,1596].Byremoving\na sensor value with its expected value obtained from the system model, we are effectively\ncontrollingasystemusingopen-loopcontrol,whichmightworkintheshort-term,butmaybe\nrisky as a long-term solution, as all physical models are not perfect, and the error between\nthe real-world and the model simulation can increase over time. Another important consid-\nerationwhendesigningvirtualsensorsasanattack-responsemechanism,istoevaluatethe\nsafetyofthesystemwheneverthesystemisactivatedduetoafalsealarm[1495].\nKACyber-PhysicalSystemsSecurity |October2019 Page623 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nConstraining Actuation: A similar principle of operating conservatively is to physically con-\nstrain the actuators of a CPS so that if the attacker ever succeeds in gaining access to the\nsystem,itisrestrictedinhowfastitcanchangetheoperationofthesystem.Thisapproach\ncanguarantee,forexample,thesafetyofvehicleplatooningsystems,evenwhentheattacker\nhascompletecontrolofoneofthevehicles[1597].\nInertial Resets: Another idea to mitigate attacks is to reset and diversify the system as\nfrequently as possible so that attackers are unable to gain persistent control of the sys-\ntem [1598, 1599]. The basic idea is that a full software reset of the system will make the\nsystem boot again in a trusted state, eliminating the presence of an attacker. This requires\nthe system to have a trusted computing base that can boot the system in a secure state\nwhere the malware is not loaded yet. However, turning off a system that is in operation is a\npotentiallydangerousaction,anditisnotclearifthisproposalwillbepractical.\nReactiveControlCompensation:Whensensorsorcontrollersareunderattack,newactions\naregeneratedinordertomaintainthesafetyofthesystem.Inspiredbytheliteratureonfault-\ntolerant control, one idea is to attempt to estimate the attack signal, and then generate a\ncompensatingactiontoeliminateit[1600].Theproblemwiththisapproachisthatitdoesnot\nconsiderstrategicadversaries;howevergame-theoreticapproachescanaddressthatlimita-\ntion. In game-theoretic models, an attacker compromises a set of control signals ua \u2208 Rma\nk\nand the defender uses the remaining controllers ud \u2208 Rmd to deploy a defence action. The\nk\ngame between the attacker and the defender can be simultaneous (zero-sum or minimax\ngame) [1601, 1602, 1603] or sequential (e.g., Stackelberg game) [1604, 1605, 1606]. One of\nthechallengeswithgametheoryisthat,inordertomodelandproveresults,theformulation\nneeds to be simplified, and in addition, models need to add a number of extra assumptions\nthatmightnotholdinpractice.\nSafe Control Actions: Another reactive approach is to change or even prevent a potentially\nmalicious control action from acting on the system. The idea of having a High Assurance\nController(HAC)asabackuptoaHighPerformanceController(HPC)predatesworkonCPS\nsecurity, and was proposed as a safety mechanism to prevent complex and hard-to verify\nHPCs from driving the system to unsafe states [1607]. A more recent and security-oriented\napproachistousetheconceptofareferencemonitortocheckifthecontrolactionwillresult\ninanyunsafebehaviourbeforeitisallowedtogointothefield[1504].Theproposedapproach\ndependsonacontrollerofcontrollers(C2),whichmediatesallcontrolsignalssentbythecon-\ntroller to the physical system. In particular, there are three main properties that C2 attempts\nto hold: 1) safety (the approach must not introduce new unsafe behaviours, i.e., when oper-\nations are denied the \u2018automated\u2019 control over the plant, it should not lead the plant to an\nunsafe behaviour); 2) security (mediation guarantees should hold under all attacks allowed\nby the threat model); and 3) performance (control systems must meet real-time deadlines\nwhileimposingminimaloverhead).\nAll the security proposals for preventing, detecting, and responding to attacks presented in\nthis section are generally applicable to CPSs. However, there are unique properties of each\nCPSapplicationthatcanmakeadifferenceinhowthesesolutionsareimplemented.Further-\nmore,someuniquepropertiesofaparticularCPSdomaincanleadtonewsolutions(suchas\nthe touch-to-access principle proposed for implantable medical devices [1608]). In the next\nsection we change focus from general and abstract CPS descriptions, to domain-specific\nproblemsandsolutions.\nKACyber-PhysicalSystemsSecurity |October2019 Page624 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n19.3 CPS DOMAINS\n[1534,1609,1610,1611,1612,1613,1614,1615]\nHaving presented general principles for securing CPSs, in this section we discuss domain-\nspecific security problems for CPSs. In particular we focus on industrial control systems,\nelectrical power grids, transportation systems, vehicles, robots, medical devices, and con-\nsumerIoT.\n19.3.1 Industrial Control Systems\nIndustrialcontrolsystemsrepresentawidevarietyofnetworkedinformationtechnologysys-\ntems connected to the physical world [1616]. Depending on the application, these control\nsystems are also called Process Control Systems (PCSs) in the chemical industry, or Dis-\ntributedControlSystems(DCSs)ifthedevicesusedforsupervisionandcontrolareprocured\nusingamonolithicarchitecture.\nControl systems are usually composed of a set of networked agents, consisting of sensors,\nactuators,controlprocessingunitssuchasProgrammableLogicControllers(PLCs),Remote\nTerminal Units (RTUs), and communication devices. For example, the oil and gas industry\nusesintegratedcontrolsystemstomanagerefiningoperationsatplantsites,remotelymoni-\ntorthepressureandflowofgaspipelines,andcontroltheflowandpathwaysofgastransmis-\nsion. Water utilities can remotely monitor well levels and control the wells\u2019 pumps; monitor\nflows, tank levels, or pressure in storage tanks; monitor pH, turbidity, and chlorine residual;\nandcontroltheadditionofchemicalstothewater.\nFigure19.5:BottomLayersofIndustrialControlSystems[1469].\nControlsystemshavealayeredhierarchy[1466],whichcanbeusedfornetworksegmentation\nand to ensure access control. Figure 19.5 shows an illustration of the lower layers of this\nhierarchy.\nThe top layers operate using mostly traditional Information Technology: computers, operat-\ning systems, and related software. They control the business logistic system, which man-\nages the basic plant production schedule, material use, shipping and inventory levels, and\nalso plant performance, and keep data historians for data-driven analytics (e.g., predictive\nmaintenance).\nThesupervisorycontrollayeriswheretheSupervisoryControlandDataAcquisition(SCADA)\nsystemsandotherserverscommunicatewithremotecontrolequipmentlikeProgrammable\nLogic Controllers (PLCs) and Remote Terminal Units (RTUs). The communication between\nKACyber-PhysicalSystemsSecurity |October2019 Page625 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nservers in a control room and these control equipment is done via a Supervisory Control\nNetwork(SCN).\nRegulatorycontrolisdoneatthelowerlayer,whichinvolvesinstrumentationinthefield,such\nassensors(thermometers,tachometers,etc.)andactuators(pumps,valves,etc.).Whiletra-\nditionallythisinterfacehasbeenanalogue(e.g.,4-20milliamperes),thegrowingnumbersof\nsensorsandactuatorsaswellastheirincreasedintelligenceandcapabilities,hasgivenrise\ntonewFieldCommunicationNetworks(FCNs)wherethePLCsandothertypesofcontrollers\ninterface with remote Input\/Output boxes or directly with sensors and actuators using new\nEthernet-basedindustrialprotocolslikeENIPandPROFINET,andwirelessnetworkslikeWire-\nlessHART.Severalringtopologieshavealsobeenproposedtoavoidasinglepointoffailure\nforthesenetworks,suchastheuseofDeviceLevelRing(DLR)overENIP.\nSCN and FCN networks represent Oblivious Transfer (OT) networks, and they have different\ncommunicationrequirementsanddifferentindustrialnetworkprotocols.WhileSCNcantoler-\natedelaysofuptotheorderofseconds,FCNtypicallyrequireanorderofmagnitudeoflower\ncommunicationdelays,typicallyenablingcommunicationsbetweendeviceswithaperiodof\n400us.\nIntrusion detection is a popular research topic for protecting control systems, and this in-\ncludes using network security monitors adapted to industrial protocols [1566, 1568, 1569,\n1570, 1571, 1617, 1618], and physics-based anomaly detection [1495, 1572, 1573, 1575, 1619,\n1620]. The layer where we monitor the physics of the system can have a significant impact\nonthetypesofattacksthatcanbedetected[1621].\nIn particular the adversary can compromise and launch attacks from (1) SCADA\nservers [1622], (2) controllers\/PLCs [1623], (3) sensors [1494], and (4) actuators [1624], and\neachoftheseattackscanbeobservableatdifferentlayersofthesystem.\nMostoftheworkonnetworksecuritymonitoringforindustrialcontrolsystemshasdeployed\nnetwork intrusion detection systems at the SCN. However, if an anomaly detection system\nis only deployed in the supervisory control network then a compromised PLC can send ma-\nnipulateddatatothefieldnetwork,whilepretendingtoreportthateverythingisnormalback\nto the supervisory control network. In the Stuxnet attack, the attacker compromised a PLC\n(Siemens 315) and sent a manipulated control signal ua (which was different from the origi-\nnalu,i.e.,ua =(cid:54) u).Uponreceptionofua,thefrequencyconvertersperiodicallyincreasedand\ndecreased the rotor speeds well above and below their intended operation levels. While the\nstatusofthefrequencyconvertersywasthenrelayedbacktothePLC,thecompromisedPLC\nreported a manipulated value y (cid:54)= y to the control centre (claiming that devices were oper-\na\nating normally). A similar attack was performed against the Siemens 417 controller [1623],\nwhereattackerscaptured21secondsofvalidsensorvariablesatthePLC,andthenreplayed\nthemcontinuouslyforthedurationoftheattack,ensuringthatthedatasentthroughtheSCN\ntotheSCADAmonitorswouldappearnormal[1623].Asystematicstudyofthedetectabilityof\nvariousICSattacks(controller,sensor,oractuatorattacks)wasgivenbyGiraldoetal.[1621],\nand the final recommendation is to deploy system monitors at the field network, as well as\natthesupervisorynetwork,andacrossdifferentloopsofthecontrolsystem.\nIn addition to attack detection, preventing the system from reaching unsafe states is also\nan active area of research [1504, 1625, 1626, 1627, 1628]. The basic idea is to identify that\na control action can cause a problem in the system, and therefore a reference monitor will\nprevent this control signal from reaching the physical system. Other research areas include\nthe retrofitting of security in legacy systems [1549, 1629], and malware in industrial control\nKACyber-PhysicalSystemsSecurity |October2019 Page626 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ndevices [1630, 1631]. A concise survey of research in ICS security was given by Krotofil and\nGollmann [1632], and reviews of state-of-the-art practices in the field of ICS security include\ntheworkofKnowlesetal.andCherdantsevaetal.[1541,1633].\nA problem for studying industrial control systems is the diversity of platforms, including the\ndiversity of devices (different manufacturers with different technologies) and applications\n(water,chemicalsystems,oilandgas,etc.).Thereforeoneofthebigchallengesinthisspace\nisthereproducibilityofresultsandthegeneralityofindustrialcontroltestbeds[1634].\n19.3.2 Electric Power Grids\nAttheturnofthecentury,theUSNationalAcademyofEngineeringselectedthetop20engi-\nneering achievements of the twentieth century (the achievements that most improved peo-\nple\u2019squalityoflife)andatthetopofthislist,wasthepowergrid[1635].Intheapproximately\n140 years since their inception, electric grids have extended transmission lines to 5 billion\npeople around the world, bringing light, refrigeration, and many other basic services to peo-\npleacrosstheglobe.\nThe power grid has three major parts: (1) generation, (2) transmission, and (3) distribution.\nElectricpowerisgeneratedwhereveritisconvenientandeconomical,andthenitistransmit-\nted at high voltages (100kV-500kV) in order to minimise energy losses\u2014electrical power is\nequaltovoltagetimeselectricalcurrent(P = VI),(andgivenaconstantpower,highvoltage\nlineshavelesselectricalcurrent),andthereforethereislessenergylostasheatasthecurrent\nmoves through the transmission lines. Geographically, a distribution system is located in a\nsmallerregiontherebyenergylossesarelessofaconcernwhilesafety(preventingaccidents,\nfires,electrocutions,etc.)ismoreimportant,thereforetheyareoperatedatlowervoltages.\nThe transmission system is an interconnected, redundant network that spans large regions\n(usually one country). Large generation plants and the transmission network (the first two\npartsofthepowergrid)areusuallyreferredtoastheBulkPowerSystem,andthisbulkpower\nsystem is responsible for the reliable delivery of electricity to large areas. A disruption in\nthe bulk power grid can cause a country-level blackout that would require several days of\na blackstart period to restart the system. In contrast, distribution systems (the third part of\nthe grid) are much smaller, their networks are radial (non-redundant), and a failure in their\nsystem usually only causes a localised outage (e.g., a blackout in a neighborhood). This is\nthe reason most government and industry efforts have prioritised the creation of standards\nforsecurityinthebulkpowersystem[1611].\nOne of the most popular lines of work related to the security of power systems is the study\nof false data injection attacks in order to cause the algorithms in the power grid to misbe-\nhave. The most popular of this type of attacks are the false data injection attacks against\nstateestimation.Inthepowergrid,operatorsneedtoestimatethephaseanglesx fromthe\nk\nmeasured power flow y in the transmission grid. As mentioned in the section about CPS\nk\nsafety,baddatadetectionalgorithmsweremeanttodetectrandomsensorfaults,notstrate-\ngicattacks,andasLiuetal.[1494,1636]showed,itispossibleforanattackertocreatefalse\nsensor signals that will not raise an alarm (experimental validation in software used by the\nenergy sector was later confirmed [1637]). There has been a significant amount of follow\nup research focusing on false data injection for state estimation in the power grid, includ-\ning the work of D\u00e1n and Sandberg[1638], who study the problem of identifying the best k\nsensors to protect in order to minimise the impact of attacks, and Kosut et al. [1639], who\nconsiderattackerstryingtominimisetheerrorintroducedintheestimate,anddefenderswith\nKACyber-PhysicalSystemsSecurity |October2019 Page627 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\na new detection algorithm that attempts to detect false data injection attacks. Further work\nincludes[1543,1583,1640,1641,1642].\n19.3.2.1 SmartGrids\nWhile the current power grid architecture has served well for many years, there is a growing\nneed to modernise the world\u2019s electric grids to address new requirements and to take ad-\nvantage of the new technologies. This modernisation includes the integration of renewable\nsourcesofenergy,thedeploymentofsmartmeters,theexchangeofelectricitybetweencon-\nsumers and the grid, etc. Figure 19.6 illustrates some of these concepts. The rationale for\nmodernisingthepowergridincludesthefollowingreasons:\nBulk Generation Transmission Distribution\nRenewable\nEnergy\nIntegration\nRenewable\nWide Area\nMonitoring\nNon Smart\nRenewable Relays\nPhasor\nMeasurement\nLarge Capacity\nUnit\nBatteries\nCustomers\nRenewable\nSmart Meter\nEnergy\nEnergy\nBatteries\nManagement\nOne-way electricity flow\nSmart Meter Systems\nTwo-way electricity flow\nSmart\nAppliances\nPlug-in Vehicles\nFigure19.6:Modernizationofthepowergrid[1643].\nEfficiency: One of the main drivers of the smart grid programs is the need to make more\nefficientuseofthecurrentassets.Thepeakdemandforelectricityisgrowingeveryyearand\nso utility companies need to spend more money each year in new power plants and their\nassociated infrastructures. However, the peak demand is only needed 16% of the time and\nso the equipment required to satisfy this peak demand will remain idle for the rest of the\ntime.\nOne of the goals for the smart grid is to change the grid from load following to load shaping\nby giving incentives to consumers for reducing electricity consumption at the times of peak\ndemand. Reducing peak demand \u2013 in addition to increasing the grid stability \u2013 can enable\nutilitiestopostponeoravoidtheconstructionofnewpowerstations.Thecontrolorincentive\nactionsusedtoshapetheloadisusuallycalledDemandResponse.\nKACyber-PhysicalSystemsSecurity |October2019 Page628 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nEfficiencyalsodealswiththeintegrationofthenewandrenewablegenerationsources,such\naswindandsolarpowerwiththeaimofreducingthecarbonfootprint.\nReliability:Thesecondmainobjectiveofmodernisingthepowergridisreliability,especiallyat\nthedistributionlayer(thetransmissionlayerismorereliable).Bydeployingnewsensorsand\nactuatorsthroughoutthepowergrid,operatorscanreceivereal-time,fine-graineddataabout\nthe status of the power grid, that enables better situational awareness, faster detection of\nfaults(orattacks),andbettercontrolofthesystem,resultinginfeweroutages.Forexample,\nthedeploymentofsmartmetersisallowingdistributionutilitiestoautomaticallyidentifythe\nlocationandsourceofanoutage.\nConsumerchoice:Thethirdobjectiveistoaddressthelackoftransparencythecurrentpower\ngridprovidestoconsumers.Currently,mostconsumersreceiveonlymonthlyupdatesabout\ntheir energy usage. In general, consumers do not know their electricity consumption and\nprices that they are paying at different times of the day. They are also not informed about\nother important aspect of their consumption such as the proportion of electricity that was\ngenerated through renewable resources. Such information can be used to shape the usage\npattern(i.e.,theload).Oneofthegoalsofthesmartgridistoofferconsumersreal-timedata\nandanalyticsabouttheirenergyuse.Smartappliancesandenergymanagementsystemswill\nautomatehomesandbusinessesaccordingtoconsumerpreferences,suchascostsavings\norbymakingsuremorerenewableenergyisconsumed.\nTo achieve these objectives, the major initiatives associated with the smart grid are the ad-\nvancedmeteringinfrastructure,demandresponse,transmissionanddistributionautomation,\ndistributedenergyresources,andtheintegrationofelectricvehicles.\nWhile modernising the power grid will bring many advantages, it can also create new threat\nvectors. For example, by increasing the amount of collected consumer information, new\nforms of attack will become possible [1644]. Smart grid technologies can be used to infer\nthe location and behaviour of users including if they are at home, the amount of energy that\ntheyconsume,andthetypeofdevicestheyown[1645,1646]).\nInadditiontonewprivacythreats,anotherpotentialnewattackhasbeenreferredtoasload-\nalteringattack.Load-alteringattackshavebeenpreviouslystudiedindemand-responsesys-\ntems[1647,1648,1649,1650,1651,1652].Demand-responseprogramsprovideanewmecha-\nnismforcontrollingthedemandofelectricitytoimprovepowergridstabilityandenergyeffi-\nciency.Intheirbasicform,demand-responseprogramsprovideincentives(e.g.,viadynamic\npricing)forconsumerstoreduceelectricityconsumptionduringpeakhours.Currently,these\nprogramsaremostlyusedbylargecommercialconsumersandgovernmentagenciesmanag-\ninglargecampusesandbuildings,andtheiroperationisbasedoninformalincentivesignals\nvia phone calls by the utility or by the demand-response provider (e.g., a company such as\nEnel X) asking the consumer to lower their energy consumption during the peak times. As\ntheseprogramsbecomemorewidespread(targetingresidentialconsumers)andautomated\n(givingutilitiesordemand-responsecompaniestheabilitytodirectlycontroltheloadoftheir\ncustomers remotely) the attack surface for load-altering attacks will increase. The attacks\nproposedconsiderthattheadversaryhasgainedaccesstothecompanycontrollingremote\nloadsandcanchangealargeamountoftheloadtoaffectthepowersystemandcauseeither\ninefficiencies to the system, economic profits for the attacker, or potentially cause enough\nload changes to change the frequency of the power grid and cause large-scale blackouts.\nDemand-response systems can be generalised by transactive energy markets, where pro-\nsumers (consumers with energy generation and storage capabilities) can trade energy with\neachother,bringingtheirownprivacyandsecuritychallenges[1653].\nKACyber-PhysicalSystemsSecurity |October2019 Page629 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nMorerecentlySoltanetal.[1654]studiedthesametypeofload-alteringattacksbutwhenthe\nattackercreatesalarge-scalebotnetwithhundredsofthousandsofhigh-energyIoTdevices\n(such as water heaters and air conditioners). With such a big botnet the attacker can cause\n(i)frequencyinstabilities,(ii)linefailures,and(iii)increasedoperatingcosts.Afollowupwork\nbyHuangetal.[1655]showedthatcreatingasystemblackout\u2014whichwouldrequireablack\nstartperiodofseveraldaystorestartthegrid\u2014orevenablackoutofalargepercentageofthe\nbulk power grid can be very difficult in part because the power grid has several protections\ntoloadchanges,includingunder-frequencyloadshedding.\n19.3.3 Transportation Systems and Autonomous Vehicles\nModern vehicular applications leverage ubiquitous sensing and actuation capabilities to im-\nprove transportation operations [1656] thanks to technologies such as smart phones [1657],\nparticipatorysensing[1658],andwirelesscommunicationnetworks[1659].Modernfunction-\nalities include Traffic flow control with ramp metering at freeway on-ramps and signal tim-\ning plans at signalised intersections to reduce congestion; Demand management which fo-\ncusesonreducingtheexcesstrafficduringpeakhours;Incidentmanagementwhichtargets\nresources to alleviate incident hot spots; and Traveler information which is used to reduce\ntravelerbuffertime,i.e.,theextratimethetravelersmustaccountfor,whenplanningtrips.\nWhile this large-scale collection of sensor data can enable various societal advantages, it\nalso raises significant privacy concerns. To address these emerging privacy concerns from\nsensordata,manytechniqueshavebeenproposed,includingdifferentialprivacy[526].\nAlthough privacy is an important concern for these systems, it is unfortunately not the only\none. Widespread vulnerabilities such as those from traffic sensors [1529, 1660, 1661] can\nbe readily exploited [1662, 1663, 1664, 1665]. For example, Wang et al. [1664] showed that\nattackers can inject false data in crowdsourced services to cause false traffic congestion\nalarmsandfakeaccidents,triggeringtheservicestoautomaticallyreroutetraffic.\nSimilar problems can be found on commercial flights. Not only are airplanes being mod-\nernisedwhileintroducingpotentiallynewattackvectorsbyattemptingtoattackavionicsys-\ntems through the entertainment network [1666] but air traffic systems might also be vulner-\nable to attacks. A new technology complementing (or potentially replacing) radar systems\nis the Automatic Dependent Surveillance-Broadcast (ADS-B) system. ADS-B consists of air-\nplanessharingtheirGPScoordinateswitheachotherandwithairtrafficcontrolsystems,but\nthese systems are currently unauthenticated and unencrypted, posing security and privacy\nproblems[1667].\n19.3.3.1 Ground,Air,andSeaVehicles\nSoftware problems in the sensors of vehicles can cause notorious failures, as the Ariane 5\nrocket accident [1668], which was caused by software in the inertial navigation system shut\ndown causing incorrect signals to be sent to the engines. With advances in manufacturing\nandmodernsensors,wearestartingtoseetheproliferationofUnmannedVehicles(UVs)in\nthe consumer market as well as across other industries. Devices that were only available to\ngovernment agencies have diversified their applications ranging from agricultural manage-\nment to aerial mapping and freight transportation [1669]. Out of all the UVs available in the\ncommercial market (aerial, ground and sea vehicles) unmanned aerial vehicles seem to be\nthemostpopularkindwithaprojected11.2billiondollarglobalmarketby2020[1670].\nThe expansionof unmannedaerial vehicles has increased securityand privacyconcerns. In\nKACyber-PhysicalSystemsSecurity |October2019 Page630 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ngeneral, there is a lack of security standards for drones and it has been shown that they are\nvulnerabletoattacksthattargeteitherthecyberand\/orphysicalelements[1613,1671].From\nthepointofviewofprivacy,dronescanletusersspyonneighbours[1672,1673],andenable\nliteralhelicopterparenting[1674].\nAttacksremotelyaccessingsomeoneelse\u2019sdrone(e.g.,aneighbour)totakephotosorvideos,\nstealing drones wirelessly (e.g., an attacker in a vehicle can take over a drone and ask it to\nfollow the vehicle), and taking down a drone operated by someone else (which can lead to\ncharges like mishandling a drone in public, which in turn has resulted in reckless endanger-\nmentconvictions)[1500].\nUVs have multiple sensors that aid them to assess their physical environments such as ac-\ncelerometers,gyroscopes,barometers,GPSandcameras.Whilerelianceonsensordatawith-\nout any form of validation has proven to be an effective trade-off in order to maintain the ef-\nficiencydemandsofreal-timesystems,itisnotasustainablepracticeasUVsbecomemore\npervasive. Transduction attacks on sensors have shown that accelerometers, gyroscopes,\nandevencamerasusedbydronesforstabilisationcanbeeasilyattacked,causingthedrone\ntomalfunction,crash,orevenbetakenoverbytheattacker[1512,1559,1675].\nEvenonmanyoperationalwarships,remotemonitoringofequipmentisnowdonewithahard-\nwired LAN by systems such as the Integrated Condition Assessment System (ICAS) [1676].\nICAS are generally installed with connections to external Programmable Logic Controllers\n(PLCs), which are used in Supervisory Control and Data Acquisition (SCADA) systems to di-\nrect the movement of control equipment that performs actual manipulation of physical de-\nvicesintheshipsuchaspropulsionandsteering(rudder)devices[1676,1677].Therefore,the\nsecureoperationofshipsishighlyrelatedtothesecurityofindustrialcontrolsystems.\nForgroundvehicles,oneoftheareasofinterestisthesecurityoftheControllerAreaNetwork\n(CAN). The CAN system is a serial broadcast bus designed by Bosch in 1983 to enable the\ncommunication of Electrical Control Units (ECUs) in cars. Examples of ECUs include brake\nsystems,thecentraltimingmodule,telematiccontrolunits,gearcontrol,andenginecontrol.\nTheCANprotocol,however,doesnothaveanysecuritymechanism,andthereforeanattacker\nwho can enter the CAN bus in a vehicle (e.g., through a local or remote exploit) can spoof\nany ECU to ignore the input from drivers, and disable the brakes or stop the engine [1678].\nTherefore,researchhasconsideredwaystoretrofitlightweightsecuritymechanismsforCAN\nsystems [1679], or how to detect spoofed CAN messages based on the physical-layer char-\nacteristics of the signal [1680] (voltage level profiles, timing, frequency of messages, etc.).\nHowever,thesecurityofsomeofthesesystemsremainsinquestion[1681].\nAutonomous vehicles will also face new threats, for example, a malicious vehicle in an\nautomated platoon can cause the platoon to behave erratically, potentially causing acci-\ndents[1682].Finally,newfunctionalitieslikearemotekill-switchcanbeabusedbyattackers,\nforexample,anattackerremotelydeactivatedhundredsofvehiclesinAustin,Texas,leaving\ntheirownerswithouttransportation[1683].\nKACyber-PhysicalSystemsSecurity |October2019 Page631 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n19.3.4 Robotics and Advanced Manufacturing\nSecurityinmanufacturinghasbeenformanyyearsapartofcriticalinfrastructuresecuritybut,\nasthemanufacturingprocessbecamemoresophisticated,thethreatshaveincreased.Wells\netal.[1614]giveahigh-levelviewabouttheconcernsofthisindustry.Theyalsomentionthat\nquality control techniques traditionally used in the manufacturing industry can be leveraged\ntodetectattacks.\nAttacks can target the structural integrity (scale, indent, or vertex) or material integrity\n(strength, roughness, or color) of the manufactured products [1684]. Physical tests, for ex-\nample,non-destructivetestssuchasvisualinspection,weightmeasure,dimensionmeasure,\n3Dlaserscanning,interferometry,X-ray,CT,anddestructivemechanicaltestslikeemploying\nthetensileandyieldpropertiesofthematerialcanhelpusindetectingattacks.\nRoboticsystemsinautomatedassemblylinescanalsobeusedtocreatedamagedpartsor\ncausesafetyproblems[1685].Safetyaccidentswithrobotsdatebackto1979,whenaworker\natFordmotorcompanywaskilledbyarobot.AspointedoutbyP.W.Singer,theFordworker\nmighthavebeenthefirst,buthewouldbefarfromthelast,asrobotshavekilledvariousother\npeople[1686].Beyondmanufacturing,roboticweaponsalsoposesignificantchallenges.For\nexample, in 2007 a software glitch in an antiaircraft system sporting two cannons began\nfiring hundreds of high-explosive rounds, and by the time they were emptied, nine soldiers\nweredead,andfourteenseriouslyinjured[1686].Wewilldiscusslaterinthisdocumenthow\nnewadvancesinCPSsmaychangethewaynationswagefuturewars.\n19.3.5 Medical Devices\nDue to their safety and privacy risks, embedded medical devices are another CPS domain\nthathasreceivedsignificantattentionintheliterature.\nWhilenotanattack,thesoftwareerroroftheTherac-25isoneofthemostwell-knownclassi-\ncal examples of how software problems can harm and even kill people. The Therac-25 was\na computer-controlled radiation therapy machine that gave massive radiation overdoses to\npatientsresultingindeathsandinjuries[1687].Ourconcernhereisiftheseproblemsarenot\naccidentalbutmalicious?\nModernImplantableMedicalDevices(IMDs)includepacemakers,defibrillators,neurostimu-\nlators, and drug delivery systems. These devices can usually be queried and reprogrammed\nbyadoctor,butthisalsoopensthesedevicesuptosecurityandprivacythreats,inparticular\nwhen an attacker can impersonate the device used by the doctor to modify the settings of\nIMDs.\nRushanan et al. [1615] and Camara et al. [1688] describe the types of adversaries that medi-\ncaldeviceswillbesubjectto,includingtheabilitytoeavesdropallcommunicationchannels\n(passive)orread,modifyandinjectdata(active).Inordertomitigatepossibleattacksinthe\ntelemetry interface, they propose authentication (e.g., biometric, distance bounding, out of\nband channels, etc.), and the use of an external wearable device that allows or denies ac-\ncess to the medical device depending on whether this extra wearable device is present. In\nadditiontoprevention,theyalsodiscussattackdetectionbyobservingpatternstodistinguish\nbetweensafeandunsafebehaviour.\nInparticular,anovelproposaltostudyproperauthenticationoftheprogrammerwiththeIMD\nisthetouch-to-accessprinciple[1608,1689].Thebasicideaisthatthepatienthasabiometric\nsignal(suchasthetimebetweenheartbeats)thatshouldonlybeavailabletootherdevices\nKACyber-PhysicalSystemsSecurity |October2019 Page632 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nin direct contact with the patient. This \u201csecret\u201d information is then used by the programmer\nandtheIMDasafuzzypasswordtobootstraptheirsecurityassociation.\nAkeychallengeistomakesurethatthebiometricsignalbeingusedtogiveaccessviatouch-\nto-access, is not remotely observable. However, heart beats can be inferred with side infor-\nmationincludingawebcam[1690],andaninfraredlaser[1691].\nSecuritygoesbeyondimplantabledevices.Ashealthcarecomputerandsoftwareinfrastruc-\ntureintroducesnewtechnology,theindustrywillneedtoincreaseitssecurityefforts.Medical\ndataisaprimetargetfortheftandprivacyviolations,anddenialofserviceattacksintheform\nofransomware[1692].\n19.3.6 The Internet of Things\nConsumer Internet of Things (IoT) devices are found everywhere: in our houses as voice-\nassistant devices, home automation smart devices, smart appliances, and surveillance sys-\ntems; in healthcare as wearable technology including fitness devices and health-monitoring\ndevices; in education including Internet-connected educational children toys; and for enter-\ntainmentincludingremotecontrolledWi-Fidevices.\nAsourlivesbecomemoredependentonthesesystems,theirsecurityhasbecomeanimpor-\ntant,growingconcern.Thesecurityofthesedevicesdependsontheintegrityofthesoftware\nandfirmwaretheyexecuteandthesecuritymechanismstheyimplement.\nNewattackvectorsmakeIoTdevicesattractivetocriminals,likebadactorsusingvulnerable\nIoT devices to orchestrate massive Distributed Denial of Service (DDoS) attacks (the Mirai\nbotnet)[682,1693],attackerswhocompromisedafishtanktopenetratetheinternalnetwork\nof a casino [1694], or attackers demanding ransomware from a hotel so they could let their\nguestsentertheirrooms[1522].\nA large number of the IoT devices included in large IoT botnets [682, 1693] include Internet-\nconnectedcameras.Internet-connectedcamerashavegivenrisetomultiplereportsofunau-\nthorised access by attackers [1695], and video feeds of multiple cameras are openly avail-\nable online and discoverable through IoT web indexing platforms like Shodan [1696], poten-\ntially compromising the privacy of consumers who do not check the default configuration\nmechanisms.ThethreatstoIoTgobeyondprivacyfearsandDDoSattacks.Vulnerabilitiesin\nconsumerIoTproductsincludingdrones,IoTcameras,smarttoysforchildren,andintimate\ndevices can lead not only to privacy invasions but also to physical damages (drones being\nused to harm people), abuse, and harassment [1697]. Understanding the consequences of\nthese new type of physical and mental abuses will require the involvement of more social\nscientistsandlegalscholarstohelpusdefineaframeworkonhowtoreasonaboutthem.\nAn area that has attracted significant attention from the research community is the security\nof voice-activated digital assistants. For example, researchers leveraged microphone non-\nlinearitiestoinjectinaudiblevoicecommandstodigitalassistants[1514].Otherrecentwork\nincludes the use of new attacks like \u201cvoice squatting\u201d or \u201cvoice masquerading\u201d to take over\nvoice-controlledapplications[1698].Forexampletheconsumermightwanttoopentheappli-\ncation \u201cCapital One\u201d, but an attacker can make an application available called \u201cCapital Won\u201d\nandthevoice-controlledpersonalassistantmightopenthesecondfunctionality.Inthe\u201cvoice\nmasquerading\u201dattack,anattackerapplicationmightremainincontrolofthesystemandpre-\ntendtobefollowingtheconsumer\u2019scommandstoopenotherfunctionalities,whileinreality\nitisimpersonatingthedesiredfunctionalities.\nKACyber-PhysicalSystemsSecurity |October2019 Page633 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nSeveral of the security solutions for consumer IoT have proposed the idea of having a cen-\ntralised IoT secure hub that mediates the communications between IoT devices in a home,\nand the Internet [1699]. One of the problems of relying on an external device to mediate IoT\ncommunications is that the connections between IoT device and the cloud servers may be\nencrypted, and therefore this hub will need to make security decisions with encrypted traf-\nfic [1700]. On the other hand, end-to-end encrypted communications can also prevent con-\nsumersfromauditingtheirIoTdevicestomakesuretheyarenotviolatingtheirprivacyexpec-\ntations.OneoptiontoaddressthisproblemistoaskthevendoroftheIoTdevicetodisclose\ntheir key (and rotate their key) to a trusted third party (called \u201cauditor\u201d) that can decrypt and\nshowtheresultstotheownersofthedata[1701].\nIn short, the proliferation of vulnerable IoT devices is raising new security and privacy\nconcerns, while making IoT devices attractive to attackers. Insecurities in these devices\nrange from insecure-by-design implementations (e.g., devices that have backdoors for trou-\nbleshooting) to their inability to apply software updates to patch vulnerable firmware. One\nofthebiggestproblemsforimprovingthesecurityofIoTand CPSsisthatmarketforcesdo\nnotincentivisevendorstocompeteforbettersecurity.Inthenextsectionwewilldiscussthe\ncausesofthislackofsecurityandsomepotentialsolutions.\n19.4 POLICY AND POLITICAL ASPECTS OF CPS SECURITY\n[1686,1702,1703]\nInthisfinalsectionofthepaperwesummarisesomeoftheindustry-andgovernment-ledef-\nfortstotrytoimprovethesecurityofCPSs,andhowtoleveragethenewfieldofCPSsecurity\nforattacksandwars.\n19.4.1 Incentives and Regulation\nMost industries in the CPS domain have rarely seen attacks sabotaging their physical pro-\ncess, in part because CPS attacks are hard to monetise by criminals. In addition to being\nrare, attacks on CPSs are not openly reported, and this lack of actuarial data leads to low\nquality risk estimates; as the US Department of Energy (DoE) stated in their Energy Delivery\nSystemsCyberSecurityRoadmap[1704]:\u201cMakingastrongbusinesscaseforcybersecurity\ninvestmentsiscomplicatedbythedifficultyofquantifyingriskinanenvironmentof(1)rapidly\nchanging,(2)unpredictablethreats,(3)withconsequencesthatarehardtodemonstrate.\u201d\nInsummary,marketincentivesaloneareinsufficienttoimprovethesecuritypostureofCPSs,\nand as a result, our CPS infrastructures remain fairly vulnerable to computer attacks and\nwith security practices that are decades behind the current security best practices used in\nenterpriseITdomains.ThismarketfailureforimprovingthesecurityofCPSshasresultedin\nseveralcallsforgovernmentintervention[1705,1706,1707].\nRegulation: Mandating cyber security standards that the CPS industries have to follow is a\npossible government intervention, and there is some precedent for this idea. Before 2003,\nthe North American Electric Reliability Corporation (NERC) merely suggested standards to\nthe power systems operators in the US but after the August 2003 blackout, regulations that\nwere once optional are now mandatory [1610]. However, CPS industries have pushed back\nagainstregulation,arguingthatregulations(e.g.,mandatingcompliancetospecificsecurity\nstandards)willstifleinnovation,andthatmoreregulationtendstocreateacultureofcompli-\nanceinsteadofacultureofsecurity.\nKACyber-PhysicalSystemsSecurity |October2019 Page634 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nSomestatesintheUSarestartingtotakeregulationintotheirhands;forexample,therecently\nproposed California Senate Bill SB-327 will make California the first state in the US with an\nIoTcybersecuritylaw\u2014startingin2020,anymanufacturerofadevicethatconnects\u201cdirectly\nor indirectly\u201d to the Internet must equip it with \u201creasonable\u201d security features, designed to\npreventunauthorisedaccess,modification,orinformationdisclosure.\nTheEuropeanUnionAgencyforcybersecurityproposedtheEUNetworkandInformationSe-\ncuritydirective[1708]asthefirstpieceofEU-widecybersecuritylegislation,whereoperators\nof essential services such as those outlined in this KA have to comply with these new sets\nofstandards.\nAnotheralternativetoimposingregulationbroadly,istousethegovernments\u2019\u201cpowerofthe\npurse\u201d by mandating cyber security standards only to companies that want to do business\nwiththegovernment.Thegoalwouldbethatoncethebestsecuritypracticesaredeveloped\ntomeetthestandardsforworkingwiththegovernment,thentheywillspreadtoothermarkets\nandproducts.Thisapproachisareasonablebalancebetweenincentivesandregulation.Only\nCPSandIoTvendorsworkingwiththeFederalgovernmentwillhavetofollowspecificsecurity\nstandards, but once they are implemented, the same security standards will benefit other\nmarketswheretheyreusethetechnologies.\nOneofthenotableexceptionstothelackofregulationisthenuclearenergyindustry.Because\nofthehighlysafety-criticalnatureofthisindustry,nuclearenergyishighlyregulatedingeneral,\nand in cyber security standards in particular, with processes such as the Office for Nuclear\nRegulation(ONR)SecurityAssessmentPrinciplesintheUK[1709].\nIncentives: A complementary way to nudge companies to improve their cyber security pos-\nture is for governments to nurture a cyber-insurance market for CPS protection. So, instead\nofaskingcompaniestofollowspecificstandards,governmentswoulddemandfirmstohave\ncyber-insurance for their operations [1710, 1711, 1712, 1713]. There is a popular view that un-\ndercertainconditions,theinsuranceindustrycanincentiviseinvestmentsinprotection[1714].\nThe idea is that premiums charged by the insurance companies would reflect the cyber se-\ncurity posture of CPS companies; if a company follows good cyber security practices, the\ninsurance premiums would be low, otherwise, the premiums would be very expensive (and\nthiswouldinprincipleincentivisethecompanytoinvestmoreincybersecurityprotections).\nIt is not clear if this cyber-insurance market will grow organically, or if it would need to be\nmandatedbythegovernment.\nIt is unclear if government incentives to improve security in CPSs will require first a catas-\ntrophic cyber-attack, but it appears that, in the future, the choice will no longer be between\ngovernment regulation and no government regulation, but between smart government regu-\nlationandstupidregulation[1702].\nKACyber-PhysicalSystemsSecurity |October2019 Page635 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n19.4.2 Cyber-Conflict\nComputernetworksenableanextensiontothewayweinteractwithothers,andanyconflict\ninthereal-world,willhaveitsrepresentationincyberspace;including(cyber-)crime,activism,\nbullying,espionage,andwar[1477].\nCybercriminals compromise computers anywhere they can find them (even in control sys-\ntems). These attacks may not be targeted (i.e., they do not have the intention of harming\ncontrol systems), but may cause negative side effects: control systems infected with mal-\nwaremayoperateinappropriately.Themostfamousnon-targetedattackoncontrolsystems\noccurredin2003,whentheSlammerwormaffectedthecomputerisedsafetymonitoringsys-\ntem at the Davis-Besse nuclear power plant in the US. While the plant was not connected to\nthe Internet, the worm entered the plant network via a contractor\u2019s infected computer con-\nnected by telephone directly to the plant\u2019s network, thereby bypassing the firewall [1515]. A\nmore recent example of a non-targeted attack occurred in 2006, when a computer system\nthatmanagedthewatertreatmentoperationsofawaterfilteringplantnearHarrisburghPen-\nsylvania, was compromised and used to send spam and redistribute illegal software [1516].\nMorerecently,ransomwarehasalsobeenusedtoattackCPSs,liketheattackontheAustrian\nhotel [1522], where guests were unable to get their room keys activated until the hotel paid\ntheransom.\nDisgruntledemployeesareamajorsourceoftargetedcomputerattacksagainstcontrolsys-\ntems [797, 1521, 1524]. These attacks are important from a security point of view because\nthey are caused by insiders: individuals with authorised access to computers and networks\nused by control systems. So, even if the systems had proper authentication and authorisa-\ntion,aswellaslittleinformationpubliclyavailableaboutthem,attacksbyinsiderswouldstill\nbepossible.Becausedisgruntledemployeesgenerallyactalone,thepotentialconsequences\nof their attacks may not be as damaging as the potential harm caused by larger organised\ngroupssuchasterroristsandnationstates.\nTerrorists, and activists are another potential threat to control systems. While there is no\nconcreteevidencethatterroristsoractivistshavetargetedcontrolsystemsviacyber-attacks,\nthereisagrowingthreatofsuchanattackinthefuture.\nNation states are establishing military units with computer security expertise for any future\nconflicts. For example, the US established Cyber Command [1715] to conduct full spectrum\noperations(offensivecapabilities)in2009,andseveralothercountriesalsoannouncedsimi-\nlareffortsaroundthesametime.Theroleofcomputernetworksinwarfarehasbeenatopic\nofacademicdiscussionsince1998[1716],andCPSsareplayingafoundationaldifferenceon\nhow wars are waged, from robotic units and unmanned vehicles supporting soldiers in the\nfield,todiscussionsofcyberwar[1717].\nInadditiontoland,air,seaandspace,cyberspaceisnowconsideredbymanynationsasan\nadditional theatre of conflict. International treaties have developed public international law\nconcerningtwomainprinciplesinthelawofwar(1)jusadbellumtherighttowageawar,and\n(2) jus in bellum acceptable wartime conduct. Two sources have considered how the law of\nwarappliestocyberspace[1703]:(1)TheTallinnManual,and(2)theKohSpeech.\nTheTallinnmanualisanon-bindingstudybyNATO\u2019scooperativecyber-defencecenterofex-\ncellence,onhowthelawofwarappliestocyberconflicts,andtheKohSpeechwasaspeech\ngivenbyHaroldKoh,aUSStateDepartmentlegaladvisor,whichexplainedhowtheUSinter-\npretsinternationallawappliedtocyberspace.Bothofthesesourcesagreethatakeyreason\nto authorise the use of force (jus ad bellum) as a response to a cyber operation, is when the\nKACyber-PhysicalSystemsSecurity |October2019 Page636 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nphysicaleffectsofacyber-attackarecomparabletokineticeffectsofotherarmedconflicts,\nfor example, when a computer attack triggers a nuclear plant meltdown, opens a dam up-\nriver, or disables air-traffic control. The argument is that the effects of any of these attacks\naresimilartowhatamissilestrikefromanenemywouldlooklike.Incontrast,whenthereis\nnophysicalharm,theproblemofdeterminingwhenacyber-attackcanbeconsideredauseof\nforcebytheenemyisunresolved,socyber-attackstothefinancial,orelectioninfrastructure\nofanationmaynotclearthebartobeconsideredanactofwar.\nOncenationsareengagedinwar,thequestionishowtoleveragecomputerattacksinaway\nthat is consistent with acceptable wartime conduct (jus in bellum). The conventional norm\nis that attacks must distinguish between military and non-military objectives. Military objec-\ntives can include war-fighting, war-supporting, and war-sustaining efforts. The problem in\nattackingcriticalinfrastructuresisthatsomeoftheinfrastructuressupportingtheseefforts\nare in dual-use by the military as well as by the civilian population. For example, a large per-\ncentage of military communications in the US use civilian networks at some stage, and the\npowergridsupportsmilitaryaswellascivilianinfrastructures.\nAnother factor to consider in designing CPS attacks is that the \u201claw of war\u201d in general pro-\nhibitsuncontrollableorunpredictableattacks,inparticularthosethatdenythecivilianpopu-\nlationofindispensableobjects,suchasfoodorwater.Whilephysicalweaponshavealimited\ngeographical area of impact, cyberweapons can have more uncontrollable side-effects; for\nexample,wormscanreplicateandescapetheirintendedtargetnetworkandinfectcivilianin-\nfrastructures. Therefore, nations will have to extensively test any cyberweapon to minimise\nunpredictableconsequences.\nInshort,anyfutureconflictinthephysicalworldwillhaveenablingtechnologiesinthecyber-\nworld,andcomputerattacksmaybeexpectedtoplayanintegralpartinfutureconflicts.There\nis a large grey area regarding what types of computer attacks can be considered an act of\nforce,andafuturechallengewillbetodesigncyber-attacksthatonlytargetmilitaryobjectives\nand minimise civilian side effects. At the same time, attack attribution in cyber-space will\nbe harder, and nation-states might be able to get away with sabotage operations without\nfacingconsequences.Itisaresponsibilityoftheinternationalcommunitytodesignnewlegal\nframeworkstocovercyber-conflicts,andfornationstatestooutlinenewdoctrinescovering\nhowtoconductcyber-operationswithphysicalsideeffects.\nFinally, cyberwar is also related to the discussion in the last section about cyber-insurance.\nFor example, after the NotPetya cyberattack in 2017 [1718], several companies who had pur-\nchased cyber-insurance protections sought to get help from their insurance companies to\ncoverpartoftheirloses.However,someinsurancecompaniesdeniedtheclaimscitingawar\nexclusionwhichprotectsinsurersfrombeingsaddledwithcostsrelatedtodamagefromwar.\nSince then insurers have been applying the war exemption to avoid claims related to digital\nattacks 2. This type of collateral damage from cyber-attacks might be more common in the\nfuture,andpresentsachallengeforinsuranceindustriesintheirquesttoquantifytheriskof\ncorrelatedlarge-scaleevents.\n2https:\/\/www.nytimes.com\/2019\/04\/15\/technology\/cyberinsurance-notpetya-attack.html\nKACyber-PhysicalSystemsSecurity |October2019 Page637 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n19.4.3 Industry Practices and Standards\nWe finalise the CPS Security KA by referencing various industry and government efforts for\nimproving the security of CPSs. There are several industrial and government-led efforts to\nimprove the security of control systems. One of the most important security standards in\nthis space started with the Instruction Set Architecture (ISA) standard ISA 99, which later\nbecame a US standard with ANSI 62443 and finally an international cyber security standard\nforcontrolsystemsknownasIEC62443[1719].\nThe US National Institute of Standards and Technology (NIST) has guidelines for security\nbest practices for general IT in Special Publication 800-53. US Federal agencies must meet\nNIST SP 800-53, but industry in general (and industry dealing with the US government in\nparticular) uses these recommendations as a basis for their security posture. To address\nthe security of control systems in particular, NIST has also published a Guide to Industrial\nControlSystem(ICS)Security[1609],aguidelinetosmartgridsecurityinNIST-IR762[1720],\nandaguidelineforIoTsecurityandprivacy[1534].Althoughtheserecommendationsarenot\nenforceable,theycanprovideguidanceforanalysingthesecurityofmostutilitycompanies.A\nmorerecenteffortistheNISTcybersecurityframeworkforprotectingcriticalinfrastructure,\nwhichwasinitiatedbyanExecutiveOrderfromthenUSPresidentObama[1721],asaneffort\ntoimprovethesecuritypostureofcriticalinfrastructures.\nAnother notable industry-led effort for protecting critical infrastructures is the North\nAmerican Electric Reliability Corporation (NERC) cyber security standards for control sys-\ntems[1611].NERCisauthorisedtoenforcecompliancetothesestandards,anditisexpected\nthatallelectricutilitiesoperatingthebulkpowersysteminNorthAmericaarefullycompliant\nwiththesestandards.\nAllofthesestandardsaregeneralandflexible.Insteadofprescribingspecifictechnologyso-\nlutions, they give a high-level overview of the variety of security technologies available (e.g.,\nauthentication, access control, network segmentation, etc.), and then give a set of general\nproceduresforprotectingsystems,startingwith(1)gatheringdatatoidentifytheattacksur-\nface of a given system (this includes a basic network enumeration procedure that seeks to\nenumerate all devices and services available in the network of the asset owner), (2) build-\ning a security policy based on the attack surface of the system, and (3) deploy the security\ncountermeasures,includingnetworksegmentation,ornetworksecuritymonitoring.\nIn addition to these general security standards for control systems, the industries that de-\nvelopandmaintainspecificindustrialcontrolprotocols,suchasthoseusedforSCADA,e.g.,\nIEC 104, or those in the process industry, e.g., PROFINET, have also released standards and\ndocumentation for securing industrial networks. Recall that most of these industrial proto-\ncols were developed before security was a pressing concern for industrial control systems,\ntherefore the communication links were not authenticated or encrypted. The new standard\nIEC62351ismeanttoguideassetownersonhowtodeployasecurenetworktoauthenticate\nand encrypt network links, and other organisations have released similar support, such as,\nproviding security extensions for PROFINET3. Instead (or in addition) to using these end-to-\nend application layer security recommendations, some operators might prefer to use lower-\nlayersecurityprotectionsofIPnetworks,includingTLSandIPSec.\nIn the IoT domain, ETSI, the European Standards Organisation developed the first globally-\napplicablesecuritystandardforconsumerIoT.ETSITS103645establishesasecuritybase-\nlineforInternet-connectedconsumerproductsandprovideabasisforfutureIoTcertification.\n3https:\/\/www.profibus.com\/download\/pi-white-paper-security-extensions-for-profinet\/\nKACyber-PhysicalSystemsSecurity |October2019 Page638 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nThis standard builds closely on the UK\u2019s Code of Practice for Consumer IoT Security [1722].\nAnothermorespecificIoTstandardbytheInternetEngineeringTaskForce(IETF)forIoTde-\nvicesistheManufacturerUsageDescription(MUD)standard[1723].Thegoalofthisstandard\nistoautomatethecreationofnetworkwhitelists,whichareusedbynetworkadministrators\ntoblockanyunauthorisedconnectionbythedevice.OtherIoTsecuritystandardsbeingdevel-\noped by the IETF include protocols for communications security, access control, restricting\ncommunications,andfirmwareandsoftwareupdates[1724].\nAll these industry efforts and standards have essentially three goals: (1) create awareness\nofsecurityissuesincontrolsystems,(2)helpoperatorsofcontrolsystemsandsecurityoffi-\ncersdesignasecuritypolicy,and(3)recommendbasicsecuritymechanismsforprevention\n(authentication, access controls, etc), detection, and response to security breaches. For the\nmost part industry efforts for protecting CPSs are based on the same technical principles\nfromgeneralInformationTechnologysystems.Therefore,industrybestpracticesarebehind\ngeneral IT security best practices and the most recent CPS security research discussed in\nthis KA. We hope that in the next decade CPS security research becomes mature enough to\nstarthavinganimpactonindustrypractices.\nCONCLUSIONS\nAs technology continues to integrate computing, networking, and control elements in new\ncyber-physical systems, we also need to train a new generation of engineers, computer sci-\nentists,andsocialscientiststobeabletocapturethemultidisciplinarynatureofCPSsecurity,\nliketransductionattacks.Inaddition,asthetechnologiesbehindCPSsecuritymature,some\nof them will become industry-accepted best practices while others might be forgotten. In\n2018, one of the areas with greatest momentum is the industry for network security mon-\nitoring (intrusion detection) in cyber-physical networks. Several start-up companies in the\nUS, Europe, and Israel offer services for profiling and characterising industrial networks, to\nhelp operators better understand what is allowed and what should be blocked. On the other\nhand,thereareotherCPSsecurityresearchareasthatarejuststartingtobeanalysed,likethe\nwork on attack mitigation, and in particular, the response to alerts from intrusion detection\nsystems.\nWeareonlyatthestartingpointforCPSsecurityresearch,andthedecadestocomewillbring\nnewchallengesaswecontinuetointegratephysicalthingswithcomputingcapabilities.\nKACyber-PhysicalSystemsSecurity |October2019 Page639 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nCROSS-REFERENCE OF TOPICS VS REFERENCE MATERIAL\nOther\n19.1Cyber-PhysicalSystemsandtheirSecurityRisks\n19.1.1CharacteristicsofCPS c1 [1467]\n19.1.2ProtectionsAgainstNaturalEventsandAccidents [1468]\n19.1.3SecurityandPrivacyConcerns [1469]\n19.2CrosscuttingSecurity\n19.2.1PreventingAttacks c6,c9 [1534]\n19.2.2DetectingAttacks c18 [1535]\n19.2.3MitigatingAttacks [1536]\n19.3CPSDomains\n19.3.1IndustrialControlSystems [1609]\n19.3.2ElectricPowerGrids c25 [1610,1611]\n19.3.3TransportationSystemsandAutonomousVehicles c26,c29 [1612,1613]\n19.3.4RoboticsandAdvancedManufacturing [1614]\n19.3.5MedicalDevices c27 [1615]\n19.3.6TheInternetofThings [1534]\n19.4PolicyandPoliticalAspectsofCPSSecurity\n19.4.1IncentivesandRegulation [1702]\n19.4.2Cyber-Conflict [1686,1703]\n19.4.3IndustryPracticesandStandards [1609]\nKACyber-PhysicalSystemsSecurity |October2019 Page640\n]5271[koobdnah2102sad Chapter 20\nPhysical Layer Security\nand Telecommunications\nSrdjan \u010capkun ETH Zurich\n641 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nINTRODUCTION\nThisKnowledgeAreaisareviewofthemostrelevanttopicsinwirelessphysicallayersecurity.\nThephysicalphenomenonutilizedbythetechniquespresentedinthisKnowledgeAreaisthe\nradiation of electromagnetic waves. The frequencies considered hereinafter consist of the\nentire spectrum that ranges from a few Hertz to frequencies beyond those of visible light\n(optical spectrum). This Knowledge Area covers concepts and techniques that exploit the\nway these signals propagate through the air and other transmission media. It is organised\ninto sections that describe security mechanisms for wireless communication methods as\nwellassomeimplicationsofunintendedradiofrequencyemanations.\nSincemostfrequenciesusedforwirelesscommunicationresideintheradiofrequencyspec-\ntrum and follow the well-understood laws of radio propagation theory, the majority of this\nKnowledge Area is dedicated to security concepts based on physical aspects of radio fre-\nquency transmission. The chapter therefore starts with an explanation of the fundamental\nconcepts and main techniques that were developed to make use of the wireless communi-\ncation layer for confidentiality, integrity, access control and covert communication. These\ntechniques mainly use properties of physical layer modulations and signal propagation to\nenhancethesecurityofsystems.\nAfterhavingpresentedschemestosecurethewirelesschannel,theKnowledgeAreacontin-\nues with a review of security issues related to the wireless physical layer, focusing on those\naspectsthatmakewirelesscommunicationsystemsdifferentfromwiredsystems.Mostno-\ntably, signal jamming, signal annihilation and jamming resilience. The section on jamming\nis followed by a review of techniques capable of performing physical device identification\n(i.e., device fingerprinting) by extracting unique characteristics from the device\u2019s (analogue)\ncircuitry.\nFollowingthis,thechaptercontinuestopresentapproachesforperformingsecuredistance\nmeasurements and secure positioning based on electromagnetic waves. Protocols for dis-\ntancemeasurementsandpositioningaredesignedinordertothwartthreatsonthephysical\nlayer as well as the logical layer. Those attack vectors are covered in detail, together with\ndefensestrategiesandtherequirementsforsecurepositionverification.\nThen, the Knowledge Area covers unintentional wireless emanations from devices such as\nfromcomputerdisplaysandsummariseswirelessside-channelattacksstudiedinliterature.\nThis is followed by a review on spoofing of analogue sensors. Unintentional emissions are\nin their nature different from wireless communication systems, especially because these\ninteractions are not structured. They are not designed to carry information, however, they\nalsomakeuseof\u2014orcanbeaffectedby\u2014electromagneticwaves.\nFinally, after having treated the fundamental concepts of wireless physical security, this\nKnowledgeAreapresentsaselectionofexistingcommunicationtechnologiesanddiscusses\ntheirsecuritymechanisms.Itexplainsdesignchoicesandhighlightspotentialshortcomings\nwhilereferringtotheprinciplesdescribedintheearliersections.Includedareexamplesfrom\nnear-field communication and wireless communication in the aviation industry, followed by\nthe security considerations of cellular networks. Security of global navigation systems and\nof terrestrial positioning systems is covered last since the security goals of such systems\nare different from communication systems and are mainly related to position spoofing re-\nsilience.\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page642 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nCONTENT\n20.1 PHYSICAL LAYER SCHEMES FOR CONFIDENTIALITY,\nINTEGRITY AND ACCESS CONTROL\n[1551,1726,1727,1728,1729,1730]\nSecuringwirelessnetworksischallengingduetothesharedbroadcastmediumwhichmakes\nit easy for remote adversaries to eavesdrop, modify and block the communication between\ndevices.However,wirelesscommunicationalsoofferssomeuniqueopportunities.Radiosig-\nnals are affected by reflection, diffraction, and scattering, all of which contribute to a com-\nplex multi-path behaviour of communicated signals. The channel response, as measured at\nthereceiver,canthereforebemodelledashavingfrequencyandpositiondependentrandom\ncomponents.Inaddition,withintheshorttimespanandintheabsenceofinterference,com-\nmunicatingpartieswillmeasurehighlycorrelatedchannelresponses.Theseresponsescan\ntherefore be used as shared randomness, unavailable to the adversary, and form a basis of\nsecurecommunication.\nIt should be noted that modern-day cryptography provides many different protocols to as-\nsure the confidentiality, integrity and authenticity of data transmitted using radio signals. If\nthe communicating parties are associated with each other or share a mutual secret, cryp-\ntographic protocols can effectively establish secure communication by making use of cryp-\ntographic keying material. However, if mere information exchange is not the only goal of a\nwirelesssystem(e.g.,inapositioningsystem),orifnopre-sharedsecretsareavailable,cryp-\ntographic protocols operating at higher layers of the protocol stack are not sufficient and\nphysical-layer constructs can be viable solutions. The main physical layer schemes are pre-\nsentedinthefollowingsections.\n20.1.1 Key Establishment based on Channel Reciprocity\nThe physical-layer randomness of a wireless channel can be used to derive a shared secret.\nOne of the main security assumptions of physical-layer key establishment schemes is that\nthe attacker is located at leasthalf a wavelengthaway from the communicating parties. Ac-\ncording to wireless communication theory, it can be assumed that the attacker\u2019s channel\nmeasurements will be de-correlated from those computed by the communicating parties if\nthey are at least half a wavelength apart. The attacker will therefore likely not have access\nto the measured secret randomness. If the attacker injects signals during the key genera-\ntion, the signal that it transmits will, due to channel distortions, be measured differently at\ncommunicatingparties,resultinginkeydisagreement.\nPhysical layer key establishment schemes operate as follows. The communicating parties\n(Alice and Bob) first exchange pre-agreed, non-secret, data packets. Each party then mea-\nsures the channel response over the received packets. The key agreement is then typically\nexecutedinthreephases.\nQuantisation Phase: Alice and Bob create a time series of channel properties that are mea-\nsuredoverthereceivedpackets.ExamplepropertiesincludeRSSIandtheCIR.Anyproperty\nthat is believed to be non-observable by the attacker can be used. The measured time se-\nriesarethenquantisedbybothpartiesindependently.Thisquantisationistypicallybasedon\nfixedordynamicthresholds.\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page643 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nInformationReconciliationPhase:Sincethequantisationphaseislikelytoresultindisagree-\ning sequences at Alice and Bob, they need to reconcile their sequences to correct for any\nerrors.Thisistypicallydoneleveragingerrorcorrectingcodesandprivacyamplificationtech-\nniques.Mostschemesusesimplelevel-crossingalgorithmsforquantisationanddonotuse\ncoding techniques. However, if the key derivation uses methods based on channel states\nwhose distributions are not necessarily symmetric, more sophisticated quantisation meth-\nods, such as approximating the channel fading phenomena as a Gaussian source, or (multi-\nlevel)codingisneeded[1727].\nKey Verification Phase: In this last phase, communicating parties confirm that they estab-\nlishedasharedsecretkey.Ifthisstepfails,thepartiesneedtorestartkeyestablishment.\nMost of the research in physical-layer techniques has been concerned with the choice of\nchannel properties and of the quantisation technique. Even if physical-layer key establish-\nment techniques seem attractive, many of them have been shown to be vulnerable to ac-\ntive, physically distributed and multi-antenna adversaries. However, in a number of scenar-\nioswherethedevicesaremobile,andwheretheattackerisrestricted,theycanbeavaluable\nreplacementorenhancementtotraditionalpublic-keykeyestablishmenttechniques.\n20.1.2 MIMO-supported Approaches: Orthogonal Blinding, Zero-Forcing\nInitially, physical-layer key establishment techniques were proposed in the context of single-\nantenna devices. However, with the emergence of MIMO devices and beam-forming, re-\nsearchers have proposed to leverage these new capabilities to further secure communica-\ntion. Two basic techniques that were proposed in this context are orthogonal blinding and\nzeroforcing.Bothofthesetechniquesaimtoenablethetransmittertowirelesslysendconfi-\ndentialdatatotheintendedreceiver,whilepreventingtheco-locatedattackerfromreceiving\nthis data. Although this might seem infeasible, since as well as the intended receiver, the\nattacker can receive all transmitted packets. However, MIMO systems allow transmitters to\n\u2019steer\u2019 the signal towards the intended receiver. For beam-forming to be effective, the trans-\nmitter needs to know some channel information for the channels from its antennas to the\nantennas of the receiver. As described in [1729], these channels are considered to be secret\nfrom the attacker. In Zero-Forcing, the transmitter knows the channels to the intended re-\nceiver as well as to the attacker. This allows the transmitter to encode the data such that it\ncanbemeasuredatthereceiver,whereastheattackermeasuresnothingrelatedtothedata.\nInmanyscenarios,assumingtheknowledgeofthechanneltotheattackersisunrealistic.In\nOrthogonalBlinding,thetransmitterdoesn\u2019tknowthechanneltotheattacker,butknowsthe\nchannels to the receiver. The transmitter then encodes the data in the way that the receiver\ncan decode the data, whereas the attacker will receive data mixed with random noise. The\nattacker therefore cannot decode the data. In order to communicate securely, the transmit-\nter and the receiver do not need to share any secrets. Instead, the transmitter only needs\nto know (or measure) the channels to the intended receivers. Like physical-layer key estab-\nlishmenttechniques,thesetechniqueshavebeenshowtobevulnerabletomulti-antennaand\nphysicallydistributedattackers.Theywerefurthershowntobevulnerabletoknown-plaintext\nattacks.\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page644 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n20.1.3 Secrecy Capacity\nSecrecycapacityisaninformation-theoreticalconceptthatattemptstodeterminethemaxi-\nmalrateatwhichawirelesschannelcanbeusedtotransmitconfidentialinformationwithout\nrelying on higher-layer encryption, even if there is an eavesdropper present. A famous result\nbyShannon[1731]saysthat,foranadversarywithunboundedcomputingpower,uncondition-\nallysecuretransmissioncanonlybeachievedifaone-time-padcipherisusedtoencryptthe\ntransmitted information. However, Wyner later showed that if the attacker\u2019s channel slightly\ndegradestheinformation,thatis,thechannelisnoisy,thesecrecycapacitycanindeedbepos-\nitive under certain conditions [1732]. This means it is possible to convey a secret message\nwithout leaking any information to an eavesdropper. Csisz\u00e1r and Korner extended Wyner\u2019s\nresultbyshowingthatthesecrecycapacityisnon-zero,unlesstheadversary\u2019schannel(wire-\ntap channel) is less noisy than the channel that carries the message from the legitimate\ntransmitter to the receiver [1733]. These theoretical results have been refined for concrete\nchannelmodelsbyassumingacertaintypeofnoise(e.g.,Gaussian)andchannellayout(e.g.,\nSIMO and MIMO). Researchers have managed to derive explicit mathematical expressions\nand bounds even when taking into account complex phenomena such as fading which is\npresentinwirelesschannels[1734].\nA practical implementation of the concept of secrecy capacity can mainly be achieved us-\ning the two methods described above. Either the communicating parties establish a secret\nkey by extracting features from the wireless channel (see 20.1.1) or they communicate with\neach other using intelligent coding and transmission strategies possibly relying on multi-\nple antennas (see 20.1.2). Therefore, the study of secrecy capacity can be understood as\nthe information-theoretical framework for key establishment and MIMO-supported security\nmechanismsinthecontextofwirelesscommunication.\n20.1.4 Friendly Jamming\nSimilartoOrthogonalBlinding,FriendlyJammingschemesusesignalinterferencegenerated\nbycollaboratingdevicestoeitherpreventanattackerfromcommunicatingwiththeprotected\ndevice, or to prevent the attacker from eavesdropping on messages sent by protected de-\nvices. Friendly Jamming can therefore be used for both confidentiality and access control.\nUnlikeOrthogonalBlinding,FriendlyJammingdoesn\u2019tleveragetheknowledgeofthechannel\nto the receiver. If a collaborating device (i.e., the friendly jammer) wants to prevent unautho-\nrised communication with the protected device it will jam the receiver of the protected de-\nvice. If it wants to prevent eavesdropping, it will transmit jamming signals in the vicinity of\ntheprotecteddevice.Preventingcommunicationwithaprotecteddevicerequiresnospecial\nassumptionsonthelocationofthecollaboratingdevices.However,protectingagainsteaves-\ndroppingrequiresthattheeavesdropperisunabletoseparatethesignalsfromtheprotected\ndevice from those originating at the collaborating device. For this to hold, the channel from\nthe protected device to the attacker should not be correlated to the channel from the col-\nlaborating device to the attacker. To ensure this, the protected device and the collaborating\ndeviceneedtobetypicallyplacedlessthanhalfacarrierwavelengthapart.Thisassumption\nisbased onthe factthat, intheory,an attacker withmultiple antennaswho triesto tellapart\nthe jamming signal from the target signal requires the two transmitters to be separated by\nmorethanhalfawavelength.However,signaldeteriorationisgradualandithasbeenshown\nthat under some conditions, a multi-antenna attacker will be able to separate these signals\nandrecoverthetransmittedmessages.\nFriendlyjammingwasoriginallyproposedfortheprotectionofthosemedicalimplants(e.g.,\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page645 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nalready implanted pacemakers) that have no abilities to perform cryptographic operations.\nThemainideawasthatthecollaboratingdevice(i.e.\u2019theshield\u2019)wouldbeplacedaroundthe\nuser\u2019sneck,closetothepacemaker.Thisdevicewouldthensimultaneouslyreceiveandjam\nall communication from the implant. The shield would then be able to forward the received\nmessagestoanyotherauthoriseddeviceusingstandardcryptographictechniques.\n20.1.5 Using Physical Layer to Protect Data Integrity\nResearch into the use of physical layer for security is not only limited to the protection of\ndata confidentiality. Physical layer can also be leveraged to protect data integrity. This is il-\nlustratedbythefollowingscenario.Assumingthattwoentities(AliceandBob)shareacom-\nmon radio communication channel, but do not share any secrets or authentication material\n(e.g.,sharedkeysorauthenticatedpublickeys),howcanthemessagesexchangedbetween\ntheseentitiesbeauthenticatedandhowcantheirintegritybepreservedinthepresenceofan\nattacker?Here,bymessageintegrity,wemeanthatthemessagemustbeprotectedagainst\nanymaliciousmodification,andbymessageauthenticationwemeanthatitshouldbeclear\nwhoisthesenderofthemessage.\nOne basic technique that was proposed in this context is integrity codes, a modulation\nscheme that provides a method of ensuring the integrity (and a basis for authentication) of\namessagetransmittedoverapublicchannel.Integritycodesrelyontheobservationthat,in\na mobile setting and in a multi-path rich environment, it is hard for the attacker to annihilate\nrandomlychosensignals.\nIntegritycodesassumeasynchronisedtransmissionbetweenthetransmitterandareceiver,\naswellasthereceiverbeingawarethatitisintherangeofthetransmitter.Totransmitames-\nsage,thesenderencodesthebinarymessageusingaunidirectionalcode(e.g.,aManchester\ncode), resulting in a known ration of 1s and 0s within an encoded message (for Manchester\ncode,thenumberof1sand0swillbeequal).Thisencodedmessageisthentransmittedusing\non-offkeying,suchthateach0istransmittedasanabsenceofsignalandeach1asarandom\nsignal. To decode the message and check its integrity, the receiver simply measures the en-\nergyofthesignal.Iftheenergyinatimeslotisaboveafixedthreshold,thebitisinterpreted\nas a 1 and if it is below a threshold, it is interpreted as a 0. If the ratio of bits 1 and 0 cor-\nresponds to the encoding scheme, the integrity of the message is validated. Integrity codes\nassume that the receiver knows when the transmitter is transmitting. This means that their\ncommunicationneedstobescheduledorthetransmitterneedstoalwaysbetransmitting.\n20.1.6 Low Probability of Intercept and Covert Communication\nLPIsignalsaresuchsignalsthataredifficulttodetectfortheunintendedrecipient.Thesim-\nplest form of LPI is communication at a reduced power and with high directionality. Since\nsuch communication limits the range and the direction of communication, more sophisti-\ncated techniques were developed: Frequency Hopping, Direct Sequence Spread Spectrum\nand Chirping. In Frequency Hopping the sender and the receiver hop between different fre-\nquency channels thus trying to avoid detection. In Direct Sequence Spread Spectrum the in-\nformationsignalismodulatedwithahighrate(andthushighbandwidth)digitalsignal,thus\nspreading across a wide frequency band. Finally, Chirps are high speed frequency sweeps\nthat carry information. The hopping sequence or chirp sequence constitute a secret shared\nbetweenreceiverandtransmitter.Thisallowsthelegitimatereceivertorecombinethesignal\nwhileaneavesdropperisunabletodoso.\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page646 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nCovert communication is parasitic and leverages legitimate and expected transmissions to\nenable unobservable communication. Typically, such communication hides within the ex-\npectedandtolerateddeviationsofthesignalfromitsnominalform.Oneprominentexample\nisembeddingofcommunicatedbitswithinthemodulationerrors.\n20.2 JAMMING AND JAMMING-RESILIENT\nCOMMUNICATION\n[1735,1736]\nCommunication jamming is an interference that prevents the intended receiver(s) from suc-\ncessfully recognising and decoding the transmitted message. It happens when the jammer\ninjectsasignalwhich,whencombinedwiththelegitimatetransmission,preventsthereceiver\nfrom extracting the information contained in the legitimate transmission. Jamming can be\nsurgicalandaffectonlythemessagepreamblethuspreventingdecoding,orcanbecompre-\nhensiveandaimtoaffecteverysymbolinthetransmission.\nDepending on their behaviour, jammers can be classified as constant or reactive. Constant\njammers transmit permanently, irrespective of the legitimate transmission. Reactive jam-\nmers are most agile as they sense for transmission and then jam. This allows them to save\nenergyaswellastostayundetected.Jammerstrengthistypicallyexpressedintermsoftheir\noutput power and their effectiveness as the jamming-to-signal ratio at the receiver. Beyond\nacertainjamming-to-signalratio,thereceiverwillnotbeabletodecodetheinformationcon-\ntainedinthesignal.Thisratioisspecifictoparticularreceiversandcommunicationschemes.\nThe main parameters that influence the success of jamming are transmission power of the\njammer and benign transmitter, their antenna gains, communication frequency, and their re-\nspective distances to the benign receiver. These parameters will determine the jamming-to-\nsignalratio.\nCountermeasuresagainstjamminginvolveconcealingfromtheadversarywhichfrequencies\nare used for communication at which time. This uncertainty forces the adversary to jam a\nwider portion of the spectrum and therefore weakens their impact on the legitimate trans-\nmission,effectivelyreducingthejamming-to-signalratio.Mostcommontechniquesinclude\nChirp, FHSS and DSSS. Typically, these techniques rely on pre-shared secret keys, in which\ncasewecallthecommunication\u2019coordinated\u2019.Recently,toenablejammingresilienceinsce-\nnarios in which keys cannot be pre-shared (e.g., broadcast), uncoordinated FHSS and DSSS\nschemeswerealsoproposed.\n20.2.1 Coordinated Spread Spectrum Techniques\nCoordinatedSpreadSpectrumtechniquesareprevalentjammingcountermeasuresinanum-\nberofcivilianandmilitaryapplications.Theyareusednotonlytoincreaseresiliencetojam-\nming,butalsotocopewithinterferencefromneighboringdevices.Spreadingisusedinpracti-\ncallyallwirelesscommunicationtechnologies,ine.g.,802.11,cellular,Bluetooth,globalsatel-\nlitepositioningsystems.\nSpread spectrum techniques are typically effective against jammers that cannot cover the\nentire communication spectrum at all times. These techniques make a sender spread a sig-\nnal over the entire available band of radio frequencies, which might require a considerable\namountofenergy.Theattacker\u2019sabilitytoimpactthetransmissionislimitedbytheachieved\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page647 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nUncoordinated Frequency Hopping (transmitter)\nM:= m, sig(m), \u2026\n1. Fragmentation\nM M M M\n1 2 3 l\n2. Fragment linking\n(protects against M M \u2026 M\n1 2 l\ninsertion)\n3. Packet Encoding (ECC) m m m\n1 2 l\n(protects against\nFigure2ja0m.m1:inIgn)UFH,thefragmentlinkingprotectagainstmessageinsertionattack.\nprocessin4.gRgeapienateodf ttrahnesmsispsrioena d-spectrum communication. This gain is the ratio by which in-\nterference can be suppressed relative to the original signal, and is computed as a ratio of\nthespreadsignalradiofrequencybandwidthtotheun-spreadinformation(baseband)band-\nwidth.\n22\nSpread-spectrum techniques use randomly generated sequences to spread information sig-\nnalsoverawiderbandoffrequencies.Theresultingsignalistransmittedandthende-spread\natthereceiversbycorrelatingitwiththespreadingsequence.Forthistowork,itisessential\nthat the transmitter and receiver share the same secret spreading sequence. In FHSS, this\nsequenceisthesetofcentralfrequenciesandtheorderinwhichthetransmitterandreceiver\nswitchbetweentheminsynchrony.InDSSS,thedatasignalismodulatedwiththespreading\nsequence;thisprocesseffectivelymixesthecarriersignalwiththespreadingsequence,thus\nincreasing the frequency bandwidth of the transmitted signal. This process allows for both\nnarrow band and wide band jamming to be suppressed at the receiver. Unless the jammer\ncan guess the spreading code, its jamming signal will be spread at the receiver, whereas\nthe legitimate transmission will be de-spread, allowing for its detection. The secrecy of the\nspreadingcodesisthereforecrucialforthejammingresilienceofspreadspectrumsystems.\nThis is why a number of civilian systems that use spreading with public spreading codes,\nsuchastheGPSand802.11b,remainvulnerabletojamming.\n20.2.2 Uncoordinated Spread Spectrum Techniques\nInbroadcastapplicationsandinapplicationsinwhichcommunicationcannotbeanticipated\nasscheduled,thereisstillaneedtoprotectsuchcommunicationfromjamming.\nToaddresssuchscenarios,uncoordinatedspreadspectrumtechniqueswereproposed:UFH\nand UDSSS. These techniques enable anti-jamming broadcast communication without pre-\nshared secrets. Uncoordinated Frequency Hopping relies on the fact that even if the sender\nhopsinamannerthatisnotcoordinatedwiththereceiver,thethroughputofthischannelwill\nbe non-zero. In fact, if the receiver is broadband, it can recover all the messages transmit-\nted by the sender. UFH however, introduces new challenges. Given that the sender and the\nreceiver are not synchronised, and short message fragments transmitted within each hop\nare not authenticated, the attacker can inject fragments that make the reassembly of the\npackets infeasible. To prevent this, UFH includes fragment linking schemes that make this\nreassemblypossibleevenunderpoisoning.\nUDSSS follows the principle of DSSS in terms of spreading the data using spreading se-\nquences.However,incontrasttoanti-jammingDSSSwherethespreadingsequenceissecret\nand shared exclusively by the communication partners, in UDSSS, a public set of spreading\nsequencesisusedbythesenderandthereceivers.Totransmitamessage,thesenderrepeat-\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page648 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nedlyselectsafresh,randomlyselectedspreadingsequencefromthepublicsetandspreads\nthe message with this sequence. Hence, UDSSS neither requires message fragmentation\nat the sender nor message reassembly at the receivers. The receivers record the signal on\nthe channel and despread the message by applying sequences from the public set, using a\ntrial-and-errorapproach.Thereceiversarenotsynchronisedtothebeginningofthesender\u2019s\nmessageandthusrecordfor(atleast)twicethemessagetransmissiontime.Afterthesam-\npling, the receiver tries to decode the data in the buffer by using code sequences from the\nsetandbyapplyingasliding-windowprotocol.\n20.2.3 Signal Annihilation and Overshadowing\nUnlike jamming where the primary goal of the attacker is to prevent information from being\ndecodedatthereceiver,signalannihilationsuppressesthesignalatthereceiverbyintroduc-\ning destructive interference. The attacker\u2019s goal is to insert a signal which cancels out the\nlegitimate transmitter\u2019s signal at the antenna of the receiver. This typically means that the\nattacker will generate a signal identical to the legitimate transmission only with a different\npolarity.Jammingattackstypicallyincreasetheenergyonthechannelandthusaremoreeas-\nily detected than signal annihilation which reduces the energy typically below the threshold\nofsignaldetection.\nThegoalofovershadowingissimilartojammingandsignalannihilationinthesensethatthe\nattacker aims to prevent the receiver from decoding a legitimate signal. However, instead\nof interfering with the signal by adding excessive noise to the channel or cancelling out the\nsignal(i.e.,signalannihilation),theattackeremitstheirownsignalatthesametimeandover-\nshadows the legitimate signal. As a result, the receiver only registers the adversarial signal\nwhich is often orders of magnitude higher in amplitude than the legitimate signal. Practical\novershadowingattackswereshowntobeeffectiveagainstQPSKmodulation[1737]andmore\nrecentlyagainstcellularLTEsystems[1738].\nMalicious signal overshadowing can not only deceive the receiver into decoding different\ndata than intended, it can also be used to alter any physical properties the receiver may\nextract during signal reception, such as angle of arrival or time of arrival. Overshadowing\nattacks have been shown to be particularly effective against systems that rely on physical\nlayerpropertiesincludingpositioningandrangingsystems.\n20.3 PHYSICAL-LAYER IDENTIFICATION\n[1739]\nPhysical-Layer Identification techniques enable the identification of wireless devices by\nunique characteristics of their analogue (radio) circuitry; this type of identification is also\nreferredtoasRadioFingerprinting.Moreprecisely,physical-layerdeviceidentificationisthe\nprocess of fingerprinting the analogue circuitry of a device by analysing the device\u2019s com-\nmunicationatthephysicallayerforthepurposeofidentifyingadeviceoraclassofdevices.\nThistypeofidentificationispossibleduetohardwareimperfectionsintheanaloguecircuitry\nintroduced at the manufacturing process. These imperfections are remotely measurable as\ntheyappearinthetransmittedsignals.Whilemoreprecisemanufacturingandqualitycontrol\ncould minimise such artefacts, it is often impractical due to significantly higher production\ncosts.\nPhysical-layer device identification systems aim at identifying (or verifying the identity of)\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page649 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ndevicesortheiraffiliationclasses,suchastheirmanufacturer.Suchsystemscanbeviewed\nas pattern recognition systems typically composed of: an acquisition setup to acquire sig-\nnalsfromdevicesunderidentification,alsoreferredtoasidentificationsignals,afeatureex-\ntraction module to obtain identification-relevant information from the acquired signals, also\nreferred to as fingerprints, and a fingerprint matcher for comparing fingerprints and notify-\ning the application system requesting the identification of the comparison results. Typically,\nthere are two modules in an identification system: one for enrollment and one for identifica-\ntion. During enrollment, signals are captured either from each device or each (set of) class-\nrepresentative device(s) considered by the application system. Fingerprints obtained from\nthe feature extraction module are then stored in a database (each fingerprint may be linked\nwith some form of unique ID representing the associated device or class). During identifica-\ntion,fingerprintsobtainedfromthedevicesunderidentificationarecomparedwithreference\nfingerprintsstoredduringenrollment.Thetaskoftheidentificationmodulecanbetwofold:ei-\ntherrecognise(identify)adeviceoritsaffiliationclassfromamongmanyenrolleddevicesor\nclasses(1:Ncomparisons),orverifythatadeviceidentityorclassmatchesaclaimedidentity\norclass(1:1comparison).\nThe identification module uses statistical methods to perform the matching of the finger-\nprints. These methods are classifiers trained with Machine Learning techniques during the\nenrollment phase. If the module has to verify a 1:1 comparison, the classifier is referred to\nas binary. It tries to verify a newly acquired signal against a stored reference pattern estab-\nlished during enrollment. If the classifier performs a 1:N comparison, on the other hand, it\nattempts to find the reference pattern in a data base which best matches with the acquired\nsignal. Often, these classifiers are designed to return a list of candidates ranked according\ntoasimilaritymetricorlikelihoodthatdenotestheconfidenceforamatch.\n20.3.1 Device under Identification\nPhysical-layer device identification is based on fingerprinting the analogue circuitry of de-\nvicesbyobservingtheirradiocommunication.Consequently,anydevicethatusesradiocom-\nmunication may be subject to physical-layer identification. So far, it has been shown that a\nnumberofdevices(orclassesofdevices)canbeidentifiedusingphysical-layeridentification.\nTheseincludeanalogueVHF,Bluetooth,WiFi,RFIDandotherradiotransmitters.\nAlthough what enables a device or a class of devices to be uniquely identified among other\ndevices or classes of devices is known to be due to imperfections introduced at the manu-\nfacturingphaseoftheanaloguecircuitry,theactualdevice\u2019scomponentscausingthesehave\nnotalwaysbeenclearlyidentifiedinallsystems.Forexample,VHFidentificationsystemsare\nbasedontheuniquenessoftransmitters\u2019frequencysynthesisers(localoscillators),whilein\nRFID systems some studies only suggested that the proposed identification system may\nrely on imperfections caused by the RFID device\u2019s antennas and charge pumps. Identifying\nthe exact components may become more difficult when considering relatively-complex de-\nvices.Inthesecases,itiscommontoidentifyinthewholeanaloguecircuitry,orinaspecific\nsub-circuit, the cause of imperfections. For example, IEEE 802.11 transceivers were identi-\nfied considering modulation-related features; the cause of hardware artefacts can be then\nlocatedinthemodulatorsubcircuitofthetransceivers.Knowingthecomponentsthatmake\ndevices uniquely identifiable may have relevant implications for both attacks and applica-\ntions, which makes the investigation of such components an important open problem and\nresearchdirection.\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page650 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n20.3.2 Identification Signals\nConsideringdevicescommunicatingthroughradiosignals,thatis,sendingdataaccordingto\nsome defined specification and protocol, identification at the physical layer aims at extract-\ninguniquecharacteristicsfromthetransmittedradiosignalsandtousethosecharacteristics\ntodistinguishamongdifferentdevicesorclassesofdevices.Wedefineidentificationsignals\nas the signals that are collected for the purpose of identification. Signal characteristics are\nmainlybasedonobservingandextractinginformationfromthepropertiesofthetransmitted\nsignals,likeamplitude,frequency,orphaseoveracertainperiodoftime.Thesetime-windows\ncancoverdifferentpartsofthetransmittedsignals.Mainly,wedistinguishbetweendataand\nnon-data related parts. The data parts of signals directly relate to data (e.g., preamble, mi-\ndamble, payload) transmission, which leads to considered data-related properties such as\nmodulation errors, preamble (midamble) amplitude, frequency and phase, spectral transfor-\nmations.Non-data-relatedpartsofsignalsarenotassociatedwithdatatransmission.Exam-\nplesincludetheturn-ontransients,near-transientregions,RFburstsignals.Thesehavebeen\nusedtoidentifyactivewirelesstransceivers(IEEE802.11,802.15.4)andpassivetransponders\n(ISO14443HFRFID).\nThe characteristics extracted from identification signals are called features. Those can be\npredefined or inferred. Predefined features relate to well-understood signal characteristics.\nThosecanbeclassifiedasin-specificationandout-specification.Specificationsareusedfor\nquality control and describe error tolerances. Examples of in-specification characteristics\ninclude modulation errors such as frequency offset, I\/Q origin offset, magnitude and phase\nerrors,aswellastime-relatedparameterssuchasthedurationoftheresponse.Examplesof\nout-specificationcharacteristicsincludeclockskewandthedurationoftheturn-ontransient.\nDifferently from predefined features, where the considered characteristics are known in ad-\nvance prior to recording of the signals, we say that features are inferred when they are ex-\ntractedfromsignals,forexample,bymeansofsomespectraltransformationssuchasFast\nFourierTransform(FFT)orDiscreteWaveletTransform(DWT),withouta-prioriknowledgeof\na specific signal characteristic. For instance, wavelet transformations have been applied on\nsignal turn-on transients and different data-related signal regions. The Fourier transforma-\ntion has also been used to extract features from the turn-on transient and other technology-\nspecific device responses. Both predefined and inferred features can be subject to further\nstatisticalanalysisinordertoimprovetheirqualityanddistinguishingpower.\n20.3.3 Device Fingerprints\nFingerprints are sets of features (or combinations of features, that are used to identify de-\nvices. The properties that fingerprints need to present in order to achieve practical imple-\nmentationsare(similartothoseofbiometrics):\n1. Universality.Everydevice(intheconsidereddevice-space)shouldhavetheconsidered\nfeatures.\n2. Uniqueness.Notwodevicesshouldhavethesamefingerprints.\n3. Permanence.Theobtainedfingerprintsshouldbeinvariantovertime.\n4. Collectability. It should be possible to capture the identification signals with existing\n(available)equipments.\nWhenconsideringphysical-layeridentificationofwirelessdevices,wefurtherconsider:\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page651 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n5. Robustness. Fingerprints should not be subject, or at least, they should be evaluated\nwithrespecttoexternalenvironmentalaspectsthatdirectlyinfluencethecollectedsig-\nnallikeradiointerferenceduetootherradiosignals,surroundingmaterials,signalreflec-\ntions, absorption, etc., as well as positioning aspects like the distance and orientation\nbetweenthedevicesunderidentificationandtheidentificationsystem.Furthermore,fin-\ngerprintsshouldberobusttodevice-relatedaspectsliketemperature,voltagelevel,and\npower level. Many types of robustness can be acceptable for a practical identification\nsystem. Generally, obtaining robust features helps in building more reliable identifica-\ntionsystems.\n6. Data-Dependency.Fingerprintscanbeobtainedfromfeaturesextractedfromaspecific\nbitpattern(data-relatedpartoftheidentificationsignal)transmittedbyadeviceunder\nidentification(e.g.,theclaimedIDsentinapacketframe).Thisdependencyhaspartic-\nularly interesting implications if the fingerprints can be associated with both devices\nand data transmitted by those devices. This might strengthen authentication and help\npreventreplayattacks.\n20.3.4 Attacks on Physical Layer Identification\nThelargemajorityofresearchworkshavefocusedonexploringfeatureextractionandmatch-\ningtechniquesforphysical-layerdeviceidentification.Onlyrecentlythesecurityofthesetech-\nniques started being addressed. Different studies showed that their identification system\nmay be vulnerable to hill-climbing attacks if the set of signals used for building the device\nfingerprint is not carefully chosen. This attack consists of repeatedly sending signals to the\ndevice identification system with modifications that gradually improve the similarity score\nbetween these signals and a target genuine signal. They also demonstrated that transient-\nbasedapproachescouldeasilybedisabledbyjammingthetransientpartofthesignalwhile\nstill enabling reliable communication. Furthermore, impersonation attacks on modulation-\nbasedidentificationtechniquesweredevelopedandshowedthatlow-costsoftware-defined\nradios as well as high end signal generators could be used to reproduce modulation fea-\nturesandimpersonateatargetdevicewithasuccessrateof50-75%.Modulation-basedtech-\nniquesarevulnerabletoimpersonationwithhighaccuracy,whiletransient-basedtechniques\narelikelytobecompromisedonlyfromthelocationofthetargetdevice.Theauthorspointed\nout that this is mostly due to presence of wireless channel effects in the considered device\nfingerprints; therefore, the channel needed to be taken into consideration for successful im-\npersonation.\nGenerally, these attacks can be divided into two groups: signal re(P)lay and feature replay\nattacks. In a signal replay attack, the attacker\u2019s goal is to observe analogue identification\nsignalsofatargetdevice,capturetheminadigitalform(digitalsampling),andthentransmit\n(replay) these signals towards the identification system by some appropriate means. The\nattackerdoesnotmodifythecapturedidentificationsignals,thatis,theanaloguesignaland\nthe data payload are preserved. This attack is similar to message replay in the Dolev-Yao\nmodel in which an attacker can observe and manipulate information currently in the air at\nwill.Unlikeinsignalreplayattacks,wherethegoaloftheattackistoreproducethecaptured\nidentification signals in their entirety, feature replay attack creates, modifies or composes\nidentificationsignalsthatreproduceonlythefeaturesconsideredbytheidentificationsystem.\nThe analogue representation of the forged signals may be different, but the features should\nbethesame(orattheleastverysimilar).\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page652 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n20.4 DISTANCE BOUNDING AND SECURE POSITIONING\n[1740,1741,1742,1743,1744,1745,1746,1747]\nSecuredistancemeasurement(i.e.,distancebounding)protocolswereproposedtoaddress\nthe issue of the verification of proximity between (wireless) devices. Their use is broad and\nrangesfromthepreventionofrelayattackstoenablingsecurepositioning.\nSecuringdistancemeasurementrequiressecureprotocolsonthelogicallayerandadistance\nmeasurementtechniqueresilienttophysicallayerattacks.Toattackdistancemeasurement,\nanattackercanexploitbothdata-layeraswellasphysical-layerweaknessesofdistancemea-\nsurementtechniquesandprotocols.Data-layerattackscanbe,toalargeextent,preventedby\nimplementingdistanceboundingprotocols.However,physical-layerattacksareofsignificant\nconcern as they can be executed independently of any higher-layer cryptographic primitive\nthatisimplemented.\n20.4.1 Distance Bounding Protocols\nSecuredistancemeasurementprotocolsaimatpreventingdistanceshorteningandenlarge-\nment attacks. When they only prevent distance shortening, they are also called distance\nboundingprotocols,whereattheendoftheprotocolasecureupperboundonthedistanceis\ncalculated.Theseprotocolsaretypicallyexecutedwithdifferenttrustassumptions.Devices\nmeasuringthedistance(typicallynamedverifierandprover)canbemutuallytrusted,inwhich\ncasetheprotocolaimsatpreventingdistancemanipulationbyanexternalattacker.Ifoneof\nthe devices, the prover, is untrusted, it will try to manipulate the measured distance. Other\nscenariosincludetheuntrustedproverbeinghelpedbythirdpartiestocheatonitsdistance.\nDistance bounding literature describes four main types of attacks \u2019frauds\u2019 corresponding to\ntheabovescenarios:distancefraud,mafiafraud,terroristfraudanddistancehijacking.\nFirst investigations of distance bounding protocols started with the work of Beth and\nDesmedt [1741], and by Brands and Chaum [1742]. These protocols, as well as many that\nfollowed,aredesignedascryptographicchallenge-responseprotocolswithRTTofflightmea-\nsurements. One of the key insights of Brands and Chaum was to minimise the processing\nat the prover so that the prover cannot cheat on its distance to the verifier. Namely, this pro-\ntocol requires that the prover only computes single bit XOR during the time-critical phase of\nthe protocol. This translates into strong security guarantees as long as the prover cannot\nimplement a faster XOR than assumed by the verifier. Hancke and Kuhn [1748] proposed an\nalternativeprotocolthatusesregisterselectionasaproverprocessingfunction.Thisdesign\nreducesthenumberofprotocolsstepsbyallowingtheverifierandtheprovertopre-agreeon\nthe nonces that will be used in the protocol exchange. Many protocols followed these two\ndesigns, notably addressing other types of frauds (especially terrorist fraud), as well as the\nrobustness to message loss, performance in terms of protocol execution time, and privacy\nofdistancemeasurement.\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page653 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n20.4.2 Distance Measurement Techniques\nEstablishing proximity requires estimating the physical distance between two or more wire-\nless entities. Typically, the distance is estimated either by observing the changes in the sig-\nnal\u2019s physical properties (e.g., amplitude, phase) that occur as the signal propagates or by\nestimatingthetimetakenforthesignaltotravelbetweentheentities.\nAradiosignalexperiencesalossinitssignalstrengthasittravelsthroughthemedium.The\namountoflossorattenuationinthesignal\u2019sstrengthisproportionaltothesquareofthedis-\ntancetravelled.Thedistancebetweenthetransmitterandthereceivercanthereforebecalcu-\nlatedbasedonthefreespacepathlossequation.Inreality,thesignalexperiencesadditional\nlossesduetoitsinteractionwiththeobjectsintheenvironmentwhicharedifficulttoaccount\nforaccurately.Thisdirectlyaffectstheaccuracyofthecomputeddistanceandthereforead-\nvanced models such as the Rayleigh fading and log-distance path loss models are typically\nused to improve the distance estimation accuracy. Bluetooth-based proximity sensing tags\n(e.g., Apple iBeacon and Passive Keyless Entry and Start Systems) use the strength of the\nreceived Bluetooth signal also referred to as the Received Signal Strength Indicator (RSSI)\nvalueasameasureofproximity.\nAlternatively, the devices can measure the distance between them by estimating the phase\ndifferencebetweenareceivedcontinuouswavesignalandalocalreferencesignal.Theneed\nforkeepingtrackofthenumberofwholecycleselapsediseliminatedbyusingsignalsofdif-\nferentfrequenciestypicallyreferredtoasmulti-carrierphase-basedranging.Duetotheirlow\ncomplexityandlowpowerconsumption,phasebasedrangingisusedinseveralcommercial\nproducts.\nFinally,thetimetakenfortheradiowavestotravelfromonepointtoanothercanbeusedto\nmeasure the distance between the devices. In RF-based RTT based distance estimation the\ndistancedbetweentwoentitiesisgivenbyd = (t \u2212t )\u00d7c,wherecisthespeedoflight,t\nrx tx tx\nandt representthetimeoftransmissionandreceptionrespectively.Themeasuredtime-of-\nrx\nflightcaneitherbeonewaytime-of-flightoraround-triptime-of-flight.Onewaytime-of-flight\nmeasurement requires the clocks of the measuring entities to be tightly synchronised. The\nerrors due to mismatched clocks are compensated in the round-trip time-of-flight measure-\nment.\nThe precise distance measurement largely depends on the system\u2019s ability to estimate the\ntimeofarrivalandthephysicalcharacteristicsoftheradiofrequencysignalitself.Theranging\nprecision is roughly proportional to the bandwidth of the ranging signal. Depending on the\nrequired level of accuracy, time-of-flight based distance measurement systems use either\nImpulse-Radio Ultra Wideband (IR-UWB) or Chirp-Spread Spectrum (CSS) signals. IR-UWB\nsystemsprovidecentimeter-levelprecisionwhiletheprecisionofCSSsystemsisoftheorder\nof1\u20132m.Thereareanumberofcommerciallyavailablewirelesssystemsthatusechirpand\nUWBround-triptime-of-flightfordistancemeasurementtoday.\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page654 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n20.4.3 Physical Layer Attacks on Secure Distance Measurement\nWith the increasing availability of low-cost software-defined radio systems, an attacker can\neavesdrop, modify, compose, and (re)play radio signals with ease. This means that the at-\ntacker has full control of the wireless communication channel and therefore is capable of\nmanipulatingallmessagestransmittedbetweenthetwoentities.InRSSI-baseddistancees-\ntimation, an attacker can manipulate the measured distance by manipulating the received\nsignal strength at the verifier. The attacker can simply amplify the signal transmitted by the\nprover before relaying it to the verifier. This will result in an incorrect distance estimation at\ntheverifier.Commerciallyavailablesolutionsclaimtosecureagainstrelayattacksbysimply\nreducingorattenuatingthepowerofthetransmittedsignal.However,anattackercantrivially\ncircumventsuchcountermeasuresbyusinghighergainamplifiersandreceivingantennas.\nSimilarly,anattackercanalsomanipulatetheestimateddistancebetweentheverifierandthe\nproverinsystemsthatusethephaseorfrequencypropertyoftheradiosignal.Forinstance,\ntheattackercanexploitthemaximummeasurablepropertyofphaseorfrequency-baseddis-\ntance measurement systems and execute distance reduction attacks. The maximum mea-\nsurabledistance,i.e.,thelargestvalueofdistanced thatcanbeestimatedusingaphase-\nmax\nbasedproximitysystem,directlydependsonthemaximummeasurablephase.Giventhatthe\nphasevaluerangesfrom0to2\u03c0 andthenrollsover,themaximummeasurabledistancealso\nrollsoverafteracertainvalue.Anattackercanleveragethismaximummeasurabledistance\nproperty of the system in order to execute the distance decreasing relay attack. During the\nattack, the attacker simply relays (amplifies and forwards) the verifier\u2019s interrogating signal\ntotheprover.Theproverdeterminesthephaseoftheinterrogatingsignalandre-transmitsa\nresponsesignalthatisphase-lockedwiththeverifier\u2019sinterrogatingsignal.Theattackerthen\nreceives the prover\u2019s response signal and forwards it to the verifier, however with a time de-\nlay.Theattackerchoosesthetimedelaysuchthatthemeasuredphasedifferencesreaches\nits maximum value of 2 and rolls over. In other words, the attacker was able to prove to the\nverifier that the prover is in close proximity (e.g., 1m away) even though the prover was far\nfromtheverifier.\nIn Time of Flight (ToF) based ranging systems, the distance is estimated based on the time\nelapsed between the verifier transmitting a ranging packet and receiving an acknowledge-\nment back from the prover. In order to reduce the distance measured, an attacker must de-\ncrease the signal\u2019s round trip time of flight. Based on the implementation, an attacker can\nreducetheestimateddistanceinatime-of-flightbasedrangingsysteminmorethanoneway.\nGiven that the radio signals travel at a speed of light, a 1 ns decrease in the time estimate\ncanresultinadistancereductionof30cm.\nThe first type of attackon time-of-flight ranging leverages the predictable nature of the data\ncontainedintherangingandtheacknowledgementpackets.Anumberoftime-of-flightrang-\ningsystemsusepre-defineddatapacketsforranging,makingittrivialforanattackertopre-\ndictandgeneratetheirownrangingoracknowledgmentsignal.Anattackercantransmitthe\nacknowledgment packet even before receiving the challenge ranging packet. Several works\nhave shown that the de-facto standard for IR-UWB, IEEE 802.15.4a does not automatically\nprovidesecurityagainstdistancedecreasingattacks.In[1749]itwasshownthatanattacker\ncanpotentiallydecreasethemeasureddistancebyasmuchas140metersbypredictingthe\npreamble and payload data with more than 99% accuracy even before receiving the entire\nsymbol.Ina\u2019Cicada\u2019attack,theattackercontinuouslytransmitsapulsewithapowergreater\nthan that of the prover. This degrades the performance of energy detection based receivers,\nresulting in reduction of the distance measurements. In order to prevent such attacks it is\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page655 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nimportant to avoid predefined or fixed data during the time critical phase of the distance\nestimationscheme.\nInadditiontohavingtheresponsepacketdependentonthechallengesignal,thewayinwhich\nthesechallengeandresponsedataareencodedintheradiosignalsaffectsthesecurityguar-\nantees provided by the ranging or localisation system. An attacker can predict the bit (early\ndetect)evenbeforereceivingthesymbolcompletely.Furthermore,theattackercanleverage\nthe robustness property of modern receivers and transmit arbitrary signal until the correct\nsymbolispredicted.Oncethebitispredicted(e.g.,early-detection),theattackerstopstrans-\nmittingthearbitrarysignalandswitchestotransmittingthebitcorrespondingtothepredicted\nsymbol, i.e., the attacker \u2019commits\u2019 to the predicted symbol, commonly known as late com-\nmit.Insuchascenario,theattackerneedn\u2019twaitfortheentireseriesofpulsestobereceived\nbefore detecting the data being transmitted. After just a time period, the attacker would be\nabletocorrectlypredictthesymbol.\nAsdescribedpreviously,round-triptime-of-flightsystemsareimplementedeitherusingchirp\nor impulse radio ultrawideband signals. Due to their long symbol lengths, both implementa-\ntionshavebeenshowntobevulnerabletoearly-detectandlate-commitattacks.Inthecase\nof chirp-based systems, an attacker can decrease the distance by more than 160 m and in\nsome scenarios even up to 700 m. Although IR-UWB pulses are of short duration (typically\n2\u20133 ns long), data symbols are typically composed of a series of UWB pulses. Furthermore,\nIEEE 802.15.4a IR-UWB standard allows long symbol lengths ranging from 32 ns to as large\nas8\u00b5s.Therefore,eventhesmallestsymbollengthof32nsallowsanattackertoreducethe\ndistance by as much as 10 m by performing early-detect and late-commit attacks. Thus, it\nis clear that in order to guarantee proximity and secure a wireless proximity system against\nearly detect and late-commit attacks, it is necessary to keep the symbol length as short as\npossible.\nDesignofaphysicallayerforsecuredistancemeasurementremainsanopentopic.However,\nresearchsofarhasyieldedsomeguidingprinciplesforitsdesign.OnlyradioRTTwithsingle-\npulse or multi-pulse UWB modulation has been shown to be secure against physical layer\nattacks. As a result, the IEEE 802.15.4z working group started the standardization of a new\nphysicallayerforUWBsecuredistancemeasurement.\nThefirstattemptatformalizingtherequirementsforsecuredistancemeasurementbasedon\ntheTimeofArrival(ToA)oftransmittedmessagescanbefoundin[1747].Saidworkpresents\naformaldefinitionofMessageTimeofArrivalCodes(MTACs),thecoreprimitiveinthecon-\nstructionofsystemsforsecureToAmeasurement.Ifimplementedcorrectly,MTACsprovide\nthe ability to withstand reduction and enlargement attacks on distance measurements. It is\nshown that systems based on UWB modulation can be implemented such that the stated\nsecurityrequirementsaremetandthereforeconstituteexamplesofMTACschemes.\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page656 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nx\nV1 V2\ny\nP P\nV3\nFigure 20.2: If the computed location of the prover is in the verification triangle, the verifiers\nconcludethatthisisacorrectlocation.Tospoofthepositionofproverinsidethetriangle,the\nattackerwouldneedtoreduceatleastoneofthedistancebounds.\n20.4.4 Secure Positioning\nSecure positioning systems allow positioning anchors (also called verifiers) to compute the\ncorrect position of a node (also called the prover) or allow the prover to determine its own\npositioncorrectlydespitemanipulationsbytheattacker.Thismeansthattheattackercannot\nconvince the verifiers or the prover that the prover is at a position that is different from its\ntrue position. This is also called spoofing-resilience. A related property is the one of secure\nposition verification which means that the verifiers can verify the position of an untrusted\nprover.Itisgenerallyassumedthattheverifiersaretrusted.Norestrictionsareposedonthe\nattackerasitfullycontrolsthecommunicationchannelbetweentheproversandtheverifiers.\nThe analysis of broadcast positioning techniques, such as GNSS has shown that such tech-\nniques are vulnerable to spoofing if the attacker controls the signals at the antenna of the\nGNSSreceiver.\nThesetypeofapproacheshavebeenproposedtoaddressthisissue:VerifiableMultilateration\nandSecurePositioningbasedonHiddenStations.\nVerifiableMultilaterationreliesonsecuredistancemeasurement\/distancebounding.Itcon-\nsistsofdistanceboundmeasurementstotheproverfromatleastthreeverifiers(in2D)and\nfourverifiers(in3D)andofsubsequentcomputationsperformedbytheverifiersorbyacen-\ntralsystem.VerifiableMultilaterationhasbeenproposedtoaddressbothsecurepositioning\nand position verification. In the case of secure positioning, the prover is trusted and mafia-\nfraud-resilient distance bounding is run between the prover and each of the verifiers. The\nverifiers form verification triangles \/ triangular pyramids (in 3D) and verify the position of\nthe prover within the triangle \/ pyramid. For the attacker to spoof a prover from position\nP to P\u2019 within a triangle\/pyramid, the attacker would need to reduce at least one of the dis-\ntanceboundsthataremeasuredtoP.Thisfollowsfromthegeometryofthetriangle\/pyramid.\nSince Distance bounding prevents distance reduction attacks, Verifiable Multilateration pre-\nvents spoofing attacks within the triangle\/pyramid. The attacker can only spoof P to P\u2019 that\nisoutsideofthetriangle\/pyramid,causingtheproverandtheverifierstorejectthecomputed\nposition. Namely, the verifiers and the prover only accept the positions that are within the\narea of coverage, defined as the area covered by the verification triangles\/pyramids. Given\nthis, when the prover is trusted, Verifiable Multilateration is resilient to all forms of spoof-\ning by the attacker. Additional care needs to be given to the management of errors and the\ncomputationofthepositionwhendistancemeasurementerrorsaretakenintoaccount.\nWhenusedforpositionverification,VerifiableMultilaterationisrunwithanuntrustedprover.\nEachverifierrunsadistance-fraudresilientdistanceboundingprotocolwiththeprover.Based\nontheobtaineddistancebounds,theverifierscomputetheprovers\u2019position.Ifthisposition\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page657 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\n(within some distance and position error bounds) falls within the verification triangle\/pyra-\nmid, the verifiers accept it as valid. Given that the prover is untrusted, it can enlarge any\nof the measured distances, but cannot reduce them since this is prevented by the use of\ndistance bounding protocols. Like in the case of secure positioning, the geometry of the tri-\nangle\/pyramid then prevents the prover from claiming a false position. Unlike in the case of\nsecure positioning, position verification is vulnerable to cloning attacks, in which the prover\nshares its key to its clones. These clones can then be strategically placed to the verifiers\nand fake any position by enlarging distances to each individual verifier. This attack can be\npossiblyaddressedbytamperresistanthardwareordevicefingerprinting.\nAnother approach to secure positioning and position verification is to prevent the attacker\nfrom deterministically spoofing the computed position by making the positions of the veri-\nfiersunpredictablefortheattacker(eitheramaliciousproveroranexternalattacker).Verifier\npositionscanthereforebehiddenortheverifierscanbemobile.Whentheverifiersarehidden\ntheyshouldonlylistentothebeaconssentbythenodestonotdisclosetheirpositions.Upon\nreceiving the beacons, the base stations compute the nodes location with TDOA and check\nifthislocationisconsistentwiththetimedifferences.\n20.5 COMPROMISING EMANATIONS AND SENSOR\nSPOOFING\n[1514,1559,1560,1750,1751,1752,1753,1754,1755]\nElectronic devices emit electromagnetic waves in the form of radio and audio signals, pro-\nduceheatandcreatevibration,allofwhichcouldcorrelatewithconfidentialinformationthat\nthe devices process or store. Such emanations, or more generally referred to as side chan-\nnels,areprevalentandhavebeenextensivelystudied.\nRemotesensorspoofingisthe(physical)oppositeofcompromisingemanations.Insteadof\neavesdropping on electromagnetic leakage, an attacker injects signals that spoof the value\nmeasured by a sensor or receiver and thereby (adversely) affects the system relying on the\nsensor readings and measurements. This is particularly critical in autonomous and other\ncyber-physicalsystemsthathavedirectconsequencesonthesafetyofthesurroundingpeo-\npleandinfrastructure.\n20.5.1 Compromising Emanations\nIn the military context, techniques for exploiting and protecting against unwanted emission\nin communication systems date back to World War II and have over the time have been col-\nlected in an umbrella-term called TEMPEST. The first public demonstration of low-cost at-\ntacks on commercial systems using compromising emanations was done in 1985 by Wim\nvan Eck [1756]. This attack demonstrated that information displayed on CRT monitors can\nbe successfully eavesdropped from a distance of hundreds of meters. This demonstration\npromptedresearchintothesourcesofsuchemanationsaswellasintoprotectivemeasures.\nIt also highlighted that not only radio emissions leak information. In general, there are four\ncategoriesofsuchemanations:acoustic,optical,thermal,andelectromagnetic.\nDetailed studies of the sources and features that lead to such compromises have been car-\nried out over the years, and on multiple occasions, it was demonstrated that compromising\nemanationsfromanalogueanddigitaldisplaysresultedfrominformationbeingtransmitted\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page658 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nthrough analogue video cables and through high-speed Digital Serial Interface (DVI) cables.\nHowever,morerecentworksshowthatsuchemanationsarenotrestrictedtocablesand,to\naggravatethesituation,compromisingemissionsarenotnecessarilycausedbyanalogueor\ndigitaldisplaysonly.\nSomeattacksdescribedinresearchshowedthathigh-frequencysoundscausedbyvibration\nof electronic components (capacitors and coils) in the computer\u2019s voltage regulation circuit\ncan be used to infer prime factors and therefore derive RSA encryption keys. Sounds ema-\nnatingfromkeypressesonakeyboardwereusedtoinferwhatauseristyping.Theresulting\nvibrations can, for instance, be sensed by the accelerometer of a phone located nearby. Fi-\nnally, reflections from different objects in the vicinity of computer screens, such as spoons,\nbottlesanduser\u2019sretinawereusedtoinferinformationshowonadisplay.\nThe increasing availability of phones that integrate high quality sensors, such as cameras,\nmicrophonesandaccelerometersmakesiteasiertomountsuccessfulattackssincenoded-\nicatedsensorequipmentneedstobecovertlyputinplace.\nToavoidunwantedsignalemissions,devicescanbeheldatadistance,canbeshieldedand\nsignalsthataretransmittedshouldbefilteredinordertoremovehigh-frequencycomponents\nthatmightreflectswitchingactivityinthecircuitry.Moreover,itisgenerallyadvisedtoplacea\nreturn wire close to the transmission wire in order to avoid exploitation of the return current.\nIn general, wires and communication systems bearing confidential information should be\nseparated(air-gapped)fromnon-confidentialsystems.\n20.5.2 Sensor Compromise\nAnaloguesensorshavebeenshowntobeparticularlyvulnerabletospoofingattacks.Similar\ntocompromisingemanations,sensorspoofingdependsonthetypeofthephysicalphenom-\nenathesensorcaptures.Itcanbeacoustic,optical,thermal,mechanicorelectromagnetic.\nNowadays,manyelectronicdevices,includingself-drivingcars,medicaldevicesandclosed-\nloopcontrolsystems,featureanaloguesensorsthathelpobservetheenvironmentandmake\ndecisionsinafullyautonomousway.Thesesystemsareequippedwithsophisticatedprotec-\ntion mechanisms to prevent unauthorised access or compromise via the device\u2019s communi-\ncationinterfaces,suchasencryption,authenticationandaccesscontrol.Unfortunately,when\nit comes to data gathered by sensors, the same level of protection is often not available or\ndifficulttoachievesinceadversarialinteractionswithasensorcanbehardtomodelandpre-\ndict. As a result, unintentional and especially intentional EMI targeted at analogue sensors\ncan pose a realistic threat to any system that relies on readings obtained from an affected\nsensor.\nEMI has been used to manipulate the output of medical devices as well as to compromise\nultrasonicrangingsystems.Researchhasshownthatconsumerelectronicdevicesequipped\nwithmicrophonesareespeciallyvulnerabletotheinjectionoffabricatedaudiosignals[1560].\nUltrasonicsignalswereusedtoinjectsilentvoicecommands,andacousticwaveswereused\nto affect the output of MEMS accelerometers. Accelerometers and intertial systems based\nonMEMSare,forinstance,usedextensivelyin(consumer-grade)dronesandmulti-copters\nUndoubtedly, sensor spoofing attacks have gained a lot of attention and will likely impact\nmanyfuturecyber-physicaldevices.Systemdesignersthereforehavetotakegreatcareand\nprotect analogue sensors from adversarial input as an attacker might trigger a critical deci-\nsion on the application layer of such a device by exposing it to intentional EMI. Potential de-\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page659 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nfence strategies include, for example, (analogue) shielding of the devices, measuring signal\ncontamination using various metrics, or accommodating dedicated EMI monitors to detect\nandflagsuspicioussensorreadings.\nApromisingstrategythatfollowstheapproachofquantifyingsignalcontaminationtodetect\nEMI sensor spoofing is presented in [1755]. The sensor output can be turned on and off ac-\ncording to a pattern unknown to the attacker. Adversarial EMI in the wires between sensor\nandthecircuitryconvertingthereadingtoadigitalvalue,i.e.,theADC,canbedetectedduring\nthetimesthesensorisoffsincethesensoroutputshouldbeataknownlevel.Incasethere\nare fluctuations in the readings, an attack is detected. Such an approach is thought to be\nespecially effective when used to protect powered or non-powered passive sensors. It has\nbeen demonstrated to successfully thwart EMI attacks against a microphone and a temper-\nature sensor system. The only modification required is the addition of an electronic switch\nthat can be operated by the control unit or microcontroller to turn the sensor on and off. A\nsimilar sensor spoofing detection scheme can be implemented for active sensors, such as\nultrasonic and infrared sensors, by incorporating a challenge-response like mechanism into\nthemeasurementacquisitionprocess[1757].Anactivesensoroftenhasanemittingelement\nandareceivingelement.Theemitterreleasesasignalthatisreflectedandcapturedbythere-\nceiver.Basedonthepropertiesofthereceivedsignal,thesensorcaninferinformationabout\ntheentityortheobjectthatreflectedthesignal.Theemittercanbeturnedoffrandomlyand\nduring that time the receiver should not be able to register any incoming signal. Otherwise,\nanattackisdetectedandthesensorreadingisdiscarded.\n20.6 PHYSICAL LAYER SECURITY OF SELECTED\nCOMMUNICATION TECHNOLOGIES\n[1758,1759,1760,1761]\nThis section presents security mechanisms of a selection of existing wireless communica-\ntiontechniquesthatareinusetoday.Themainfocusisonphysical-layersecurityconstructs\nas well as any lack thereof. The communication techniques that are discussed in detail are\nnear-field communication, air traffic communication networks, cellular networks and global\nnavigationsatellitesystems.\n20.6.1 Near-field communication (NFC)\nNear-field communication commonly refers to wireless communication protocols between\ntwo small (portable) electronic devices. The standard is used for contact-less payment and\nmobile payment systems in general. NFC-enabled devices can also exchange identity infor-\nmation, such as keycards, for access control, and negotiate parameters to establish a sub-\nsequenthigh-bandwidthwirelessconnectionusingmorecapableprotocols.\nNFC is designed to only transmit and receive data to a distance of up to a few centimeters.\nEven if higher-layer cryptographic protocols are used, vanilla NFC protocols do not offer se-\ncurecommunicationandcannotguaranteethattwocommunicatingdevicesareindeedonly\na short distance apart. NFC is vulnerable to eavesdropping, man-in-the-middle attacks and\nmessagerelayattacks.\nEvennowadays,standardNFCisdeployedinsecurity-criticalcontextsduetotheassumption\nthat communicating devices are in close proximity. Research has shown, however, that this\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page660 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nassumption can not be verified reliably using NFC protocols. The distance can be made al-\nmostarbitrarilylargebyrelayingmessagesbetweenNFC-enableddevices.Theattackworks\nas follows: The benign NFC devices are made to believe that they are communicating with\neachother,buttheyareactuallyexchangingdatawithamodifiedsmartphone.Anadversary\ncanstrategicallyplaceasmartphonenexttoeachbenignNFCdevicewhilethesmartphones\nthemselvesuseacommunicationmethodthatcancoverlongdistances,suchasWiFi.They\nsimply forward the messages the benign devices are sending to each other. Such an attack\nis also referred to as a wormhole attack where communicating parties are tricked into as-\nsuming that they are closer than they actually are. This is a problem that cannot be solved\nusingtechniquesonthelogicallayeroronthedatalayer.\nObviously, most of the described attacks can be mitigated by shielding the NFC devices or\nenhance the protocol with two-factor authentication, for example. Such mechanisms unfor-\ntunatelytransfersecurity-relevantdecisionstotheuserofanNFCsystem.Countermeasures\nthatdonotimposeuserburdencanroughlybecategorisedintophysicallayermethodsand\ntheaugmentationwithcontext-ordevice-specificidentifiers[1758].\nProtocolaugmentationentailscontext-awareNFCdevicesthatincorporatelocationinforma-\ntion into the NFC system to verify proximity. The location sensing can be implemented with\nthe help of a variety of different services, each with its own accuracy and granularity. Con-\nceivable are, for instance, GNSS\/GPS based proximity verification or leveraging the cell-ID\nof the base station to which the NFC device is currently closest in order to infer a notion of\nproximity.\nPhysical layer methods that have been suggested in research literature are timing restric-\ntions and distance bounding. Enforcing strict timing restraints on the protocol messages\ncan be understood as a crude form of distance bounding. As discussed in Section 4.1, dis-\ntance bounding determines an upper bound on the physical distance between two commu-\nnicating devices. While distance bounding is considered the most effective approach, it still\nremains to be shown if secure distance bounding can be implemented in practice for small\nNFC-enableddevices.\n20.6.2 Air Traffic Communication Networks\nThroughout different flight phases commercial and non-commercial aviation uses several\nwireless communication technologies to exchange information with aviation authorities on\nthe ground as well as between airborne vehicles. Often legacy systems are still in use and\nsecurityhasneverbeenpartofthedesignofsuchsystems.\nWhilenewproposalssuggesttooverhaulthesesystemsandtotightlyintegratesecuritymea-\nsuresintothedatalayer,suchasencryptionandmessageauthentication,airtrafficcommu-\nnicationnetworksarenotonlyusedforinformationtransmission,butalsotoextractphysical\nlayerfeaturesfromthesignalinordertoperformaircraftlocationpositioning.\nA prominent example is ADS-B. An ADS-B transponder periodically (or when requested)\nbroadcaststheaircraft\u2019spositioninformation,suchascoordinates,thathavebeenobtained\nthrough an on-board GNSS receiver. Most versions of ADS-B only support unauthenticated\nmessagesandtherefore,thistechnologysuffersfromactiveandpassiveattacks,i.e.,eaves-\ndropping,modifying,injectingandjammingmessages.Itis,forinstance,possibletoprevent\nanaircraft\u2019slocationfrombeingtrackedbyAirTrafficControl(ATC)bysimplyjammingthere-\nspectivemessages.Similarly,anadversarycouldcreateghostplanesbyemittingfabricated\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page661 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\ntransponder messages. A sophisticated attacker could even fully distort the view ATC has\nonitsairspace.\nMultilateration(MLAT)canbeseenasatechnologythatmitigatessomeoftheshortcomings\nofunauthenticatedADS-BandisthereforeusuallydeployedinconjunctionwithADS-B.MLAT\ndoes not rely on the transmitted information encapsulated in the message, but makes use\nof the physical and geometrical constellation between the transmitter (i.e., transponder of\nthe aircraft) and several receivers. MLAT systems extract physical layer properties from the\nreceived messages. The time of arrival of a message is recorded at different co-located re-\nceiversand,usingthepropagationspeedofthesignal,thelocationoftheaircraft\u2019stranspon-\nder can be estimated. Multilateration techniques infer the aircraft\u2019s location even if the con-\ntents of the ADS-B messages are incorrect and thus MLAT provides a means to crosscheck\nthelocationinformationdisseminatedbytheaircraft\u2019stransponder.\nAlthoughMLAToffersadditionalsecuritybasedonphysicallayerproperties,adistributedad-\nversarycanstillmanipulateADS-Bmessages.Inadditiontoalteringthelocationinformation,\nanattackercanmodifyorinjectsignalsthataffectthetime-of-arrivalmeasurementatthere-\nceivers.Iftheattackerhasaccesstomultipledistributedantennasandisabletocoordinate\nadversarial signal emission precisely, attacks similar to those on standard ADS-B are feasi-\nble. However, the more receivers used to record the signals, the more difficult such attacks\nbecome. Unfortunately, MLAT is not always an effective solution in aviation as strategic re-\nceiver placement is crucial and time of arrival calculations can be susceptible to multi-path\ninterference[1759].\n20.6.3 Cellular Networks\nCellular networks provide voice, data and messaging communication through a network of\nbase stations, each covering one or more cells. The security provisions of these networks\naremainlygovernedbythestandardsthatwereadoptedintheGSMAssociationandlaterin\ntheThirdGenerationPartnershipPlan(3GPP).\nSecond Generation (2G) \u2018GSM\u2019 networks were introduced during the 1990s, and restricted\ntheir services to voice and text messaging. 2G networks were capable of carrying data via\na Circuit-Switched Data Service (CSD) which operated in a manner similar to the dial-up\nmodems,justovercellularnetworks.Furtherdevelopmentofemailandwebservicesresulted\ninaneedforenhancedspeedsandservices\n3GPP improved 2G GSM standard with packet switched data service, resulting in the Gen-\neralPacketRadioService(GPRS).LikeGSM,GPRSmadeuseoftheHomeLocationRegister\n(HLR), a component that was responsible for subscriber key management and authentica-\ntion. However, GPRS enhanced GSM by adding the Serving GPRS Support Node (SGSN) for\ndata traffic routing and mobility management for better data traffic delivery. Third Genera-\ntion(3G)ofcellularnetworks,alsoknownasUniversalMobileTelecommunicationsSystems\n(UMTS),introducedanumberofimprovementsover2Gnetworks,includingsecurityenhance-\nments, as well as increased uplink and downlink speeds and capacities. Fourth Generation\n(4G)cellularnetworks,alsoknownasLongTermEvolution(LTE)introducedfurtherincrease\nintransmissionspeedsandcapacities.\nOneofthemainsecuritypropertiesthatcellularnetworksaimtoprotectistheconfidentiality\nofthecommunicationofthelinkbetweenthemobilestation,andthebasestationandcorrect\nbilling. The security of cellular networks has evolved with network generations, but all gen-\nerations have the same overarching concept. Subscribers are identified via their (Universal)\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page662 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nSubscriberIdentityModulestheirInternationalMobileSubscriberIdentity(IMSI)numberand\nits related secret key. IMSI and the keys are used to authenticate subscribers as well as to\ngeneratethenecessarysharedsecretstoprotectthecommunicationtothecellularnetwork.\n2G security focused on the confidentiality of the wireless link between the mobile station\nandthebasestation.Thiswasachievedthroughtheauthenticationviaachallenge-response\nprotocol, 2G Authentication and Key Agreement (AKA). This protocol is executed each time\nwhen a mobile station initiates a billable operation. 2G AKA achieved authentication based\non a long term key K shared between the subscriber SIM card and the network. This key is\ni\nused by the network to authenticate the subscriber and to derive a session key K . This is\nc\ndone within in a challenge response protocol, executed between the SGSN and the mobile\nstation. Before theexecutionof theprotocol,SGSN receives fromthe HLRtheK , arandom\nc\nvalue RAND and an expected response XRES. Both K and XRES are generated within\nc\nthe HLR based on RAND and K . When the mobile station attempts to authenticate to the\ni\nnetworkitissentRAND.Toauthenticate,themobilestationcombinesitslongtermkeyK\ni\n(storedonitsSIMcard)withthereceivedRANDtogenerateRESandK .Themobilestation\nc\nsends RES to the SGSN which compares it to XRES. If the two values match, the mobile\nstation is authenticated to the network. The SGSN then sends the K to the base station to\nc\nwhichthemobilestationisconnectedinordertoprotectthemobiletobasestationwireless\nlink.\n2GAKAofferedverylimitedprotection.Itusedinadequatekeysize(56-64bits),andweakau-\nthenticationandkeygenerationalgorithms(A3,A5andA8)whichwere,oncereleased,broken,\nallowingforeavesdroppingandmessageforgery.Furthermore,AKAwasdesignedtoprovide\nonly one-way authentication of the mobile station to the network. Since the network did not\nauthenticatetothemobilestationsthisenabledattacksbyfakebasestationsviolatingusers\nlocationprivacyandconfidentialityoftheircommunication.\nInordertoaddressthe2Gsecurityshortcomings,3Gnetworksintroducednew3GAuthenti-\ncation and Key Agreement (3G AKA) procedures. 3G AKA replaced the weak cryptographic\nalgorithms that were used in 2G and provided mutual authentication between the network\nand the mobile stations. Like in 2G, the goal of the protocol is the authentication (now mu-\ntual) of the network and the mobile station. The input into the protocol is a secret key K\nshared between the HLR and the subscriber. The outcome of the protocol are two keys, the\nencryption\/confidentiality key CK and the integrity key IK. The generation of two keys al-\nlows the network and the mobile station to protect the integrity and confidentiality of their\ncommunication using two different keys, in line with common security practices. CK and IK\nareeach128bitslongwhichisconsideredadequate.\nThe authentication and key derivation is performed as follows. The HLR first generates the\nrandom challenge RAND, from it the expected response XRES, the keys CK and IK and\ntheauthenticationtokenAUTN.ItthensendsthesevaluestotheSGSN.TheSGSNsendsthe\nRAND as well as the AUTN to the mobile station (also denoted as User Equipment (UE)),\nwhichwillthenuseitslongtermkeyK togeneratetheresponseRES andtoverifyifAUTN\nwasgeneratedbytheHLR.TheAUTN isfromthesharedkeyandthecountermaintainedby\nboththeHLRandthemobilestation.UponreceivingtheRES fromthemobilestation,SGSN\nwill compare it with the XRES and if they match, will forward the CK and IK to the base\nstation.Thebaseandmobilestationcannowusethesekeystoprotecttheircommunication.\n3G, however, still didn\u2019t resolve the vulnerabilities within the operator\u2019s networks. CK and\nIK are transmitted between different entities in the network. They are transmitted between\nSGSNandtheassociatedbasestationaswellasbetweendifferentbasestationsduringmo-\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page663 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nbility.Thisallowsnetworkattackerstorecordthesekeysandthereforeeavesdroponwireless\nconnections.\n4G (LTE) security architecture preserved many of the core elements of 2G and 3G networks,\nbut aimed to address the shortcomings of 3G in terms of the protection of the in-network\ntraffic through the protection of network links and redistribution of different roles. For ex-\nample, the long term key storage was moved from the HLR to the Home Subscriber Server\n(HSS).MobilitymanagementwasmovedfromtheSGSNtotheMobilityManagementEngine\n(MME).\n5G security architecture evolves 4G but follows a similar set of principles and entities. 5G\nintroduces a new versions of Authentication and Key Agreement (AKA) protocols that was\ndesignedtofixtheissuesfoundin4G,howeverwithmixedsuccess[1762].\n20.6.4 GNSS Security and Spoofing Attacks\nGNSS such as GPS and Galileo provide global navigation service through satellites that are\norbiting the earth approximately 20,000km above the ground. Satellites are equipped with\nhigh-precision atomic clocks which allows the satellites to remain synchronised. Satellites\ntransmit navigation messages at central frequencies of 1575.42MHz (L1) and 1227.60MHz\n(L2).DirectSequenceSpreadingisusedtoenableacquisitionandtoprotectthesignalscarry-\ningthosemessagesfromspoofingandjammingattacks.Civiliancodesarepublicandthere-\nforedonotoffersuchprotection,whereasmilitaryandspecialinterestcodesarekeptconfi-\ndential.Navigationmessagescarrydataincludingsatelliteclockinformation,theephemeris\n(information related to the satellite orbit) and the almanac (the satellite orbital and clock in-\nformation). Satellite messages are broadcasted and the reception of messages from four\nof more satellites will allow a receiver to calculate its position. This position calculation is\nbasedontrilateration.Thereceivermeasuresthetimesofarrivalofthesatellitesignals,con-\nvertsthemintodistances(pseudoranges),andthencalculatesitspositionaswellasitsclock\noffsetwithrespecttothesatelliteclocks.\nA GPS signal spoofing attack is a physical-layer attack in which an attacker transmits spe-\nciallycraftedradiosignalsthatareidenticaltoauthenticsatellitesignals.CivilianGPSiseas-\nily vulnerable to signal spoofing attacks. This is due to the lack of any signal authentication\nand the publicly known spreading codes for each satellite, modulation schemes, and data\nstructure. In a signal spoofing attack, the objective of an attacker may be to force a target\nreceiverto(i)computeanincorrectposition,(ii)computeanincorrecttimeor(iii)disruptthe\nreceiver. Due to the low power of the legitimate satellite signal at the receiver, the attacker\u2019s\nspoofingsignalscantriviallyovershadowtheauthenticsignals.Inaspoofingattack,theGPS\nreceiver typically locks (acquires and tracks) onto the stronger, attacker\u2019s signal, thus ignor-\ningthesatellitesignals.\nAnattackercaninfluencethereceiver\u2019spositionandtimeestimateintwoways:(i)bymanip-\nulating the contents of the navigation messages (e.g., the location of satellites, navigation\nmessage transmission time) and\/or (ii) by modifying the arrival time of the navigation mes-\nsages. The attacker can manipulate the receiver time of arrival by temporally shifting the\nnavigation message signals while transmitting the spoofing signals. We can classify spoof-\ningattacksbasedonhowsynchronous(intime)andconsistent(withrespecttothecontents\nof the navigation messages) the spoofing signals are in comparison to the legitimate GPS\nsignalscurrentlybeingreceivedatthereceiver\u2019struelocation.\nNon-Coherent and Modified Message Contents: In this type of attack, the attacker\u2019s signals\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page664 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nFigure 20.3: Seamless takeover attack on GPS. The spoofing aligns its signal with the legit-\nimate signal and slowly increase the transmit power. Once receiver locks on to attacker\u2019s\nsignal,hestartstomanipulateit.\narebothunsynchronisedandcontaindifferentnavigationmessagedataincomparisontothe\nauthentic signals. Attackers who use GPS signal generators to execute the spoofing attack\ntypically fall under this category. An attacker with a little know-how can execute a spoof-\ning attack using these simulators due to their low complexity, portability and ease of use.\nSome advanced GPS signal generators are even capable of recording and replaying signals,\nhowevernotinreal-time.Inotherwords,theattackerusesthesimulatortorecordatonepar-\nticulartimeinagivenlocationandlaterreplaysit.Sincetheyarereplayedatalatertime,the\nattacker\u2019s signals are not coherent and contain different navigation message data than the\nlegitimatesignalscurrentlybeingreceived.\nNon-Coherent but Unmodified Message Contents: In this type of attack, the navigation mes-\nsagecontentsofthetransmittedspoofingsignalsareidenticaltothelegitimateGPSsignals\ncurrentlybeingreceived.However,theattackertemporallyshiftsthespoofingsignalthereby\nmanipulatingthespoofingsignaltimeofarrivalatthetargetreceiver.Forexample,attackers\ncapable of real-time recording and replaying of GPS signals fall under this category as they\nwillhavethesamenavigationcontentsasthatofthelegitimateGPSsignals,howevershifted\nintime.Thelocationortimeoffsetcausedbysuchanattackonthetargetreceiverdepends\non the time delay introduced both by the attacker and due to the propagation time of the\nrelayedsignal.Theattackercanprecomputethesedelaysandsuccessfullyspoofareceiver\ntoadesiredlocation.\nCoherent but Modified Message Contents: The attacker generates spoofing signals that are\nsynchronised to the authentic GPS signals. However, the contents of the navigation mes-\nsages are not the same as that of the currently seen authentic signals. For instance, Phase-\nCoherentSignalSynthesisersarecapableofgeneratingspoofingsignalswiththesamecode\nphaseasthelegitimateGPSsignalthatthetargetreceiveriscurrentlylockedonto.Addition-\nally,theattackermodifiesthecontentsofthenavigationmessageinreal-time(andwithmin-\nimal delay) and replays it to the target receiver. A variety of commercial GPS receivers were\nshowntobevulnerabletothisattackandinsomecases,itevencausedpermanentdamage\ntothereceivers.\nCoherentandUnmodifiedMessageContents:Here,theattackerdoesnotmodifythecontents\nofthenavigationmessageandiscompletelysynchronisedtotheauthenticGPSsignals.Even\nthoughthereceiverlocksontotheattacker\u2019sspoofingsignals(duetothehigherpower),there\nisnochangeinthelocationortimecomputedbythetargetreceiver.Therefore,thisisnotan\nattackinitselfbutisanimportantfirststepinexecutingtheseamlesstakeoverattack.\nThe seamless takeover attack is considered one of the strongest attacks in literature. In a\nmajority of applications, the target receiver is already locked on to the legitimate GPS satel-\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page665 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nlitesignals.ThemainstepsarehighlightedinFigure20.3.Thegoalofanattackeristoforce\nthe receiver to stop tracking the authentic GPS signals and lock onto the spoofing signals\nwithout causing any signal disruption or data loss. This is because the target receiver can\npotentiallydetecttheattackbasedontheabruptlossofGPSsignal.Inaseamlesstakeover\nattack,first,theattackertransmitsspoofingsignalsthataresynchronisedwiththelegitimate\nsatellitesignalsandareatapowerlevellowerthanthereceivedsatellitesignals.Thereceiver\nisstilllockedontothelegitimatesatellitesignalsduetothehigherpowerandhencethereis\nno change in the ships route. The attacker then gradually increases the power of the spoof-\ning signals until the target receiver stops tracking the authentic signal and locks on to the\nspoofing signals. Note that during this takeover, the receiver does not see any loss of lock,\ninotherwords,thetakeoverwasseamless.Eventhoughthetargetreceiverisnowlockedon\ntotheattacker,thereisstillnochangeintherouteasthespoofingsignalsarebothcoherent\nwiththelegitimatesatellitesignalsaswellasthereisnomodificationtothecontentsofthe\nnavigation message itself. Now, the attacker begins to manipulate the spoofing signal such\nthat the receiver computes a false location and begins to alter its course. The attacker can\neitherslowlyintroduceatemporalshiftfromthelegitimatesignalsordirectlymanipulatethe\nnavigationmessagecontentstoslowlydeviatethecourseoftheshiptoahostiledestination.\nIfanattackercontrolsallthesignalsthatarriveatthereceiver\u2019santenna(s)thereceivercan-\nnotdetectspoofing.However,iftheattackisremote,andtheattackercannotfullycontrolthe\nsignalsatthereceiver,anomalydetectiontechniquescanbeusedtodetectspoofing.Inpar-\nticular,AutomaticGainControl(AGC)values,ReceivedSignalStrength(RSS)fromindividual\nsatellites, carrier phase values, estimated noise floor levels, number of visible satellites all\ncanbeusedtodetectspoofing.Particularlyinterestingaretechniquesbasedontrackingand\nanalysisofautocorrelationpeaksthatareusedforthedetectionofGNSSsignals.Distortion,\nthenumberandthebehaviourovertimeofthesepeakscanbeusedtodetecteventhemost\nsophisticatedseamlesstakeoverattacks.\nThe detection of GNSS spoofing can be improved if spoofing signals are simultaneously re-\nceived by several receivers. This can be used for the detection of spoofing as well as for\nspoofer localisation. If the receivers know their mutual distances (e.g., are placed at fixed\ndistances),thespooferneedstopreservethosedistanceswhenperformingthespoofingat-\ntack.Whenasinglespooferbroadcastsitssignals,itwillresultinallreceiversbeingspoofed\nto the same position, therefore enabling detection. This basic detection technique can be\ngeneralisedtoseveralreceivers,allowingeventhedetectionofdistributedspoofers.\nFinally, GNSS spoofing can be made harder through the authentication and hiding of GNSS\nsignals. Although currently civilian GNSS systems do not support authentication, digital sig-\nnatures as well as hash-based signatures such as TESLA can be added to prevent the at-\ntacker from generating GNSS signals. This would, however, not prevent all spoofing attacks\nsince the attacker can still selectively delay navigation messages and therefore modify the\ncomputed position. This attack can be prevented by the use of spreading with delayed key\ndisclosure. Even this approach still does not fully prevent against spoofing by broadband\nreceiversthatareabletorelayfullGNSSfrequencybandbetweenlocations.\nMilitaryGPSsignalsareauthenticated,andtrytoachievelow-probabilityofinterceptaswell\nas jamming resilience via the use of secret spreading codes. This approach prevents some\nof the spoofing attacks, but still fails to fully prevent record-and-relay attacks. In addition,\nthisapproachdoesnotscalewellsincesecretspreadingcodesneedtobedistributedtoall\nintendedreceivers,increasingthelikelihoodoftheirleakageandreducingusability.\nIn conclusion, although newly proposed and deployed countermeasures make it more dif-\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page666 TheCyberSecurityBodyOfKnowledge\nwww.cybok.org\nficult for the attacker to spoof GNS systems like GPS, currently no measure fully prevents\nspoofingunderstrongattackermodels.Thisisanareaofactiveresearch.\nCONCLUSION\nAs we have shown in this knowledge area, the wireless physical layer presents both chal-\nlenges and opportunities. Challenges typically come from the broadcast nature of wireless\ncommunication and from it not being protected against confidentiality and integrity viola-\ntions.Physicallayeristypicallyapplicationagnostic.Opportunitiesstemfromthestochastic\nnatureofthechannelaswellasfromitsrobustnesstofine-grainedmanipulations.Underdif-\nferentattackermodels,physicallayercansupportbothhighlyusableandsecuresolutions.\nCROSS-REFERENCE OF TOPICS VS REFERENCE MATERIAL\nThe table below lists the reference material that serves as the basis for for this chapter and\nexplains how it relates to the different topics. Whenever possible, references are further di-\nvidedintosub-topics.\nKAPhysicalLayerSecurityandTelecommunications |October2019 Page667 "}